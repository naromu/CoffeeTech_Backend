postgresql://coffeetech:Coffeetech.12@localhost:5432/CoffeeTech
Conexión exitosa a la base de datos
Help on module dataBase:

NAME
    dataBase

FUNCTIONS
    get_db_session()
        Proporciona una sesión de base de datos, que se puede utilizar
        en las operaciones CRUD. Asegura que la sesión se cierre
        correctamente después de su uso.

        Yields:
            Session: Una sesión de base de datos.

    reload_env()
        Carga las variables de entorno desde el archivo .env,
        sobrescribiendo las existentes si es necesario.

DATA
    DB_HOST = 'localhost'
    DB_NAME = 'CoffeeTech'
    DB_PASSWORD = 'Coffeetech.12'
    DB_PORT = '5432'
    DB_USER = 'coffeetech'
    SQLALCHEMY_DATABASE_URL = 'postgresql://coffeetech:Coffeetech.12@local...
    SessionLocal = sessionmaker(class_='Session', autocommit=False,...feeT...
    __warningregistry__ = {'version': 0}
    connection = <sqlalchemy.engine.base.Connection object>
    engine = Engine(postgresql://coffeetech:***@localhost:5432/CoffeeTech)
    result = <sqlalchemy.engine.cursor.CursorResult object>

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\database.py



================================================================================
INFO:endpoints.auth:Aplicación iniciada
postgresql://coffeetech:Coffeetech.12@localhost:5432/CoffeeTech
Conexión exitosa a la base de datos
Help on module main:

NAME
    main

FUNCTIONS
    read_root()
        Ruta raíz que retorna un mensaje de bienvenida.

        Returns:
            dict: Un diccionario con un mensaje de bienvenida.

DATA
    app = <fastapi.applications.FastAPI object>
    engine = Engine(postgresql://coffeetech:***@localhost:5432/CoffeeTech)

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\main.py



================================================================================
Help on module backend.Lib.site-packages.argon2._utils in backend.Lib.site-packages.argon2:

NAME
    backend.Lib.site-packages.argon2._utils - # SPDX-License-Identifier: MIT

CLASSES
    builtins.object
        argon2.Parameters
    enum.Enum(builtins.object)
        argon2.Type

    class Parameters(builtins.object)
     |  Parameters(type: 'Type', version: 'int', salt_len: 'int', hash_len: 'int', time_cost: 'int', memory_cost: 'int', parallelism: 'int') -> None
     |
     |  Argon2 hash parameters.
     |
     |  See :doc:`parameters` on how to pick them.
     |
     |  :ivar Type type: Hash type.
     |  :ivar int version: Argon2 version.
     |  :ivar int salt_len: Length of the salt in bytes.
     |  :ivar int hash_len: Length of the hash in bytes.
     |  :ivar int time_cost: Time cost in iterations.
     |  :ivar int memory_cost: Memory cost in kibibytes.
     |  :ivar int parallelism: Number of parallel threads.
     |
     |  .. versionadded:: 18.2.0
     |
     |  Methods defined here:
     |
     |  __eq__(self, other) from Parameters
     |      Return self==value.
     |
     |  __init__(self, type: 'Type', version: 'int', salt_len: 'int', hash_len: 'int', time_cost: 'int', memory_cost: 'int', parallelism: 'int') -> None from Parameters
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  __repr__(self) from Parameters
     |      Return repr(self).
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  hash_len
     |
     |  memory_cost
     |
     |  parallelism
     |
     |  salt_len
     |
     |  time_cost
     |
     |  type
     |
     |  version
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  __annotations__ = {'hash_len': 'int', 'memory_cost': 'int', 'paralleli...
     |
     |  __dataclass_fields__ = {'hash_len': Field(name='hash_len',type='int',d...
     |
     |  __dataclass_params__ = _DataclassParams(init=True,repr=True,eq=True,or...
     |
     |  __hash__ = None
     |
     |  __match_args__ = ('type', 'version', 'salt_len', 'hash_len', 'time_cos...

    class Type(enum.Enum)
     |  Type(*values)
     |
     |  Enum of Argon2 variants.
     |
     |  Please see :doc:`parameters` on how to pick one.
     |
     |  Method resolution order:
     |      Type
     |      enum.Enum
     |      builtins.object
     |
     |  Data and other attributes defined here:
     |
     |  D = <Type.D: 0>
     |
     |  I = <Type.I: 1>
     |
     |  ID = <Type.ID: 2>
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from enum.Enum:
     |
     |  name
     |      The name of the Enum member.
     |
     |  value
     |      The value of the Enum member.
     |
     |  ----------------------------------------------------------------------
     |  Static methods inherited from enum.EnumType:
     |
     |  __contains__(value)
     |      Return True if `value` is in `cls`.
     |
     |      `value` is in `cls` if:
     |      1) `value` is a member of `cls`, or
     |      2) `value` is the value of one of the `cls`'s members.
     |
     |  __getitem__(name)
     |      Return the member matching `name`.
     |
     |  __iter__()
     |      Return members in definition order.
     |
     |  __len__()
     |      Return the number of members (no aliases)
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from enum.EnumType:
     |
     |  __members__
     |      Returns a mapping of member name->value.
     |
     |      This mapping lists all enum members, including aliases. Note that this
     |      is a read-only view of the internal mapping.

FUNCTIONS
    extract_parameters(hash: 'str') -> 'Parameters'
        Extract parameters from an encoded *hash*.

        :param str params: An encoded Argon2 hash string.

        :rtype: Parameters

        .. versionadded:: 18.2.0

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\backend\lib\site-packages\argon2\_utils.py



================================================================================
Help on module backend.Lib.site-packages.asyncpg.connect_utils in backend.Lib.site-packages.asyncpg:

NAME
    backend.Lib.site-packages.asyncpg.connect_utils

DESCRIPTION
    # Copyright (C) 2016-present the asyncpg authors and contributors
    # <see AUTHORS file>
    #
    # This module is part of asyncpg and is released under
    # the Apache 2.0 License: http://www.apache.org/licenses/LICENSE-2.0

CLASSES
    asyncio.protocols.Protocol(asyncio.protocols.BaseProtocol)
        TLSUpgradeProto
    builtins.str(builtins.object)
        SessionAttribute(builtins.str, enum.Enum)
    enum.Enum(builtins.object)
        SessionAttribute(builtins.str, enum.Enum)
    enum.IntEnum(builtins.int, enum.ReprEnum)
        SSLMode

    class SSLMode(enum.IntEnum)
     |  SSLMode(*values)
     |
     |  Method resolution order:
     |      SSLMode
     |      enum.IntEnum
     |      builtins.int
     |      enum.ReprEnum
     |      enum.Enum
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __format__(self, format_spec, /) from builtins.int
     |      Convert to a string according to format_spec.
     |
     |  __new__(cls, value) from enum.Enum
     |      Create and return a new object.  See help(type) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  allow = <SSLMode.allow: 1>
     |
     |  disable = <SSLMode.disable: 0>
     |
     |  prefer = <SSLMode.prefer: 2>
     |
     |  require = <SSLMode.require: 3>
     |
     |  verify_ca = <SSLMode.verify_ca: 4>
     |
     |  verify_full = <SSLMode.verify_full: 5>
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from enum.IntEnum:
     |
     |  __repr__(self) from enum.Enum
     |      Return repr(self).
     |
     |  __str__ = __repr__(self, /) from builtins.int
     |      Return repr(self).
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.int:
     |
     |  __abs__(self, /)
     |      abs(self)
     |
     |  __add__(self, value, /)
     |      Return self+value.
     |
     |  __and__(self, value, /)
     |      Return self&value.
     |
     |  __bool__(self, /)
     |      True if self else False
     |
     |  __ceil__(...)
     |      Ceiling of an Integral returns itself.
     |
     |  __divmod__(self, value, /)
     |      Return divmod(self, value).
     |
     |  __eq__(self, value, /)
     |      Return self==value.
     |
     |  __float__(self, /)
     |      float(self)
     |
     |  __floor__(...)
     |      Flooring an Integral returns itself.
     |
     |  __floordiv__(self, value, /)
     |      Return self//value.
     |
     |  __ge__(self, value, /)
     |      Return self>=value.
     |
     |  __getattribute__(self, name, /)
     |      Return getattr(self, name).
     |
     |  __getnewargs__(self, /)
     |
     |  __gt__(self, value, /)
     |      Return self>value.
     |
     |  __hash__(self, /)
     |      Return hash(self).
     |
     |  __index__(self, /)
     |      Return self converted to an integer, if self is suitable for use as an index into a list.
     |
     |  __int__(self, /)
     |      int(self)
     |
     |  __invert__(self, /)
     |      ~self
     |
     |  __le__(self, value, /)
     |      Return self<=value.
     |
     |  __lshift__(self, value, /)
     |      Return self<<value.
     |
     |  __lt__(self, value, /)
     |      Return self<value.
     |
     |  __mod__(self, value, /)
     |      Return self%value.
     |
     |  __mul__(self, value, /)
     |      Return self*value.
     |
     |  __ne__(self, value, /)
     |      Return self!=value.
     |
     |  __neg__(self, /)
     |      -self
     |
     |  __or__(self, value, /)
     |      Return self|value.
     |
     |  __pos__(self, /)
     |      +self
     |
     |  __pow__(self, value, mod=None, /)
     |      Return pow(self, value, mod).
     |
     |  __radd__(self, value, /)
     |      Return value+self.
     |
     |  __rand__(self, value, /)
     |      Return value&self.
     |
     |  __rdivmod__(self, value, /)
     |      Return divmod(value, self).
     |
     |  __rfloordiv__(self, value, /)
     |      Return value//self.
     |
     |  __rlshift__(self, value, /)
     |      Return value<<self.
     |
     |  __rmod__(self, value, /)
     |      Return value%self.
     |
     |  __rmul__(self, value, /)
     |      Return value*self.
     |
     |  __ror__(self, value, /)
     |      Return value|self.
     |
     |  __round__(...)
     |      Rounding an Integral returns itself.
     |
     |      Rounding with an ndigits argument also returns an integer.
     |
     |  __rpow__(self, value, mod=None, /)
     |      Return pow(value, self, mod).
     |
     |  __rrshift__(self, value, /)
     |      Return value>>self.
     |
     |  __rshift__(self, value, /)
     |      Return self>>value.
     |
     |  __rsub__(self, value, /)
     |      Return value-self.
     |
     |  __rtruediv__(self, value, /)
     |      Return value/self.
     |
     |  __rxor__(self, value, /)
     |      Return value^self.
     |
     |  __sizeof__(self, /)
     |      Returns size in memory, in bytes.
     |
     |  __sub__(self, value, /)
     |      Return self-value.
     |
     |  __truediv__(self, value, /)
     |      Return self/value.
     |
     |  __trunc__(...)
     |      Truncating an Integral returns itself.
     |
     |  __xor__(self, value, /)
     |      Return self^value.
     |
     |  as_integer_ratio(self, /)
     |      Return a pair of integers, whose ratio is equal to the original int.
     |
     |      The ratio is in lowest terms and has a positive denominator.
     |
     |      >>> (10).as_integer_ratio()
     |      (10, 1)
     |      >>> (-10).as_integer_ratio()
     |      (-10, 1)
     |      >>> (0).as_integer_ratio()
     |      (0, 1)
     |
     |  bit_count(self, /)
     |      Number of ones in the binary representation of the absolute value of self.
     |
     |      Also known as the population count.
     |
     |      >>> bin(13)
     |      '0b1101'
     |      >>> (13).bit_count()
     |      3
     |
     |  bit_length(self, /)
     |      Number of bits necessary to represent self in binary.
     |
     |      >>> bin(37)
     |      '0b100101'
     |      >>> (37).bit_length()
     |      6
     |
     |  conjugate(...)
     |      Returns self, the complex conjugate of any int.
     |
     |  is_integer(self, /)
     |      Returns True. Exists for duck type compatibility with float.is_integer.
     |
     |  to_bytes(self, /, length=1, byteorder='big', *, signed=False)
     |      Return an array of bytes representing an integer.
     |
     |      length
     |        Length of bytes object to use.  An OverflowError is raised if the
     |        integer is not representable with the given number of bytes.  Default
     |        is length 1.
     |      byteorder
     |        The byte order used to represent the integer.  If byteorder is 'big',
     |        the most significant byte is at the beginning of the byte array.  If
     |        byteorder is 'little', the most significant byte is at the end of the
     |        byte array.  To request the native byte order of the host system, use
     |        `sys.byteorder' as the byte order value.  Default is to use 'big'.
     |      signed
     |        Determines whether two's complement is used to represent the integer.
     |        If signed is False and a negative integer is given, an OverflowError
     |        is raised.
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from builtins.int:
     |
     |  from_bytes(bytes, byteorder='big', *, signed=False)
     |      Return the integer represented by the given array of bytes.
     |
     |      bytes
     |        Holds the array of bytes to convert.  The argument must either
     |        support the buffer protocol or be an iterable object producing bytes.
     |        Bytes and bytearray are examples of built-in objects that support the
     |        buffer protocol.
     |      byteorder
     |        The byte order used to represent the integer.  If byteorder is 'big',
     |        the most significant byte is at the beginning of the byte array.  If
     |        byteorder is 'little', the most significant byte is at the end of the
     |        byte array.  To request the native byte order of the host system, use
     |        `sys.byteorder' as the byte order value.  Default is to use 'big'.
     |      signed
     |        Indicates whether two's complement is used to represent the integer.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from builtins.int:
     |
     |  denominator
     |      the denominator of a rational number in lowest terms
     |
     |  imag
     |      the imaginary part of a complex number
     |
     |  numerator
     |      the numerator of a rational number in lowest terms
     |
     |  real
     |      the real part of a complex number
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from enum.Enum:
     |
     |  __dir__(self)
     |      Returns public methods and other interesting attributes.
     |
     |  __init__(self, *args, **kwds)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  __reduce_ex__(self, proto)
     |      Helper for pickle.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from enum.Enum:
     |
     |  name
     |      The name of the Enum member.
     |
     |  value
     |      The value of the Enum member.
     |
     |  ----------------------------------------------------------------------
     |  Static methods inherited from enum.EnumType:
     |
     |  __contains__(value)
     |      Return True if `value` is in `cls`.
     |
     |      `value` is in `cls` if:
     |      1) `value` is a member of `cls`, or
     |      2) `value` is the value of one of the `cls`'s members.
     |
     |  __getitem__(name)
     |      Return the member matching `name`.
     |
     |  __iter__()
     |      Return members in definition order.
     |
     |  __len__()
     |      Return the number of members (no aliases)
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from enum.EnumType:
     |
     |  __members__
     |      Returns a mapping of member name->value.
     |
     |      This mapping lists all enum members, including aliases. Note that this
     |      is a read-only view of the internal mapping.

    class SessionAttribute(builtins.str, enum.Enum)
     |  SessionAttribute(*values)
     |
     |  Method resolution order:
     |      SessionAttribute
     |      builtins.str
     |      enum.Enum
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __format__(self, format_spec) from enum.Enum
     |      Default object formatter.
     |
     |      Return str(self) if format_spec is empty. Raise TypeError otherwise.
     |
     |  __new__(cls, value) from enum.Enum
     |      Create and return a new object.  See help(type) for accurate signature.
     |
     |  __repr__(self) from enum.Enum
     |      Return repr(self).
     |
     |  __str__(self) from enum.Enum
     |      Return str(self).
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  any = <SessionAttribute.any: 'any'>
     |
     |  prefer_standby = <SessionAttribute.prefer_standby: 'prefer-standby'>
     |
     |  primary = <SessionAttribute.primary: 'primary'>
     |
     |  read_only = <SessionAttribute.read_only: 'read-only'>
     |
     |  read_write = <SessionAttribute.read_write: 'read-write'>
     |
     |  standby = <SessionAttribute.standby: 'standby'>
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.str:
     |
     |  __add__(self, value, /)
     |      Return self+value.
     |
     |  __contains__(self, key, /)
     |      Return bool(key in self).
     |
     |  __eq__(self, value, /)
     |      Return self==value.
     |
     |  __ge__(self, value, /)
     |      Return self>=value.
     |
     |  __getattribute__(self, name, /)
     |      Return getattr(self, name).
     |
     |  __getitem__(self, key, /)
     |      Return self[key].
     |
     |  __getnewargs__(...)
     |
     |  __gt__(self, value, /)
     |      Return self>value.
     |
     |  __hash__(self, /)
     |      Return hash(self).
     |
     |  __iter__(self, /)
     |      Implement iter(self).
     |
     |  __le__(self, value, /)
     |      Return self<=value.
     |
     |  __len__(self, /)
     |      Return len(self).
     |
     |  __lt__(self, value, /)
     |      Return self<value.
     |
     |  __mod__(self, value, /)
     |      Return self%value.
     |
     |  __mul__(self, value, /)
     |      Return self*value.
     |
     |  __ne__(self, value, /)
     |      Return self!=value.
     |
     |  __rmod__(self, value, /)
     |      Return value%self.
     |
     |  __rmul__(self, value, /)
     |      Return value*self.
     |
     |  __sizeof__(self, /)
     |      Return the size of the string in memory, in bytes.
     |
     |  capitalize(self, /)
     |      Return a capitalized version of the string.
     |
     |      More specifically, make the first character have upper case and the rest lower
     |      case.
     |
     |  casefold(self, /)
     |      Return a version of the string suitable for caseless comparisons.
     |
     |  center(self, width, fillchar=' ', /)
     |      Return a centered string of length width.
     |
     |      Padding is done using the specified fill character (default is a space).
     |
     |  count(...)
     |      S.count(sub[, start[, end]]) -> int
     |
     |      Return the number of non-overlapping occurrences of substring sub in
     |      string S[start:end].  Optional arguments start and end are
     |      interpreted as in slice notation.
     |
     |  encode(self, /, encoding='utf-8', errors='strict')
     |      Encode the string using the codec registered for encoding.
     |
     |      encoding
     |        The encoding in which to encode the string.
     |      errors
     |        The error handling scheme to use for encoding errors.
     |        The default is 'strict' meaning that encoding errors raise a
     |        UnicodeEncodeError.  Other possible values are 'ignore', 'replace' and
     |        'xmlcharrefreplace' as well as any other name registered with
     |        codecs.register_error that can handle UnicodeEncodeErrors.
     |
     |  endswith(...)
     |      S.endswith(suffix[, start[, end]]) -> bool
     |
     |      Return True if S ends with the specified suffix, False otherwise.
     |      With optional start, test S beginning at that position.
     |      With optional end, stop comparing S at that position.
     |      suffix can also be a tuple of strings to try.
     |
     |  expandtabs(self, /, tabsize=8)
     |      Return a copy where all tab characters are expanded using spaces.
     |
     |      If tabsize is not given, a tab size of 8 characters is assumed.
     |
     |  find(...)
     |      S.find(sub[, start[, end]]) -> int
     |
     |      Return the lowest index in S where substring sub is found,
     |      such that sub is contained within S[start:end].  Optional
     |      arguments start and end are interpreted as in slice notation.
     |
     |      Return -1 on failure.
     |
     |  format(...)
     |      S.format(*args, **kwargs) -> str
     |
     |      Return a formatted version of S, using substitutions from args and kwargs.
     |      The substitutions are identified by braces ('{' and '}').
     |
     |  format_map(...)
     |      S.format_map(mapping) -> str
     |
     |      Return a formatted version of S, using substitutions from mapping.
     |      The substitutions are identified by braces ('{' and '}').
     |
     |  index(...)
     |      S.index(sub[, start[, end]]) -> int
     |
     |      Return the lowest index in S where substring sub is found,
     |      such that sub is contained within S[start:end].  Optional
     |      arguments start and end are interpreted as in slice notation.
     |
     |      Raises ValueError when the substring is not found.
     |
     |  isalnum(self, /)
     |      Return True if the string is an alpha-numeric string, False otherwise.
     |
     |      A string is alpha-numeric if all characters in the string are alpha-numeric and
     |      there is at least one character in the string.
     |
     |  isalpha(self, /)
     |      Return True if the string is an alphabetic string, False otherwise.
     |
     |      A string is alphabetic if all characters in the string are alphabetic and there
     |      is at least one character in the string.
     |
     |  isascii(self, /)
     |      Return True if all characters in the string are ASCII, False otherwise.
     |
     |      ASCII characters have code points in the range U+0000-U+007F.
     |      Empty string is ASCII too.
     |
     |  isdecimal(self, /)
     |      Return True if the string is a decimal string, False otherwise.
     |
     |      A string is a decimal string if all characters in the string are decimal and
     |      there is at least one character in the string.
     |
     |  isdigit(self, /)
     |      Return True if the string is a digit string, False otherwise.
     |
     |      A string is a digit string if all characters in the string are digits and there
     |      is at least one character in the string.
     |
     |  isidentifier(self, /)
     |      Return True if the string is a valid Python identifier, False otherwise.
     |
     |      Call keyword.iskeyword(s) to test whether string s is a reserved identifier,
     |      such as "def" or "class".
     |
     |  islower(self, /)
     |      Return True if the string is a lowercase string, False otherwise.
     |
     |      A string is lowercase if all cased characters in the string are lowercase and
     |      there is at least one cased character in the string.
     |
     |  isnumeric(self, /)
     |      Return True if the string is a numeric string, False otherwise.
     |
     |      A string is numeric if all characters in the string are numeric and there is at
     |      least one character in the string.
     |
     |  isprintable(self, /)
     |      Return True if the string is printable, False otherwise.
     |
     |      A string is printable if all of its characters are considered printable in
     |      repr() or if it is empty.
     |
     |  isspace(self, /)
     |      Return True if the string is a whitespace string, False otherwise.
     |
     |      A string is whitespace if all characters in the string are whitespace and there
     |      is at least one character in the string.
     |
     |  istitle(self, /)
     |      Return True if the string is a title-cased string, False otherwise.
     |
     |      In a title-cased string, upper- and title-case characters may only
     |      follow uncased characters and lowercase characters only cased ones.
     |
     |  isupper(self, /)
     |      Return True if the string is an uppercase string, False otherwise.
     |
     |      A string is uppercase if all cased characters in the string are uppercase and
     |      there is at least one cased character in the string.
     |
     |  join(self, iterable, /)
     |      Concatenate any number of strings.
     |
     |      The string whose method is called is inserted in between each given string.
     |      The result is returned as a new string.
     |
     |      Example: '.'.join(['ab', 'pq', 'rs']) -> 'ab.pq.rs'
     |
     |  ljust(self, width, fillchar=' ', /)
     |      Return a left-justified string of length width.
     |
     |      Padding is done using the specified fill character (default is a space).
     |
     |  lower(self, /)
     |      Return a copy of the string converted to lowercase.
     |
     |  lstrip(self, chars=None, /)
     |      Return a copy of the string with leading whitespace removed.
     |
     |      If chars is given and not None, remove characters in chars instead.
     |
     |  partition(self, sep, /)
     |      Partition the string into three parts using the given separator.
     |
     |      This will search for the separator in the string.  If the separator is found,
     |      returns a 3-tuple containing the part before the separator, the separator
     |      itself, and the part after it.
     |
     |      If the separator is not found, returns a 3-tuple containing the original string
     |      and two empty strings.
     |
     |  removeprefix(self, prefix, /)
     |      Return a str with the given prefix string removed if present.
     |
     |      If the string starts with the prefix string, return string[len(prefix):].
     |      Otherwise, return a copy of the original string.
     |
     |  removesuffix(self, suffix, /)
     |      Return a str with the given suffix string removed if present.
     |
     |      If the string ends with the suffix string and that suffix is not empty,
     |      return string[:-len(suffix)]. Otherwise, return a copy of the original
     |      string.
     |
     |  replace(self, old, new, count=-1, /)
     |      Return a copy with all occurrences of substring old replaced by new.
     |
     |        count
     |          Maximum number of occurrences to replace.
     |          -1 (the default value) means replace all occurrences.
     |
     |      If the optional argument count is given, only the first count occurrences are
     |      replaced.
     |
     |  rfind(...)
     |      S.rfind(sub[, start[, end]]) -> int
     |
     |      Return the highest index in S where substring sub is found,
     |      such that sub is contained within S[start:end].  Optional
     |      arguments start and end are interpreted as in slice notation.
     |
     |      Return -1 on failure.
     |
     |  rindex(...)
     |      S.rindex(sub[, start[, end]]) -> int
     |
     |      Return the highest index in S where substring sub is found,
     |      such that sub is contained within S[start:end].  Optional
     |      arguments start and end are interpreted as in slice notation.
     |
     |      Raises ValueError when the substring is not found.
     |
     |  rjust(self, width, fillchar=' ', /)
     |      Return a right-justified string of length width.
     |
     |      Padding is done using the specified fill character (default is a space).
     |
     |  rpartition(self, sep, /)
     |      Partition the string into three parts using the given separator.
     |
     |      This will search for the separator in the string, starting at the end. If
     |      the separator is found, returns a 3-tuple containing the part before the
     |      separator, the separator itself, and the part after it.
     |
     |      If the separator is not found, returns a 3-tuple containing two empty strings
     |      and the original string.
     |
     |  rsplit(self, /, sep=None, maxsplit=-1)
     |      Return a list of the substrings in the string, using sep as the separator string.
     |
     |        sep
     |          The separator used to split the string.
     |
     |          When set to None (the default value), will split on any whitespace
     |          character (including \n \r \t \f and spaces) and will discard
     |          empty strings from the result.
     |        maxsplit
     |          Maximum number of splits.
     |          -1 (the default value) means no limit.
     |
     |      Splitting starts at the end of the string and works to the front.
     |
     |  rstrip(self, chars=None, /)
     |      Return a copy of the string with trailing whitespace removed.
     |
     |      If chars is given and not None, remove characters in chars instead.
     |
     |  split(self, /, sep=None, maxsplit=-1)
     |      Return a list of the substrings in the string, using sep as the separator string.
     |
     |        sep
     |          The separator used to split the string.
     |
     |          When set to None (the default value), will split on any whitespace
     |          character (including \n \r \t \f and spaces) and will discard
     |          empty strings from the result.
     |        maxsplit
     |          Maximum number of splits.
     |          -1 (the default value) means no limit.
     |
     |      Splitting starts at the front of the string and works to the end.
     |
     |      Note, str.split() is mainly useful for data that has been intentionally
     |      delimited.  With natural text that includes punctuation, consider using
     |      the regular expression module.
     |
     |  splitlines(self, /, keepends=False)
     |      Return a list of the lines in the string, breaking at line boundaries.
     |
     |      Line breaks are not included in the resulting list unless keepends is given and
     |      true.
     |
     |  startswith(...)
     |      S.startswith(prefix[, start[, end]]) -> bool
     |
     |      Return True if S starts with the specified prefix, False otherwise.
     |      With optional start, test S beginning at that position.
     |      With optional end, stop comparing S at that position.
     |      prefix can also be a tuple of strings to try.
     |
     |  strip(self, chars=None, /)
     |      Return a copy of the string with leading and trailing whitespace removed.
     |
     |      If chars is given and not None, remove characters in chars instead.
     |
     |  swapcase(self, /)
     |      Convert uppercase characters to lowercase and lowercase characters to uppercase.
     |
     |  title(self, /)
     |      Return a version of the string where each word is titlecased.
     |
     |      More specifically, words start with uppercased characters and all remaining
     |      cased characters have lower case.
     |
     |  translate(self, table, /)
     |      Replace each character in the string using the given translation table.
     |
     |        table
     |          Translation table, which must be a mapping of Unicode ordinals to
     |          Unicode ordinals, strings, or None.
     |
     |      The table must implement lookup/indexing via __getitem__, for instance a
     |      dictionary or list.  If this operation raises LookupError, the character is
     |      left untouched.  Characters mapped to None are deleted.
     |
     |  upper(self, /)
     |      Return a copy of the string converted to uppercase.
     |
     |  zfill(self, width, /)
     |      Pad a numeric string with zeros on the left, to fill a field of the given width.
     |
     |      The string is never truncated.
     |
     |  ----------------------------------------------------------------------
     |  Static methods inherited from builtins.str:
     |
     |  maketrans(...)
     |      Return a translation table usable for str.translate().
     |
     |      If there is only one argument, it must be a dictionary mapping Unicode
     |      ordinals (integers) or characters to Unicode ordinals, strings or None.
     |      Character keys will be then converted to ordinals.
     |      If there are two arguments, they must be strings of equal length, and
     |      in the resulting dictionary, each character in x will be mapped to the
     |      character at the same position in y. If there is a third argument, it
     |      must be a string, whose characters will be mapped to None in the result.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from enum.Enum:
     |
     |  __dir__(self)
     |      Returns public methods and other interesting attributes.
     |
     |  __init__(self, *args, **kwds)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  __reduce_ex__(self, proto)
     |      Helper for pickle.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from enum.Enum:
     |
     |  name
     |      The name of the Enum member.
     |
     |  value
     |      The value of the Enum member.
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from enum.EnumType:
     |
     |  __members__
     |      Returns a mapping of member name->value.
     |
     |      This mapping lists all enum members, including aliases. Note that this
     |      is a read-only view of the internal mapping.

    class TLSUpgradeProto(asyncio.protocols.Protocol)
     |  TLSUpgradeProto(loop, host, port, ssl_context, ssl_is_advisory)
     |
     |  Method resolution order:
     |      TLSUpgradeProto
     |      asyncio.protocols.Protocol
     |      asyncio.protocols.BaseProtocol
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, loop, host, port, ssl_context, ssl_is_advisory)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  connection_lost(self, exc)
     |      Called when the connection is lost or closed.
     |
     |      The argument is an exception object or None (the latter
     |      meaning a regular EOF is received or the connection was
     |      aborted or closed).
     |
     |  data_received(self, data)
     |      Called when some data is received.
     |
     |      The argument is a bytes object.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from asyncio.protocols.Protocol:
     |
     |  eof_received(self)
     |      Called when the other end calls write_eof() or equivalent.
     |
     |      If this returns a false value (including None), the transport
     |      will close itself.  If it returns a true value, closing the
     |      transport is up to the protocol.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from asyncio.protocols.BaseProtocol:
     |
     |  connection_made(self, transport)
     |      Called when a connection is made.
     |
     |      The argument is the transport representing the pipe connection.
     |      To receive data, wait for data_received() calls.
     |      When the connection is closed, connection_lost() is called.
     |
     |  pause_writing(self)
     |      Called when the transport's buffer goes over the high-water mark.
     |
     |      Pause and resume calls are paired -- pause_writing() is called
     |      once when the buffer goes strictly over the high-water mark
     |      (even if subsequent writes increases the buffer size even
     |      more), and eventually resume_writing() is called once when the
     |      buffer size reaches the low-water mark.
     |
     |      Note that if the buffer size equals the high-water mark,
     |      pause_writing() is not called -- it must go strictly over.
     |      Conversely, resume_writing() is called when the buffer size is
     |      equal or lower than the low-water mark.  These end conditions
     |      are important to ensure that things go as expected when either
     |      mark is zero.
     |
     |      NOTE: This is the only Protocol callback that is not called
     |      through EventLoop.call_soon() -- if it were, it would have no
     |      effect when it's most needed (when the app keeps writing
     |      without yielding until pause_writing() is called).
     |
     |  resume_writing(self)
     |      Called when the transport's buffer drains below the low-water mark.
     |
     |      See pause_writing() for details.

DATA
    PGPASSFILE = 'pgpass.conf'
    target_attrs_check = {<SessionAttribute.any: 'any'>: <function _accept...

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\backend\lib\site-packages\asyncpg\connect_utils.py



================================================================================
Help on module backend.Lib.site-packages.asyncpg.utils in backend.Lib.site-packages.asyncpg:

NAME
    backend.Lib.site-packages.asyncpg.utils

DESCRIPTION
    # Copyright (C) 2016-present the ayncpg authors and contributors
    # <see AUTHORS file>
    #
    # This module is part of asyncpg and is released under
    # the Apache 2.0 License: http://www.apache.org/licenses/LICENSE-2.0

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\backend\lib\site-packages\asyncpg\utils.py



================================================================================
Help on module backend.Lib.site-packages.charset_normalizer.models in backend.Lib.site-packages.charset_normalizer:

NAME
    backend.Lib.site-packages.charset_normalizer.models

CLASSES
    builtins.object
        CharsetMatch
        CharsetMatches
        CliDetectionResult

    class CharsetMatch(builtins.object)
     |  CharsetMatch(payload: bytes, guessed_encoding: str, mean_mess_ratio: float, has_sig_or_bom: bool, languages: 'CoherenceMatches', decoded_payload: Optional[str] = None)
     |
     |  Methods defined here:
     |
     |  __eq__(self, other: object) -> bool
     |      Return self==value.
     |
     |  __init__(self, payload: bytes, guessed_encoding: str, mean_mess_ratio: float, has_sig_or_bom: bool, languages: 'CoherenceMatches', decoded_payload: Optional[str] = None)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  __lt__(self, other: object) -> bool
     |      Implemented to make sorted available upon CharsetMatches items.
     |
     |  __repr__(self) -> str
     |      Return repr(self).
     |
     |  __str__(self) -> str
     |      Return str(self).
     |
     |  add_submatch(self, other: 'CharsetMatch') -> None
     |
     |  output(self, encoding: str = 'utf_8') -> bytes
     |      Method to get re-encoded bytes payload using given target encoding. Default to UTF-8.
     |      Any errors will be simply ignored by the encoder NOT replaced.
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties defined here:
     |
     |  alphabets
     |
     |  bom
     |
     |  byte_order_mark
     |
     |  chaos
     |
     |  coherence
     |
     |  could_be_from_charset
     |      The complete list of encoding that output the exact SAME str result and therefore could be the originating
     |      encoding.
     |      This list does include the encoding available in property 'encoding'.
     |
     |  encoding
     |
     |  encoding_aliases
     |      Encoding name are known by many name, using this could help when searching for IBM855 when it's listed as CP855.
     |
     |  fingerprint
     |      Retrieve the unique SHA256 computed using the transformed (re-encoded) payload. Not the original one.
     |
     |  has_submatch
     |
     |  language
     |      Most probable language found in decoded sequence. If none were detected or inferred, the property will return
     |      "Unknown".
     |
     |  languages
     |      Return the complete list of possible languages found in decoded sequence.
     |      Usually not really useful. Returned list may be empty even if 'language' property return something != 'Unknown'.
     |
     |  multi_byte_usage
     |
     |  percent_chaos
     |
     |  percent_coherence
     |
     |  raw
     |      Original untouched bytes.
     |
     |  submatch
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  __hash__ = None

    class CharsetMatches(builtins.object)
     |  CharsetMatches(results: Optional[List[backend.Lib.site-packages.charset_normalizer.models.CharsetMatch]] = None)
     |
     |  Container with every CharsetMatch items ordered by default from most probable to the less one.
     |  Act like a list(iterable) but does not implements all related methods.
     |
     |  Methods defined here:
     |
     |  __bool__(self) -> bool
     |
     |  __getitem__(self, item: Union[int, str]) -> backend.Lib.site-packages.charset_normalizer.models.CharsetMatch
     |      Retrieve a single item either by its position or encoding name (alias may be used here).
     |      Raise KeyError upon invalid index or encoding not present in results.
     |
     |  __init__(self, results: Optional[List[backend.Lib.site-packages.charset_normalizer.models.CharsetMatch]] = None)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  __iter__(self) -> Iterator[backend.Lib.site-packages.charset_normalizer.models.CharsetMatch]
     |
     |  __len__(self) -> int
     |
     |  append(self, item: backend.Lib.site-packages.charset_normalizer.models.CharsetMatch) -> None
     |      Insert a single match. Will be inserted accordingly to preserve sort.
     |      Can be inserted as a submatch.
     |
     |  best(self) -> Optional[ForwardRef('CharsetMatch')]
     |      Simply return the first match. Strict equivalent to matches[0].
     |
     |  first(self) -> Optional[ForwardRef('CharsetMatch')]
     |      Redundant method, call the method best(). Kept for BC reasons.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

    class CliDetectionResult(builtins.object)
     |  CliDetectionResult(path: str, encoding: Optional[str], encoding_aliases: List[str], alternative_encodings: List[str], language: str, alphabets: List[str], has_sig_or_bom: bool, chaos: float, coherence: float, unicode_path: Optional[str], is_preferred: bool)
     |
     |  Methods defined here:
     |
     |  __init__(self, path: str, encoding: Optional[str], encoding_aliases: List[str], alternative_encodings: List[str], language: str, alphabets: List[str], has_sig_or_bom: bool, chaos: float, coherence: float, unicode_path: Optional[str], is_preferred: bool)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  to_json(self) -> str
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties defined here:
     |
     |  __dict__
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __weakref__
     |      list of weak references to the object

FUNCTIONS
    sha256 = openssl_sha256(string=b'', *, usedforsecurity=True)
        Returns a sha256 hash object; optionally initialized with a string

DATA
    CoherenceMatch = typing.Tuple[str, float]
    CoherenceMatches = typing.List[typing.Tuple[str, float]]
    Dict = typing.Dict
        A generic version of dict.

    Iterator = typing.Iterator
        A generic version of collections.abc.Iterator.

    List = typing.List
        A generic version of list.

    Optional = typing.Optional
        Optional[X] is equivalent to Union[X, None].

    TOO_BIG_SEQUENCE = 10000000
    Tuple = typing.Tuple
        Deprecated alias to builtins.tuple.

        Tuple[X, Y] is the cross-product type of X and Y.

        Example: Tuple[T1, T2] is a tuple of two elements corresponding
        to type variables T1 and T2.  Tuple[int, float, str] is a tuple
        of an int, a float and a string.

        To specify a variable-length tuple of homogeneous type, use Tuple[T, ...].

    Union = typing.Union
        Union type; Union[X, Y] means either X or Y.

        On Python 3.10 and higher, the | operator
        can also be used to denote unions;
        X | Y means the same thing to the type checker as Union[X, Y].

        To define a union, use e.g. Union[int, str]. Details:
        - The arguments must be types and there must be at least one.
        - None as an argument is a special case and is replaced by
          type(None).
        - Unions of unions are flattened, e.g.::

            assert Union[Union[int, str], float] == Union[int, str, float]

        - Unions of a single argument vanish, e.g.::

            assert Union[int] == int  # The constructor actually returns int

        - Redundant arguments are skipped, e.g.::

            assert Union[int, str, int] == Union[int, str]

        - When comparing unions, the argument order is ignored, e.g.::

            assert Union[int, str] == Union[str, int]

        - You cannot subclass or instantiate a union.
        - You can use Optional[X] as a shorthand for Union[X, None].

    aliases = {'037': 'cp037', '1026': 'cp1026', '1125': 'cp1125', '1140':...

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\backend\lib\site-packages\charset_normalizer\models.py



================================================================================
Help on module backend.Lib.site-packages.charset_normalizer.utils in backend.Lib.site-packages.charset_normalizer:

NAME
    backend.Lib.site-packages.charset_normalizer.utils

FUNCTIONS
    any_specified_encoding(sequence: bytes, search_zone: int = 8192) -> Optional[str]
        Extract using ASCII-only decoder any specified encoding in the first n-bytes.

    cp_similarity(iana_name_a: str, iana_name_b: str) -> float

    cut_sequence_chunks(sequences: bytes, encoding_iana: str, offsets: range, chunk_size: int, bom_or_sig_available: bool, strip_sig_or_bom: bool, sig_payload: bytes, is_multi_byte_decoder: bool, decoded_payload: Optional[str] = None) -> Generator[str, NoneType, NoneType]

    iana_name(cp_name: str, strict: bool = True) -> str

    identify_sig_or_bom(sequence: bytes) -> Tuple[Optional[str], bytes]
        Identify and extract SIG/BOM in given sequence.

    is_accentuated(character: str) -> bool

    is_arabic(character: str) -> bool

    is_arabic_isolated_form(character: str) -> bool

    is_case_variable(character: str) -> bool

    is_cjk(character: str) -> bool

    is_cp_similar(iana_name_a: str, iana_name_b: str) -> bool
        Determine if two code page are at least 80% similar. IANA_SUPPORTED_SIMILAR dict was generated using
        the function cp_similarity.

    is_emoticon(character: str) -> bool

    is_hangul(character: str) -> bool

    is_hiragana(character: str) -> bool

    is_katakana(character: str) -> bool

    is_latin(character: str) -> bool

    is_multi_byte_encoding(name: str) -> bool
        Verify is a specific encoding is a multi byte one based on it IANA name

    is_punctuation(character: str) -> bool

    is_separator(character: str) -> bool

    is_symbol(character: str) -> bool

    is_thai(character: str) -> bool

    is_unicode_range_secondary(range_name: str) -> bool

    is_unprintable(character: str) -> bool

    range_scan(decoded_sequence: str) -> List[str]

    remove_accent(character: str) -> str

    set_logging_handler(name: str = 'charset_normalizer', level: int = 20, format_string: str = '%(asctime)s | %(levelname)s | %(message)s') -> None

    should_strip_sig_or_bom(iana_encoding: str) -> bool

    unicode_range(character: str) -> Optional[str]
        Retrieve the Unicode range official name from a single character.

DATA
    ENCODING_MARKS = {'gb18030': b'\x841\x953', 'utf_16': [b'\xfe\xff', b'...
    Generator = typing.Generator
        A generic version of collections.abc.Generator.

    IANA_SUPPORTED_SIMILAR = {'cp037': ['cp1026', 'cp1140', 'cp273', 'cp50...
    List = typing.List
        A generic version of list.

    Optional = typing.Optional
        Optional[X] is equivalent to Union[X, None].

    RE_POSSIBLE_ENCODING_INDICATION = re.compile('(?:(?:encoding)|(?:chars...
    Set = typing.Set
        A generic version of set.

    Tuple = typing.Tuple
        Deprecated alias to builtins.tuple.

        Tuple[X, Y] is the cross-product type of X and Y.

        Example: Tuple[T1, T2] is a tuple of two elements corresponding
        to type variables T1 and T2.  Tuple[int, float, str] is a tuple
        of an int, a float and a string.

        To specify a variable-length tuple of homogeneous type, use Tuple[T, ...].

    UNICODE_RANGES_COMBINED = {'Adlam': range(125184, 125280), 'Aegean Num...
    UNICODE_SECONDARY_RANGE_KEYWORD = ['Supplement', 'Extended', 'Extensio...
    UTF8_MAXIMAL_ALLOCATION = 1112064
    Union = typing.Union
        Union type; Union[X, Y] means either X or Y.

        On Python 3.10 and higher, the | operator
        can also be used to denote unions;
        X | Y means the same thing to the type checker as Union[X, Y].

        To define a union, use e.g. Union[int, str]. Details:
        - The arguments must be types and there must be at least one.
        - None as an argument is a special case and is replaced by
          type(None).
        - Unions of unions are flattened, e.g.::

            assert Union[Union[int, str], float] == Union[int, str, float]

        - Unions of a single argument vanish, e.g.::

            assert Union[int] == int  # The constructor actually returns int

        - Redundant arguments are skipped, e.g.::

            assert Union[int, str, int] == Union[int, str]

        - When comparing unions, the argument order is ignored, e.g.::

            assert Union[int, str] == Union[str, int]

        - You cannot subclass or instantiate a union.
        - You can use Optional[X] as a shorthand for Union[X, None].

    aliases = {'037': 'cp037', '1026': 'cp1026', '1125': 'cp1125', '1140':...

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\backend\lib\site-packages\charset_normalizer\utils.py



================================================================================
Help on module backend.Lib.site-packages.click.utils in backend.Lib.site-packages.click:

NAME
    backend.Lib.site-packages.click.utils

CLASSES
    builtins.object
        KeepOpenFile
        LazyFile
        PacifyFlushWrapper

    class KeepOpenFile(builtins.object)
     |  KeepOpenFile(file: IO[Any]) -> None
     |
     |  Methods defined here:
     |
     |  __enter__(self) -> 'KeepOpenFile'
     |
     |  __exit__(self, exc_type: Optional[Type[BaseException]], exc_value: Optional[BaseException], tb: Optional[traceback]) -> None
     |
     |  __getattr__(self, name: str) -> Any
     |
     |  __init__(self, file: IO[Any]) -> None
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  __iter__(self) -> Iterator[~AnyStr]
     |
     |  __repr__(self) -> str
     |      Return repr(self).
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

    class LazyFile(builtins.object)
     |  LazyFile(filename: Union[str, ForwardRef('os.PathLike[str]')], mode: str = 'r', encoding: Optional[str] = None, errors: Optional[str] = 'strict', atomic: bool = False)
     |
     |  A lazy file works like a regular file but it does not fully open
     |  the file but it does perform some basic checks early to see if the
     |  filename parameter does make sense.  This is useful for safely opening
     |  files for writing.
     |
     |  Methods defined here:
     |
     |  __enter__(self) -> 'LazyFile'
     |
     |  __exit__(self, exc_type: Optional[Type[BaseException]], exc_value: Optional[BaseException], tb: Optional[traceback]) -> None
     |
     |  __getattr__(self, name: str) -> Any
     |
     |  __init__(self, filename: Union[str, ForwardRef('os.PathLike[str]')], mode: str = 'r', encoding: Optional[str] = None, errors: Optional[str] = 'strict', atomic: bool = False)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  __iter__(self) -> Iterator[~AnyStr]
     |
     |  __repr__(self) -> str
     |      Return repr(self).
     |
     |  close(self) -> None
     |      Closes the underlying file, no matter what.
     |
     |  close_intelligently(self) -> None
     |      This function only closes the file if it was opened by the lazy
     |      file wrapper.  For instance this will never close stdin.
     |
     |  open(self) -> IO[Any]
     |      Opens the file if it's not yet open.  This call might fail with
     |      a :exc:`FileError`.  Not handling this error will produce an error
     |      that Click shows.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

    class PacifyFlushWrapper(builtins.object)
     |  PacifyFlushWrapper(wrapped: IO[Any]) -> None
     |
     |  This wrapper is used to catch and suppress BrokenPipeErrors resulting
     |  from ``.flush()`` being called on broken pipe during the shutdown/final-GC
     |  of the Python interpreter. Notably ``.flush()`` is always called on
     |  ``sys.stdout`` and ``sys.stderr``. So as to have minimal impact on any
     |  other cleanup code, and the case where the underlying file is not a broken
     |  pipe, all calls and attributes are proxied.
     |
     |  Methods defined here:
     |
     |  __getattr__(self, attr: str) -> Any
     |
     |  __init__(self, wrapped: IO[Any]) -> None
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  flush(self) -> None
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

FUNCTIONS
    echo(message: Optional[Any] = None, file: Optional[IO[Any]] = None, nl: bool = True, err: bool = False, color: Optional[bool] = None) -> None
        Print a message and newline to stdout or a file. This should be
        used instead of :func:`print` because it provides better support
        for different data, files, and environments.

        Compared to :func:`print`, this does the following:

        -   Ensures that the output encoding is not misconfigured on Linux.
        -   Supports Unicode in the Windows console.
        -   Supports writing to binary outputs, and supports writing bytes
            to text outputs.
        -   Supports colors and styles on Windows.
        -   Removes ANSI color and style codes if the output does not look
            like an interactive terminal.
        -   Always flushes the output.

        :param message: The string or bytes to output. Other objects are
            converted to strings.
        :param file: The file to write to. Defaults to ``stdout``.
        :param err: Write to ``stderr`` instead of ``stdout``.
        :param nl: Print a newline after the message. Enabled by default.
        :param color: Force showing or hiding colors and other styles. By
            default Click will remove color if the output does not look like
            an interactive terminal.

        .. versionchanged:: 6.0
            Support Unicode output on the Windows console. Click does not
            modify ``sys.stdout``, so ``sys.stdout.write()`` and ``print()``
            will still not support Unicode.

        .. versionchanged:: 4.0
            Added the ``color`` parameter.

        .. versionadded:: 3.0
            Added the ``err`` parameter.

        .. versionchanged:: 2.0
            Support colors on Windows if colorama is installed.

    format_filename(filename: 't.Union[str, bytes, os.PathLike[str], os.PathLike[bytes]]', shorten: bool = False) -> str
        Format a filename as a string for display. Ensures the filename can be
        displayed by replacing any invalid bytes or surrogate escapes in the name
        with the replacement character ``\ufffd``.

        Invalid bytes or surrogate escapes will raise an error when written to a
        stream with ``errors="strict". This will typically happen with ``stdout``
        when the locale is something like ``en_GB.UTF-8``.

        Many scenarios *are* safe to write surrogates though, due to PEP 538 and
        PEP 540, including:

        -   Writing to ``stderr``, which uses ``errors="backslashreplace"``.
        -   The system has ``LANG=C.UTF-8``, ``C``, or ``POSIX``. Python opens
            stdout and stderr with ``errors="surrogateescape"``.
        -   None of ``LANG/LC_*`` are set. Python assumes ``LANG=C.UTF-8``.
        -   Python is started in UTF-8 mode  with  ``PYTHONUTF8=1`` or ``-X utf8``.
            Python opens stdout and stderr with ``errors="surrogateescape"``.

        :param filename: formats a filename for UI display.  This will also convert
                         the filename into unicode without failing.
        :param shorten: this optionally shortens the filename to strip of the
                        path that leads up to it.

    get_app_dir(app_name: str, roaming: bool = True, force_posix: bool = False) -> str
        Returns the config folder for the application.  The default behavior
        is to return whatever is most appropriate for the operating system.

        To give you an idea, for an app called ``"Foo Bar"``, something like
        the following folders could be returned:

        Mac OS X:
          ``~/Library/Application Support/Foo Bar``
        Mac OS X (POSIX):
          ``~/.foo-bar``
        Unix:
          ``~/.config/foo-bar``
        Unix (POSIX):
          ``~/.foo-bar``
        Windows (roaming):
          ``C:\Users\<user>\AppData\Roaming\Foo Bar``
        Windows (not roaming):
          ``C:\Users\<user>\AppData\Local\Foo Bar``

        .. versionadded:: 2.0

        :param app_name: the application name.  This should be properly capitalized
                         and can contain whitespace.
        :param roaming: controls if the folder should be roaming or not on Windows.
                        Has no effect otherwise.
        :param force_posix: if this is set to `True` then on any POSIX system the
                            folder will be stored in the home folder with a leading
                            dot instead of the XDG config home or darwin's
                            application support folder.

    get_binary_stream(name: "te.Literal['stdin', 'stdout', 'stderr']") -> <class 'BinaryIO'>
        Returns a system stream for byte processing.

        :param name: the name of the stream to open.  Valid names are ``'stdin'``,
                     ``'stdout'`` and ``'stderr'``

    get_text_stream(name: "te.Literal['stdin', 'stdout', 'stderr']", encoding: Optional[str] = None, errors: Optional[str] = 'strict') -> <class 'TextIO'>
        Returns a system stream for text processing.  This usually returns
        a wrapped stream around a binary stream returned from
        :func:`get_binary_stream` but it also can take shortcuts for already
        correctly configured streams.

        :param name: the name of the stream to open.  Valid names are ``'stdin'``,
                     ``'stdout'`` and ``'stderr'``
        :param encoding: overrides the detected default encoding.
        :param errors: overrides the default error mode.

    make_default_short_help(help: str, max_length: int = 45) -> str
        Returns a condensed version of help string.

    make_str(value: Any) -> str
        Converts a value into a valid string.

    open_file(filename: str, mode: str = 'r', encoding: Optional[str] = None, errors: Optional[str] = 'strict', lazy: bool = False, atomic: bool = False) -> IO[Any]
        Open a file, with extra behavior to handle ``'-'`` to indicate
        a standard stream, lazy open on write, and atomic write. Similar to
        the behavior of the :class:`~click.File` param type.

        If ``'-'`` is given to open ``stdout`` or ``stdin``, the stream is
        wrapped so that using it in a context manager will not close it.
        This makes it possible to use the function without accidentally
        closing a standard stream:

        .. code-block:: python

            with open_file(filename) as f:
                ...

        :param filename: The name of the file to open, or ``'-'`` for
            ``stdin``/``stdout``.
        :param mode: The mode in which to open the file.
        :param encoding: The encoding to decode or encode a file opened in
            text mode.
        :param errors: The error handling mode.
        :param lazy: Wait to open the file until it is accessed. For read
            mode, the file is temporarily opened to raise access errors
            early, then closed until it is read again.
        :param atomic: Write to a temporary file and replace the given file
            on close.

        .. versionadded:: 3.0

    safecall(func: 't.Callable[P, R]') -> 't.Callable[P, t.Optional[R]]'
        Wraps a function so that it swallows exceptions.

DATA
    R = ~R
    WIN = True
    binary_streams = {'stderr': <function get_binary_stderr>, 'stdin': <fu...
    text_streams = {'stderr': <function get_text_stderr>, 'stdin': <functi...

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\backend\lib\site-packages\click\utils.py



================================================================================
Help on module backend.Lib.site-packages.colorama.tests.utils in backend.Lib.site-packages.colorama.tests:

NAME
    backend.Lib.site-packages.colorama.tests.utils - # Copyright Jonathan Hartley 2013. BSD 3-Clause license, see LICENSE file.

CLASSES
    _io.StringIO(_io._TextIOBase)
        StreamNonTTY
        StreamTTY

    class StreamNonTTY(_io.StringIO)
     |  StreamNonTTY(initial_value='', newline='\n')
     |
     |  Method resolution order:
     |      StreamNonTTY
     |      _io.StringIO
     |      _io._TextIOBase
     |      _io._IOBase
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  isatty(self)
     |      Return whether this is an 'interactive' stream.
     |
     |      Return False if it can't be determined.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from _io.StringIO:
     |
     |  __getstate__(...)
     |      Helper for pickle.
     |
     |  __init__(self, /, *args, **kwargs)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  __next__(self, /)
     |      Implement next(self).
     |
     |  __setstate__(...)
     |
     |  close(self, /)
     |      Close the IO object.
     |
     |      Attempting any further operation after the object is closed
     |      will raise a ValueError.
     |
     |      This method has no effect if the file is already closed.
     |
     |  getvalue(self, /)
     |      Retrieve the entire contents of the object.
     |
     |  read(self, size=-1, /)
     |      Read at most size characters, returned as a string.
     |
     |      If the argument is negative or omitted, read until EOF
     |      is reached. Return an empty string at EOF.
     |
     |  readable(self, /)
     |      Returns True if the IO object can be read.
     |
     |  readline(self, size=-1, /)
     |      Read until newline or EOF.
     |
     |      Returns an empty string if EOF is hit immediately.
     |
     |  seek(self, pos, whence=0, /)
     |      Change stream position.
     |
     |      Seek to character offset pos relative to position indicated by whence:
     |          0  Start of stream (the default).  pos should be >= 0;
     |          1  Current position - pos must be 0;
     |          2  End of stream - pos must be 0.
     |      Returns the new absolute position.
     |
     |  seekable(self, /)
     |      Returns True if the IO object can be seeked.
     |
     |  tell(self, /)
     |      Tell the current file position.
     |
     |  truncate(self, pos=None, /)
     |      Truncate size to pos.
     |
     |      The pos argument defaults to the current file position, as
     |      returned by tell().  The current file position is unchanged.
     |      Returns the new absolute position.
     |
     |  writable(self, /)
     |      Returns True if the IO object can be written.
     |
     |  write(self, s, /)
     |      Write string to file.
     |
     |      Returns the number of characters written, which is always equal to
     |      the length of the string.
     |
     |  ----------------------------------------------------------------------
     |  Static methods inherited from _io.StringIO:
     |
     |  __new__(*args, **kwargs) class method of _io.StringIO
     |      Create and return a new object.  See help(type) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from _io.StringIO:
     |
     |  closed
     |
     |  line_buffering
     |
     |  newlines
     |      Line endings translated so far.
     |
     |      Only line endings translated during reading are considered.
     |
     |      Subclasses should override.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from _io._TextIOBase:
     |
     |  detach(self, /)
     |      Separate the underlying buffer from the TextIOBase and return it.
     |
     |      After the underlying buffer has been detached, the TextIO is in an unusable state.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from _io._TextIOBase:
     |
     |  encoding
     |      Encoding of the text stream.
     |
     |      Subclasses should override.
     |
     |  errors
     |      The error setting of the decoder or encoder.
     |
     |      Subclasses should override.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from _io._IOBase:
     |
     |  __del__(...)
     |
     |  __enter__(...)
     |
     |  __exit__(...)
     |
     |  __iter__(self, /)
     |      Implement iter(self).
     |
     |  fileno(self, /)
     |      Return underlying file descriptor if one exists.
     |
     |      Raise OSError if the IO object does not use a file descriptor.
     |
     |  flush(self, /)
     |      Flush write buffers, if applicable.
     |
     |      This is not implemented for read-only and non-blocking streams.
     |
     |  readlines(self, hint=-1, /)
     |      Return a list of lines from the stream.
     |
     |      hint can be specified to control the number of lines read: no more
     |      lines will be read if the total size (in bytes/characters) of all
     |      lines so far exceeds hint.
     |
     |  writelines(self, lines, /)
     |      Write a list of lines to stream.
     |
     |      Line separators are not added, so it is usual for each of the
     |      lines provided to have a line separator at the end.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from _io._IOBase:
     |
     |  __dict__

    class StreamTTY(_io.StringIO)
     |  StreamTTY(initial_value='', newline='\n')
     |
     |  Method resolution order:
     |      StreamTTY
     |      _io.StringIO
     |      _io._TextIOBase
     |      _io._IOBase
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  isatty(self)
     |      Return whether this is an 'interactive' stream.
     |
     |      Return False if it can't be determined.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from _io.StringIO:
     |
     |  __getstate__(...)
     |      Helper for pickle.
     |
     |  __init__(self, /, *args, **kwargs)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  __next__(self, /)
     |      Implement next(self).
     |
     |  __setstate__(...)
     |
     |  close(self, /)
     |      Close the IO object.
     |
     |      Attempting any further operation after the object is closed
     |      will raise a ValueError.
     |
     |      This method has no effect if the file is already closed.
     |
     |  getvalue(self, /)
     |      Retrieve the entire contents of the object.
     |
     |  read(self, size=-1, /)
     |      Read at most size characters, returned as a string.
     |
     |      If the argument is negative or omitted, read until EOF
     |      is reached. Return an empty string at EOF.
     |
     |  readable(self, /)
     |      Returns True if the IO object can be read.
     |
     |  readline(self, size=-1, /)
     |      Read until newline or EOF.
     |
     |      Returns an empty string if EOF is hit immediately.
     |
     |  seek(self, pos, whence=0, /)
     |      Change stream position.
     |
     |      Seek to character offset pos relative to position indicated by whence:
     |          0  Start of stream (the default).  pos should be >= 0;
     |          1  Current position - pos must be 0;
     |          2  End of stream - pos must be 0.
     |      Returns the new absolute position.
     |
     |  seekable(self, /)
     |      Returns True if the IO object can be seeked.
     |
     |  tell(self, /)
     |      Tell the current file position.
     |
     |  truncate(self, pos=None, /)
     |      Truncate size to pos.
     |
     |      The pos argument defaults to the current file position, as
     |      returned by tell().  The current file position is unchanged.
     |      Returns the new absolute position.
     |
     |  writable(self, /)
     |      Returns True if the IO object can be written.
     |
     |  write(self, s, /)
     |      Write string to file.
     |
     |      Returns the number of characters written, which is always equal to
     |      the length of the string.
     |
     |  ----------------------------------------------------------------------
     |  Static methods inherited from _io.StringIO:
     |
     |  __new__(*args, **kwargs) class method of _io.StringIO
     |      Create and return a new object.  See help(type) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from _io.StringIO:
     |
     |  closed
     |
     |  line_buffering
     |
     |  newlines
     |      Line endings translated so far.
     |
     |      Only line endings translated during reading are considered.
     |
     |      Subclasses should override.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from _io._TextIOBase:
     |
     |  detach(self, /)
     |      Separate the underlying buffer from the TextIOBase and return it.
     |
     |      After the underlying buffer has been detached, the TextIO is in an unusable state.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from _io._TextIOBase:
     |
     |  encoding
     |      Encoding of the text stream.
     |
     |      Subclasses should override.
     |
     |  errors
     |      The error setting of the decoder or encoder.
     |
     |      Subclasses should override.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from _io._IOBase:
     |
     |  __del__(...)
     |
     |  __enter__(...)
     |
     |  __exit__(...)
     |
     |  __iter__(self, /)
     |      Implement iter(self).
     |
     |  fileno(self, /)
     |      Return underlying file descriptor if one exists.
     |
     |      Raise OSError if the IO object does not use a file descriptor.
     |
     |  flush(self, /)
     |      Flush write buffers, if applicable.
     |
     |      This is not implemented for read-only and non-blocking streams.
     |
     |  readlines(self, hint=-1, /)
     |      Return a list of lines from the stream.
     |
     |      hint can be specified to control the number of lines read: no more
     |      lines will be read if the total size (in bytes/characters) of all
     |      lines so far exceeds hint.
     |
     |  writelines(self, lines, /)
     |      Write a list of lines to stream.
     |
     |      Line separators are not added, so it is usual for each of the
     |      lines provided to have a line separator at the end.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from _io._IOBase:
     |
     |  __dict__

FUNCTIONS
    osname(name)

    pycharm()

    replace_by(stream)

    replace_original_by(stream)

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\backend\lib\site-packages\colorama\tests\utils.py



================================================================================
Help on module backend.Lib.site-packages.cryptography.utils in backend.Lib.site-packages.cryptography:

NAME
    backend.Lib.site-packages.cryptography.utils

DESCRIPTION
    # This file is dual licensed under the terms of the Apache License, Version
    # 2.0, and the BSD License. See the LICENSE file in the root of this repository
    # for complete details.

CLASSES
    builtins.Exception(builtins.BaseException)
        InterfaceNotImplemented
    builtins.UserWarning(builtins.Warning)
        CryptographyDeprecationWarning
    enum.Enum(builtins.object)
        Enum

    class CryptographyDeprecationWarning(builtins.UserWarning)
     |  # We use a UserWarning subclass, instead of DeprecationWarning, because CPython
     |  # decided deprecation warnings should be invisible by default.
     |
     |  Method resolution order:
     |      CryptographyDeprecationWarning
     |      builtins.UserWarning
     |      builtins.Warning
     |      builtins.Exception
     |      builtins.BaseException
     |      builtins.object
     |
     |  Data descriptors defined here:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.UserWarning:
     |
     |  __init__(self, /, *args, **kwargs)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Static methods inherited from builtins.UserWarning:
     |
     |  __new__(*args, **kwargs) class method of builtins.UserWarning
     |      Create and return a new object.  See help(type) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.BaseException:
     |
     |  __delattr__(self, name, /)
     |      Implement delattr(self, name).
     |
     |  __getattribute__(self, name, /)
     |      Return getattr(self, name).
     |
     |  __reduce__(...)
     |      Helper for pickle.
     |
     |  __repr__(self, /)
     |      Return repr(self).
     |
     |  __setattr__(self, name, value, /)
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(...)
     |
     |  __str__(self, /)
     |      Return str(self).
     |
     |  add_note(...)
     |      Exception.add_note(note) --
     |      add a note to the exception
     |
     |  with_traceback(...)
     |      Exception.with_traceback(tb) --
     |      set self.__traceback__ to tb and return self.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from builtins.BaseException:
     |
     |  __cause__
     |      exception cause
     |
     |  __context__
     |      exception context
     |
     |  __dict__
     |
     |  __suppress_context__
     |
     |  __traceback__
     |
     |  args

    DeprecatedIn36 = class CryptographyDeprecationWarning(builtins.UserWarning)
     |  # We use a UserWarning subclass, instead of DeprecationWarning, because CPython
     |  # decided deprecation warnings should be invisible by default.
     |
     |  Method resolution order:
     |      CryptographyDeprecationWarning
     |      builtins.UserWarning
     |      builtins.Warning
     |      builtins.Exception
     |      builtins.BaseException
     |      builtins.object
     |
     |  Data descriptors defined here:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.UserWarning:
     |
     |  __init__(self, /, *args, **kwargs)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Static methods inherited from builtins.UserWarning:
     |
     |  __new__(*args, **kwargs) class method of builtins.UserWarning
     |      Create and return a new object.  See help(type) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.BaseException:
     |
     |  __delattr__(self, name, /)
     |      Implement delattr(self, name).
     |
     |  __getattribute__(self, name, /)
     |      Return getattr(self, name).
     |
     |  __reduce__(...)
     |      Helper for pickle.
     |
     |  __repr__(self, /)
     |      Return repr(self).
     |
     |  __setattr__(self, name, value, /)
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(...)
     |
     |  __str__(self, /)
     |      Return str(self).
     |
     |  add_note(...)
     |      Exception.add_note(note) --
     |      add a note to the exception
     |
     |  with_traceback(...)
     |      Exception.with_traceback(tb) --
     |      set self.__traceback__ to tb and return self.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from builtins.BaseException:
     |
     |  __cause__
     |      exception cause
     |
     |  __context__
     |      exception context
     |
     |  __dict__
     |
     |  __suppress_context__
     |
     |  __traceback__
     |
     |  args

    DeprecatedIn37 = class CryptographyDeprecationWarning(builtins.UserWarning)
     |  # We use a UserWarning subclass, instead of DeprecationWarning, because CPython
     |  # decided deprecation warnings should be invisible by default.
     |
     |  Method resolution order:
     |      CryptographyDeprecationWarning
     |      builtins.UserWarning
     |      builtins.Warning
     |      builtins.Exception
     |      builtins.BaseException
     |      builtins.object
     |
     |  Data descriptors defined here:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.UserWarning:
     |
     |  __init__(self, /, *args, **kwargs)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Static methods inherited from builtins.UserWarning:
     |
     |  __new__(*args, **kwargs) class method of builtins.UserWarning
     |      Create and return a new object.  See help(type) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.BaseException:
     |
     |  __delattr__(self, name, /)
     |      Implement delattr(self, name).
     |
     |  __getattribute__(self, name, /)
     |      Return getattr(self, name).
     |
     |  __reduce__(...)
     |      Helper for pickle.
     |
     |  __repr__(self, /)
     |      Return repr(self).
     |
     |  __setattr__(self, name, value, /)
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(...)
     |
     |  __str__(self, /)
     |      Return str(self).
     |
     |  add_note(...)
     |      Exception.add_note(note) --
     |      add a note to the exception
     |
     |  with_traceback(...)
     |      Exception.with_traceback(tb) --
     |      set self.__traceback__ to tb and return self.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from builtins.BaseException:
     |
     |  __cause__
     |      exception cause
     |
     |  __context__
     |      exception context
     |
     |  __dict__
     |
     |  __suppress_context__
     |
     |  __traceback__
     |
     |  args

    DeprecatedIn40 = class CryptographyDeprecationWarning(builtins.UserWarning)
     |  # We use a UserWarning subclass, instead of DeprecationWarning, because CPython
     |  # decided deprecation warnings should be invisible by default.
     |
     |  Method resolution order:
     |      CryptographyDeprecationWarning
     |      builtins.UserWarning
     |      builtins.Warning
     |      builtins.Exception
     |      builtins.BaseException
     |      builtins.object
     |
     |  Data descriptors defined here:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.UserWarning:
     |
     |  __init__(self, /, *args, **kwargs)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Static methods inherited from builtins.UserWarning:
     |
     |  __new__(*args, **kwargs) class method of builtins.UserWarning
     |      Create and return a new object.  See help(type) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.BaseException:
     |
     |  __delattr__(self, name, /)
     |      Implement delattr(self, name).
     |
     |  __getattribute__(self, name, /)
     |      Return getattr(self, name).
     |
     |  __reduce__(...)
     |      Helper for pickle.
     |
     |  __repr__(self, /)
     |      Return repr(self).
     |
     |  __setattr__(self, name, value, /)
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(...)
     |
     |  __str__(self, /)
     |      Return str(self).
     |
     |  add_note(...)
     |      Exception.add_note(note) --
     |      add a note to the exception
     |
     |  with_traceback(...)
     |      Exception.with_traceback(tb) --
     |      set self.__traceback__ to tb and return self.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from builtins.BaseException:
     |
     |  __cause__
     |      exception cause
     |
     |  __context__
     |      exception context
     |
     |  __dict__
     |
     |  __suppress_context__
     |
     |  __traceback__
     |
     |  args

    DeprecatedIn41 = class CryptographyDeprecationWarning(builtins.UserWarning)
     |  # We use a UserWarning subclass, instead of DeprecationWarning, because CPython
     |  # decided deprecation warnings should be invisible by default.
     |
     |  Method resolution order:
     |      CryptographyDeprecationWarning
     |      builtins.UserWarning
     |      builtins.Warning
     |      builtins.Exception
     |      builtins.BaseException
     |      builtins.object
     |
     |  Data descriptors defined here:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.UserWarning:
     |
     |  __init__(self, /, *args, **kwargs)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Static methods inherited from builtins.UserWarning:
     |
     |  __new__(*args, **kwargs) class method of builtins.UserWarning
     |      Create and return a new object.  See help(type) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.BaseException:
     |
     |  __delattr__(self, name, /)
     |      Implement delattr(self, name).
     |
     |  __getattribute__(self, name, /)
     |      Return getattr(self, name).
     |
     |  __reduce__(...)
     |      Helper for pickle.
     |
     |  __repr__(self, /)
     |      Return repr(self).
     |
     |  __setattr__(self, name, value, /)
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(...)
     |
     |  __str__(self, /)
     |      Return str(self).
     |
     |  add_note(...)
     |      Exception.add_note(note) --
     |      add a note to the exception
     |
     |  with_traceback(...)
     |      Exception.with_traceback(tb) --
     |      set self.__traceback__ to tb and return self.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from builtins.BaseException:
     |
     |  __cause__
     |      exception cause
     |
     |  __context__
     |      exception context
     |
     |  __dict__
     |
     |  __suppress_context__
     |
     |  __traceback__
     |
     |  args

    DeprecatedIn42 = class CryptographyDeprecationWarning(builtins.UserWarning)
     |  # We use a UserWarning subclass, instead of DeprecationWarning, because CPython
     |  # decided deprecation warnings should be invisible by default.
     |
     |  Method resolution order:
     |      CryptographyDeprecationWarning
     |      builtins.UserWarning
     |      builtins.Warning
     |      builtins.Exception
     |      builtins.BaseException
     |      builtins.object
     |
     |  Data descriptors defined here:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.UserWarning:
     |
     |  __init__(self, /, *args, **kwargs)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Static methods inherited from builtins.UserWarning:
     |
     |  __new__(*args, **kwargs) class method of builtins.UserWarning
     |      Create and return a new object.  See help(type) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.BaseException:
     |
     |  __delattr__(self, name, /)
     |      Implement delattr(self, name).
     |
     |  __getattribute__(self, name, /)
     |      Return getattr(self, name).
     |
     |  __reduce__(...)
     |      Helper for pickle.
     |
     |  __repr__(self, /)
     |      Return repr(self).
     |
     |  __setattr__(self, name, value, /)
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(...)
     |
     |  __str__(self, /)
     |      Return str(self).
     |
     |  add_note(...)
     |      Exception.add_note(note) --
     |      add a note to the exception
     |
     |  with_traceback(...)
     |      Exception.with_traceback(tb) --
     |      set self.__traceback__ to tb and return self.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from builtins.BaseException:
     |
     |  __cause__
     |      exception cause
     |
     |  __context__
     |      exception context
     |
     |  __dict__
     |
     |  __suppress_context__
     |
     |  __traceback__
     |
     |  args

    DeprecatedIn43 = class CryptographyDeprecationWarning(builtins.UserWarning)
     |  # We use a UserWarning subclass, instead of DeprecationWarning, because CPython
     |  # decided deprecation warnings should be invisible by default.
     |
     |  Method resolution order:
     |      CryptographyDeprecationWarning
     |      builtins.UserWarning
     |      builtins.Warning
     |      builtins.Exception
     |      builtins.BaseException
     |      builtins.object
     |
     |  Data descriptors defined here:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.UserWarning:
     |
     |  __init__(self, /, *args, **kwargs)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Static methods inherited from builtins.UserWarning:
     |
     |  __new__(*args, **kwargs) class method of builtins.UserWarning
     |      Create and return a new object.  See help(type) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.BaseException:
     |
     |  __delattr__(self, name, /)
     |      Implement delattr(self, name).
     |
     |  __getattribute__(self, name, /)
     |      Return getattr(self, name).
     |
     |  __reduce__(...)
     |      Helper for pickle.
     |
     |  __repr__(self, /)
     |      Return repr(self).
     |
     |  __setattr__(self, name, value, /)
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(...)
     |
     |  __str__(self, /)
     |      Return str(self).
     |
     |  add_note(...)
     |      Exception.add_note(note) --
     |      add a note to the exception
     |
     |  with_traceback(...)
     |      Exception.with_traceback(tb) --
     |      set self.__traceback__ to tb and return self.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from builtins.BaseException:
     |
     |  __cause__
     |      exception cause
     |
     |  __context__
     |      exception context
     |
     |  __dict__
     |
     |  __suppress_context__
     |
     |  __traceback__
     |
     |  args

    class Enum(enum.Enum)
     |  Enum(new_class_name, /, names, *, module=None, qualname=None, type=None, start=1, boundary=None)
     |
     |  # Python 3.10 changed representation of enums. We use well-defined object
     |  # representation and string representation from Python 3.9.
     |
     |  Method resolution order:
     |      Enum
     |      enum.Enum
     |      builtins.object
     |
     |  Data descriptors inherited from enum.Enum:
     |
     |  name
     |      The name of the Enum member.
     |
     |  value
     |      The value of the Enum member.
     |
     |  ----------------------------------------------------------------------
     |  Static methods inherited from enum.EnumType:
     |
     |  __contains__(value)
     |      Return True if `value` is in `cls`.
     |
     |      `value` is in `cls` if:
     |      1) `value` is a member of `cls`, or
     |      2) `value` is the value of one of the `cls`'s members.
     |
     |  __getitem__(name)
     |      Return the member matching `name`.
     |
     |  __iter__()
     |      Return members in definition order.
     |
     |  __len__()
     |      Return the number of members (no aliases)
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from enum.EnumType:
     |
     |  __members__
     |      Returns a mapping of member name->value.
     |
     |      This mapping lists all enum members, including aliases. Note that this
     |      is a read-only view of the internal mapping.

    class InterfaceNotImplemented(builtins.Exception)
     |  Method resolution order:
     |      InterfaceNotImplemented
     |      builtins.Exception
     |      builtins.BaseException
     |      builtins.object
     |
     |  Data descriptors defined here:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.Exception:
     |
     |  __init__(self, /, *args, **kwargs)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Static methods inherited from builtins.Exception:
     |
     |  __new__(*args, **kwargs) class method of builtins.Exception
     |      Create and return a new object.  See help(type) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.BaseException:
     |
     |  __delattr__(self, name, /)
     |      Implement delattr(self, name).
     |
     |  __getattribute__(self, name, /)
     |      Return getattr(self, name).
     |
     |  __reduce__(...)
     |      Helper for pickle.
     |
     |  __repr__(self, /)
     |      Return repr(self).
     |
     |  __setattr__(self, name, value, /)
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(...)
     |
     |  __str__(self, /)
     |      Return str(self).
     |
     |  add_note(...)
     |      Exception.add_note(note) --
     |      add a note to the exception
     |
     |  with_traceback(...)
     |      Exception.with_traceback(tb) --
     |      set self.__traceback__ to tb and return self.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from builtins.BaseException:
     |
     |  __cause__
     |      exception cause
     |
     |  __context__
     |      exception context
     |
     |  __dict__
     |
     |  __suppress_context__
     |
     |  __traceback__
     |
     |  args

FUNCTIONS
    cached_property(func: 'typing.Callable') -> 'property'

    deprecated(value: 'object', module_name: 'str', message: 'str', warning_class: 'type[Warning]', name: 'str | None' = None) -> '_DeprecatedValue'

    int_to_bytes(integer: 'int', length: 'int | None' = None) -> 'bytes'

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\backend\lib\site-packages\cryptography\utils.py



================================================================================
Help on module backend.Lib.site-packages.cryptography.hazmat.primitives.asymmetric.utils in backend.Lib.site-packages.cryptography.hazmat.primitives.asymmetric:

NAME
    backend.Lib.site-packages.cryptography.hazmat.primitives.asymmetric.utils

DESCRIPTION
    # This file is dual licensed under the terms of the Apache License, Version
    # 2.0, and the BSD License. See the LICENSE file in the root of this repository
    # for complete details.

CLASSES
    builtins.object
        Prehashed

    class Prehashed(builtins.object)
     |  Prehashed(algorithm: 'hashes.HashAlgorithm')
     |
     |  Methods defined here:
     |
     |  __init__(self, algorithm: 'hashes.HashAlgorithm')
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties defined here:
     |
     |  digest_size
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

FUNCTIONS
    decode_dss_signature(data)

    encode_dss_signature(r, s)

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\backend\lib\site-packages\cryptography\hazmat\primitives\asymmetric\utils.py



================================================================================
Help on module backend.Lib.site-packages.dotenv.main in backend.Lib.site-packages.dotenv:

NAME
    backend.Lib.site-packages.dotenv.main

CLASSES
    builtins.object
        DotEnv

    class DotEnv(builtins.object)
     |  DotEnv(dotenv_path: Union[str, os.PathLike, NoneType], stream: Optional[IO[str]] = None, verbose: bool = False, encoding: Optional[str] = None, interpolate: bool = True, override: bool = True) -> None
     |
     |  Methods defined here:
     |
     |  __init__(self, dotenv_path: Union[str, os.PathLike, NoneType], stream: Optional[IO[str]] = None, verbose: bool = False, encoding: Optional[str] = None, interpolate: bool = True, override: bool = True) -> None
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  dict(self) -> Dict[str, Optional[str]]
     |      Return dotenv as dict
     |
     |  get(self, key: str) -> Optional[str]
     |
     |  parse(self) -> Iterator[Tuple[str, Optional[str]]]
     |
     |  set_as_environment_variables(self) -> bool
     |      Load the current dotenv as system environment variable.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

FUNCTIONS
    dotenv_values(dotenv_path: Union[str, os.PathLike, NoneType] = None, stream: Optional[IO[str]] = None, verbose: bool = False, interpolate: bool = True, encoding: Optional[str] = 'utf-8') -> Dict[str, Optional[str]]
        Parse a .env file and return its content as a dict.

        - *dotenv_path*: absolute or relative path to .env file.
        - *stream*: `StringIO` object with .env content, used if `dotenv_path` is `None`.
        - *verbose*: whether to output a warning the .env file is missing. Defaults to
          `False`.
          in `.env` file.  Defaults to `False`.
        - *encoding*: encoding to be used to read the file.

        If both `dotenv_path` and `stream`, `find_dotenv()` is used to find the .env file.

    find_dotenv(filename: str = '.env', raise_error_if_not_found: bool = False, usecwd: bool = False) -> str
        Search in increasingly higher folders for the given file

        Returns path to the file if found, or an empty string otherwise

    get_key(dotenv_path: Union[str, os.PathLike], key_to_get: str) -> Optional[str]
        Gets the value of a given key from the given .env

        If the .env path given doesn't exist, fails

    load_dotenv(dotenv_path: Union[str, os.PathLike, NoneType] = None, stream: Optional[IO[str]] = None, verbose: bool = False, override: bool = False, interpolate: bool = True, encoding: Optional[str] = 'utf-8') -> bool
        Parse a .env file and then load all the variables found as environment variables.

        - *dotenv_path*: absolute or relative path to .env file.
        - *stream*: Text stream (such as `io.StringIO`) with .env content, used if
          `dotenv_path` is `None`.
        - *verbose*: whether to output a warning the .env file is missing. Defaults to
          `False`.
        - *override*: whether to override the system environment variables with the variables
          in `.env` file.  Defaults to `False`.
        - *encoding*: encoding to be used to read the file.

        If both `dotenv_path` and `stream`, `find_dotenv()` is used to find the .env file.

    resolve_variables(values: Iterable[Tuple[str, Optional[str]]], override: bool) -> Mapping[str, Optional[str]]

    rewrite(path: Union[str, os.PathLike]) -> Iterator[Tuple[IO[str], IO[str]]]

    set_key(dotenv_path: Union[str, os.PathLike], key_to_set: str, value_to_set: str, quote_mode: str = 'always', export: bool = False) -> Tuple[Optional[bool], str, str]
        Adds or Updates a key/value to the given .env

        If the .env path given doesn't exist, fails instead of risking creating
        an orphan .env somewhere in the filesystem

    unset_key(dotenv_path: Union[str, os.PathLike], key_to_unset: str, quote_mode: str = 'always') -> Tuple[Optional[bool], str]
        Removes a given key from the given .env

        If the .env path given doesn't exist, fails
        If the given key doesn't exist in the .env, fails

    with_warn_for_invalid_lines(mappings: Iterator[backend.Lib.site-packages.dotenv.parser.Binding]) -> Iterator[backend.Lib.site-packages.dotenv.parser.Binding]

DATA
    Dict = typing.Dict
        A generic version of dict.

    Iterable = typing.Iterable
        A generic version of collections.abc.Iterable.

    Iterator = typing.Iterator
        A generic version of collections.abc.Iterator.

    Mapping = typing.Mapping
        A generic version of collections.abc.Mapping.

    Optional = typing.Optional
        Optional[X] is equivalent to Union[X, None].

    Tuple = typing.Tuple
        Deprecated alias to builtins.tuple.

        Tuple[X, Y] is the cross-product type of X and Y.

        Example: Tuple[T1, T2] is a tuple of two elements corresponding
        to type variables T1 and T2.  Tuple[int, float, str] is a tuple
        of an int, a float and a string.

        To specify a variable-length tuple of homogeneous type, use Tuple[T, ...].

    Union = typing.Union
        Union type; Union[X, Y] means either X or Y.

        On Python 3.10 and higher, the | operator
        can also be used to denote unions;
        X | Y means the same thing to the type checker as Union[X, Y].

        To define a union, use e.g. Union[int, str]. Details:
        - The arguments must be types and there must be at least one.
        - None as an argument is a special case and is replaced by
          type(None).
        - Unions of unions are flattened, e.g.::

            assert Union[Union[int, str], float] == Union[int, str, float]

        - Unions of a single argument vanish, e.g.::

            assert Union[int] == int  # The constructor actually returns int

        - Redundant arguments are skipped, e.g.::

            assert Union[int, str, int] == Union[int, str]

        - When comparing unions, the argument order is ignored, e.g.::

            assert Union[int, str] == Union[str, int]

        - You cannot subclass or instantiate a union.
        - You can use Optional[X] as a shorthand for Union[X, None].

    logger = <Logger backend.Lib.site-packages.dotenv.main (WARNING)>

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\backend\lib\site-packages\dotenv\main.py



================================================================================
Help on module backend.Lib.site-packages.email_validator.validate_email in backend.Lib.site-packages.email_validator:

NAME
    backend.Lib.site-packages.email_validator.validate_email

FUNCTIONS
    validate_email(email: Union[str, bytes], /, *, allow_smtputf8: Optional[bool] = None, allow_empty_local: bool = False, allow_quoted_local: Optional[bool] = None, allow_domain_literal: Optional[bool] = None, allow_display_name: Optional[bool] = None, check_deliverability: Optional[bool] = None, test_environment: Optional[bool] = None, globally_deliverable: Optional[bool] = None, timeout: Optional[int] = None, dns_resolver: Optional[object] = None) -> backend.Lib.site-packages.email_validator.exceptions_types.ValidatedEmail
        Given an email address, and some options, returns a ValidatedEmail instance
        with information about the address if it is valid or, if the address is not
        valid, raises an EmailNotValidError. This is the main function of the module.

DATA
    CASE_INSENSITIVE_MAILBOX_NAMES = ['info', 'marketing', 'sales', 'suppo...
    Optional = typing.Optional
        Optional[X] is equivalent to Union[X, None].

    TYPE_CHECKING = False
    Union = typing.Union
        Union type; Union[X, Y] means either X or Y.

        On Python 3.10 and higher, the | operator
        can also be used to denote unions;
        X | Y means the same thing to the type checker as Union[X, Y].

        To define a union, use e.g. Union[int, str]. Details:
        - The arguments must be types and there must be at least one.
        - None as an argument is a special case and is replaced by
          type(None).
        - Unions of unions are flattened, e.g.::

            assert Union[Union[int, str], float] == Union[int, str, float]

        - Unions of a single argument vanish, e.g.::

            assert Union[int] == int  # The constructor actually returns int

        - Redundant arguments are skipped, e.g.::

            assert Union[int, str, int] == Union[int, str]

        - When comparing unions, the argument order is ignored, e.g.::

            assert Union[int, str] == Union[str, int]

        - You cannot subclass or instantiate a union.
        - You can use Optional[X] as a shorthand for Union[X, None].

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\backend\lib\site-packages\email_validator\validate_email.py



================================================================================
Help on module backend.Lib.site-packages.fastapi.utils in backend.Lib.site-packages.fastapi:

NAME
    backend.Lib.site-packages.fastapi.utils

FUNCTIONS
    create_cloned_field(field: fastapi._compat.ModelField, *, cloned_types: Optional[MutableMapping[Type[pydantic.main.BaseModel], Type[pydantic.main.BaseModel]]] = None) -> fastapi._compat.ModelField

    create_response_field(name: str, type_: Type[Any], class_validators: Optional[Dict[str, Any]] = None, default: Optional[Any] = PydanticUndefined, required: Union[bool, pydantic_core._pydantic_core.PydanticUndefinedType] = PydanticUndefined, model_config: Type[fastapi._compat.BaseConfig] = <class 'fastapi._compat.BaseConfig'>, field_info: Optional[pydantic.fields.FieldInfo] = None, alias: Optional[str] = None, mode: Literal['validation', 'serialization'] = 'validation') -> fastapi._compat.ModelField
        Create a new response field. Raises if type_ is invalid.

    deep_dict_update(main_dict: Dict[Any, Any], update_dict: Dict[Any, Any]) -> None

    generate_operation_id_for_path(*, name: str, path: str, method: str) -> str

    generate_unique_id(route: 'APIRoute') -> str

    get_path_param_names(path: str) -> Set[str]

    get_value_or_default(first_item: Union[fastapi.datastructures.DefaultPlaceholder, ~DefaultType], *extra_items: Union[fastapi.datastructures.DefaultPlaceholder, ~DefaultType]) -> Union[fastapi.datastructures.DefaultPlaceholder, ~DefaultType]
        Pass items or `DefaultPlaceholder`s by descending priority.

        The first one to _not_ be a `DefaultPlaceholder` will be returned.

        Otherwise, the first item (a `DefaultPlaceholder`) will be returned.

    is_body_allowed_for_status_code(status_code: Union[int, str, NoneType]) -> bool

DATA
    DefaultType = ~DefaultType
    Dict = typing.Dict
        A generic version of dict.

    Literal = typing.Literal
        Special typing form to define literal types (a.k.a. value types).

        This form can be used to indicate to type checkers that the corresponding
        variable or function parameter has a value equivalent to the provided
        literal (or one of several literals)::

            def validate_simple(data: Any) -> Literal[True]:  # always returns True
                ...

            MODE = Literal['r', 'rb', 'w', 'wb']
            def open_helper(file: str, mode: MODE) -> str:
                ...

            open_helper('/some/path', 'r')  # Passes type check
            open_helper('/other/path', 'typo')  # Error in type checker

        Literal[...] cannot be subclassed. At runtime, an arbitrary value
        is allowed as type argument to Literal[...], but type checkers may
        impose restrictions.

    MutableMapping = typing.MutableMapping
        A generic version of collections.abc.MutableMapping.

    Optional = typing.Optional
        Optional[X] is equivalent to Union[X, None].

    PYDANTIC_V2 = True
    Set = typing.Set
        A generic version of set.

    TYPE_CHECKING = False
    Type = typing.Type
        Deprecated alias to builtins.type.

        builtins.type or typing.Type can be used to annotate class objects.
        For example, suppose we have the following classes::

            class User: ...  # Abstract base for User classes
            class BasicUser(User): ...
            class ProUser(User): ...
            class TeamUser(User): ...

        And a function that takes a class argument that's a subclass of
        User and returns an instance of the corresponding class::

            def new_user[U](user_class: Type[U]) -> U:
                user = user_class()
                # (Here we could write the user object to a database)
                return user

            joe = new_user(BasicUser)

        At this point the type checker knows that joe has type BasicUser.

    Undefined = PydanticUndefined
    Union = typing.Union
        Union type; Union[X, Y] means either X or Y.

        On Python 3.10 and higher, the | operator
        can also be used to denote unions;
        X | Y means the same thing to the type checker as Union[X, Y].

        To define a union, use e.g. Union[int, str]. Details:
        - The arguments must be types and there must be at least one.
        - None as an argument is a special case and is replaced by
          type(None).
        - Unions of unions are flattened, e.g.::

            assert Union[Union[int, str], float] == Union[int, str, float]

        - Unions of a single argument vanish, e.g.::

            assert Union[int] == int  # The constructor actually returns int

        - Redundant arguments are skipped, e.g.::

            assert Union[int, str, int] == Union[int, str]

        - When comparing unions, the argument order is ignored, e.g.::

            assert Union[int, str] == Union[str, int]

        - You cannot subclass or instantiate a union.
        - You can use Optional[X] as a shorthand for Union[X, None].

    __annotations__ = {'_CLONED_TYPES_CACHE': typing.MutableMapping[typing...

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\backend\lib\site-packages\fastapi\utils.py



================================================================================
Help on module backend.Lib.site-packages.fastapi.dependencies.models in backend.Lib.site-packages.fastapi.dependencies:

NAME
    backend.Lib.site-packages.fastapi.dependencies.models

CLASSES
    builtins.object
        Dependant
        SecurityRequirement

    class Dependant(builtins.object)
     |  Dependant(*, path_params: Optional[List[fastapi._compat.ModelField]] = None, query_params: Optional[List[fastapi._compat.ModelField]] = None, header_params: Optional[List[fastapi._compat.ModelField]] = None, cookie_params: Optional[List[fastapi._compat.ModelField]] = None, body_params: Optional[List[fastapi._compat.ModelField]] = None, dependencies: Optional[List[ForwardRef('Dependant')]] = None, security_schemes: Optional[List[backend.Lib.site-packages.fastapi.dependencies.models.SecurityRequirement]] = None, name: Optional[str] = None, call: Optional[Callable[..., Any]] = None, request_param_name: Optional[str] = None, websocket_param_name: Optional[str] = None, http_connection_param_name: Optional[str] = None, response_param_name: Optional[str] = None, background_tasks_param_name: Optional[str] = None, security_scopes_param_name: Optional[str] = None, security_scopes: Optional[List[str]] = None, use_cache: bool = True, path: Optional[str] = None) -> None
     |
     |  Methods defined here:
     |
     |  __init__(self, *, path_params: Optional[List[fastapi._compat.ModelField]] = None, query_params: Optional[List[fastapi._compat.ModelField]] = None, header_params: Optional[List[fastapi._compat.ModelField]] = None, cookie_params: Optional[List[fastapi._compat.ModelField]] = None, body_params: Optional[List[fastapi._compat.ModelField]] = None, dependencies: Optional[List[ForwardRef('Dependant')]] = None, security_schemes: Optional[List[backend.Lib.site-packages.fastapi.dependencies.models.SecurityRequirement]] = None, name: Optional[str] = None, call: Optional[Callable[..., Any]] = None, request_param_name: Optional[str] = None, websocket_param_name: Optional[str] = None, http_connection_param_name: Optional[str] = None, response_param_name: Optional[str] = None, background_tasks_param_name: Optional[str] = None, security_scopes_param_name: Optional[str] = None, security_scopes: Optional[List[str]] = None, use_cache: bool = True, path: Optional[str] = None) -> None
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

    class SecurityRequirement(builtins.object)
     |  SecurityRequirement(security_scheme: fastapi.security.base.SecurityBase, scopes: Optional[Sequence[str]] = None)
     |
     |  Methods defined here:
     |
     |  __init__(self, security_scheme: fastapi.security.base.SecurityBase, scopes: Optional[Sequence[str]] = None)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

DATA
    Callable = typing.Callable
        Deprecated alias to collections.abc.Callable.

        Callable[[int], str] signifies a function that takes a single
        parameter of type int and returns a str.

        The subscription syntax must always be used with exactly two
        values: the argument list and the return type.
        The argument list must be a list of types, a ParamSpec,
        Concatenate or ellipsis. The return type must be a single type.

        There is no syntax to indicate optional or keyword arguments;
        such function types are rarely used as callback types.

    List = typing.List
        A generic version of list.

    Optional = typing.Optional
        Optional[X] is equivalent to Union[X, None].

    Sequence = typing.Sequence
        A generic version of collections.abc.Sequence.

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\backend\lib\site-packages\fastapi\dependencies\models.py



================================================================================
Help on module backend.Lib.site-packages.fastapi.dependencies.utils in backend.Lib.site-packages.fastapi.dependencies:

NAME
    backend.Lib.site-packages.fastapi.dependencies.utils

FUNCTIONS
    add_non_field_param_to_dependency(*, param_name: str, type_annotation: Any, dependant: fastapi.dependencies.models.Dependant) -> Optional[bool]

    add_param_to_fields(*, field: fastapi._compat.ModelField, dependant: fastapi.dependencies.models.Dependant) -> None

    analyze_param(*, param_name: str, annotation: Any, value: Any, is_path_param: bool) -> Tuple[Any, Optional[fastapi.params.Depends], Optional[fastapi._compat.ModelField]]

    check_file_field(field: fastapi._compat.ModelField) -> None

    get_body_field(*, dependant: fastapi.dependencies.models.Dependant, name: str) -> Optional[fastapi._compat.ModelField]

    get_dependant(*, path: str, call: Callable[..., Any], name: Optional[str] = None, security_scopes: Optional[List[str]] = None, use_cache: bool = True) -> fastapi.dependencies.models.Dependant

    get_flat_dependant(dependant: fastapi.dependencies.models.Dependant, *, skip_repeats: bool = False, visited: Optional[List[Tuple[Optional[Callable[..., Any]], Tuple[str, ...]]]] = None) -> fastapi.dependencies.models.Dependant

    get_flat_params(dependant: fastapi.dependencies.models.Dependant) -> List[fastapi._compat.ModelField]

    get_param_sub_dependant(*, param_name: str, depends: fastapi.params.Depends, path: str, security_scopes: Optional[List[str]] = None) -> fastapi.dependencies.models.Dependant

    get_parameterless_sub_dependant(*, depends: fastapi.params.Depends, path: str) -> fastapi.dependencies.models.Dependant

    get_sub_dependant(*, depends: fastapi.params.Depends, dependency: Callable[..., Any], path: str, name: Optional[str] = None, security_scopes: Optional[List[str]] = None) -> fastapi.dependencies.models.Dependant

    get_typed_annotation(annotation: Any, globalns: Dict[str, Any]) -> Any

    get_typed_return_annotation(call: Callable[..., Any]) -> Any

    get_typed_signature(call: Callable[..., Any]) -> inspect.Signature

    is_async_gen_callable(call: Callable[..., Any]) -> bool

    is_body_param(*, param_field: fastapi._compat.ModelField, is_path_param: bool) -> bool

    is_coroutine_callable(call: Callable[..., Any]) -> bool

    is_gen_callable(call: Callable[..., Any]) -> bool

    async request_body_to_args(required_params: List[fastapi._compat.ModelField], received_body: Union[Dict[str, Any], starlette.datastructures.FormData, NoneType]) -> Tuple[Dict[str, Any], List[Dict[str, Any]]]

    request_params_to_args(required_params: Sequence[fastapi._compat.ModelField], received_params: Union[Mapping[str, Any], starlette.datastructures.QueryParams, starlette.datastructures.Headers]) -> Tuple[Dict[str, Any], List[Any]]

    async solve_dependencies(*, request: Union[starlette.requests.Request, starlette.websockets.WebSocket], dependant: fastapi.dependencies.models.Dependant, body: Union[Dict[str, Any], starlette.datastructures.FormData, NoneType] = None, background_tasks: Optional[starlette.background.BackgroundTasks] = None, response: Optional[starlette.responses.Response] = None, dependency_overrides_provider: Optional[Any] = None, dependency_cache: Optional[Dict[Tuple[Callable[..., Any], Tuple[str]], Any]] = None, async_exit_stack: contextlib.AsyncExitStack) -> Tuple[Dict[str, Any], List[Any], Optional[starlette.background.BackgroundTasks], starlette.responses.Response, Dict[Tuple[Callable[..., Any], Tuple[str]], Any]]

    async solve_generator(*, call: Callable[..., Any], stack: contextlib.AsyncExitStack, sub_values: Dict[str, Any]) -> Any

DATA
    CacheKey = typing.Tuple[typing.Optional[typing.Callable[..., typing.An...
    Callable = typing.Callable
        Deprecated alias to collections.abc.Callable.

        Callable[[int], str] signifies a function that takes a single
        parameter of type int and returns a str.

        The subscription syntax must always be used with exactly two
        values: the argument list and the return type.
        The argument list must be a list of types, a ParamSpec,
        Concatenate or ellipsis. The return type must be a single type.

        There is no syntax to indicate optional or keyword arguments;
        such function types are rarely used as callback types.

    Coroutine = typing.Coroutine
        A generic version of collections.abc.Coroutine.

    Dict = typing.Dict
        A generic version of dict.

    List = typing.List
        A generic version of list.

    Mapping = typing.Mapping
        A generic version of collections.abc.Mapping.

    Optional = typing.Optional
        Optional[X] is equivalent to Union[X, None].

    PYDANTIC_V2 = True
    Required = PydanticUndefined
    Sequence = typing.Sequence
        A generic version of collections.abc.Sequence.

    Tuple = typing.Tuple
        Deprecated alias to builtins.tuple.

        Tuple[X, Y] is the cross-product type of X and Y.

        Example: Tuple[T1, T2] is a tuple of two elements corresponding
        to type variables T1 and T2.  Tuple[int, float, str] is a tuple
        of an int, a float and a string.

        To specify a variable-length tuple of homogeneous type, use Tuple[T, ...].

    Type = typing.Type
        Deprecated alias to builtins.type.

        builtins.type or typing.Type can be used to annotate class objects.
        For example, suppose we have the following classes::

            class User: ...  # Abstract base for User classes
            class BasicUser(User): ...
            class ProUser(User): ...
            class TeamUser(User): ...

        And a function that takes a class argument that's a subclass of
        User and returns an instance of the corresponding class::

            def new_user[U](user_class: Type[U]) -> U:
                user = user_class()
                # (Here we could write the user object to a database)
                return user

            joe = new_user(BasicUser)

        At this point the type checker knows that joe has type BasicUser.

    Undefined = PydanticUndefined
    Union = typing.Union
        Union type; Union[X, Y] means either X or Y.

        On Python 3.10 and higher, the | operator
        can also be used to denote unions;
        X | Y means the same thing to the type checker as Union[X, Y].

        To define a union, use e.g. Union[int, str]. Details:
        - The arguments must be types and there must be at least one.
        - None as an argument is a special case and is replaced by
          type(None).
        - Unions of unions are flattened, e.g.::

            assert Union[Union[int, str], float] == Union[int, str, float]

        - Unions of a single argument vanish, e.g.::

            assert Union[int] == int  # The constructor actually returns int

        - Redundant arguments are skipped, e.g.::

            assert Union[int, str, int] == Union[int, str]

        - When comparing unions, the argument order is ignored, e.g.::

            assert Union[int, str] == Union[str, int]

        - You cannot subclass or instantiate a union.
        - You can use Optional[X] as a shorthand for Union[X, None].

    logger = <Logger fastapi (WARNING)>
    multipart_incorrect_install_error = 'Form data requires "python-multip...
    multipart_not_installed_error = 'Form data requires "python-multipart"...
    sequence_types = (typing.Sequence, typing.List, <class 'list'>, typing...

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\backend\lib\site-packages\fastapi\dependencies\utils.py



================================================================================
Help on module backend.Lib.site-packages.fastapi.openapi.models in backend.Lib.site-packages.fastapi.openapi:

NAME
    backend.Lib.site-packages.fastapi.openapi.models

CLASSES
    builtins.dict(builtins.object)
        Example
    enum.Enum(builtins.object)
        APIKeyIn
        ParameterInType
        SecuritySchemeType
    pydantic.main.BaseModel(builtins.object)
        BaseModelWithConfig
            Components
            Contact
            Encoding
            ExternalDocumentation
            Info
            License
            Link
            MediaType
            OAuthFlow
                OAuthFlowAuthorizationCode
                OAuthFlowClientCredentials
                OAuthFlowImplicit
                OAuthFlowPassword
            OAuthFlows
            OpenAPI
            Operation
            ParameterBase
                Header
                Parameter
            PathItem
            RequestBody
            Response
            Schema
            SecurityBase
                APIKey
                HTTPBase
                    HTTPBearer
                OAuth2
                OpenIdConnect
            Server
            ServerVariable
            Tag
            XML
        Discriminator
        Reference

    class APIKey(SecurityBase)
     |  APIKey(*, type: backend.Lib.site-packages.fastapi.openapi.models.SecuritySchemeType = <SecuritySchemeType.apiKey: 'apiKey'>, description: Optional[str] = None, in_: backend.Lib.site-packages.fastapi.openapi.models.APIKeyIn, name: str, **extra_data: Any) -> None
     |
     |  Method resolution order:
     |      APIKey
     |      SecurityBase
     |      BaseModelWithConfig
     |      pydantic.main.BaseModel
     |      builtins.object
     |
     |  Data and other attributes defined here:
     |
     |  __abstractmethods__ = frozenset()
     |
     |  __annotations__ = {'in_': <enum 'APIKeyIn'>, 'name': <class 'str'>, 't...
     |
     |  __class_vars__ = set()
     |
     |  __private_attributes__ = {}
     |
     |  __pydantic_complete__ = True
     |
     |  __pydantic_core_schema__ = {'cls': <class 'backend.Lib.site-packages.f...
     |
     |  __pydantic_custom_init__ = False
     |
     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...
     |
     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...
     |
     |  __pydantic_parent_namespace__ = {'APIKeyIn': <pydantic._internal._mode...
     |
     |  __pydantic_post_init__ = None
     |
     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(
     |      Model...
     |
     |  __pydantic_validator__ = SchemaValidator(title="APIKey", validator=Mod...
     |
     |  __signature__ = <Signature (*, type: backend.Lib.site-packages.f....AP...
     |
     |  model_computed_fields = {}
     |
     |  model_config = {'extra': 'allow'}
     |
     |  model_fields = {'description': FieldInfo(annotation=Union[str, NoneTyp...
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from BaseModelWithConfig:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from pydantic.main.BaseModel:
     |
     |  __copy__(self) -> 'Self'
     |      Returns a shallow copy of the model.
     |
     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'
     |      Returns a deep copy of the model.
     |
     |  __delattr__(self, item: 'str') -> 'Any'
     |      Implement delattr(self, name).
     |
     |  __eq__(self, other: 'Any') -> 'bool'
     |      Return self==value.
     |
     |  __getattr__(self, item: 'str') -> 'Any'
     |
     |  __getstate__(self) -> 'dict[Any, Any]'
     |      Helper for pickle.
     |
     |  __init__(self, /, **data: 'Any') -> 'None'
     |      Create a new model by parsing and validating input data from keyword arguments.
     |
     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be
     |      validated to form a valid model.
     |
     |      `self` is explicitly positional-only to allow `self` as a field name.
     |
     |  __iter__(self) -> 'TupleGenerator'
     |      So `dict(model)` works.
     |
     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation
     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.
     |
     |  __repr__(self) -> 'str'
     |      Return repr(self).
     |
     |  __repr_args__(self) -> '_repr.ReprArgs'
     |
     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation
     |      Name of the instance's class, used in __repr__.
     |
     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation
     |
     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation
     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.
     |
     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'
     |
     |  __str__(self) -> 'str'
     |      Return str(self).
     |
     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Returns a copy of the model.
     |
     |      !!! warning "Deprecated"
     |          This method is now deprecated; use `model_copy` instead.
     |
     |      If you need `include` or `exclude`, use:
     |
     |      ```py
     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)
     |      data = {**data, **(update or {})}
     |      copied = self.model_validate(data)
     |      ```
     |
     |      Args:
     |          include: Optional set or mapping specifying which fields to include in the copied model.
     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.
     |          update: Optional dictionary of field-value pairs to override field values in the copied model.
     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.
     |
     |      Returns:
     |          A copy of the model with included, excluded and updated fields as specified.
     |
     |  dict(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'
     |
     |  json(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'
     |
     |  model_copy(self, *, update: 'dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#model_copy
     |
     |      Returns a copy of the model.
     |
     |      Args:
     |          update: Values to change/add in the new model. Note: the data is not validated
     |              before creating the new model. You should trust this data.
     |          deep: Set to `True` to make a deep copy of the model.
     |
     |      Returns:
     |          New model instance.
     |
     |  model_dump(self, *, mode: "Literal['json', 'python'] | str" = 'python', include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump
     |
     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.
     |
     |      Args:
     |          mode: The mode in which `to_python` should run.
     |              If mode is 'json', the output will only contain JSON serializable types.
     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.
     |          include: A set of fields to include in the output.
     |          exclude: A set of fields to exclude from the output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to use the field's alias in the dictionary key if defined.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A dictionary representation of the model.
     |
     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'str'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump_json
     |
     |      Generates a JSON representation of the model using Pydantic's `to_json` method.
     |
     |      Args:
     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.
     |          include: Field(s) to include in the JSON output.
     |          exclude: Field(s) to exclude from the JSON output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to serialize using field aliases.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A JSON string representation of the model.
     |
     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'
     |      Override this method to perform additional initialization after `__init__` and `model_construct`.
     |      This is useful if you want to do some validation that requires the entire model to be initialized.
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from pydantic.main.BaseModel:
     |
     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'
     |
     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'
     |      Hook into generating the model's CoreSchema.
     |
     |      Args:
     |          source: The class we are generating a schema for.
     |              This will generally be the same as the `cls` argument if this is a classmethod.
     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.
     |
     |      Returns:
     |          A `pydantic-core` `CoreSchema`.
     |
     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'
     |      Hook into generating the model's JSON schema.
     |
     |      Args:
     |          core_schema: A `pydantic-core` CoreSchema.
     |              You can ignore this argument and call the handler with a new CoreSchema,
     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),
     |              or just call the handler with the original schema.
     |          handler: Call into Pydantic's internal JSON schema generation.
     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema
     |              generation fails.
     |              Since this gets called by `BaseModel.model_json_schema` you can override the
     |              `schema_generator` argument to that function to change JSON schema generation globally
     |              for a type.
     |
     |      Returns:
     |          A JSON schema, as a Python object.
     |
     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'
     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`
     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will
     |      be present when this is called.
     |
     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,
     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that
     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.
     |
     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,
     |      any kwargs passed to the class definition that aren't used internally by pydantic.
     |
     |      Args:
     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally
     |              by pydantic.
     |
     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |
     |  from_orm(obj: 'Any') -> 'Self'
     |
     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |      Creates a new instance of the `Model` class with validated data.
     |
     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.
     |      Default values are respected, but no other validation is performed.
     |
     |      !!! note
     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.
     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`
     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.
     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in
     |          an error if extra values are passed, but they will be ignored.
     |
     |      Args:
     |          _fields_set: The set of field names accepted for the Model instance.
     |          values: Trusted or pre-validated data dictionary.
     |
     |      Returns:
     |          A new instance of the `Model` class with validated data.
     |
     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'
     |      Generates a JSON schema for a model class.
     |
     |      Args:
     |          by_alias: Whether to use attribute aliases or not.
     |          ref_template: The reference template.
     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of
     |              `GenerateJsonSchema` with your desired modifications
     |          mode: The mode in which to generate the schema.
     |
     |      Returns:
     |          The JSON schema for the given model class.
     |
     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'
     |      Compute the class name for parametrizations of generic classes.
     |
     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.
     |
     |      Args:
     |          params: Tuple of types of the class. Given a generic class
     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,
     |              the value `(str, int)` would be passed to `params`.
     |
     |      Returns:
     |          String representing the new class where `params` are passed to `cls` as type variables.
     |
     |      Raises:
     |          TypeError: Raised when trying to generate concrete names for non-generic models.
     |
     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'dict[str, Any] | None' = None) -> 'bool | None'
     |      Try to rebuild the pydantic-core schema for the model.
     |
     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during
     |      the initial attempt to build the schema, and automatic rebuilding fails.
     |
     |      Args:
     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.
     |          raise_errors: Whether to raise errors, defaults to `True`.
     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.
     |          _types_namespace: The types namespace, defaults to `None`.
     |
     |      Returns:
     |          Returns `None` if the schema is already "complete" and rebuilding was not required.
     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.
     |
     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate a pydantic model instance.
     |
     |      Args:
     |          obj: The object to validate.
     |          strict: Whether to enforce types strictly.
     |          from_attributes: Whether to extract data from object attributes.
     |          context: Additional context to pass to the validator.
     |
     |      Raises:
     |          ValidationError: If the object could not be validated.
     |
     |      Returns:
     |          The validated model instance.
     |
     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/json/#json-parsing
     |
     |      Validate the given JSON data against the Pydantic model.
     |
     |      Args:
     |          json_data: The JSON data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |      Raises:
     |          ValueError: If `json_data` is not a JSON string.
     |
     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate the given object with string data against the Pydantic model.
     |
     |      Args:
     |          obj: The object containing string data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  parse_obj(obj: 'Any') -> 'Self'
     |
     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'
     |
     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'
     |
     |  update_forward_refs(**localns: 'Any') -> 'None'
     |
     |  validate(value: 'Any') -> 'Self'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from pydantic.main.BaseModel:
     |
     |  __fields_set__
     |
     |  model_extra
     |      Get extra fields set during validation.
     |
     |      Returns:
     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `"allow"`.
     |
     |  model_fields_set
     |      Returns the set of fields that have been explicitly set on this model instance.
     |
     |      Returns:
     |          A set of strings representing the fields that have been set,
     |              i.e. that were not filled from defaults.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from pydantic.main.BaseModel:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __pydantic_extra__
     |
     |  __pydantic_fields_set__
     |
     |  __pydantic_private__
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from pydantic.main.BaseModel:
     |
     |  __hash__ = None
     |
     |  __pydantic_root_model__ = False

    class APIKeyIn(enum.Enum)
     |  APIKeyIn(*values)
     |
     |  Method resolution order:
     |      APIKeyIn
     |      enum.Enum
     |      builtins.object
     |
     |  Data and other attributes defined here:
     |
     |  cookie = <APIKeyIn.cookie: 'cookie'>
     |
     |  header = <APIKeyIn.header: 'header'>
     |
     |  query = <APIKeyIn.query: 'query'>
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from enum.Enum:
     |
     |  name
     |      The name of the Enum member.
     |
     |  value
     |      The value of the Enum member.
     |
     |  ----------------------------------------------------------------------
     |  Static methods inherited from enum.EnumType:
     |
     |  __contains__(value)
     |      Return True if `value` is in `cls`.
     |
     |      `value` is in `cls` if:
     |      1) `value` is a member of `cls`, or
     |      2) `value` is the value of one of the `cls`'s members.
     |
     |  __getitem__(name)
     |      Return the member matching `name`.
     |
     |  __iter__()
     |      Return members in definition order.
     |
     |  __len__()
     |      Return the number of members (no aliases)
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from enum.EnumType:
     |
     |  __members__
     |      Returns a mapping of member name->value.
     |
     |      This mapping lists all enum members, including aliases. Note that this
     |      is a read-only view of the internal mapping.

    class BaseModelWithConfig(pydantic.main.BaseModel)
     |  BaseModelWithConfig(**extra_data: Any) -> None
     |
     |  Method resolution order:
     |      BaseModelWithConfig
     |      pydantic.main.BaseModel
     |      builtins.object
     |
     |  Data descriptors defined here:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  __abstractmethods__ = frozenset()
     |
     |  __annotations__ = {}
     |
     |  __class_vars__ = set()
     |
     |  __private_attributes__ = {}
     |
     |  __pydantic_complete__ = True
     |
     |  __pydantic_core_schema__ = {'cls': <class 'backend.Lib.site-packages.f...
     |
     |  __pydantic_custom_init__ = False
     |
     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...
     |
     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...
     |
     |  __pydantic_parent_namespace__ = {'Annotated': <pydantic._internal._mod...
     |
     |  __pydantic_post_init__ = None
     |
     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(
     |      Model...
     |
     |  __pydantic_validator__ = SchemaValidator(title="BaseModelWithConfig", ...
     |
     |  __signature__ = <Signature (**extra_data: Any) -> None>
     |
     |  model_computed_fields = {}
     |
     |  model_config = {'extra': 'allow'}
     |
     |  model_fields = {}
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from pydantic.main.BaseModel:
     |
     |  __copy__(self) -> 'Self'
     |      Returns a shallow copy of the model.
     |
     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'
     |      Returns a deep copy of the model.
     |
     |  __delattr__(self, item: 'str') -> 'Any'
     |      Implement delattr(self, name).
     |
     |  __eq__(self, other: 'Any') -> 'bool'
     |      Return self==value.
     |
     |  __getattr__(self, item: 'str') -> 'Any'
     |
     |  __getstate__(self) -> 'dict[Any, Any]'
     |      Helper for pickle.
     |
     |  __init__(self, /, **data: 'Any') -> 'None'
     |      Create a new model by parsing and validating input data from keyword arguments.
     |
     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be
     |      validated to form a valid model.
     |
     |      `self` is explicitly positional-only to allow `self` as a field name.
     |
     |  __iter__(self) -> 'TupleGenerator'
     |      So `dict(model)` works.
     |
     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation
     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.
     |
     |  __repr__(self) -> 'str'
     |      Return repr(self).
     |
     |  __repr_args__(self) -> '_repr.ReprArgs'
     |
     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation
     |      Name of the instance's class, used in __repr__.
     |
     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation
     |
     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation
     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.
     |
     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'
     |
     |  __str__(self) -> 'str'
     |      Return str(self).
     |
     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Returns a copy of the model.
     |
     |      !!! warning "Deprecated"
     |          This method is now deprecated; use `model_copy` instead.
     |
     |      If you need `include` or `exclude`, use:
     |
     |      ```py
     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)
     |      data = {**data, **(update or {})}
     |      copied = self.model_validate(data)
     |      ```
     |
     |      Args:
     |          include: Optional set or mapping specifying which fields to include in the copied model.
     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.
     |          update: Optional dictionary of field-value pairs to override field values in the copied model.
     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.
     |
     |      Returns:
     |          A copy of the model with included, excluded and updated fields as specified.
     |
     |  dict(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'
     |
     |  json(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'
     |
     |  model_copy(self, *, update: 'dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#model_copy
     |
     |      Returns a copy of the model.
     |
     |      Args:
     |          update: Values to change/add in the new model. Note: the data is not validated
     |              before creating the new model. You should trust this data.
     |          deep: Set to `True` to make a deep copy of the model.
     |
     |      Returns:
     |          New model instance.
     |
     |  model_dump(self, *, mode: "Literal['json', 'python'] | str" = 'python', include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump
     |
     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.
     |
     |      Args:
     |          mode: The mode in which `to_python` should run.
     |              If mode is 'json', the output will only contain JSON serializable types.
     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.
     |          include: A set of fields to include in the output.
     |          exclude: A set of fields to exclude from the output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to use the field's alias in the dictionary key if defined.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A dictionary representation of the model.
     |
     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'str'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump_json
     |
     |      Generates a JSON representation of the model using Pydantic's `to_json` method.
     |
     |      Args:
     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.
     |          include: Field(s) to include in the JSON output.
     |          exclude: Field(s) to exclude from the JSON output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to serialize using field aliases.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A JSON string representation of the model.
     |
     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'
     |      Override this method to perform additional initialization after `__init__` and `model_construct`.
     |      This is useful if you want to do some validation that requires the entire model to be initialized.
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from pydantic.main.BaseModel:
     |
     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'
     |
     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'
     |      Hook into generating the model's CoreSchema.
     |
     |      Args:
     |          source: The class we are generating a schema for.
     |              This will generally be the same as the `cls` argument if this is a classmethod.
     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.
     |
     |      Returns:
     |          A `pydantic-core` `CoreSchema`.
     |
     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'
     |      Hook into generating the model's JSON schema.
     |
     |      Args:
     |          core_schema: A `pydantic-core` CoreSchema.
     |              You can ignore this argument and call the handler with a new CoreSchema,
     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),
     |              or just call the handler with the original schema.
     |          handler: Call into Pydantic's internal JSON schema generation.
     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema
     |              generation fails.
     |              Since this gets called by `BaseModel.model_json_schema` you can override the
     |              `schema_generator` argument to that function to change JSON schema generation globally
     |              for a type.
     |
     |      Returns:
     |          A JSON schema, as a Python object.
     |
     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'
     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`
     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will
     |      be present when this is called.
     |
     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,
     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that
     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.
     |
     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,
     |      any kwargs passed to the class definition that aren't used internally by pydantic.
     |
     |      Args:
     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally
     |              by pydantic.
     |
     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |
     |  from_orm(obj: 'Any') -> 'Self'
     |
     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |      Creates a new instance of the `Model` class with validated data.
     |
     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.
     |      Default values are respected, but no other validation is performed.
     |
     |      !!! note
     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.
     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`
     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.
     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in
     |          an error if extra values are passed, but they will be ignored.
     |
     |      Args:
     |          _fields_set: The set of field names accepted for the Model instance.
     |          values: Trusted or pre-validated data dictionary.
     |
     |      Returns:
     |          A new instance of the `Model` class with validated data.
     |
     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'
     |      Generates a JSON schema for a model class.
     |
     |      Args:
     |          by_alias: Whether to use attribute aliases or not.
     |          ref_template: The reference template.
     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of
     |              `GenerateJsonSchema` with your desired modifications
     |          mode: The mode in which to generate the schema.
     |
     |      Returns:
     |          The JSON schema for the given model class.
     |
     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'
     |      Compute the class name for parametrizations of generic classes.
     |
     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.
     |
     |      Args:
     |          params: Tuple of types of the class. Given a generic class
     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,
     |              the value `(str, int)` would be passed to `params`.
     |
     |      Returns:
     |          String representing the new class where `params` are passed to `cls` as type variables.
     |
     |      Raises:
     |          TypeError: Raised when trying to generate concrete names for non-generic models.
     |
     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'dict[str, Any] | None' = None) -> 'bool | None'
     |      Try to rebuild the pydantic-core schema for the model.
     |
     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during
     |      the initial attempt to build the schema, and automatic rebuilding fails.
     |
     |      Args:
     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.
     |          raise_errors: Whether to raise errors, defaults to `True`.
     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.
     |          _types_namespace: The types namespace, defaults to `None`.
     |
     |      Returns:
     |          Returns `None` if the schema is already "complete" and rebuilding was not required.
     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.
     |
     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate a pydantic model instance.
     |
     |      Args:
     |          obj: The object to validate.
     |          strict: Whether to enforce types strictly.
     |          from_attributes: Whether to extract data from object attributes.
     |          context: Additional context to pass to the validator.
     |
     |      Raises:
     |          ValidationError: If the object could not be validated.
     |
     |      Returns:
     |          The validated model instance.
     |
     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/json/#json-parsing
     |
     |      Validate the given JSON data against the Pydantic model.
     |
     |      Args:
     |          json_data: The JSON data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |      Raises:
     |          ValueError: If `json_data` is not a JSON string.
     |
     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate the given object with string data against the Pydantic model.
     |
     |      Args:
     |          obj: The object containing string data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  parse_obj(obj: 'Any') -> 'Self'
     |
     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'
     |
     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'
     |
     |  update_forward_refs(**localns: 'Any') -> 'None'
     |
     |  validate(value: 'Any') -> 'Self'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from pydantic.main.BaseModel:
     |
     |  __fields_set__
     |
     |  model_extra
     |      Get extra fields set during validation.
     |
     |      Returns:
     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `"allow"`.
     |
     |  model_fields_set
     |      Returns the set of fields that have been explicitly set on this model instance.
     |
     |      Returns:
     |          A set of strings representing the fields that have been set,
     |              i.e. that were not filled from defaults.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from pydantic.main.BaseModel:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __pydantic_extra__
     |
     |  __pydantic_fields_set__
     |
     |  __pydantic_private__
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from pydantic.main.BaseModel:
     |
     |  __hash__ = None
     |
     |  __pydantic_root_model__ = False

    class Components(BaseModelWithConfig)
     |  Components(*, schemas: Optional[Dict[str, Union[backend.Lib.site-packages.fastapi.openapi.models.Schema, backend.Lib.site-packages.fastapi.openapi.models.Reference]]] = None, responses: Optional[Dict[str, Union[backend.Lib.site-packages.fastapi.openapi.models.Response, backend.Lib.site-packages.fastapi.openapi.models.Reference]]] = None, parameters: Optional[Dict[str, Union[backend.Lib.site-packages.fastapi.openapi.models.Parameter, backend.Lib.site-packages.fastapi.openapi.models.Reference]]] = None, examples: Optional[Dict[str, Union[backend.Lib.site-packages.fastapi.openapi.models.Example, backend.Lib.site-packages.fastapi.openapi.models.Reference]]] = None, requestBodies: Optional[Dict[str, Union[backend.Lib.site-packages.fastapi.openapi.models.RequestBody, backend.Lib.site-packages.fastapi.openapi.models.Reference]]] = None, headers: Optional[Dict[str, Union[backend.Lib.site-packages.fastapi.openapi.models.Header, backend.Lib.site-packages.fastapi.openapi.models.Reference]]] = None, securitySchemes: Optional[Dict[str, Union[backend.Lib.site-packages.fastapi.openapi.models.APIKey, backend.Lib.site-packages.fastapi.openapi.models.HTTPBase, backend.Lib.site-packages.fastapi.openapi.models.OAuth2, backend.Lib.site-packages.fastapi.openapi.models.OpenIdConnect, backend.Lib.site-packages.fastapi.openapi.models.HTTPBearer, backend.Lib.site-packages.fastapi.openapi.models.Reference]]] = None, links: Optional[Dict[str, Union[backend.Lib.site-packages.fastapi.openapi.models.Link, backend.Lib.site-packages.fastapi.openapi.models.Reference]]] = None, callbacks: Optional[Dict[str, Union[Dict[str, backend.Lib.site-packages.fastapi.openapi.models.PathItem], backend.Lib.site-packages.fastapi.openapi.models.Reference, Any]]] = None, pathItems: Optional[Dict[str, Union[backend.Lib.site-packages.fastapi.openapi.models.PathItem, backend.Lib.site-packages.fastapi.openapi.models.Reference]]] = None, **extra_data: Any) -> None
     |
     |  Method resolution order:
     |      Components
     |      BaseModelWithConfig
     |      pydantic.main.BaseModel
     |      builtins.object
     |
     |  Data and other attributes defined here:
     |
     |  __abstractmethods__ = frozenset()
     |
     |  __annotations__ = {'callbacks': typing.Optional[typing.Dict[str, typin...
     |
     |  __class_vars__ = set()
     |
     |  __private_attributes__ = {}
     |
     |  __pydantic_complete__ = True
     |
     |  __pydantic_core_schema__ = {'definitions': [{'cls': <class 'backend.Li...
     |
     |  __pydantic_custom_init__ = False
     |
     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...
     |
     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...
     |
     |  __pydantic_parent_namespace__ = {'APIKey': <pydantic._internal._model_...
     |
     |  __pydantic_post_init__ = None
     |
     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(
     |      Model...
     |
     |  __pydantic_validator__ = SchemaValidator(title="Components", validator...
     |
     |  __signature__ = <Signature (*, schemas: Optional[Dict[str, Union....Re...
     |
     |  model_computed_fields = {}
     |
     |  model_config = {'extra': 'allow'}
     |
     |  model_fields = {'callbacks': FieldInfo(annotation=Union[Dict[str, Unio...
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from BaseModelWithConfig:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from pydantic.main.BaseModel:
     |
     |  __copy__(self) -> 'Self'
     |      Returns a shallow copy of the model.
     |
     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'
     |      Returns a deep copy of the model.
     |
     |  __delattr__(self, item: 'str') -> 'Any'
     |      Implement delattr(self, name).
     |
     |  __eq__(self, other: 'Any') -> 'bool'
     |      Return self==value.
     |
     |  __getattr__(self, item: 'str') -> 'Any'
     |
     |  __getstate__(self) -> 'dict[Any, Any]'
     |      Helper for pickle.
     |
     |  __init__(self, /, **data: 'Any') -> 'None'
     |      Create a new model by parsing and validating input data from keyword arguments.
     |
     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be
     |      validated to form a valid model.
     |
     |      `self` is explicitly positional-only to allow `self` as a field name.
     |
     |  __iter__(self) -> 'TupleGenerator'
     |      So `dict(model)` works.
     |
     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation
     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.
     |
     |  __repr__(self) -> 'str'
     |      Return repr(self).
     |
     |  __repr_args__(self) -> '_repr.ReprArgs'
     |
     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation
     |      Name of the instance's class, used in __repr__.
     |
     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation
     |
     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation
     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.
     |
     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'
     |
     |  __str__(self) -> 'str'
     |      Return str(self).
     |
     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Returns a copy of the model.
     |
     |      !!! warning "Deprecated"
     |          This method is now deprecated; use `model_copy` instead.
     |
     |      If you need `include` or `exclude`, use:
     |
     |      ```py
     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)
     |      data = {**data, **(update or {})}
     |      copied = self.model_validate(data)
     |      ```
     |
     |      Args:
     |          include: Optional set or mapping specifying which fields to include in the copied model.
     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.
     |          update: Optional dictionary of field-value pairs to override field values in the copied model.
     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.
     |
     |      Returns:
     |          A copy of the model with included, excluded and updated fields as specified.
     |
     |  dict(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'
     |
     |  json(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'
     |
     |  model_copy(self, *, update: 'dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#model_copy
     |
     |      Returns a copy of the model.
     |
     |      Args:
     |          update: Values to change/add in the new model. Note: the data is not validated
     |              before creating the new model. You should trust this data.
     |          deep: Set to `True` to make a deep copy of the model.
     |
     |      Returns:
     |          New model instance.
     |
     |  model_dump(self, *, mode: "Literal['json', 'python'] | str" = 'python', include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump
     |
     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.
     |
     |      Args:
     |          mode: The mode in which `to_python` should run.
     |              If mode is 'json', the output will only contain JSON serializable types.
     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.
     |          include: A set of fields to include in the output.
     |          exclude: A set of fields to exclude from the output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to use the field's alias in the dictionary key if defined.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A dictionary representation of the model.
     |
     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'str'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump_json
     |
     |      Generates a JSON representation of the model using Pydantic's `to_json` method.
     |
     |      Args:
     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.
     |          include: Field(s) to include in the JSON output.
     |          exclude: Field(s) to exclude from the JSON output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to serialize using field aliases.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A JSON string representation of the model.
     |
     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'
     |      Override this method to perform additional initialization after `__init__` and `model_construct`.
     |      This is useful if you want to do some validation that requires the entire model to be initialized.
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from pydantic.main.BaseModel:
     |
     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'
     |
     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'
     |      Hook into generating the model's CoreSchema.
     |
     |      Args:
     |          source: The class we are generating a schema for.
     |              This will generally be the same as the `cls` argument if this is a classmethod.
     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.
     |
     |      Returns:
     |          A `pydantic-core` `CoreSchema`.
     |
     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'
     |      Hook into generating the model's JSON schema.
     |
     |      Args:
     |          core_schema: A `pydantic-core` CoreSchema.
     |              You can ignore this argument and call the handler with a new CoreSchema,
     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),
     |              or just call the handler with the original schema.
     |          handler: Call into Pydantic's internal JSON schema generation.
     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema
     |              generation fails.
     |              Since this gets called by `BaseModel.model_json_schema` you can override the
     |              `schema_generator` argument to that function to change JSON schema generation globally
     |              for a type.
     |
     |      Returns:
     |          A JSON schema, as a Python object.
     |
     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'
     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`
     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will
     |      be present when this is called.
     |
     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,
     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that
     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.
     |
     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,
     |      any kwargs passed to the class definition that aren't used internally by pydantic.
     |
     |      Args:
     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally
     |              by pydantic.
     |
     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |
     |  from_orm(obj: 'Any') -> 'Self'
     |
     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |      Creates a new instance of the `Model` class with validated data.
     |
     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.
     |      Default values are respected, but no other validation is performed.
     |
     |      !!! note
     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.
     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`
     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.
     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in
     |          an error if extra values are passed, but they will be ignored.
     |
     |      Args:
     |          _fields_set: The set of field names accepted for the Model instance.
     |          values: Trusted or pre-validated data dictionary.
     |
     |      Returns:
     |          A new instance of the `Model` class with validated data.
     |
     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'
     |      Generates a JSON schema for a model class.
     |
     |      Args:
     |          by_alias: Whether to use attribute aliases or not.
     |          ref_template: The reference template.
     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of
     |              `GenerateJsonSchema` with your desired modifications
     |          mode: The mode in which to generate the schema.
     |
     |      Returns:
     |          The JSON schema for the given model class.
     |
     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'
     |      Compute the class name for parametrizations of generic classes.
     |
     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.
     |
     |      Args:
     |          params: Tuple of types of the class. Given a generic class
     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,
     |              the value `(str, int)` would be passed to `params`.
     |
     |      Returns:
     |          String representing the new class where `params` are passed to `cls` as type variables.
     |
     |      Raises:
     |          TypeError: Raised when trying to generate concrete names for non-generic models.
     |
     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'dict[str, Any] | None' = None) -> 'bool | None'
     |      Try to rebuild the pydantic-core schema for the model.
     |
     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during
     |      the initial attempt to build the schema, and automatic rebuilding fails.
     |
     |      Args:
     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.
     |          raise_errors: Whether to raise errors, defaults to `True`.
     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.
     |          _types_namespace: The types namespace, defaults to `None`.
     |
     |      Returns:
     |          Returns `None` if the schema is already "complete" and rebuilding was not required.
     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.
     |
     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate a pydantic model instance.
     |
     |      Args:
     |          obj: The object to validate.
     |          strict: Whether to enforce types strictly.
     |          from_attributes: Whether to extract data from object attributes.
     |          context: Additional context to pass to the validator.
     |
     |      Raises:
     |          ValidationError: If the object could not be validated.
     |
     |      Returns:
     |          The validated model instance.
     |
     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/json/#json-parsing
     |
     |      Validate the given JSON data against the Pydantic model.
     |
     |      Args:
     |          json_data: The JSON data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |      Raises:
     |          ValueError: If `json_data` is not a JSON string.
     |
     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate the given object with string data against the Pydantic model.
     |
     |      Args:
     |          obj: The object containing string data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  parse_obj(obj: 'Any') -> 'Self'
     |
     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'
     |
     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'
     |
     |  update_forward_refs(**localns: 'Any') -> 'None'
     |
     |  validate(value: 'Any') -> 'Self'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from pydantic.main.BaseModel:
     |
     |  __fields_set__
     |
     |  model_extra
     |      Get extra fields set during validation.
     |
     |      Returns:
     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `"allow"`.
     |
     |  model_fields_set
     |      Returns the set of fields that have been explicitly set on this model instance.
     |
     |      Returns:
     |          A set of strings representing the fields that have been set,
     |              i.e. that were not filled from defaults.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from pydantic.main.BaseModel:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __pydantic_extra__
     |
     |  __pydantic_fields_set__
     |
     |  __pydantic_private__
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from pydantic.main.BaseModel:
     |
     |  __hash__ = None
     |
     |  __pydantic_root_model__ = False

    class Contact(BaseModelWithConfig)
     |  Contact(*, name: Optional[str] = None, url: Optional[pydantic_core._pydantic_core.Url] = None, email: Optional[pydantic.networks.EmailStr] = None, **extra_data: Any) -> None
     |
     |  Method resolution order:
     |      Contact
     |      BaseModelWithConfig
     |      pydantic.main.BaseModel
     |      builtins.object
     |
     |  Data and other attributes defined here:
     |
     |  __abstractmethods__ = frozenset()
     |
     |  __annotations__ = {'email': typing.Optional[pydantic.networks.EmailStr...
     |
     |  __class_vars__ = set()
     |
     |  __private_attributes__ = {}
     |
     |  __pydantic_complete__ = True
     |
     |  __pydantic_core_schema__ = {'cls': <class 'backend.Lib.site-packages.f...
     |
     |  __pydantic_custom_init__ = False
     |
     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...
     |
     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...
     |
     |  __pydantic_parent_namespace__ = {'Annotated': <pydantic._internal._mod...
     |
     |  __pydantic_post_init__ = None
     |
     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(
     |      Model...
     |
     |  __pydantic_validator__ = SchemaValidator(title="Contact", validator=Mo...
     |
     |  __signature__ = <Signature (*, name: Optional[str] = None, url: ...rks...
     |
     |  model_computed_fields = {}
     |
     |  model_config = {'extra': 'allow'}
     |
     |  model_fields = {'email': FieldInfo(annotation=Union[EmailStr, NoneType...
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from BaseModelWithConfig:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from pydantic.main.BaseModel:
     |
     |  __copy__(self) -> 'Self'
     |      Returns a shallow copy of the model.
     |
     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'
     |      Returns a deep copy of the model.
     |
     |  __delattr__(self, item: 'str') -> 'Any'
     |      Implement delattr(self, name).
     |
     |  __eq__(self, other: 'Any') -> 'bool'
     |      Return self==value.
     |
     |  __getattr__(self, item: 'str') -> 'Any'
     |
     |  __getstate__(self) -> 'dict[Any, Any]'
     |      Helper for pickle.
     |
     |  __init__(self, /, **data: 'Any') -> 'None'
     |      Create a new model by parsing and validating input data from keyword arguments.
     |
     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be
     |      validated to form a valid model.
     |
     |      `self` is explicitly positional-only to allow `self` as a field name.
     |
     |  __iter__(self) -> 'TupleGenerator'
     |      So `dict(model)` works.
     |
     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation
     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.
     |
     |  __repr__(self) -> 'str'
     |      Return repr(self).
     |
     |  __repr_args__(self) -> '_repr.ReprArgs'
     |
     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation
     |      Name of the instance's class, used in __repr__.
     |
     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation
     |
     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation
     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.
     |
     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'
     |
     |  __str__(self) -> 'str'
     |      Return str(self).
     |
     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Returns a copy of the model.
     |
     |      !!! warning "Deprecated"
     |          This method is now deprecated; use `model_copy` instead.
     |
     |      If you need `include` or `exclude`, use:
     |
     |      ```py
     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)
     |      data = {**data, **(update or {})}
     |      copied = self.model_validate(data)
     |      ```
     |
     |      Args:
     |          include: Optional set or mapping specifying which fields to include in the copied model.
     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.
     |          update: Optional dictionary of field-value pairs to override field values in the copied model.
     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.
     |
     |      Returns:
     |          A copy of the model with included, excluded and updated fields as specified.
     |
     |  dict(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'
     |
     |  json(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'
     |
     |  model_copy(self, *, update: 'dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#model_copy
     |
     |      Returns a copy of the model.
     |
     |      Args:
     |          update: Values to change/add in the new model. Note: the data is not validated
     |              before creating the new model. You should trust this data.
     |          deep: Set to `True` to make a deep copy of the model.
     |
     |      Returns:
     |          New model instance.
     |
     |  model_dump(self, *, mode: "Literal['json', 'python'] | str" = 'python', include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump
     |
     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.
     |
     |      Args:
     |          mode: The mode in which `to_python` should run.
     |              If mode is 'json', the output will only contain JSON serializable types.
     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.
     |          include: A set of fields to include in the output.
     |          exclude: A set of fields to exclude from the output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to use the field's alias in the dictionary key if defined.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A dictionary representation of the model.
     |
     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'str'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump_json
     |
     |      Generates a JSON representation of the model using Pydantic's `to_json` method.
     |
     |      Args:
     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.
     |          include: Field(s) to include in the JSON output.
     |          exclude: Field(s) to exclude from the JSON output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to serialize using field aliases.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A JSON string representation of the model.
     |
     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'
     |      Override this method to perform additional initialization after `__init__` and `model_construct`.
     |      This is useful if you want to do some validation that requires the entire model to be initialized.
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from pydantic.main.BaseModel:
     |
     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'
     |
     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'
     |      Hook into generating the model's CoreSchema.
     |
     |      Args:
     |          source: The class we are generating a schema for.
     |              This will generally be the same as the `cls` argument if this is a classmethod.
     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.
     |
     |      Returns:
     |          A `pydantic-core` `CoreSchema`.
     |
     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'
     |      Hook into generating the model's JSON schema.
     |
     |      Args:
     |          core_schema: A `pydantic-core` CoreSchema.
     |              You can ignore this argument and call the handler with a new CoreSchema,
     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),
     |              or just call the handler with the original schema.
     |          handler: Call into Pydantic's internal JSON schema generation.
     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema
     |              generation fails.
     |              Since this gets called by `BaseModel.model_json_schema` you can override the
     |              `schema_generator` argument to that function to change JSON schema generation globally
     |              for a type.
     |
     |      Returns:
     |          A JSON schema, as a Python object.
     |
     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'
     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`
     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will
     |      be present when this is called.
     |
     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,
     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that
     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.
     |
     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,
     |      any kwargs passed to the class definition that aren't used internally by pydantic.
     |
     |      Args:
     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally
     |              by pydantic.
     |
     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |
     |  from_orm(obj: 'Any') -> 'Self'
     |
     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |      Creates a new instance of the `Model` class with validated data.
     |
     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.
     |      Default values are respected, but no other validation is performed.
     |
     |      !!! note
     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.
     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`
     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.
     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in
     |          an error if extra values are passed, but they will be ignored.
     |
     |      Args:
     |          _fields_set: The set of field names accepted for the Model instance.
     |          values: Trusted or pre-validated data dictionary.
     |
     |      Returns:
     |          A new instance of the `Model` class with validated data.
     |
     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'
     |      Generates a JSON schema for a model class.
     |
     |      Args:
     |          by_alias: Whether to use attribute aliases or not.
     |          ref_template: The reference template.
     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of
     |              `GenerateJsonSchema` with your desired modifications
     |          mode: The mode in which to generate the schema.
     |
     |      Returns:
     |          The JSON schema for the given model class.
     |
     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'
     |      Compute the class name for parametrizations of generic classes.
     |
     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.
     |
     |      Args:
     |          params: Tuple of types of the class. Given a generic class
     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,
     |              the value `(str, int)` would be passed to `params`.
     |
     |      Returns:
     |          String representing the new class where `params` are passed to `cls` as type variables.
     |
     |      Raises:
     |          TypeError: Raised when trying to generate concrete names for non-generic models.
     |
     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'dict[str, Any] | None' = None) -> 'bool | None'
     |      Try to rebuild the pydantic-core schema for the model.
     |
     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during
     |      the initial attempt to build the schema, and automatic rebuilding fails.
     |
     |      Args:
     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.
     |          raise_errors: Whether to raise errors, defaults to `True`.
     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.
     |          _types_namespace: The types namespace, defaults to `None`.
     |
     |      Returns:
     |          Returns `None` if the schema is already "complete" and rebuilding was not required.
     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.
     |
     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate a pydantic model instance.
     |
     |      Args:
     |          obj: The object to validate.
     |          strict: Whether to enforce types strictly.
     |          from_attributes: Whether to extract data from object attributes.
     |          context: Additional context to pass to the validator.
     |
     |      Raises:
     |          ValidationError: If the object could not be validated.
     |
     |      Returns:
     |          The validated model instance.
     |
     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/json/#json-parsing
     |
     |      Validate the given JSON data against the Pydantic model.
     |
     |      Args:
     |          json_data: The JSON data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |      Raises:
     |          ValueError: If `json_data` is not a JSON string.
     |
     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate the given object with string data against the Pydantic model.
     |
     |      Args:
     |          obj: The object containing string data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  parse_obj(obj: 'Any') -> 'Self'
     |
     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'
     |
     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'
     |
     |  update_forward_refs(**localns: 'Any') -> 'None'
     |
     |  validate(value: 'Any') -> 'Self'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from pydantic.main.BaseModel:
     |
     |  __fields_set__
     |
     |  model_extra
     |      Get extra fields set during validation.
     |
     |      Returns:
     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `"allow"`.
     |
     |  model_fields_set
     |      Returns the set of fields that have been explicitly set on this model instance.
     |
     |      Returns:
     |          A set of strings representing the fields that have been set,
     |              i.e. that were not filled from defaults.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from pydantic.main.BaseModel:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __pydantic_extra__
     |
     |  __pydantic_fields_set__
     |
     |  __pydantic_private__
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from pydantic.main.BaseModel:
     |
     |  __hash__ = None
     |
     |  __pydantic_root_model__ = False

    class Discriminator(pydantic.main.BaseModel)
     |  Discriminator(*, propertyName: str, mapping: Optional[Dict[str, str]] = None) -> None
     |
     |  Method resolution order:
     |      Discriminator
     |      pydantic.main.BaseModel
     |      builtins.object
     |
     |  Data descriptors defined here:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  __abstractmethods__ = frozenset()
     |
     |  __annotations__ = {'mapping': typing.Optional[typing.Dict[str, str]], ...
     |
     |  __class_vars__ = set()
     |
     |  __private_attributes__ = {}
     |
     |  __pydantic_complete__ = True
     |
     |  __pydantic_core_schema__ = {'cls': <class 'backend.Lib.site-packages.f...
     |
     |  __pydantic_custom_init__ = False
     |
     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...
     |
     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...
     |
     |  __pydantic_parent_namespace__ = {'Annotated': <pydantic._internal._mod...
     |
     |  __pydantic_post_init__ = None
     |
     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(
     |      Model...
     |
     |  __pydantic_validator__ = SchemaValidator(title="Discriminator", valida...
     |
     |  __signature__ = <Signature (*, propertyName: str, mapping: Optional[Di...
     |
     |  model_computed_fields = {}
     |
     |  model_config = {}
     |
     |  model_fields = {'mapping': FieldInfo(annotation=Union[Dict[str, str], ...
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from pydantic.main.BaseModel:
     |
     |  __copy__(self) -> 'Self'
     |      Returns a shallow copy of the model.
     |
     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'
     |      Returns a deep copy of the model.
     |
     |  __delattr__(self, item: 'str') -> 'Any'
     |      Implement delattr(self, name).
     |
     |  __eq__(self, other: 'Any') -> 'bool'
     |      Return self==value.
     |
     |  __getattr__(self, item: 'str') -> 'Any'
     |
     |  __getstate__(self) -> 'dict[Any, Any]'
     |      Helper for pickle.
     |
     |  __init__(self, /, **data: 'Any') -> 'None'
     |      Create a new model by parsing and validating input data from keyword arguments.
     |
     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be
     |      validated to form a valid model.
     |
     |      `self` is explicitly positional-only to allow `self` as a field name.
     |
     |  __iter__(self) -> 'TupleGenerator'
     |      So `dict(model)` works.
     |
     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation
     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.
     |
     |  __repr__(self) -> 'str'
     |      Return repr(self).
     |
     |  __repr_args__(self) -> '_repr.ReprArgs'
     |
     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation
     |      Name of the instance's class, used in __repr__.
     |
     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation
     |
     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation
     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.
     |
     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'
     |
     |  __str__(self) -> 'str'
     |      Return str(self).
     |
     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Returns a copy of the model.
     |
     |      !!! warning "Deprecated"
     |          This method is now deprecated; use `model_copy` instead.
     |
     |      If you need `include` or `exclude`, use:
     |
     |      ```py
     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)
     |      data = {**data, **(update or {})}
     |      copied = self.model_validate(data)
     |      ```
     |
     |      Args:
     |          include: Optional set or mapping specifying which fields to include in the copied model.
     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.
     |          update: Optional dictionary of field-value pairs to override field values in the copied model.
     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.
     |
     |      Returns:
     |          A copy of the model with included, excluded and updated fields as specified.
     |
     |  dict(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'
     |
     |  json(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'
     |
     |  model_copy(self, *, update: 'dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#model_copy
     |
     |      Returns a copy of the model.
     |
     |      Args:
     |          update: Values to change/add in the new model. Note: the data is not validated
     |              before creating the new model. You should trust this data.
     |          deep: Set to `True` to make a deep copy of the model.
     |
     |      Returns:
     |          New model instance.
     |
     |  model_dump(self, *, mode: "Literal['json', 'python'] | str" = 'python', include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump
     |
     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.
     |
     |      Args:
     |          mode: The mode in which `to_python` should run.
     |              If mode is 'json', the output will only contain JSON serializable types.
     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.
     |          include: A set of fields to include in the output.
     |          exclude: A set of fields to exclude from the output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to use the field's alias in the dictionary key if defined.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A dictionary representation of the model.
     |
     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'str'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump_json
     |
     |      Generates a JSON representation of the model using Pydantic's `to_json` method.
     |
     |      Args:
     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.
     |          include: Field(s) to include in the JSON output.
     |          exclude: Field(s) to exclude from the JSON output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to serialize using field aliases.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A JSON string representation of the model.
     |
     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'
     |      Override this method to perform additional initialization after `__init__` and `model_construct`.
     |      This is useful if you want to do some validation that requires the entire model to be initialized.
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from pydantic.main.BaseModel:
     |
     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'
     |
     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'
     |      Hook into generating the model's CoreSchema.
     |
     |      Args:
     |          source: The class we are generating a schema for.
     |              This will generally be the same as the `cls` argument if this is a classmethod.
     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.
     |
     |      Returns:
     |          A `pydantic-core` `CoreSchema`.
     |
     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'
     |      Hook into generating the model's JSON schema.
     |
     |      Args:
     |          core_schema: A `pydantic-core` CoreSchema.
     |              You can ignore this argument and call the handler with a new CoreSchema,
     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),
     |              or just call the handler with the original schema.
     |          handler: Call into Pydantic's internal JSON schema generation.
     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema
     |              generation fails.
     |              Since this gets called by `BaseModel.model_json_schema` you can override the
     |              `schema_generator` argument to that function to change JSON schema generation globally
     |              for a type.
     |
     |      Returns:
     |          A JSON schema, as a Python object.
     |
     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'
     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`
     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will
     |      be present when this is called.
     |
     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,
     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that
     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.
     |
     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,
     |      any kwargs passed to the class definition that aren't used internally by pydantic.
     |
     |      Args:
     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally
     |              by pydantic.
     |
     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |
     |  from_orm(obj: 'Any') -> 'Self'
     |
     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |      Creates a new instance of the `Model` class with validated data.
     |
     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.
     |      Default values are respected, but no other validation is performed.
     |
     |      !!! note
     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.
     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`
     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.
     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in
     |          an error if extra values are passed, but they will be ignored.
     |
     |      Args:
     |          _fields_set: The set of field names accepted for the Model instance.
     |          values: Trusted or pre-validated data dictionary.
     |
     |      Returns:
     |          A new instance of the `Model` class with validated data.
     |
     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'
     |      Generates a JSON schema for a model class.
     |
     |      Args:
     |          by_alias: Whether to use attribute aliases or not.
     |          ref_template: The reference template.
     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of
     |              `GenerateJsonSchema` with your desired modifications
     |          mode: The mode in which to generate the schema.
     |
     |      Returns:
     |          The JSON schema for the given model class.
     |
     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'
     |      Compute the class name for parametrizations of generic classes.
     |
     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.
     |
     |      Args:
     |          params: Tuple of types of the class. Given a generic class
     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,
     |              the value `(str, int)` would be passed to `params`.
     |
     |      Returns:
     |          String representing the new class where `params` are passed to `cls` as type variables.
     |
     |      Raises:
     |          TypeError: Raised when trying to generate concrete names for non-generic models.
     |
     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'dict[str, Any] | None' = None) -> 'bool | None'
     |      Try to rebuild the pydantic-core schema for the model.
     |
     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during
     |      the initial attempt to build the schema, and automatic rebuilding fails.
     |
     |      Args:
     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.
     |          raise_errors: Whether to raise errors, defaults to `True`.
     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.
     |          _types_namespace: The types namespace, defaults to `None`.
     |
     |      Returns:
     |          Returns `None` if the schema is already "complete" and rebuilding was not required.
     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.
     |
     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate a pydantic model instance.
     |
     |      Args:
     |          obj: The object to validate.
     |          strict: Whether to enforce types strictly.
     |          from_attributes: Whether to extract data from object attributes.
     |          context: Additional context to pass to the validator.
     |
     |      Raises:
     |          ValidationError: If the object could not be validated.
     |
     |      Returns:
     |          The validated model instance.
     |
     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/json/#json-parsing
     |
     |      Validate the given JSON data against the Pydantic model.
     |
     |      Args:
     |          json_data: The JSON data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |      Raises:
     |          ValueError: If `json_data` is not a JSON string.
     |
     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate the given object with string data against the Pydantic model.
     |
     |      Args:
     |          obj: The object containing string data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  parse_obj(obj: 'Any') -> 'Self'
     |
     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'
     |
     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'
     |
     |  update_forward_refs(**localns: 'Any') -> 'None'
     |
     |  validate(value: 'Any') -> 'Self'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from pydantic.main.BaseModel:
     |
     |  __fields_set__
     |
     |  model_extra
     |      Get extra fields set during validation.
     |
     |      Returns:
     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `"allow"`.
     |
     |  model_fields_set
     |      Returns the set of fields that have been explicitly set on this model instance.
     |
     |      Returns:
     |          A set of strings representing the fields that have been set,
     |              i.e. that were not filled from defaults.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from pydantic.main.BaseModel:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __pydantic_extra__
     |
     |  __pydantic_fields_set__
     |
     |  __pydantic_private__
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from pydantic.main.BaseModel:
     |
     |  __hash__ = None
     |
     |  __pydantic_root_model__ = False

    class Encoding(BaseModelWithConfig)
     |  Encoding(*, contentType: Optional[str] = None, headers: Optional[Dict[str, Union[backend.Lib.site-packages.fastapi.openapi.models.Header, backend.Lib.site-packages.fastapi.openapi.models.Reference]]] = None, style: Optional[str] = None, explode: Optional[bool] = None, allowReserved: Optional[bool] = None, **extra_data: Any) -> None
     |
     |  Method resolution order:
     |      Encoding
     |      BaseModelWithConfig
     |      pydantic.main.BaseModel
     |      builtins.object
     |
     |  Data and other attributes defined here:
     |
     |  __abstractmethods__ = frozenset()
     |
     |  __annotations__ = {'allowReserved': typing.Optional[bool], 'contentTyp...
     |
     |  __class_vars__ = set()
     |
     |  __private_attributes__ = {}
     |
     |  __pydantic_complete__ = True
     |
     |  __pydantic_core_schema__ = {'definitions': [{'cls': <class 'backend.Li...
     |
     |  __pydantic_custom_init__ = False
     |
     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...
     |
     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...
     |
     |  __pydantic_parent_namespace__ = {'Annotated': <pydantic._internal._mod...
     |
     |  __pydantic_post_init__ = None
     |
     |  __pydantic_serializer__ = SchemaSerializer(serializer=Recursive(
     |      D...
     |
     |  __pydantic_validator__ = SchemaValidator(title="Encoding", validator=D...
     |
     |  __signature__ = <Signature (*, contentType: Optional[str] = None...pti...
     |
     |  model_computed_fields = {}
     |
     |  model_config = {'extra': 'allow'}
     |
     |  model_fields = {'allowReserved': FieldInfo(annotation=Union[bool, None...
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from BaseModelWithConfig:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from pydantic.main.BaseModel:
     |
     |  __copy__(self) -> 'Self'
     |      Returns a shallow copy of the model.
     |
     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'
     |      Returns a deep copy of the model.
     |
     |  __delattr__(self, item: 'str') -> 'Any'
     |      Implement delattr(self, name).
     |
     |  __eq__(self, other: 'Any') -> 'bool'
     |      Return self==value.
     |
     |  __getattr__(self, item: 'str') -> 'Any'
     |
     |  __getstate__(self) -> 'dict[Any, Any]'
     |      Helper for pickle.
     |
     |  __init__(self, /, **data: 'Any') -> 'None'
     |      Create a new model by parsing and validating input data from keyword arguments.
     |
     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be
     |      validated to form a valid model.
     |
     |      `self` is explicitly positional-only to allow `self` as a field name.
     |
     |  __iter__(self) -> 'TupleGenerator'
     |      So `dict(model)` works.
     |
     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation
     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.
     |
     |  __repr__(self) -> 'str'
     |      Return repr(self).
     |
     |  __repr_args__(self) -> '_repr.ReprArgs'
     |
     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation
     |      Name of the instance's class, used in __repr__.
     |
     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation
     |
     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation
     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.
     |
     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'
     |
     |  __str__(self) -> 'str'
     |      Return str(self).
     |
     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Returns a copy of the model.
     |
     |      !!! warning "Deprecated"
     |          This method is now deprecated; use `model_copy` instead.
     |
     |      If you need `include` or `exclude`, use:
     |
     |      ```py
     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)
     |      data = {**data, **(update or {})}
     |      copied = self.model_validate(data)
     |      ```
     |
     |      Args:
     |          include: Optional set or mapping specifying which fields to include in the copied model.
     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.
     |          update: Optional dictionary of field-value pairs to override field values in the copied model.
     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.
     |
     |      Returns:
     |          A copy of the model with included, excluded and updated fields as specified.
     |
     |  dict(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'
     |
     |  json(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'
     |
     |  model_copy(self, *, update: 'dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#model_copy
     |
     |      Returns a copy of the model.
     |
     |      Args:
     |          update: Values to change/add in the new model. Note: the data is not validated
     |              before creating the new model. You should trust this data.
     |          deep: Set to `True` to make a deep copy of the model.
     |
     |      Returns:
     |          New model instance.
     |
     |  model_dump(self, *, mode: "Literal['json', 'python'] | str" = 'python', include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump
     |
     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.
     |
     |      Args:
     |          mode: The mode in which `to_python` should run.
     |              If mode is 'json', the output will only contain JSON serializable types.
     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.
     |          include: A set of fields to include in the output.
     |          exclude: A set of fields to exclude from the output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to use the field's alias in the dictionary key if defined.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A dictionary representation of the model.
     |
     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'str'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump_json
     |
     |      Generates a JSON representation of the model using Pydantic's `to_json` method.
     |
     |      Args:
     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.
     |          include: Field(s) to include in the JSON output.
     |          exclude: Field(s) to exclude from the JSON output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to serialize using field aliases.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A JSON string representation of the model.
     |
     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'
     |      Override this method to perform additional initialization after `__init__` and `model_construct`.
     |      This is useful if you want to do some validation that requires the entire model to be initialized.
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from pydantic.main.BaseModel:
     |
     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'
     |
     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'
     |      Hook into generating the model's CoreSchema.
     |
     |      Args:
     |          source: The class we are generating a schema for.
     |              This will generally be the same as the `cls` argument if this is a classmethod.
     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.
     |
     |      Returns:
     |          A `pydantic-core` `CoreSchema`.
     |
     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'
     |      Hook into generating the model's JSON schema.
     |
     |      Args:
     |          core_schema: A `pydantic-core` CoreSchema.
     |              You can ignore this argument and call the handler with a new CoreSchema,
     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),
     |              or just call the handler with the original schema.
     |          handler: Call into Pydantic's internal JSON schema generation.
     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema
     |              generation fails.
     |              Since this gets called by `BaseModel.model_json_schema` you can override the
     |              `schema_generator` argument to that function to change JSON schema generation globally
     |              for a type.
     |
     |      Returns:
     |          A JSON schema, as a Python object.
     |
     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'
     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`
     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will
     |      be present when this is called.
     |
     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,
     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that
     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.
     |
     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,
     |      any kwargs passed to the class definition that aren't used internally by pydantic.
     |
     |      Args:
     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally
     |              by pydantic.
     |
     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |
     |  from_orm(obj: 'Any') -> 'Self'
     |
     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |      Creates a new instance of the `Model` class with validated data.
     |
     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.
     |      Default values are respected, but no other validation is performed.
     |
     |      !!! note
     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.
     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`
     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.
     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in
     |          an error if extra values are passed, but they will be ignored.
     |
     |      Args:
     |          _fields_set: The set of field names accepted for the Model instance.
     |          values: Trusted or pre-validated data dictionary.
     |
     |      Returns:
     |          A new instance of the `Model` class with validated data.
     |
     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'
     |      Generates a JSON schema for a model class.
     |
     |      Args:
     |          by_alias: Whether to use attribute aliases or not.
     |          ref_template: The reference template.
     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of
     |              `GenerateJsonSchema` with your desired modifications
     |          mode: The mode in which to generate the schema.
     |
     |      Returns:
     |          The JSON schema for the given model class.
     |
     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'
     |      Compute the class name for parametrizations of generic classes.
     |
     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.
     |
     |      Args:
     |          params: Tuple of types of the class. Given a generic class
     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,
     |              the value `(str, int)` would be passed to `params`.
     |
     |      Returns:
     |          String representing the new class where `params` are passed to `cls` as type variables.
     |
     |      Raises:
     |          TypeError: Raised when trying to generate concrete names for non-generic models.
     |
     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'dict[str, Any] | None' = None) -> 'bool | None'
     |      Try to rebuild the pydantic-core schema for the model.
     |
     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during
     |      the initial attempt to build the schema, and automatic rebuilding fails.
     |
     |      Args:
     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.
     |          raise_errors: Whether to raise errors, defaults to `True`.
     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.
     |          _types_namespace: The types namespace, defaults to `None`.
     |
     |      Returns:
     |          Returns `None` if the schema is already "complete" and rebuilding was not required.
     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.
     |
     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate a pydantic model instance.
     |
     |      Args:
     |          obj: The object to validate.
     |          strict: Whether to enforce types strictly.
     |          from_attributes: Whether to extract data from object attributes.
     |          context: Additional context to pass to the validator.
     |
     |      Raises:
     |          ValidationError: If the object could not be validated.
     |
     |      Returns:
     |          The validated model instance.
     |
     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/json/#json-parsing
     |
     |      Validate the given JSON data against the Pydantic model.
     |
     |      Args:
     |          json_data: The JSON data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |      Raises:
     |          ValueError: If `json_data` is not a JSON string.
     |
     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate the given object with string data against the Pydantic model.
     |
     |      Args:
     |          obj: The object containing string data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  parse_obj(obj: 'Any') -> 'Self'
     |
     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'
     |
     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'
     |
     |  update_forward_refs(**localns: 'Any') -> 'None'
     |
     |  validate(value: 'Any') -> 'Self'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from pydantic.main.BaseModel:
     |
     |  __fields_set__
     |
     |  model_extra
     |      Get extra fields set during validation.
     |
     |      Returns:
     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `"allow"`.
     |
     |  model_fields_set
     |      Returns the set of fields that have been explicitly set on this model instance.
     |
     |      Returns:
     |          A set of strings representing the fields that have been set,
     |              i.e. that were not filled from defaults.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from pydantic.main.BaseModel:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __pydantic_extra__
     |
     |  __pydantic_fields_set__
     |
     |  __pydantic_private__
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from pydantic.main.BaseModel:
     |
     |  __hash__ = None
     |
     |  __pydantic_root_model__ = False

    class Example(builtins.dict)
     |  Method resolution order:
     |      Example
     |      builtins.dict
     |      builtins.object
     |
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  __annotations__ = {'description': typing.Optional[str], 'externalValue...
     |
     |  __closed__ = False
     |
     |  __extra_items__ = None
     |
     |  __mutable_keys__ = frozenset({'description', 'externalValue', 'summary...
     |
     |  __optional_keys__ = frozenset({'description', 'externalValue', 'summar...
     |
     |  __orig_bases__ = (<function TypedDict>,)
     |
     |  __pydantic_config__ = {'extra': 'allow'}
     |
     |  __readonly_keys__ = frozenset()
     |
     |  __required_keys__ = frozenset()
     |
     |  __total__ = False
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.dict:
     |
     |  __contains__(self, key, /)
     |      True if the dictionary has the specified key, else False.
     |
     |  __delitem__(self, key, /)
     |      Delete self[key].
     |
     |  __eq__(self, value, /)
     |      Return self==value.
     |
     |  __ge__(self, value, /)
     |      Return self>=value.
     |
     |  __getattribute__(self, name, /)
     |      Return getattr(self, name).
     |
     |  __getitem__(self, key, /)
     |      Return self[key].
     |
     |  __gt__(self, value, /)
     |      Return self>value.
     |
     |  __init__(self, /, *args, **kwargs)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  __ior__(self, value, /)
     |      Return self|=value.
     |
     |  __iter__(self, /)
     |      Implement iter(self).
     |
     |  __le__(self, value, /)
     |      Return self<=value.
     |
     |  __len__(self, /)
     |      Return len(self).
     |
     |  __lt__(self, value, /)
     |      Return self<value.
     |
     |  __ne__(self, value, /)
     |      Return self!=value.
     |
     |  __or__(self, value, /)
     |      Return self|value.
     |
     |  __repr__(self, /)
     |      Return repr(self).
     |
     |  __reversed__(self, /)
     |      Return a reverse iterator over the dict keys.
     |
     |  __ror__(self, value, /)
     |      Return value|self.
     |
     |  __setitem__(self, key, value, /)
     |      Set self[key] to value.
     |
     |  __sizeof__(...)
     |      D.__sizeof__() -> size of D in memory, in bytes
     |
     |  clear(...)
     |      D.clear() -> None.  Remove all items from D.
     |
     |  copy(...)
     |      D.copy() -> a shallow copy of D
     |
     |  get(self, key, default=None, /)
     |      Return the value for key if key is in the dictionary, else default.
     |
     |  items(...)
     |      D.items() -> a set-like object providing a view on D's items
     |
     |  keys(...)
     |      D.keys() -> a set-like object providing a view on D's keys
     |
     |  pop(...)
     |      D.pop(k[,d]) -> v, remove specified key and return the corresponding value.
     |
     |      If the key is not found, return the default if given; otherwise,
     |      raise a KeyError.
     |
     |  popitem(self, /)
     |      Remove and return a (key, value) pair as a 2-tuple.
     |
     |      Pairs are returned in LIFO (last-in, first-out) order.
     |      Raises KeyError if the dict is empty.
     |
     |  setdefault(self, key, default=None, /)
     |      Insert key with a value of default if key is not in the dictionary.
     |
     |      Return the value for key if key is in the dictionary, else default.
     |
     |  update(...)
     |      D.update([E, ]**F) -> None.  Update D from dict/iterable E and F.
     |      If E is present and has a .keys() method, then does:  for k in E: D[k] = E[k]
     |      If E is present and lacks a .keys() method, then does:  for k, v in E: D[k] = v
     |      In either case, this is followed by: for k in F:  D[k] = F[k]
     |
     |  values(...)
     |      D.values() -> an object providing a view on D's values
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from builtins.dict:
     |
     |  __class_getitem__(...)
     |      See PEP 585
     |
     |  fromkeys(iterable, value=None, /)
     |      Create a new dictionary with keys from iterable and values set to value.
     |
     |  ----------------------------------------------------------------------
     |  Static methods inherited from builtins.dict:
     |
     |  __new__(*args, **kwargs) class method of builtins.dict
     |      Create and return a new object.  See help(type) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from builtins.dict:
     |
     |  __hash__ = None

    class ExternalDocumentation(BaseModelWithConfig)
     |  ExternalDocumentation(*, description: Optional[str] = None, url: pydantic_core._pydantic_core.Url, **extra_data: Any) -> None
     |
     |  Method resolution order:
     |      ExternalDocumentation
     |      BaseModelWithConfig
     |      pydantic.main.BaseModel
     |      builtins.object
     |
     |  Data and other attributes defined here:
     |
     |  __abstractmethods__ = frozenset()
     |
     |  __annotations__ = {'description': typing.Optional[str], 'url': <class ...
     |
     |  __class_vars__ = set()
     |
     |  __private_attributes__ = {}
     |
     |  __pydantic_complete__ = True
     |
     |  __pydantic_core_schema__ = {'cls': <class 'backend.Lib.site-packages.f...
     |
     |  __pydantic_custom_init__ = False
     |
     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...
     |
     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...
     |
     |  __pydantic_parent_namespace__ = {'Annotated': <pydantic._internal._mod...
     |
     |  __pydantic_post_init__ = None
     |
     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(
     |      Model...
     |
     |  __pydantic_validator__ = SchemaValidator(title="ExternalDocumentation"...
     |
     |  __signature__ = <Signature (*, description: Optional[str] = None...e._...
     |
     |  model_computed_fields = {}
     |
     |  model_config = {'extra': 'allow'}
     |
     |  model_fields = {'description': FieldInfo(annotation=Union[str, NoneTyp...
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from BaseModelWithConfig:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from pydantic.main.BaseModel:
     |
     |  __copy__(self) -> 'Self'
     |      Returns a shallow copy of the model.
     |
     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'
     |      Returns a deep copy of the model.
     |
     |  __delattr__(self, item: 'str') -> 'Any'
     |      Implement delattr(self, name).
     |
     |  __eq__(self, other: 'Any') -> 'bool'
     |      Return self==value.
     |
     |  __getattr__(self, item: 'str') -> 'Any'
     |
     |  __getstate__(self) -> 'dict[Any, Any]'
     |      Helper for pickle.
     |
     |  __init__(self, /, **data: 'Any') -> 'None'
     |      Create a new model by parsing and validating input data from keyword arguments.
     |
     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be
     |      validated to form a valid model.
     |
     |      `self` is explicitly positional-only to allow `self` as a field name.
     |
     |  __iter__(self) -> 'TupleGenerator'
     |      So `dict(model)` works.
     |
     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation
     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.
     |
     |  __repr__(self) -> 'str'
     |      Return repr(self).
     |
     |  __repr_args__(self) -> '_repr.ReprArgs'
     |
     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation
     |      Name of the instance's class, used in __repr__.
     |
     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation
     |
     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation
     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.
     |
     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'
     |
     |  __str__(self) -> 'str'
     |      Return str(self).
     |
     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Returns a copy of the model.
     |
     |      !!! warning "Deprecated"
     |          This method is now deprecated; use `model_copy` instead.
     |
     |      If you need `include` or `exclude`, use:
     |
     |      ```py
     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)
     |      data = {**data, **(update or {})}
     |      copied = self.model_validate(data)
     |      ```
     |
     |      Args:
     |          include: Optional set or mapping specifying which fields to include in the copied model.
     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.
     |          update: Optional dictionary of field-value pairs to override field values in the copied model.
     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.
     |
     |      Returns:
     |          A copy of the model with included, excluded and updated fields as specified.
     |
     |  dict(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'
     |
     |  json(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'
     |
     |  model_copy(self, *, update: 'dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#model_copy
     |
     |      Returns a copy of the model.
     |
     |      Args:
     |          update: Values to change/add in the new model. Note: the data is not validated
     |              before creating the new model. You should trust this data.
     |          deep: Set to `True` to make a deep copy of the model.
     |
     |      Returns:
     |          New model instance.
     |
     |  model_dump(self, *, mode: "Literal['json', 'python'] | str" = 'python', include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump
     |
     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.
     |
     |      Args:
     |          mode: The mode in which `to_python` should run.
     |              If mode is 'json', the output will only contain JSON serializable types.
     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.
     |          include: A set of fields to include in the output.
     |          exclude: A set of fields to exclude from the output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to use the field's alias in the dictionary key if defined.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A dictionary representation of the model.
     |
     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'str'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump_json
     |
     |      Generates a JSON representation of the model using Pydantic's `to_json` method.
     |
     |      Args:
     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.
     |          include: Field(s) to include in the JSON output.
     |          exclude: Field(s) to exclude from the JSON output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to serialize using field aliases.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A JSON string representation of the model.
     |
     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'
     |      Override this method to perform additional initialization after `__init__` and `model_construct`.
     |      This is useful if you want to do some validation that requires the entire model to be initialized.
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from pydantic.main.BaseModel:
     |
     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'
     |
     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'
     |      Hook into generating the model's CoreSchema.
     |
     |      Args:
     |          source: The class we are generating a schema for.
     |              This will generally be the same as the `cls` argument if this is a classmethod.
     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.
     |
     |      Returns:
     |          A `pydantic-core` `CoreSchema`.
     |
     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'
     |      Hook into generating the model's JSON schema.
     |
     |      Args:
     |          core_schema: A `pydantic-core` CoreSchema.
     |              You can ignore this argument and call the handler with a new CoreSchema,
     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),
     |              or just call the handler with the original schema.
     |          handler: Call into Pydantic's internal JSON schema generation.
     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema
     |              generation fails.
     |              Since this gets called by `BaseModel.model_json_schema` you can override the
     |              `schema_generator` argument to that function to change JSON schema generation globally
     |              for a type.
     |
     |      Returns:
     |          A JSON schema, as a Python object.
     |
     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'
     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`
     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will
     |      be present when this is called.
     |
     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,
     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that
     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.
     |
     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,
     |      any kwargs passed to the class definition that aren't used internally by pydantic.
     |
     |      Args:
     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally
     |              by pydantic.
     |
     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |
     |  from_orm(obj: 'Any') -> 'Self'
     |
     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |      Creates a new instance of the `Model` class with validated data.
     |
     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.
     |      Default values are respected, but no other validation is performed.
     |
     |      !!! note
     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.
     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`
     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.
     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in
     |          an error if extra values are passed, but they will be ignored.
     |
     |      Args:
     |          _fields_set: The set of field names accepted for the Model instance.
     |          values: Trusted or pre-validated data dictionary.
     |
     |      Returns:
     |          A new instance of the `Model` class with validated data.
     |
     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'
     |      Generates a JSON schema for a model class.
     |
     |      Args:
     |          by_alias: Whether to use attribute aliases or not.
     |          ref_template: The reference template.
     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of
     |              `GenerateJsonSchema` with your desired modifications
     |          mode: The mode in which to generate the schema.
     |
     |      Returns:
     |          The JSON schema for the given model class.
     |
     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'
     |      Compute the class name for parametrizations of generic classes.
     |
     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.
     |
     |      Args:
     |          params: Tuple of types of the class. Given a generic class
     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,
     |              the value `(str, int)` would be passed to `params`.
     |
     |      Returns:
     |          String representing the new class where `params` are passed to `cls` as type variables.
     |
     |      Raises:
     |          TypeError: Raised when trying to generate concrete names for non-generic models.
     |
     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'dict[str, Any] | None' = None) -> 'bool | None'
     |      Try to rebuild the pydantic-core schema for the model.
     |
     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during
     |      the initial attempt to build the schema, and automatic rebuilding fails.
     |
     |      Args:
     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.
     |          raise_errors: Whether to raise errors, defaults to `True`.
     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.
     |          _types_namespace: The types namespace, defaults to `None`.
     |
     |      Returns:
     |          Returns `None` if the schema is already "complete" and rebuilding was not required.
     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.
     |
     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate a pydantic model instance.
     |
     |      Args:
     |          obj: The object to validate.
     |          strict: Whether to enforce types strictly.
     |          from_attributes: Whether to extract data from object attributes.
     |          context: Additional context to pass to the validator.
     |
     |      Raises:
     |          ValidationError: If the object could not be validated.
     |
     |      Returns:
     |          The validated model instance.
     |
     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/json/#json-parsing
     |
     |      Validate the given JSON data against the Pydantic model.
     |
     |      Args:
     |          json_data: The JSON data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |      Raises:
     |          ValueError: If `json_data` is not a JSON string.
     |
     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate the given object with string data against the Pydantic model.
     |
     |      Args:
     |          obj: The object containing string data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  parse_obj(obj: 'Any') -> 'Self'
     |
     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'
     |
     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'
     |
     |  update_forward_refs(**localns: 'Any') -> 'None'
     |
     |  validate(value: 'Any') -> 'Self'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from pydantic.main.BaseModel:
     |
     |  __fields_set__
     |
     |  model_extra
     |      Get extra fields set during validation.
     |
     |      Returns:
     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `"allow"`.
     |
     |  model_fields_set
     |      Returns the set of fields that have been explicitly set on this model instance.
     |
     |      Returns:
     |          A set of strings representing the fields that have been set,
     |              i.e. that were not filled from defaults.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from pydantic.main.BaseModel:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __pydantic_extra__
     |
     |  __pydantic_fields_set__
     |
     |  __pydantic_private__
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from pydantic.main.BaseModel:
     |
     |  __hash__ = None
     |
     |  __pydantic_root_model__ = False

    class HTTPBase(SecurityBase)
     |  HTTPBase(*, type: backend.Lib.site-packages.fastapi.openapi.models.SecuritySchemeType = <SecuritySchemeType.http: 'http'>, description: Optional[str] = None, scheme: str, **extra_data: Any) -> None
     |
     |  Method resolution order:
     |      HTTPBase
     |      SecurityBase
     |      BaseModelWithConfig
     |      pydantic.main.BaseModel
     |      builtins.object
     |
     |  Data and other attributes defined here:
     |
     |  __abstractmethods__ = frozenset()
     |
     |  __annotations__ = {'scheme': <class 'str'>, 'type_': <enum 'SecuritySc...
     |
     |  __class_vars__ = set()
     |
     |  __private_attributes__ = {}
     |
     |  __pydantic_complete__ = True
     |
     |  __pydantic_core_schema__ = {'cls': <class 'backend.Lib.site-packages.f...
     |
     |  __pydantic_custom_init__ = False
     |
     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...
     |
     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...
     |
     |  __pydantic_parent_namespace__ = {'APIKey': <pydantic._internal._model_...
     |
     |  __pydantic_post_init__ = None
     |
     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(
     |      Model...
     |
     |  __pydantic_validator__ = SchemaValidator(title="HTTPBase", validator=M...
     |
     |  __signature__ = <Signature (*, type: backend.Lib.site-packages.f... = ...
     |
     |  model_computed_fields = {}
     |
     |  model_config = {'extra': 'allow'}
     |
     |  model_fields = {'description': FieldInfo(annotation=Union[str, NoneTyp...
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from BaseModelWithConfig:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from pydantic.main.BaseModel:
     |
     |  __copy__(self) -> 'Self'
     |      Returns a shallow copy of the model.
     |
     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'
     |      Returns a deep copy of the model.
     |
     |  __delattr__(self, item: 'str') -> 'Any'
     |      Implement delattr(self, name).
     |
     |  __eq__(self, other: 'Any') -> 'bool'
     |      Return self==value.
     |
     |  __getattr__(self, item: 'str') -> 'Any'
     |
     |  __getstate__(self) -> 'dict[Any, Any]'
     |      Helper for pickle.
     |
     |  __init__(self, /, **data: 'Any') -> 'None'
     |      Create a new model by parsing and validating input data from keyword arguments.
     |
     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be
     |      validated to form a valid model.
     |
     |      `self` is explicitly positional-only to allow `self` as a field name.
     |
     |  __iter__(self) -> 'TupleGenerator'
     |      So `dict(model)` works.
     |
     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation
     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.
     |
     |  __repr__(self) -> 'str'
     |      Return repr(self).
     |
     |  __repr_args__(self) -> '_repr.ReprArgs'
     |
     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation
     |      Name of the instance's class, used in __repr__.
     |
     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation
     |
     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation
     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.
     |
     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'
     |
     |  __str__(self) -> 'str'
     |      Return str(self).
     |
     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Returns a copy of the model.
     |
     |      !!! warning "Deprecated"
     |          This method is now deprecated; use `model_copy` instead.
     |
     |      If you need `include` or `exclude`, use:
     |
     |      ```py
     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)
     |      data = {**data, **(update or {})}
     |      copied = self.model_validate(data)
     |      ```
     |
     |      Args:
     |          include: Optional set or mapping specifying which fields to include in the copied model.
     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.
     |          update: Optional dictionary of field-value pairs to override field values in the copied model.
     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.
     |
     |      Returns:
     |          A copy of the model with included, excluded and updated fields as specified.
     |
     |  dict(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'
     |
     |  json(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'
     |
     |  model_copy(self, *, update: 'dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#model_copy
     |
     |      Returns a copy of the model.
     |
     |      Args:
     |          update: Values to change/add in the new model. Note: the data is not validated
     |              before creating the new model. You should trust this data.
     |          deep: Set to `True` to make a deep copy of the model.
     |
     |      Returns:
     |          New model instance.
     |
     |  model_dump(self, *, mode: "Literal['json', 'python'] | str" = 'python', include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump
     |
     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.
     |
     |      Args:
     |          mode: The mode in which `to_python` should run.
     |              If mode is 'json', the output will only contain JSON serializable types.
     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.
     |          include: A set of fields to include in the output.
     |          exclude: A set of fields to exclude from the output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to use the field's alias in the dictionary key if defined.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A dictionary representation of the model.
     |
     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'str'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump_json
     |
     |      Generates a JSON representation of the model using Pydantic's `to_json` method.
     |
     |      Args:
     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.
     |          include: Field(s) to include in the JSON output.
     |          exclude: Field(s) to exclude from the JSON output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to serialize using field aliases.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A JSON string representation of the model.
     |
     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'
     |      Override this method to perform additional initialization after `__init__` and `model_construct`.
     |      This is useful if you want to do some validation that requires the entire model to be initialized.
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from pydantic.main.BaseModel:
     |
     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'
     |
     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'
     |      Hook into generating the model's CoreSchema.
     |
     |      Args:
     |          source: The class we are generating a schema for.
     |              This will generally be the same as the `cls` argument if this is a classmethod.
     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.
     |
     |      Returns:
     |          A `pydantic-core` `CoreSchema`.
     |
     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'
     |      Hook into generating the model's JSON schema.
     |
     |      Args:
     |          core_schema: A `pydantic-core` CoreSchema.
     |              You can ignore this argument and call the handler with a new CoreSchema,
     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),
     |              or just call the handler with the original schema.
     |          handler: Call into Pydantic's internal JSON schema generation.
     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema
     |              generation fails.
     |              Since this gets called by `BaseModel.model_json_schema` you can override the
     |              `schema_generator` argument to that function to change JSON schema generation globally
     |              for a type.
     |
     |      Returns:
     |          A JSON schema, as a Python object.
     |
     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'
     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`
     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will
     |      be present when this is called.
     |
     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,
     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that
     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.
     |
     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,
     |      any kwargs passed to the class definition that aren't used internally by pydantic.
     |
     |      Args:
     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally
     |              by pydantic.
     |
     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |
     |  from_orm(obj: 'Any') -> 'Self'
     |
     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |      Creates a new instance of the `Model` class with validated data.
     |
     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.
     |      Default values are respected, but no other validation is performed.
     |
     |      !!! note
     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.
     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`
     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.
     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in
     |          an error if extra values are passed, but they will be ignored.
     |
     |      Args:
     |          _fields_set: The set of field names accepted for the Model instance.
     |          values: Trusted or pre-validated data dictionary.
     |
     |      Returns:
     |          A new instance of the `Model` class with validated data.
     |
     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'
     |      Generates a JSON schema for a model class.
     |
     |      Args:
     |          by_alias: Whether to use attribute aliases or not.
     |          ref_template: The reference template.
     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of
     |              `GenerateJsonSchema` with your desired modifications
     |          mode: The mode in which to generate the schema.
     |
     |      Returns:
     |          The JSON schema for the given model class.
     |
     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'
     |      Compute the class name for parametrizations of generic classes.
     |
     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.
     |
     |      Args:
     |          params: Tuple of types of the class. Given a generic class
     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,
     |              the value `(str, int)` would be passed to `params`.
     |
     |      Returns:
     |          String representing the new class where `params` are passed to `cls` as type variables.
     |
     |      Raises:
     |          TypeError: Raised when trying to generate concrete names for non-generic models.
     |
     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'dict[str, Any] | None' = None) -> 'bool | None'
     |      Try to rebuild the pydantic-core schema for the model.
     |
     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during
     |      the initial attempt to build the schema, and automatic rebuilding fails.
     |
     |      Args:
     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.
     |          raise_errors: Whether to raise errors, defaults to `True`.
     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.
     |          _types_namespace: The types namespace, defaults to `None`.
     |
     |      Returns:
     |          Returns `None` if the schema is already "complete" and rebuilding was not required.
     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.
     |
     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate a pydantic model instance.
     |
     |      Args:
     |          obj: The object to validate.
     |          strict: Whether to enforce types strictly.
     |          from_attributes: Whether to extract data from object attributes.
     |          context: Additional context to pass to the validator.
     |
     |      Raises:
     |          ValidationError: If the object could not be validated.
     |
     |      Returns:
     |          The validated model instance.
     |
     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/json/#json-parsing
     |
     |      Validate the given JSON data against the Pydantic model.
     |
     |      Args:
     |          json_data: The JSON data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |      Raises:
     |          ValueError: If `json_data` is not a JSON string.
     |
     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate the given object with string data against the Pydantic model.
     |
     |      Args:
     |          obj: The object containing string data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  parse_obj(obj: 'Any') -> 'Self'
     |
     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'
     |
     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'
     |
     |  update_forward_refs(**localns: 'Any') -> 'None'
     |
     |  validate(value: 'Any') -> 'Self'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from pydantic.main.BaseModel:
     |
     |  __fields_set__
     |
     |  model_extra
     |      Get extra fields set during validation.
     |
     |      Returns:
     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `"allow"`.
     |
     |  model_fields_set
     |      Returns the set of fields that have been explicitly set on this model instance.
     |
     |      Returns:
     |          A set of strings representing the fields that have been set,
     |              i.e. that were not filled from defaults.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from pydantic.main.BaseModel:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __pydantic_extra__
     |
     |  __pydantic_fields_set__
     |
     |  __pydantic_private__
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from pydantic.main.BaseModel:
     |
     |  __hash__ = None
     |
     |  __pydantic_root_model__ = False

    class HTTPBearer(HTTPBase)
     |  HTTPBearer(*, type: backend.Lib.site-packages.fastapi.openapi.models.SecuritySchemeType = <SecuritySchemeType.http: 'http'>, description: Optional[str] = None, scheme: Literal['bearer'] = 'bearer', bearerFormat: Optional[str] = None, **extra_data: Any) -> None
     |
     |  Method resolution order:
     |      HTTPBearer
     |      HTTPBase
     |      SecurityBase
     |      BaseModelWithConfig
     |      pydantic.main.BaseModel
     |      builtins.object
     |
     |  Data and other attributes defined here:
     |
     |  __abstractmethods__ = frozenset()
     |
     |  __annotations__ = {'bearerFormat': typing.Optional[str], 'scheme': typ...
     |
     |  __class_vars__ = set()
     |
     |  __private_attributes__ = {}
     |
     |  __pydantic_complete__ = True
     |
     |  __pydantic_core_schema__ = {'cls': <class 'backend.Lib.site-packages.f...
     |
     |  __pydantic_custom_init__ = False
     |
     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...
     |
     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...
     |
     |  __pydantic_parent_namespace__ = {'APIKey': <pydantic._internal._model_...
     |
     |  __pydantic_post_init__ = None
     |
     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(
     |      Model...
     |
     |  __pydantic_validator__ = SchemaValidator(title="HTTPBearer", validator...
     |
     |  __signature__ = <Signature (*, type: backend.Lib.site-packages.f...Opt...
     |
     |  model_computed_fields = {}
     |
     |  model_config = {'extra': 'allow'}
     |
     |  model_fields = {'bearerFormat': FieldInfo(annotation=Union[str, NoneTy...
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from BaseModelWithConfig:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from pydantic.main.BaseModel:
     |
     |  __copy__(self) -> 'Self'
     |      Returns a shallow copy of the model.
     |
     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'
     |      Returns a deep copy of the model.
     |
     |  __delattr__(self, item: 'str') -> 'Any'
     |      Implement delattr(self, name).
     |
     |  __eq__(self, other: 'Any') -> 'bool'
     |      Return self==value.
     |
     |  __getattr__(self, item: 'str') -> 'Any'
     |
     |  __getstate__(self) -> 'dict[Any, Any]'
     |      Helper for pickle.
     |
     |  __init__(self, /, **data: 'Any') -> 'None'
     |      Create a new model by parsing and validating input data from keyword arguments.
     |
     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be
     |      validated to form a valid model.
     |
     |      `self` is explicitly positional-only to allow `self` as a field name.
     |
     |  __iter__(self) -> 'TupleGenerator'
     |      So `dict(model)` works.
     |
     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation
     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.
     |
     |  __repr__(self) -> 'str'
     |      Return repr(self).
     |
     |  __repr_args__(self) -> '_repr.ReprArgs'
     |
     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation
     |      Name of the instance's class, used in __repr__.
     |
     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation
     |
     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation
     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.
     |
     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'
     |
     |  __str__(self) -> 'str'
     |      Return str(self).
     |
     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Returns a copy of the model.
     |
     |      !!! warning "Deprecated"
     |          This method is now deprecated; use `model_copy` instead.
     |
     |      If you need `include` or `exclude`, use:
     |
     |      ```py
     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)
     |      data = {**data, **(update or {})}
     |      copied = self.model_validate(data)
     |      ```
     |
     |      Args:
     |          include: Optional set or mapping specifying which fields to include in the copied model.
     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.
     |          update: Optional dictionary of field-value pairs to override field values in the copied model.
     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.
     |
     |      Returns:
     |          A copy of the model with included, excluded and updated fields as specified.
     |
     |  dict(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'
     |
     |  json(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'
     |
     |  model_copy(self, *, update: 'dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#model_copy
     |
     |      Returns a copy of the model.
     |
     |      Args:
     |          update: Values to change/add in the new model. Note: the data is not validated
     |              before creating the new model. You should trust this data.
     |          deep: Set to `True` to make a deep copy of the model.
     |
     |      Returns:
     |          New model instance.
     |
     |  model_dump(self, *, mode: "Literal['json', 'python'] | str" = 'python', include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump
     |
     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.
     |
     |      Args:
     |          mode: The mode in which `to_python` should run.
     |              If mode is 'json', the output will only contain JSON serializable types.
     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.
     |          include: A set of fields to include in the output.
     |          exclude: A set of fields to exclude from the output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to use the field's alias in the dictionary key if defined.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A dictionary representation of the model.
     |
     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'str'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump_json
     |
     |      Generates a JSON representation of the model using Pydantic's `to_json` method.
     |
     |      Args:
     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.
     |          include: Field(s) to include in the JSON output.
     |          exclude: Field(s) to exclude from the JSON output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to serialize using field aliases.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A JSON string representation of the model.
     |
     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'
     |      Override this method to perform additional initialization after `__init__` and `model_construct`.
     |      This is useful if you want to do some validation that requires the entire model to be initialized.
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from pydantic.main.BaseModel:
     |
     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'
     |
     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'
     |      Hook into generating the model's CoreSchema.
     |
     |      Args:
     |          source: The class we are generating a schema for.
     |              This will generally be the same as the `cls` argument if this is a classmethod.
     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.
     |
     |      Returns:
     |          A `pydantic-core` `CoreSchema`.
     |
     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'
     |      Hook into generating the model's JSON schema.
     |
     |      Args:
     |          core_schema: A `pydantic-core` CoreSchema.
     |              You can ignore this argument and call the handler with a new CoreSchema,
     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),
     |              or just call the handler with the original schema.
     |          handler: Call into Pydantic's internal JSON schema generation.
     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema
     |              generation fails.
     |              Since this gets called by `BaseModel.model_json_schema` you can override the
     |              `schema_generator` argument to that function to change JSON schema generation globally
     |              for a type.
     |
     |      Returns:
     |          A JSON schema, as a Python object.
     |
     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'
     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`
     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will
     |      be present when this is called.
     |
     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,
     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that
     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.
     |
     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,
     |      any kwargs passed to the class definition that aren't used internally by pydantic.
     |
     |      Args:
     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally
     |              by pydantic.
     |
     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |
     |  from_orm(obj: 'Any') -> 'Self'
     |
     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |      Creates a new instance of the `Model` class with validated data.
     |
     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.
     |      Default values are respected, but no other validation is performed.
     |
     |      !!! note
     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.
     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`
     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.
     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in
     |          an error if extra values are passed, but they will be ignored.
     |
     |      Args:
     |          _fields_set: The set of field names accepted for the Model instance.
     |          values: Trusted or pre-validated data dictionary.
     |
     |      Returns:
     |          A new instance of the `Model` class with validated data.
     |
     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'
     |      Generates a JSON schema for a model class.
     |
     |      Args:
     |          by_alias: Whether to use attribute aliases or not.
     |          ref_template: The reference template.
     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of
     |              `GenerateJsonSchema` with your desired modifications
     |          mode: The mode in which to generate the schema.
     |
     |      Returns:
     |          The JSON schema for the given model class.
     |
     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'
     |      Compute the class name for parametrizations of generic classes.
     |
     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.
     |
     |      Args:
     |          params: Tuple of types of the class. Given a generic class
     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,
     |              the value `(str, int)` would be passed to `params`.
     |
     |      Returns:
     |          String representing the new class where `params` are passed to `cls` as type variables.
     |
     |      Raises:
     |          TypeError: Raised when trying to generate concrete names for non-generic models.
     |
     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'dict[str, Any] | None' = None) -> 'bool | None'
     |      Try to rebuild the pydantic-core schema for the model.
     |
     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during
     |      the initial attempt to build the schema, and automatic rebuilding fails.
     |
     |      Args:
     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.
     |          raise_errors: Whether to raise errors, defaults to `True`.
     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.
     |          _types_namespace: The types namespace, defaults to `None`.
     |
     |      Returns:
     |          Returns `None` if the schema is already "complete" and rebuilding was not required.
     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.
     |
     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate a pydantic model instance.
     |
     |      Args:
     |          obj: The object to validate.
     |          strict: Whether to enforce types strictly.
     |          from_attributes: Whether to extract data from object attributes.
     |          context: Additional context to pass to the validator.
     |
     |      Raises:
     |          ValidationError: If the object could not be validated.
     |
     |      Returns:
     |          The validated model instance.
     |
     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/json/#json-parsing
     |
     |      Validate the given JSON data against the Pydantic model.
     |
     |      Args:
     |          json_data: The JSON data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |      Raises:
     |          ValueError: If `json_data` is not a JSON string.
     |
     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate the given object with string data against the Pydantic model.
     |
     |      Args:
     |          obj: The object containing string data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  parse_obj(obj: 'Any') -> 'Self'
     |
     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'
     |
     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'
     |
     |  update_forward_refs(**localns: 'Any') -> 'None'
     |
     |  validate(value: 'Any') -> 'Self'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from pydantic.main.BaseModel:
     |
     |  __fields_set__
     |
     |  model_extra
     |      Get extra fields set during validation.
     |
     |      Returns:
     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `"allow"`.
     |
     |  model_fields_set
     |      Returns the set of fields that have been explicitly set on this model instance.
     |
     |      Returns:
     |          A set of strings representing the fields that have been set,
     |              i.e. that were not filled from defaults.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from pydantic.main.BaseModel:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __pydantic_extra__
     |
     |  __pydantic_fields_set__
     |
     |  __pydantic_private__
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from pydantic.main.BaseModel:
     |
     |  __hash__ = None
     |
     |  __pydantic_root_model__ = False

    class Header(ParameterBase)
     |  Header(*, description: Optional[str] = None, required: Optional[bool] = None, deprecated: Optional[bool] = None, style: Optional[str] = None, explode: Optional[bool] = None, allowReserved: Optional[bool] = None, schema: Union[backend.Lib.site-packages.fastapi.openapi.models.Schema, backend.Lib.site-packages.fastapi.openapi.models.Reference, NoneType] = None, example: Optional[Any] = None, examples: Optional[Dict[str, Union[backend.Lib.site-packages.fastapi.openapi.models.Example, backend.Lib.site-packages.fastapi.openapi.models.Reference]]] = None, content: Optional[Dict[str, backend.Lib.site-packages.fastapi.openapi.models.MediaType]] = None, **extra_data: Any) -> None
     |
     |  Method resolution order:
     |      Header
     |      ParameterBase
     |      BaseModelWithConfig
     |      pydantic.main.BaseModel
     |      builtins.object
     |
     |  Data and other attributes defined here:
     |
     |  __abstractmethods__ = frozenset()
     |
     |  __annotations__ = {}
     |
     |  __class_vars__ = set()
     |
     |  __private_attributes__ = {}
     |
     |  __pydantic_complete__ = True
     |
     |  __pydantic_core_schema__ = {'definitions': [{'cls': <class 'backend.Li...
     |
     |  __pydantic_custom_init__ = False
     |
     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...
     |
     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...
     |
     |  __pydantic_parent_namespace__ = {'Annotated': <pydantic._internal._mod...
     |
     |  __pydantic_post_init__ = None
     |
     |  __pydantic_serializer__ = SchemaSerializer(serializer=Recursive(
     |      D...
     |
     |  __pydantic_validator__ = SchemaValidator(title="Header", validator=Def...
     |
     |  __signature__ = <Signature (*, description: Optional[str] = None...s.M...
     |
     |  model_computed_fields = {}
     |
     |  model_config = {'extra': 'allow'}
     |
     |  model_fields = {'allowReserved': FieldInfo(annotation=Union[bool, None...
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from BaseModelWithConfig:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from pydantic.main.BaseModel:
     |
     |  __copy__(self) -> 'Self'
     |      Returns a shallow copy of the model.
     |
     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'
     |      Returns a deep copy of the model.
     |
     |  __delattr__(self, item: 'str') -> 'Any'
     |      Implement delattr(self, name).
     |
     |  __eq__(self, other: 'Any') -> 'bool'
     |      Return self==value.
     |
     |  __getattr__(self, item: 'str') -> 'Any'
     |
     |  __getstate__(self) -> 'dict[Any, Any]'
     |      Helper for pickle.
     |
     |  __init__(self, /, **data: 'Any') -> 'None'
     |      Create a new model by parsing and validating input data from keyword arguments.
     |
     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be
     |      validated to form a valid model.
     |
     |      `self` is explicitly positional-only to allow `self` as a field name.
     |
     |  __iter__(self) -> 'TupleGenerator'
     |      So `dict(model)` works.
     |
     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation
     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.
     |
     |  __repr__(self) -> 'str'
     |      Return repr(self).
     |
     |  __repr_args__(self) -> '_repr.ReprArgs'
     |
     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation
     |      Name of the instance's class, used in __repr__.
     |
     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation
     |
     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation
     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.
     |
     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'
     |
     |  __str__(self) -> 'str'
     |      Return str(self).
     |
     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Returns a copy of the model.
     |
     |      !!! warning "Deprecated"
     |          This method is now deprecated; use `model_copy` instead.
     |
     |      If you need `include` or `exclude`, use:
     |
     |      ```py
     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)
     |      data = {**data, **(update or {})}
     |      copied = self.model_validate(data)
     |      ```
     |
     |      Args:
     |          include: Optional set or mapping specifying which fields to include in the copied model.
     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.
     |          update: Optional dictionary of field-value pairs to override field values in the copied model.
     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.
     |
     |      Returns:
     |          A copy of the model with included, excluded and updated fields as specified.
     |
     |  dict(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'
     |
     |  json(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'
     |
     |  model_copy(self, *, update: 'dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#model_copy
     |
     |      Returns a copy of the model.
     |
     |      Args:
     |          update: Values to change/add in the new model. Note: the data is not validated
     |              before creating the new model. You should trust this data.
     |          deep: Set to `True` to make a deep copy of the model.
     |
     |      Returns:
     |          New model instance.
     |
     |  model_dump(self, *, mode: "Literal['json', 'python'] | str" = 'python', include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump
     |
     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.
     |
     |      Args:
     |          mode: The mode in which `to_python` should run.
     |              If mode is 'json', the output will only contain JSON serializable types.
     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.
     |          include: A set of fields to include in the output.
     |          exclude: A set of fields to exclude from the output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to use the field's alias in the dictionary key if defined.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A dictionary representation of the model.
     |
     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'str'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump_json
     |
     |      Generates a JSON representation of the model using Pydantic's `to_json` method.
     |
     |      Args:
     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.
     |          include: Field(s) to include in the JSON output.
     |          exclude: Field(s) to exclude from the JSON output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to serialize using field aliases.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A JSON string representation of the model.
     |
     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'
     |      Override this method to perform additional initialization after `__init__` and `model_construct`.
     |      This is useful if you want to do some validation that requires the entire model to be initialized.
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from pydantic.main.BaseModel:
     |
     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'
     |
     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'
     |      Hook into generating the model's CoreSchema.
     |
     |      Args:
     |          source: The class we are generating a schema for.
     |              This will generally be the same as the `cls` argument if this is a classmethod.
     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.
     |
     |      Returns:
     |          A `pydantic-core` `CoreSchema`.
     |
     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'
     |      Hook into generating the model's JSON schema.
     |
     |      Args:
     |          core_schema: A `pydantic-core` CoreSchema.
     |              You can ignore this argument and call the handler with a new CoreSchema,
     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),
     |              or just call the handler with the original schema.
     |          handler: Call into Pydantic's internal JSON schema generation.
     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema
     |              generation fails.
     |              Since this gets called by `BaseModel.model_json_schema` you can override the
     |              `schema_generator` argument to that function to change JSON schema generation globally
     |              for a type.
     |
     |      Returns:
     |          A JSON schema, as a Python object.
     |
     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'
     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`
     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will
     |      be present when this is called.
     |
     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,
     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that
     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.
     |
     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,
     |      any kwargs passed to the class definition that aren't used internally by pydantic.
     |
     |      Args:
     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally
     |              by pydantic.
     |
     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |
     |  from_orm(obj: 'Any') -> 'Self'
     |
     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |      Creates a new instance of the `Model` class with validated data.
     |
     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.
     |      Default values are respected, but no other validation is performed.
     |
     |      !!! note
     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.
     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`
     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.
     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in
     |          an error if extra values are passed, but they will be ignored.
     |
     |      Args:
     |          _fields_set: The set of field names accepted for the Model instance.
     |          values: Trusted or pre-validated data dictionary.
     |
     |      Returns:
     |          A new instance of the `Model` class with validated data.
     |
     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'
     |      Generates a JSON schema for a model class.
     |
     |      Args:
     |          by_alias: Whether to use attribute aliases or not.
     |          ref_template: The reference template.
     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of
     |              `GenerateJsonSchema` with your desired modifications
     |          mode: The mode in which to generate the schema.
     |
     |      Returns:
     |          The JSON schema for the given model class.
     |
     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'
     |      Compute the class name for parametrizations of generic classes.
     |
     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.
     |
     |      Args:
     |          params: Tuple of types of the class. Given a generic class
     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,
     |              the value `(str, int)` would be passed to `params`.
     |
     |      Returns:
     |          String representing the new class where `params` are passed to `cls` as type variables.
     |
     |      Raises:
     |          TypeError: Raised when trying to generate concrete names for non-generic models.
     |
     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'dict[str, Any] | None' = None) -> 'bool | None'
     |      Try to rebuild the pydantic-core schema for the model.
     |
     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during
     |      the initial attempt to build the schema, and automatic rebuilding fails.
     |
     |      Args:
     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.
     |          raise_errors: Whether to raise errors, defaults to `True`.
     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.
     |          _types_namespace: The types namespace, defaults to `None`.
     |
     |      Returns:
     |          Returns `None` if the schema is already "complete" and rebuilding was not required.
     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.
     |
     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate a pydantic model instance.
     |
     |      Args:
     |          obj: The object to validate.
     |          strict: Whether to enforce types strictly.
     |          from_attributes: Whether to extract data from object attributes.
     |          context: Additional context to pass to the validator.
     |
     |      Raises:
     |          ValidationError: If the object could not be validated.
     |
     |      Returns:
     |          The validated model instance.
     |
     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/json/#json-parsing
     |
     |      Validate the given JSON data against the Pydantic model.
     |
     |      Args:
     |          json_data: The JSON data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |      Raises:
     |          ValueError: If `json_data` is not a JSON string.
     |
     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate the given object with string data against the Pydantic model.
     |
     |      Args:
     |          obj: The object containing string data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  parse_obj(obj: 'Any') -> 'Self'
     |
     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'
     |
     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'
     |
     |  update_forward_refs(**localns: 'Any') -> 'None'
     |
     |  validate(value: 'Any') -> 'Self'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from pydantic.main.BaseModel:
     |
     |  __fields_set__
     |
     |  model_extra
     |      Get extra fields set during validation.
     |
     |      Returns:
     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `"allow"`.
     |
     |  model_fields_set
     |      Returns the set of fields that have been explicitly set on this model instance.
     |
     |      Returns:
     |          A set of strings representing the fields that have been set,
     |              i.e. that were not filled from defaults.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from pydantic.main.BaseModel:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __pydantic_extra__
     |
     |  __pydantic_fields_set__
     |
     |  __pydantic_private__
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from pydantic.main.BaseModel:
     |
     |  __hash__ = None
     |
     |  __pydantic_root_model__ = False

    class Info(BaseModelWithConfig)
     |  Info(*, title: str, summary: Optional[str] = None, description: Optional[str] = None, termsOfService: Optional[str] = None, contact: Optional[backend.Lib.site-packages.fastapi.openapi.models.Contact] = None, license: Optional[backend.Lib.site-packages.fastapi.openapi.models.License] = None, version: str, **extra_data: Any) -> None
     |
     |  Method resolution order:
     |      Info
     |      BaseModelWithConfig
     |      pydantic.main.BaseModel
     |      builtins.object
     |
     |  Data and other attributes defined here:
     |
     |  __abstractmethods__ = frozenset()
     |
     |  __annotations__ = {'contact': typing.Optional[backend.Lib.site-package...
     |
     |  __class_vars__ = set()
     |
     |  __private_attributes__ = {}
     |
     |  __pydantic_complete__ = True
     |
     |  __pydantic_core_schema__ = {'cls': <class 'backend.Lib.site-packages.f...
     |
     |  __pydantic_custom_init__ = False
     |
     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...
     |
     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...
     |
     |  __pydantic_parent_namespace__ = {'Annotated': <pydantic._internal._mod...
     |
     |  __pydantic_post_init__ = None
     |
     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(
     |      Model...
     |
     |  __pydantic_validator__ = SchemaValidator(title="Info", validator=Model...
     |
     |  __signature__ = <Signature (*, title: str, summary: Optional[str...= N...
     |
     |  model_computed_fields = {}
     |
     |  model_config = {'extra': 'allow'}
     |
     |  model_fields = {'contact': FieldInfo(annotation=Union[Contact, NoneTyp...
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from BaseModelWithConfig:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from pydantic.main.BaseModel:
     |
     |  __copy__(self) -> 'Self'
     |      Returns a shallow copy of the model.
     |
     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'
     |      Returns a deep copy of the model.
     |
     |  __delattr__(self, item: 'str') -> 'Any'
     |      Implement delattr(self, name).
     |
     |  __eq__(self, other: 'Any') -> 'bool'
     |      Return self==value.
     |
     |  __getattr__(self, item: 'str') -> 'Any'
     |
     |  __getstate__(self) -> 'dict[Any, Any]'
     |      Helper for pickle.
     |
     |  __init__(self, /, **data: 'Any') -> 'None'
     |      Create a new model by parsing and validating input data from keyword arguments.
     |
     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be
     |      validated to form a valid model.
     |
     |      `self` is explicitly positional-only to allow `self` as a field name.
     |
     |  __iter__(self) -> 'TupleGenerator'
     |      So `dict(model)` works.
     |
     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation
     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.
     |
     |  __repr__(self) -> 'str'
     |      Return repr(self).
     |
     |  __repr_args__(self) -> '_repr.ReprArgs'
     |
     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation
     |      Name of the instance's class, used in __repr__.
     |
     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation
     |
     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation
     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.
     |
     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'
     |
     |  __str__(self) -> 'str'
     |      Return str(self).
     |
     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Returns a copy of the model.
     |
     |      !!! warning "Deprecated"
     |          This method is now deprecated; use `model_copy` instead.
     |
     |      If you need `include` or `exclude`, use:
     |
     |      ```py
     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)
     |      data = {**data, **(update or {})}
     |      copied = self.model_validate(data)
     |      ```
     |
     |      Args:
     |          include: Optional set or mapping specifying which fields to include in the copied model.
     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.
     |          update: Optional dictionary of field-value pairs to override field values in the copied model.
     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.
     |
     |      Returns:
     |          A copy of the model with included, excluded and updated fields as specified.
     |
     |  dict(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'
     |
     |  json(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'
     |
     |  model_copy(self, *, update: 'dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#model_copy
     |
     |      Returns a copy of the model.
     |
     |      Args:
     |          update: Values to change/add in the new model. Note: the data is not validated
     |              before creating the new model. You should trust this data.
     |          deep: Set to `True` to make a deep copy of the model.
     |
     |      Returns:
     |          New model instance.
     |
     |  model_dump(self, *, mode: "Literal['json', 'python'] | str" = 'python', include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump
     |
     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.
     |
     |      Args:
     |          mode: The mode in which `to_python` should run.
     |              If mode is 'json', the output will only contain JSON serializable types.
     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.
     |          include: A set of fields to include in the output.
     |          exclude: A set of fields to exclude from the output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to use the field's alias in the dictionary key if defined.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A dictionary representation of the model.
     |
     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'str'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump_json
     |
     |      Generates a JSON representation of the model using Pydantic's `to_json` method.
     |
     |      Args:
     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.
     |          include: Field(s) to include in the JSON output.
     |          exclude: Field(s) to exclude from the JSON output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to serialize using field aliases.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A JSON string representation of the model.
     |
     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'
     |      Override this method to perform additional initialization after `__init__` and `model_construct`.
     |      This is useful if you want to do some validation that requires the entire model to be initialized.
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from pydantic.main.BaseModel:
     |
     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'
     |
     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'
     |      Hook into generating the model's CoreSchema.
     |
     |      Args:
     |          source: The class we are generating a schema for.
     |              This will generally be the same as the `cls` argument if this is a classmethod.
     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.
     |
     |      Returns:
     |          A `pydantic-core` `CoreSchema`.
     |
     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'
     |      Hook into generating the model's JSON schema.
     |
     |      Args:
     |          core_schema: A `pydantic-core` CoreSchema.
     |              You can ignore this argument and call the handler with a new CoreSchema,
     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),
     |              or just call the handler with the original schema.
     |          handler: Call into Pydantic's internal JSON schema generation.
     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema
     |              generation fails.
     |              Since this gets called by `BaseModel.model_json_schema` you can override the
     |              `schema_generator` argument to that function to change JSON schema generation globally
     |              for a type.
     |
     |      Returns:
     |          A JSON schema, as a Python object.
     |
     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'
     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`
     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will
     |      be present when this is called.
     |
     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,
     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that
     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.
     |
     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,
     |      any kwargs passed to the class definition that aren't used internally by pydantic.
     |
     |      Args:
     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally
     |              by pydantic.
     |
     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |
     |  from_orm(obj: 'Any') -> 'Self'
     |
     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |      Creates a new instance of the `Model` class with validated data.
     |
     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.
     |      Default values are respected, but no other validation is performed.
     |
     |      !!! note
     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.
     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`
     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.
     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in
     |          an error if extra values are passed, but they will be ignored.
     |
     |      Args:
     |          _fields_set: The set of field names accepted for the Model instance.
     |          values: Trusted or pre-validated data dictionary.
     |
     |      Returns:
     |          A new instance of the `Model` class with validated data.
     |
     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'
     |      Generates a JSON schema for a model class.
     |
     |      Args:
     |          by_alias: Whether to use attribute aliases or not.
     |          ref_template: The reference template.
     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of
     |              `GenerateJsonSchema` with your desired modifications
     |          mode: The mode in which to generate the schema.
     |
     |      Returns:
     |          The JSON schema for the given model class.
     |
     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'
     |      Compute the class name for parametrizations of generic classes.
     |
     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.
     |
     |      Args:
     |          params: Tuple of types of the class. Given a generic class
     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,
     |              the value `(str, int)` would be passed to `params`.
     |
     |      Returns:
     |          String representing the new class where `params` are passed to `cls` as type variables.
     |
     |      Raises:
     |          TypeError: Raised when trying to generate concrete names for non-generic models.
     |
     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'dict[str, Any] | None' = None) -> 'bool | None'
     |      Try to rebuild the pydantic-core schema for the model.
     |
     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during
     |      the initial attempt to build the schema, and automatic rebuilding fails.
     |
     |      Args:
     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.
     |          raise_errors: Whether to raise errors, defaults to `True`.
     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.
     |          _types_namespace: The types namespace, defaults to `None`.
     |
     |      Returns:
     |          Returns `None` if the schema is already "complete" and rebuilding was not required.
     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.
     |
     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate a pydantic model instance.
     |
     |      Args:
     |          obj: The object to validate.
     |          strict: Whether to enforce types strictly.
     |          from_attributes: Whether to extract data from object attributes.
     |          context: Additional context to pass to the validator.
     |
     |      Raises:
     |          ValidationError: If the object could not be validated.
     |
     |      Returns:
     |          The validated model instance.
     |
     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/json/#json-parsing
     |
     |      Validate the given JSON data against the Pydantic model.
     |
     |      Args:
     |          json_data: The JSON data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |      Raises:
     |          ValueError: If `json_data` is not a JSON string.
     |
     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate the given object with string data against the Pydantic model.
     |
     |      Args:
     |          obj: The object containing string data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  parse_obj(obj: 'Any') -> 'Self'
     |
     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'
     |
     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'
     |
     |  update_forward_refs(**localns: 'Any') -> 'None'
     |
     |  validate(value: 'Any') -> 'Self'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from pydantic.main.BaseModel:
     |
     |  __fields_set__
     |
     |  model_extra
     |      Get extra fields set during validation.
     |
     |      Returns:
     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `"allow"`.
     |
     |  model_fields_set
     |      Returns the set of fields that have been explicitly set on this model instance.
     |
     |      Returns:
     |          A set of strings representing the fields that have been set,
     |              i.e. that were not filled from defaults.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from pydantic.main.BaseModel:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __pydantic_extra__
     |
     |  __pydantic_fields_set__
     |
     |  __pydantic_private__
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from pydantic.main.BaseModel:
     |
     |  __hash__ = None
     |
     |  __pydantic_root_model__ = False

    class License(BaseModelWithConfig)
     |  License(*, name: str, identifier: Optional[str] = None, url: Optional[pydantic_core._pydantic_core.Url] = None, **extra_data: Any) -> None
     |
     |  Method resolution order:
     |      License
     |      BaseModelWithConfig
     |      pydantic.main.BaseModel
     |      builtins.object
     |
     |  Data and other attributes defined here:
     |
     |  __abstractmethods__ = frozenset()
     |
     |  __annotations__ = {'identifier': typing.Optional[str], 'name': <class ...
     |
     |  __class_vars__ = set()
     |
     |  __private_attributes__ = {}
     |
     |  __pydantic_complete__ = True
     |
     |  __pydantic_core_schema__ = {'cls': <class 'backend.Lib.site-packages.f...
     |
     |  __pydantic_custom_init__ = False
     |
     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...
     |
     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...
     |
     |  __pydantic_parent_namespace__ = {'Annotated': <pydantic._internal._mod...
     |
     |  __pydantic_post_init__ = None
     |
     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(
     |      Model...
     |
     |  __pydantic_validator__ = SchemaValidator(title="License", validator=Mo...
     |
     |  __signature__ = <Signature (*, name: str, identifier: Optional[s...tic...
     |
     |  model_computed_fields = {}
     |
     |  model_config = {'extra': 'allow'}
     |
     |  model_fields = {'identifier': FieldInfo(annotation=Union[str, NoneType...
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from BaseModelWithConfig:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from pydantic.main.BaseModel:
     |
     |  __copy__(self) -> 'Self'
     |      Returns a shallow copy of the model.
     |
     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'
     |      Returns a deep copy of the model.
     |
     |  __delattr__(self, item: 'str') -> 'Any'
     |      Implement delattr(self, name).
     |
     |  __eq__(self, other: 'Any') -> 'bool'
     |      Return self==value.
     |
     |  __getattr__(self, item: 'str') -> 'Any'
     |
     |  __getstate__(self) -> 'dict[Any, Any]'
     |      Helper for pickle.
     |
     |  __init__(self, /, **data: 'Any') -> 'None'
     |      Create a new model by parsing and validating input data from keyword arguments.
     |
     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be
     |      validated to form a valid model.
     |
     |      `self` is explicitly positional-only to allow `self` as a field name.
     |
     |  __iter__(self) -> 'TupleGenerator'
     |      So `dict(model)` works.
     |
     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation
     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.
     |
     |  __repr__(self) -> 'str'
     |      Return repr(self).
     |
     |  __repr_args__(self) -> '_repr.ReprArgs'
     |
     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation
     |      Name of the instance's class, used in __repr__.
     |
     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation
     |
     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation
     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.
     |
     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'
     |
     |  __str__(self) -> 'str'
     |      Return str(self).
     |
     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Returns a copy of the model.
     |
     |      !!! warning "Deprecated"
     |          This method is now deprecated; use `model_copy` instead.
     |
     |      If you need `include` or `exclude`, use:
     |
     |      ```py
     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)
     |      data = {**data, **(update or {})}
     |      copied = self.model_validate(data)
     |      ```
     |
     |      Args:
     |          include: Optional set or mapping specifying which fields to include in the copied model.
     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.
     |          update: Optional dictionary of field-value pairs to override field values in the copied model.
     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.
     |
     |      Returns:
     |          A copy of the model with included, excluded and updated fields as specified.
     |
     |  dict(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'
     |
     |  json(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'
     |
     |  model_copy(self, *, update: 'dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#model_copy
     |
     |      Returns a copy of the model.
     |
     |      Args:
     |          update: Values to change/add in the new model. Note: the data is not validated
     |              before creating the new model. You should trust this data.
     |          deep: Set to `True` to make a deep copy of the model.
     |
     |      Returns:
     |          New model instance.
     |
     |  model_dump(self, *, mode: "Literal['json', 'python'] | str" = 'python', include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump
     |
     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.
     |
     |      Args:
     |          mode: The mode in which `to_python` should run.
     |              If mode is 'json', the output will only contain JSON serializable types.
     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.
     |          include: A set of fields to include in the output.
     |          exclude: A set of fields to exclude from the output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to use the field's alias in the dictionary key if defined.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A dictionary representation of the model.
     |
     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'str'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump_json
     |
     |      Generates a JSON representation of the model using Pydantic's `to_json` method.
     |
     |      Args:
     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.
     |          include: Field(s) to include in the JSON output.
     |          exclude: Field(s) to exclude from the JSON output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to serialize using field aliases.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A JSON string representation of the model.
     |
     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'
     |      Override this method to perform additional initialization after `__init__` and `model_construct`.
     |      This is useful if you want to do some validation that requires the entire model to be initialized.
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from pydantic.main.BaseModel:
     |
     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'
     |
     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'
     |      Hook into generating the model's CoreSchema.
     |
     |      Args:
     |          source: The class we are generating a schema for.
     |              This will generally be the same as the `cls` argument if this is a classmethod.
     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.
     |
     |      Returns:
     |          A `pydantic-core` `CoreSchema`.
     |
     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'
     |      Hook into generating the model's JSON schema.
     |
     |      Args:
     |          core_schema: A `pydantic-core` CoreSchema.
     |              You can ignore this argument and call the handler with a new CoreSchema,
     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),
     |              or just call the handler with the original schema.
     |          handler: Call into Pydantic's internal JSON schema generation.
     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema
     |              generation fails.
     |              Since this gets called by `BaseModel.model_json_schema` you can override the
     |              `schema_generator` argument to that function to change JSON schema generation globally
     |              for a type.
     |
     |      Returns:
     |          A JSON schema, as a Python object.
     |
     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'
     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`
     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will
     |      be present when this is called.
     |
     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,
     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that
     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.
     |
     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,
     |      any kwargs passed to the class definition that aren't used internally by pydantic.
     |
     |      Args:
     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally
     |              by pydantic.
     |
     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |
     |  from_orm(obj: 'Any') -> 'Self'
     |
     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |      Creates a new instance of the `Model` class with validated data.
     |
     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.
     |      Default values are respected, but no other validation is performed.
     |
     |      !!! note
     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.
     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`
     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.
     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in
     |          an error if extra values are passed, but they will be ignored.
     |
     |      Args:
     |          _fields_set: The set of field names accepted for the Model instance.
     |          values: Trusted or pre-validated data dictionary.
     |
     |      Returns:
     |          A new instance of the `Model` class with validated data.
     |
     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'
     |      Generates a JSON schema for a model class.
     |
     |      Args:
     |          by_alias: Whether to use attribute aliases or not.
     |          ref_template: The reference template.
     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of
     |              `GenerateJsonSchema` with your desired modifications
     |          mode: The mode in which to generate the schema.
     |
     |      Returns:
     |          The JSON schema for the given model class.
     |
     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'
     |      Compute the class name for parametrizations of generic classes.
     |
     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.
     |
     |      Args:
     |          params: Tuple of types of the class. Given a generic class
     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,
     |              the value `(str, int)` would be passed to `params`.
     |
     |      Returns:
     |          String representing the new class where `params` are passed to `cls` as type variables.
     |
     |      Raises:
     |          TypeError: Raised when trying to generate concrete names for non-generic models.
     |
     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'dict[str, Any] | None' = None) -> 'bool | None'
     |      Try to rebuild the pydantic-core schema for the model.
     |
     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during
     |      the initial attempt to build the schema, and automatic rebuilding fails.
     |
     |      Args:
     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.
     |          raise_errors: Whether to raise errors, defaults to `True`.
     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.
     |          _types_namespace: The types namespace, defaults to `None`.
     |
     |      Returns:
     |          Returns `None` if the schema is already "complete" and rebuilding was not required.
     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.
     |
     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate a pydantic model instance.
     |
     |      Args:
     |          obj: The object to validate.
     |          strict: Whether to enforce types strictly.
     |          from_attributes: Whether to extract data from object attributes.
     |          context: Additional context to pass to the validator.
     |
     |      Raises:
     |          ValidationError: If the object could not be validated.
     |
     |      Returns:
     |          The validated model instance.
     |
     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/json/#json-parsing
     |
     |      Validate the given JSON data against the Pydantic model.
     |
     |      Args:
     |          json_data: The JSON data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |      Raises:
     |          ValueError: If `json_data` is not a JSON string.
     |
     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate the given object with string data against the Pydantic model.
     |
     |      Args:
     |          obj: The object containing string data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  parse_obj(obj: 'Any') -> 'Self'
     |
     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'
     |
     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'
     |
     |  update_forward_refs(**localns: 'Any') -> 'None'
     |
     |  validate(value: 'Any') -> 'Self'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from pydantic.main.BaseModel:
     |
     |  __fields_set__
     |
     |  model_extra
     |      Get extra fields set during validation.
     |
     |      Returns:
     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `"allow"`.
     |
     |  model_fields_set
     |      Returns the set of fields that have been explicitly set on this model instance.
     |
     |      Returns:
     |          A set of strings representing the fields that have been set,
     |              i.e. that were not filled from defaults.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from pydantic.main.BaseModel:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __pydantic_extra__
     |
     |  __pydantic_fields_set__
     |
     |  __pydantic_private__
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from pydantic.main.BaseModel:
     |
     |  __hash__ = None
     |
     |  __pydantic_root_model__ = False

    class Link(BaseModelWithConfig)
     |  Link(*, operationRef: Optional[str] = None, operationId: Optional[str] = None, parameters: Optional[Dict[str, Union[Any, str]]] = None, requestBody: Union[Any, str, NoneType] = None, description: Optional[str] = None, server: Optional[backend.Lib.site-packages.fastapi.openapi.models.Server] = None, **extra_data: Any) -> None
     |
     |  Method resolution order:
     |      Link
     |      BaseModelWithConfig
     |      pydantic.main.BaseModel
     |      builtins.object
     |
     |  Data and other attributes defined here:
     |
     |  __abstractmethods__ = frozenset()
     |
     |  __annotations__ = {'description': typing.Optional[str], 'operationId':...
     |
     |  __class_vars__ = set()
     |
     |  __private_attributes__ = {}
     |
     |  __pydantic_complete__ = True
     |
     |  __pydantic_core_schema__ = {'cls': <class 'backend.Lib.site-packages.f...
     |
     |  __pydantic_custom_init__ = False
     |
     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...
     |
     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...
     |
     |  __pydantic_parent_namespace__ = {'Annotated': <pydantic._internal._mod...
     |
     |  __pydantic_post_init__ = None
     |
     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(
     |      Model...
     |
     |  __pydantic_validator__ = SchemaValidator(title="Link", validator=Model...
     |
     |  __signature__ = <Signature (*, operationRef: Optional[str] = Non...ode...
     |
     |  model_computed_fields = {}
     |
     |  model_config = {'extra': 'allow'}
     |
     |  model_fields = {'description': FieldInfo(annotation=Union[str, NoneTyp...
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from BaseModelWithConfig:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from pydantic.main.BaseModel:
     |
     |  __copy__(self) -> 'Self'
     |      Returns a shallow copy of the model.
     |
     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'
     |      Returns a deep copy of the model.
     |
     |  __delattr__(self, item: 'str') -> 'Any'
     |      Implement delattr(self, name).
     |
     |  __eq__(self, other: 'Any') -> 'bool'
     |      Return self==value.
     |
     |  __getattr__(self, item: 'str') -> 'Any'
     |
     |  __getstate__(self) -> 'dict[Any, Any]'
     |      Helper for pickle.
     |
     |  __init__(self, /, **data: 'Any') -> 'None'
     |      Create a new model by parsing and validating input data from keyword arguments.
     |
     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be
     |      validated to form a valid model.
     |
     |      `self` is explicitly positional-only to allow `self` as a field name.
     |
     |  __iter__(self) -> 'TupleGenerator'
     |      So `dict(model)` works.
     |
     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation
     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.
     |
     |  __repr__(self) -> 'str'
     |      Return repr(self).
     |
     |  __repr_args__(self) -> '_repr.ReprArgs'
     |
     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation
     |      Name of the instance's class, used in __repr__.
     |
     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation
     |
     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation
     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.
     |
     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'
     |
     |  __str__(self) -> 'str'
     |      Return str(self).
     |
     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Returns a copy of the model.
     |
     |      !!! warning "Deprecated"
     |          This method is now deprecated; use `model_copy` instead.
     |
     |      If you need `include` or `exclude`, use:
     |
     |      ```py
     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)
     |      data = {**data, **(update or {})}
     |      copied = self.model_validate(data)
     |      ```
     |
     |      Args:
     |          include: Optional set or mapping specifying which fields to include in the copied model.
     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.
     |          update: Optional dictionary of field-value pairs to override field values in the copied model.
     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.
     |
     |      Returns:
     |          A copy of the model with included, excluded and updated fields as specified.
     |
     |  dict(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'
     |
     |  json(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'
     |
     |  model_copy(self, *, update: 'dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#model_copy
     |
     |      Returns a copy of the model.
     |
     |      Args:
     |          update: Values to change/add in the new model. Note: the data is not validated
     |              before creating the new model. You should trust this data.
     |          deep: Set to `True` to make a deep copy of the model.
     |
     |      Returns:
     |          New model instance.
     |
     |  model_dump(self, *, mode: "Literal['json', 'python'] | str" = 'python', include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump
     |
     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.
     |
     |      Args:
     |          mode: The mode in which `to_python` should run.
     |              If mode is 'json', the output will only contain JSON serializable types.
     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.
     |          include: A set of fields to include in the output.
     |          exclude: A set of fields to exclude from the output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to use the field's alias in the dictionary key if defined.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A dictionary representation of the model.
     |
     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'str'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump_json
     |
     |      Generates a JSON representation of the model using Pydantic's `to_json` method.
     |
     |      Args:
     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.
     |          include: Field(s) to include in the JSON output.
     |          exclude: Field(s) to exclude from the JSON output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to serialize using field aliases.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A JSON string representation of the model.
     |
     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'
     |      Override this method to perform additional initialization after `__init__` and `model_construct`.
     |      This is useful if you want to do some validation that requires the entire model to be initialized.
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from pydantic.main.BaseModel:
     |
     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'
     |
     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'
     |      Hook into generating the model's CoreSchema.
     |
     |      Args:
     |          source: The class we are generating a schema for.
     |              This will generally be the same as the `cls` argument if this is a classmethod.
     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.
     |
     |      Returns:
     |          A `pydantic-core` `CoreSchema`.
     |
     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'
     |      Hook into generating the model's JSON schema.
     |
     |      Args:
     |          core_schema: A `pydantic-core` CoreSchema.
     |              You can ignore this argument and call the handler with a new CoreSchema,
     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),
     |              or just call the handler with the original schema.
     |          handler: Call into Pydantic's internal JSON schema generation.
     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema
     |              generation fails.
     |              Since this gets called by `BaseModel.model_json_schema` you can override the
     |              `schema_generator` argument to that function to change JSON schema generation globally
     |              for a type.
     |
     |      Returns:
     |          A JSON schema, as a Python object.
     |
     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'
     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`
     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will
     |      be present when this is called.
     |
     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,
     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that
     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.
     |
     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,
     |      any kwargs passed to the class definition that aren't used internally by pydantic.
     |
     |      Args:
     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally
     |              by pydantic.
     |
     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |
     |  from_orm(obj: 'Any') -> 'Self'
     |
     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |      Creates a new instance of the `Model` class with validated data.
     |
     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.
     |      Default values are respected, but no other validation is performed.
     |
     |      !!! note
     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.
     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`
     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.
     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in
     |          an error if extra values are passed, but they will be ignored.
     |
     |      Args:
     |          _fields_set: The set of field names accepted for the Model instance.
     |          values: Trusted or pre-validated data dictionary.
     |
     |      Returns:
     |          A new instance of the `Model` class with validated data.
     |
     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'
     |      Generates a JSON schema for a model class.
     |
     |      Args:
     |          by_alias: Whether to use attribute aliases or not.
     |          ref_template: The reference template.
     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of
     |              `GenerateJsonSchema` with your desired modifications
     |          mode: The mode in which to generate the schema.
     |
     |      Returns:
     |          The JSON schema for the given model class.
     |
     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'
     |      Compute the class name for parametrizations of generic classes.
     |
     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.
     |
     |      Args:
     |          params: Tuple of types of the class. Given a generic class
     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,
     |              the value `(str, int)` would be passed to `params`.
     |
     |      Returns:
     |          String representing the new class where `params` are passed to `cls` as type variables.
     |
     |      Raises:
     |          TypeError: Raised when trying to generate concrete names for non-generic models.
     |
     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'dict[str, Any] | None' = None) -> 'bool | None'
     |      Try to rebuild the pydantic-core schema for the model.
     |
     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during
     |      the initial attempt to build the schema, and automatic rebuilding fails.
     |
     |      Args:
     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.
     |          raise_errors: Whether to raise errors, defaults to `True`.
     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.
     |          _types_namespace: The types namespace, defaults to `None`.
     |
     |      Returns:
     |          Returns `None` if the schema is already "complete" and rebuilding was not required.
     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.
     |
     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate a pydantic model instance.
     |
     |      Args:
     |          obj: The object to validate.
     |          strict: Whether to enforce types strictly.
     |          from_attributes: Whether to extract data from object attributes.
     |          context: Additional context to pass to the validator.
     |
     |      Raises:
     |          ValidationError: If the object could not be validated.
     |
     |      Returns:
     |          The validated model instance.
     |
     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/json/#json-parsing
     |
     |      Validate the given JSON data against the Pydantic model.
     |
     |      Args:
     |          json_data: The JSON data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |      Raises:
     |          ValueError: If `json_data` is not a JSON string.
     |
     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate the given object with string data against the Pydantic model.
     |
     |      Args:
     |          obj: The object containing string data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  parse_obj(obj: 'Any') -> 'Self'
     |
     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'
     |
     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'
     |
     |  update_forward_refs(**localns: 'Any') -> 'None'
     |
     |  validate(value: 'Any') -> 'Self'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from pydantic.main.BaseModel:
     |
     |  __fields_set__
     |
     |  model_extra
     |      Get extra fields set during validation.
     |
     |      Returns:
     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `"allow"`.
     |
     |  model_fields_set
     |      Returns the set of fields that have been explicitly set on this model instance.
     |
     |      Returns:
     |          A set of strings representing the fields that have been set,
     |              i.e. that were not filled from defaults.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from pydantic.main.BaseModel:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __pydantic_extra__
     |
     |  __pydantic_fields_set__
     |
     |  __pydantic_private__
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from pydantic.main.BaseModel:
     |
     |  __hash__ = None
     |
     |  __pydantic_root_model__ = False

    class MediaType(BaseModelWithConfig)
     |  MediaType(**extra_data: Any) -> None
     |
     |  Method resolution order:
     |      MediaType
     |      BaseModelWithConfig
     |      pydantic.main.BaseModel
     |      builtins.object
     |
     |  Data and other attributes defined here:
     |
     |  __abstractmethods__ = frozenset()
     |
     |  __annotations__ = {'encoding': typing.Optional[typing.Dict[str, backen...
     |
     |  __class_vars__ = set()
     |
     |  __private_attributes__ = {}
     |
     |  __pydantic_complete__ = True
     |
     |  __pydantic_core_schema__ = {'definitions': [{'cls': <class 'backend.Li...
     |
     |  __pydantic_custom_init__ = False
     |
     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...
     |
     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...
     |
     |  __pydantic_parent_namespace__ = {'Annotated': <pydantic._internal._mod...
     |
     |  __pydantic_post_init__ = None
     |
     |  __pydantic_serializer__ = SchemaSerializer(serializer=Recursive(
     |      D...
     |
     |  __pydantic_validator__ = SchemaValidator(title="MediaType", validator=...
     |
     |  __signature__ = <Signature (*, schema: Union[backend.Lib.site-pa...ls....
     |
     |  model_computed_fields = {}
     |
     |  model_config = {'extra': 'allow'}
     |
     |  model_fields = {'encoding': FieldInfo(annotation=Union[Dict[str, Encod...
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from BaseModelWithConfig:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from pydantic.main.BaseModel:
     |
     |  __copy__(self) -> 'Self'
     |      Returns a shallow copy of the model.
     |
     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'
     |      Returns a deep copy of the model.
     |
     |  __delattr__(self, item: 'str') -> 'Any'
     |      Implement delattr(self, name).
     |
     |  __eq__(self, other: 'Any') -> 'bool'
     |      Return self==value.
     |
     |  __getattr__(self, item: 'str') -> 'Any'
     |
     |  __getstate__(self) -> 'dict[Any, Any]'
     |      Helper for pickle.
     |
     |  __init__(self, /, **data: 'Any') -> 'None'
     |      Create a new model by parsing and validating input data from keyword arguments.
     |
     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be
     |      validated to form a valid model.
     |
     |      `self` is explicitly positional-only to allow `self` as a field name.
     |
     |  __iter__(self) -> 'TupleGenerator'
     |      So `dict(model)` works.
     |
     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation
     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.
     |
     |  __repr__(self) -> 'str'
     |      Return repr(self).
     |
     |  __repr_args__(self) -> '_repr.ReprArgs'
     |
     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation
     |      Name of the instance's class, used in __repr__.
     |
     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation
     |
     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation
     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.
     |
     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'
     |
     |  __str__(self) -> 'str'
     |      Return str(self).
     |
     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Returns a copy of the model.
     |
     |      !!! warning "Deprecated"
     |          This method is now deprecated; use `model_copy` instead.
     |
     |      If you need `include` or `exclude`, use:
     |
     |      ```py
     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)
     |      data = {**data, **(update or {})}
     |      copied = self.model_validate(data)
     |      ```
     |
     |      Args:
     |          include: Optional set or mapping specifying which fields to include in the copied model.
     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.
     |          update: Optional dictionary of field-value pairs to override field values in the copied model.
     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.
     |
     |      Returns:
     |          A copy of the model with included, excluded and updated fields as specified.
     |
     |  dict(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'
     |
     |  json(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'
     |
     |  model_copy(self, *, update: 'dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#model_copy
     |
     |      Returns a copy of the model.
     |
     |      Args:
     |          update: Values to change/add in the new model. Note: the data is not validated
     |              before creating the new model. You should trust this data.
     |          deep: Set to `True` to make a deep copy of the model.
     |
     |      Returns:
     |          New model instance.
     |
     |  model_dump(self, *, mode: "Literal['json', 'python'] | str" = 'python', include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump
     |
     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.
     |
     |      Args:
     |          mode: The mode in which `to_python` should run.
     |              If mode is 'json', the output will only contain JSON serializable types.
     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.
     |          include: A set of fields to include in the output.
     |          exclude: A set of fields to exclude from the output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to use the field's alias in the dictionary key if defined.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A dictionary representation of the model.
     |
     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'str'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump_json
     |
     |      Generates a JSON representation of the model using Pydantic's `to_json` method.
     |
     |      Args:
     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.
     |          include: Field(s) to include in the JSON output.
     |          exclude: Field(s) to exclude from the JSON output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to serialize using field aliases.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A JSON string representation of the model.
     |
     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'
     |      Override this method to perform additional initialization after `__init__` and `model_construct`.
     |      This is useful if you want to do some validation that requires the entire model to be initialized.
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from pydantic.main.BaseModel:
     |
     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'
     |
     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'
     |      Hook into generating the model's CoreSchema.
     |
     |      Args:
     |          source: The class we are generating a schema for.
     |              This will generally be the same as the `cls` argument if this is a classmethod.
     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.
     |
     |      Returns:
     |          A `pydantic-core` `CoreSchema`.
     |
     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'
     |      Hook into generating the model's JSON schema.
     |
     |      Args:
     |          core_schema: A `pydantic-core` CoreSchema.
     |              You can ignore this argument and call the handler with a new CoreSchema,
     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),
     |              or just call the handler with the original schema.
     |          handler: Call into Pydantic's internal JSON schema generation.
     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema
     |              generation fails.
     |              Since this gets called by `BaseModel.model_json_schema` you can override the
     |              `schema_generator` argument to that function to change JSON schema generation globally
     |              for a type.
     |
     |      Returns:
     |          A JSON schema, as a Python object.
     |
     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'
     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`
     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will
     |      be present when this is called.
     |
     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,
     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that
     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.
     |
     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,
     |      any kwargs passed to the class definition that aren't used internally by pydantic.
     |
     |      Args:
     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally
     |              by pydantic.
     |
     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |
     |  from_orm(obj: 'Any') -> 'Self'
     |
     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |      Creates a new instance of the `Model` class with validated data.
     |
     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.
     |      Default values are respected, but no other validation is performed.
     |
     |      !!! note
     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.
     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`
     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.
     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in
     |          an error if extra values are passed, but they will be ignored.
     |
     |      Args:
     |          _fields_set: The set of field names accepted for the Model instance.
     |          values: Trusted or pre-validated data dictionary.
     |
     |      Returns:
     |          A new instance of the `Model` class with validated data.
     |
     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'
     |      Generates a JSON schema for a model class.
     |
     |      Args:
     |          by_alias: Whether to use attribute aliases or not.
     |          ref_template: The reference template.
     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of
     |              `GenerateJsonSchema` with your desired modifications
     |          mode: The mode in which to generate the schema.
     |
     |      Returns:
     |          The JSON schema for the given model class.
     |
     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'
     |      Compute the class name for parametrizations of generic classes.
     |
     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.
     |
     |      Args:
     |          params: Tuple of types of the class. Given a generic class
     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,
     |              the value `(str, int)` would be passed to `params`.
     |
     |      Returns:
     |          String representing the new class where `params` are passed to `cls` as type variables.
     |
     |      Raises:
     |          TypeError: Raised when trying to generate concrete names for non-generic models.
     |
     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'dict[str, Any] | None' = None) -> 'bool | None'
     |      Try to rebuild the pydantic-core schema for the model.
     |
     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during
     |      the initial attempt to build the schema, and automatic rebuilding fails.
     |
     |      Args:
     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.
     |          raise_errors: Whether to raise errors, defaults to `True`.
     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.
     |          _types_namespace: The types namespace, defaults to `None`.
     |
     |      Returns:
     |          Returns `None` if the schema is already "complete" and rebuilding was not required.
     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.
     |
     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate a pydantic model instance.
     |
     |      Args:
     |          obj: The object to validate.
     |          strict: Whether to enforce types strictly.
     |          from_attributes: Whether to extract data from object attributes.
     |          context: Additional context to pass to the validator.
     |
     |      Raises:
     |          ValidationError: If the object could not be validated.
     |
     |      Returns:
     |          The validated model instance.
     |
     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/json/#json-parsing
     |
     |      Validate the given JSON data against the Pydantic model.
     |
     |      Args:
     |          json_data: The JSON data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |      Raises:
     |          ValueError: If `json_data` is not a JSON string.
     |
     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate the given object with string data against the Pydantic model.
     |
     |      Args:
     |          obj: The object containing string data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  parse_obj(obj: 'Any') -> 'Self'
     |
     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'
     |
     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'
     |
     |  update_forward_refs(**localns: 'Any') -> 'None'
     |
     |  validate(value: 'Any') -> 'Self'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from pydantic.main.BaseModel:
     |
     |  __fields_set__
     |
     |  model_extra
     |      Get extra fields set during validation.
     |
     |      Returns:
     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `"allow"`.
     |
     |  model_fields_set
     |      Returns the set of fields that have been explicitly set on this model instance.
     |
     |      Returns:
     |          A set of strings representing the fields that have been set,
     |              i.e. that were not filled from defaults.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from pydantic.main.BaseModel:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __pydantic_extra__
     |
     |  __pydantic_fields_set__
     |
     |  __pydantic_private__
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from pydantic.main.BaseModel:
     |
     |  __hash__ = None
     |
     |  __pydantic_root_model__ = False

    class OAuth2(SecurityBase)
     |  OAuth2(*, type: backend.Lib.site-packages.fastapi.openapi.models.SecuritySchemeType = <SecuritySchemeType.oauth2: 'oauth2'>, description: Optional[str] = None, flows: backend.Lib.site-packages.fastapi.openapi.models.OAuthFlows, **extra_data: Any) -> None
     |
     |  Method resolution order:
     |      OAuth2
     |      SecurityBase
     |      BaseModelWithConfig
     |      pydantic.main.BaseModel
     |      builtins.object
     |
     |  Data and other attributes defined here:
     |
     |  __abstractmethods__ = frozenset()
     |
     |  __annotations__ = {'flows': <class 'backend.Lib.site-packages.fastapi....
     |
     |  __class_vars__ = set()
     |
     |  __private_attributes__ = {}
     |
     |  __pydantic_complete__ = True
     |
     |  __pydantic_core_schema__ = {'cls': <class 'backend.Lib.site-packages.f...
     |
     |  __pydantic_custom_init__ = False
     |
     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...
     |
     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...
     |
     |  __pydantic_parent_namespace__ = {'APIKey': <pydantic._internal._model_...
     |
     |  __pydantic_post_init__ = None
     |
     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(
     |      Model...
     |
     |  __pydantic_validator__ = SchemaValidator(title="OAuth2", validator=Mod...
     |
     |  __signature__ = <Signature (*, type: backend.Lib.site-packages.f...pi....
     |
     |  model_computed_fields = {}
     |
     |  model_config = {'extra': 'allow'}
     |
     |  model_fields = {'description': FieldInfo(annotation=Union[str, NoneTyp...
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from BaseModelWithConfig:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from pydantic.main.BaseModel:
     |
     |  __copy__(self) -> 'Self'
     |      Returns a shallow copy of the model.
     |
     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'
     |      Returns a deep copy of the model.
     |
     |  __delattr__(self, item: 'str') -> 'Any'
     |      Implement delattr(self, name).
     |
     |  __eq__(self, other: 'Any') -> 'bool'
     |      Return self==value.
     |
     |  __getattr__(self, item: 'str') -> 'Any'
     |
     |  __getstate__(self) -> 'dict[Any, Any]'
     |      Helper for pickle.
     |
     |  __init__(self, /, **data: 'Any') -> 'None'
     |      Create a new model by parsing and validating input data from keyword arguments.
     |
     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be
     |      validated to form a valid model.
     |
     |      `self` is explicitly positional-only to allow `self` as a field name.
     |
     |  __iter__(self) -> 'TupleGenerator'
     |      So `dict(model)` works.
     |
     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation
     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.
     |
     |  __repr__(self) -> 'str'
     |      Return repr(self).
     |
     |  __repr_args__(self) -> '_repr.ReprArgs'
     |
     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation
     |      Name of the instance's class, used in __repr__.
     |
     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation
     |
     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation
     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.
     |
     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'
     |
     |  __str__(self) -> 'str'
     |      Return str(self).
     |
     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Returns a copy of the model.
     |
     |      !!! warning "Deprecated"
     |          This method is now deprecated; use `model_copy` instead.
     |
     |      If you need `include` or `exclude`, use:
     |
     |      ```py
     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)
     |      data = {**data, **(update or {})}
     |      copied = self.model_validate(data)
     |      ```
     |
     |      Args:
     |          include: Optional set or mapping specifying which fields to include in the copied model.
     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.
     |          update: Optional dictionary of field-value pairs to override field values in the copied model.
     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.
     |
     |      Returns:
     |          A copy of the model with included, excluded and updated fields as specified.
     |
     |  dict(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'
     |
     |  json(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'
     |
     |  model_copy(self, *, update: 'dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#model_copy
     |
     |      Returns a copy of the model.
     |
     |      Args:
     |          update: Values to change/add in the new model. Note: the data is not validated
     |              before creating the new model. You should trust this data.
     |          deep: Set to `True` to make a deep copy of the model.
     |
     |      Returns:
     |          New model instance.
     |
     |  model_dump(self, *, mode: "Literal['json', 'python'] | str" = 'python', include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump
     |
     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.
     |
     |      Args:
     |          mode: The mode in which `to_python` should run.
     |              If mode is 'json', the output will only contain JSON serializable types.
     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.
     |          include: A set of fields to include in the output.
     |          exclude: A set of fields to exclude from the output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to use the field's alias in the dictionary key if defined.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A dictionary representation of the model.
     |
     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'str'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump_json
     |
     |      Generates a JSON representation of the model using Pydantic's `to_json` method.
     |
     |      Args:
     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.
     |          include: Field(s) to include in the JSON output.
     |          exclude: Field(s) to exclude from the JSON output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to serialize using field aliases.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A JSON string representation of the model.
     |
     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'
     |      Override this method to perform additional initialization after `__init__` and `model_construct`.
     |      This is useful if you want to do some validation that requires the entire model to be initialized.
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from pydantic.main.BaseModel:
     |
     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'
     |
     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'
     |      Hook into generating the model's CoreSchema.
     |
     |      Args:
     |          source: The class we are generating a schema for.
     |              This will generally be the same as the `cls` argument if this is a classmethod.
     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.
     |
     |      Returns:
     |          A `pydantic-core` `CoreSchema`.
     |
     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'
     |      Hook into generating the model's JSON schema.
     |
     |      Args:
     |          core_schema: A `pydantic-core` CoreSchema.
     |              You can ignore this argument and call the handler with a new CoreSchema,
     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),
     |              or just call the handler with the original schema.
     |          handler: Call into Pydantic's internal JSON schema generation.
     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema
     |              generation fails.
     |              Since this gets called by `BaseModel.model_json_schema` you can override the
     |              `schema_generator` argument to that function to change JSON schema generation globally
     |              for a type.
     |
     |      Returns:
     |          A JSON schema, as a Python object.
     |
     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'
     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`
     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will
     |      be present when this is called.
     |
     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,
     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that
     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.
     |
     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,
     |      any kwargs passed to the class definition that aren't used internally by pydantic.
     |
     |      Args:
     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally
     |              by pydantic.
     |
     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |
     |  from_orm(obj: 'Any') -> 'Self'
     |
     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |      Creates a new instance of the `Model` class with validated data.
     |
     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.
     |      Default values are respected, but no other validation is performed.
     |
     |      !!! note
     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.
     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`
     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.
     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in
     |          an error if extra values are passed, but they will be ignored.
     |
     |      Args:
     |          _fields_set: The set of field names accepted for the Model instance.
     |          values: Trusted or pre-validated data dictionary.
     |
     |      Returns:
     |          A new instance of the `Model` class with validated data.
     |
     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'
     |      Generates a JSON schema for a model class.
     |
     |      Args:
     |          by_alias: Whether to use attribute aliases or not.
     |          ref_template: The reference template.
     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of
     |              `GenerateJsonSchema` with your desired modifications
     |          mode: The mode in which to generate the schema.
     |
     |      Returns:
     |          The JSON schema for the given model class.
     |
     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'
     |      Compute the class name for parametrizations of generic classes.
     |
     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.
     |
     |      Args:
     |          params: Tuple of types of the class. Given a generic class
     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,
     |              the value `(str, int)` would be passed to `params`.
     |
     |      Returns:
     |          String representing the new class where `params` are passed to `cls` as type variables.
     |
     |      Raises:
     |          TypeError: Raised when trying to generate concrete names for non-generic models.
     |
     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'dict[str, Any] | None' = None) -> 'bool | None'
     |      Try to rebuild the pydantic-core schema for the model.
     |
     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during
     |      the initial attempt to build the schema, and automatic rebuilding fails.
     |
     |      Args:
     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.
     |          raise_errors: Whether to raise errors, defaults to `True`.
     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.
     |          _types_namespace: The types namespace, defaults to `None`.
     |
     |      Returns:
     |          Returns `None` if the schema is already "complete" and rebuilding was not required.
     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.
     |
     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate a pydantic model instance.
     |
     |      Args:
     |          obj: The object to validate.
     |          strict: Whether to enforce types strictly.
     |          from_attributes: Whether to extract data from object attributes.
     |          context: Additional context to pass to the validator.
     |
     |      Raises:
     |          ValidationError: If the object could not be validated.
     |
     |      Returns:
     |          The validated model instance.
     |
     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/json/#json-parsing
     |
     |      Validate the given JSON data against the Pydantic model.
     |
     |      Args:
     |          json_data: The JSON data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |      Raises:
     |          ValueError: If `json_data` is not a JSON string.
     |
     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate the given object with string data against the Pydantic model.
     |
     |      Args:
     |          obj: The object containing string data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  parse_obj(obj: 'Any') -> 'Self'
     |
     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'
     |
     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'
     |
     |  update_forward_refs(**localns: 'Any') -> 'None'
     |
     |  validate(value: 'Any') -> 'Self'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from pydantic.main.BaseModel:
     |
     |  __fields_set__
     |
     |  model_extra
     |      Get extra fields set during validation.
     |
     |      Returns:
     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `"allow"`.
     |
     |  model_fields_set
     |      Returns the set of fields that have been explicitly set on this model instance.
     |
     |      Returns:
     |          A set of strings representing the fields that have been set,
     |              i.e. that were not filled from defaults.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from pydantic.main.BaseModel:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __pydantic_extra__
     |
     |  __pydantic_fields_set__
     |
     |  __pydantic_private__
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from pydantic.main.BaseModel:
     |
     |  __hash__ = None
     |
     |  __pydantic_root_model__ = False

    class OAuthFlow(BaseModelWithConfig)
     |  OAuthFlow(*, refreshUrl: Optional[str] = None, scopes: Dict[str, str] = {}, **extra_data: Any) -> None
     |
     |  Method resolution order:
     |      OAuthFlow
     |      BaseModelWithConfig
     |      pydantic.main.BaseModel
     |      builtins.object
     |
     |  Data and other attributes defined here:
     |
     |  __abstractmethods__ = frozenset()
     |
     |  __annotations__ = {'refreshUrl': typing.Optional[str], 'scopes': typin...
     |
     |  __class_vars__ = set()
     |
     |  __private_attributes__ = {}
     |
     |  __pydantic_complete__ = True
     |
     |  __pydantic_core_schema__ = {'cls': <class 'backend.Lib.site-packages.f...
     |
     |  __pydantic_custom_init__ = False
     |
     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...
     |
     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...
     |
     |  __pydantic_parent_namespace__ = {'APIKey': <pydantic._internal._model_...
     |
     |  __pydantic_post_init__ = None
     |
     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(
     |      Model...
     |
     |  __pydantic_validator__ = SchemaValidator(title="OAuthFlow", validator=...
     |
     |  __signature__ = <Signature (*, refreshUrl: Optional[str] = None,... Di...
     |
     |  model_computed_fields = {}
     |
     |  model_config = {'extra': 'allow'}
     |
     |  model_fields = {'refreshUrl': FieldInfo(annotation=Union[str, NoneType...
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from BaseModelWithConfig:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from pydantic.main.BaseModel:
     |
     |  __copy__(self) -> 'Self'
     |      Returns a shallow copy of the model.
     |
     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'
     |      Returns a deep copy of the model.
     |
     |  __delattr__(self, item: 'str') -> 'Any'
     |      Implement delattr(self, name).
     |
     |  __eq__(self, other: 'Any') -> 'bool'
     |      Return self==value.
     |
     |  __getattr__(self, item: 'str') -> 'Any'
     |
     |  __getstate__(self) -> 'dict[Any, Any]'
     |      Helper for pickle.
     |
     |  __init__(self, /, **data: 'Any') -> 'None'
     |      Create a new model by parsing and validating input data from keyword arguments.
     |
     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be
     |      validated to form a valid model.
     |
     |      `self` is explicitly positional-only to allow `self` as a field name.
     |
     |  __iter__(self) -> 'TupleGenerator'
     |      So `dict(model)` works.
     |
     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation
     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.
     |
     |  __repr__(self) -> 'str'
     |      Return repr(self).
     |
     |  __repr_args__(self) -> '_repr.ReprArgs'
     |
     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation
     |      Name of the instance's class, used in __repr__.
     |
     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation
     |
     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation
     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.
     |
     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'
     |
     |  __str__(self) -> 'str'
     |      Return str(self).
     |
     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Returns a copy of the model.
     |
     |      !!! warning "Deprecated"
     |          This method is now deprecated; use `model_copy` instead.
     |
     |      If you need `include` or `exclude`, use:
     |
     |      ```py
     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)
     |      data = {**data, **(update or {})}
     |      copied = self.model_validate(data)
     |      ```
     |
     |      Args:
     |          include: Optional set or mapping specifying which fields to include in the copied model.
     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.
     |          update: Optional dictionary of field-value pairs to override field values in the copied model.
     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.
     |
     |      Returns:
     |          A copy of the model with included, excluded and updated fields as specified.
     |
     |  dict(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'
     |
     |  json(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'
     |
     |  model_copy(self, *, update: 'dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#model_copy
     |
     |      Returns a copy of the model.
     |
     |      Args:
     |          update: Values to change/add in the new model. Note: the data is not validated
     |              before creating the new model. You should trust this data.
     |          deep: Set to `True` to make a deep copy of the model.
     |
     |      Returns:
     |          New model instance.
     |
     |  model_dump(self, *, mode: "Literal['json', 'python'] | str" = 'python', include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump
     |
     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.
     |
     |      Args:
     |          mode: The mode in which `to_python` should run.
     |              If mode is 'json', the output will only contain JSON serializable types.
     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.
     |          include: A set of fields to include in the output.
     |          exclude: A set of fields to exclude from the output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to use the field's alias in the dictionary key if defined.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A dictionary representation of the model.
     |
     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'str'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump_json
     |
     |      Generates a JSON representation of the model using Pydantic's `to_json` method.
     |
     |      Args:
     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.
     |          include: Field(s) to include in the JSON output.
     |          exclude: Field(s) to exclude from the JSON output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to serialize using field aliases.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A JSON string representation of the model.
     |
     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'
     |      Override this method to perform additional initialization after `__init__` and `model_construct`.
     |      This is useful if you want to do some validation that requires the entire model to be initialized.
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from pydantic.main.BaseModel:
     |
     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'
     |
     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'
     |      Hook into generating the model's CoreSchema.
     |
     |      Args:
     |          source: The class we are generating a schema for.
     |              This will generally be the same as the `cls` argument if this is a classmethod.
     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.
     |
     |      Returns:
     |          A `pydantic-core` `CoreSchema`.
     |
     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'
     |      Hook into generating the model's JSON schema.
     |
     |      Args:
     |          core_schema: A `pydantic-core` CoreSchema.
     |              You can ignore this argument and call the handler with a new CoreSchema,
     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),
     |              or just call the handler with the original schema.
     |          handler: Call into Pydantic's internal JSON schema generation.
     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema
     |              generation fails.
     |              Since this gets called by `BaseModel.model_json_schema` you can override the
     |              `schema_generator` argument to that function to change JSON schema generation globally
     |              for a type.
     |
     |      Returns:
     |          A JSON schema, as a Python object.
     |
     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'
     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`
     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will
     |      be present when this is called.
     |
     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,
     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that
     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.
     |
     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,
     |      any kwargs passed to the class definition that aren't used internally by pydantic.
     |
     |      Args:
     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally
     |              by pydantic.
     |
     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |
     |  from_orm(obj: 'Any') -> 'Self'
     |
     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |      Creates a new instance of the `Model` class with validated data.
     |
     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.
     |      Default values are respected, but no other validation is performed.
     |
     |      !!! note
     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.
     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`
     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.
     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in
     |          an error if extra values are passed, but they will be ignored.
     |
     |      Args:
     |          _fields_set: The set of field names accepted for the Model instance.
     |          values: Trusted or pre-validated data dictionary.
     |
     |      Returns:
     |          A new instance of the `Model` class with validated data.
     |
     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'
     |      Generates a JSON schema for a model class.
     |
     |      Args:
     |          by_alias: Whether to use attribute aliases or not.
     |          ref_template: The reference template.
     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of
     |              `GenerateJsonSchema` with your desired modifications
     |          mode: The mode in which to generate the schema.
     |
     |      Returns:
     |          The JSON schema for the given model class.
     |
     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'
     |      Compute the class name for parametrizations of generic classes.
     |
     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.
     |
     |      Args:
     |          params: Tuple of types of the class. Given a generic class
     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,
     |              the value `(str, int)` would be passed to `params`.
     |
     |      Returns:
     |          String representing the new class where `params` are passed to `cls` as type variables.
     |
     |      Raises:
     |          TypeError: Raised when trying to generate concrete names for non-generic models.
     |
     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'dict[str, Any] | None' = None) -> 'bool | None'
     |      Try to rebuild the pydantic-core schema for the model.
     |
     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during
     |      the initial attempt to build the schema, and automatic rebuilding fails.
     |
     |      Args:
     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.
     |          raise_errors: Whether to raise errors, defaults to `True`.
     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.
     |          _types_namespace: The types namespace, defaults to `None`.
     |
     |      Returns:
     |          Returns `None` if the schema is already "complete" and rebuilding was not required.
     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.
     |
     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate a pydantic model instance.
     |
     |      Args:
     |          obj: The object to validate.
     |          strict: Whether to enforce types strictly.
     |          from_attributes: Whether to extract data from object attributes.
     |          context: Additional context to pass to the validator.
     |
     |      Raises:
     |          ValidationError: If the object could not be validated.
     |
     |      Returns:
     |          The validated model instance.
     |
     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/json/#json-parsing
     |
     |      Validate the given JSON data against the Pydantic model.
     |
     |      Args:
     |          json_data: The JSON data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |      Raises:
     |          ValueError: If `json_data` is not a JSON string.
     |
     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate the given object with string data against the Pydantic model.
     |
     |      Args:
     |          obj: The object containing string data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  parse_obj(obj: 'Any') -> 'Self'
     |
     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'
     |
     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'
     |
     |  update_forward_refs(**localns: 'Any') -> 'None'
     |
     |  validate(value: 'Any') -> 'Self'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from pydantic.main.BaseModel:
     |
     |  __fields_set__
     |
     |  model_extra
     |      Get extra fields set during validation.
     |
     |      Returns:
     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `"allow"`.
     |
     |  model_fields_set
     |      Returns the set of fields that have been explicitly set on this model instance.
     |
     |      Returns:
     |          A set of strings representing the fields that have been set,
     |              i.e. that were not filled from defaults.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from pydantic.main.BaseModel:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __pydantic_extra__
     |
     |  __pydantic_fields_set__
     |
     |  __pydantic_private__
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from pydantic.main.BaseModel:
     |
     |  __hash__ = None
     |
     |  __pydantic_root_model__ = False

    class OAuthFlowAuthorizationCode(OAuthFlow)
     |  OAuthFlowAuthorizationCode(*, refreshUrl: Optional[str] = None, scopes: Dict[str, str] = {}, authorizationUrl: str, tokenUrl: str, **extra_data: Any) -> None
     |
     |  Method resolution order:
     |      OAuthFlowAuthorizationCode
     |      OAuthFlow
     |      BaseModelWithConfig
     |      pydantic.main.BaseModel
     |      builtins.object
     |
     |  Data and other attributes defined here:
     |
     |  __abstractmethods__ = frozenset()
     |
     |  __annotations__ = {'authorizationUrl': <class 'str'>, 'tokenUrl': <cla...
     |
     |  __class_vars__ = set()
     |
     |  __private_attributes__ = {}
     |
     |  __pydantic_complete__ = True
     |
     |  __pydantic_core_schema__ = {'cls': <class 'backend.Lib.site-packages.f...
     |
     |  __pydantic_custom_init__ = False
     |
     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...
     |
     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...
     |
     |  __pydantic_parent_namespace__ = {'APIKey': <pydantic._internal._model_...
     |
     |  __pydantic_post_init__ = None
     |
     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(
     |      Model...
     |
     |  __pydantic_validator__ = SchemaValidator(title="OAuthFlowAuthorization...
     |
     |  __signature__ = <Signature (*, refreshUrl: Optional[str] = None,...: s...
     |
     |  model_computed_fields = {}
     |
     |  model_config = {'extra': 'allow'}
     |
     |  model_fields = {'authorizationUrl': FieldInfo(annotation=str, required...
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from BaseModelWithConfig:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from pydantic.main.BaseModel:
     |
     |  __copy__(self) -> 'Self'
     |      Returns a shallow copy of the model.
     |
     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'
     |      Returns a deep copy of the model.
     |
     |  __delattr__(self, item: 'str') -> 'Any'
     |      Implement delattr(self, name).
     |
     |  __eq__(self, other: 'Any') -> 'bool'
     |      Return self==value.
     |
     |  __getattr__(self, item: 'str') -> 'Any'
     |
     |  __getstate__(self) -> 'dict[Any, Any]'
     |      Helper for pickle.
     |
     |  __init__(self, /, **data: 'Any') -> 'None'
     |      Create a new model by parsing and validating input data from keyword arguments.
     |
     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be
     |      validated to form a valid model.
     |
     |      `self` is explicitly positional-only to allow `self` as a field name.
     |
     |  __iter__(self) -> 'TupleGenerator'
     |      So `dict(model)` works.
     |
     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation
     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.
     |
     |  __repr__(self) -> 'str'
     |      Return repr(self).
     |
     |  __repr_args__(self) -> '_repr.ReprArgs'
     |
     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation
     |      Name of the instance's class, used in __repr__.
     |
     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation
     |
     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation
     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.
     |
     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'
     |
     |  __str__(self) -> 'str'
     |      Return str(self).
     |
     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Returns a copy of the model.
     |
     |      !!! warning "Deprecated"
     |          This method is now deprecated; use `model_copy` instead.
     |
     |      If you need `include` or `exclude`, use:
     |
     |      ```py
     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)
     |      data = {**data, **(update or {})}
     |      copied = self.model_validate(data)
     |      ```
     |
     |      Args:
     |          include: Optional set or mapping specifying which fields to include in the copied model.
     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.
     |          update: Optional dictionary of field-value pairs to override field values in the copied model.
     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.
     |
     |      Returns:
     |          A copy of the model with included, excluded and updated fields as specified.
     |
     |  dict(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'
     |
     |  json(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'
     |
     |  model_copy(self, *, update: 'dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#model_copy
     |
     |      Returns a copy of the model.
     |
     |      Args:
     |          update: Values to change/add in the new model. Note: the data is not validated
     |              before creating the new model. You should trust this data.
     |          deep: Set to `True` to make a deep copy of the model.
     |
     |      Returns:
     |          New model instance.
     |
     |  model_dump(self, *, mode: "Literal['json', 'python'] | str" = 'python', include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump
     |
     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.
     |
     |      Args:
     |          mode: The mode in which `to_python` should run.
     |              If mode is 'json', the output will only contain JSON serializable types.
     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.
     |          include: A set of fields to include in the output.
     |          exclude: A set of fields to exclude from the output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to use the field's alias in the dictionary key if defined.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A dictionary representation of the model.
     |
     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'str'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump_json
     |
     |      Generates a JSON representation of the model using Pydantic's `to_json` method.
     |
     |      Args:
     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.
     |          include: Field(s) to include in the JSON output.
     |          exclude: Field(s) to exclude from the JSON output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to serialize using field aliases.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A JSON string representation of the model.
     |
     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'
     |      Override this method to perform additional initialization after `__init__` and `model_construct`.
     |      This is useful if you want to do some validation that requires the entire model to be initialized.
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from pydantic.main.BaseModel:
     |
     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'
     |
     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'
     |      Hook into generating the model's CoreSchema.
     |
     |      Args:
     |          source: The class we are generating a schema for.
     |              This will generally be the same as the `cls` argument if this is a classmethod.
     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.
     |
     |      Returns:
     |          A `pydantic-core` `CoreSchema`.
     |
     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'
     |      Hook into generating the model's JSON schema.
     |
     |      Args:
     |          core_schema: A `pydantic-core` CoreSchema.
     |              You can ignore this argument and call the handler with a new CoreSchema,
     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),
     |              or just call the handler with the original schema.
     |          handler: Call into Pydantic's internal JSON schema generation.
     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema
     |              generation fails.
     |              Since this gets called by `BaseModel.model_json_schema` you can override the
     |              `schema_generator` argument to that function to change JSON schema generation globally
     |              for a type.
     |
     |      Returns:
     |          A JSON schema, as a Python object.
     |
     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'
     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`
     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will
     |      be present when this is called.
     |
     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,
     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that
     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.
     |
     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,
     |      any kwargs passed to the class definition that aren't used internally by pydantic.
     |
     |      Args:
     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally
     |              by pydantic.
     |
     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |
     |  from_orm(obj: 'Any') -> 'Self'
     |
     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |      Creates a new instance of the `Model` class with validated data.
     |
     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.
     |      Default values are respected, but no other validation is performed.
     |
     |      !!! note
     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.
     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`
     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.
     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in
     |          an error if extra values are passed, but they will be ignored.
     |
     |      Args:
     |          _fields_set: The set of field names accepted for the Model instance.
     |          values: Trusted or pre-validated data dictionary.
     |
     |      Returns:
     |          A new instance of the `Model` class with validated data.
     |
     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'
     |      Generates a JSON schema for a model class.
     |
     |      Args:
     |          by_alias: Whether to use attribute aliases or not.
     |          ref_template: The reference template.
     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of
     |              `GenerateJsonSchema` with your desired modifications
     |          mode: The mode in which to generate the schema.
     |
     |      Returns:
     |          The JSON schema for the given model class.
     |
     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'
     |      Compute the class name for parametrizations of generic classes.
     |
     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.
     |
     |      Args:
     |          params: Tuple of types of the class. Given a generic class
     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,
     |              the value `(str, int)` would be passed to `params`.
     |
     |      Returns:
     |          String representing the new class where `params` are passed to `cls` as type variables.
     |
     |      Raises:
     |          TypeError: Raised when trying to generate concrete names for non-generic models.
     |
     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'dict[str, Any] | None' = None) -> 'bool | None'
     |      Try to rebuild the pydantic-core schema for the model.
     |
     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during
     |      the initial attempt to build the schema, and automatic rebuilding fails.
     |
     |      Args:
     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.
     |          raise_errors: Whether to raise errors, defaults to `True`.
     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.
     |          _types_namespace: The types namespace, defaults to `None`.
     |
     |      Returns:
     |          Returns `None` if the schema is already "complete" and rebuilding was not required.
     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.
     |
     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate a pydantic model instance.
     |
     |      Args:
     |          obj: The object to validate.
     |          strict: Whether to enforce types strictly.
     |          from_attributes: Whether to extract data from object attributes.
     |          context: Additional context to pass to the validator.
     |
     |      Raises:
     |          ValidationError: If the object could not be validated.
     |
     |      Returns:
     |          The validated model instance.
     |
     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/json/#json-parsing
     |
     |      Validate the given JSON data against the Pydantic model.
     |
     |      Args:
     |          json_data: The JSON data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |      Raises:
     |          ValueError: If `json_data` is not a JSON string.
     |
     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate the given object with string data against the Pydantic model.
     |
     |      Args:
     |          obj: The object containing string data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  parse_obj(obj: 'Any') -> 'Self'
     |
     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'
     |
     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'
     |
     |  update_forward_refs(**localns: 'Any') -> 'None'
     |
     |  validate(value: 'Any') -> 'Self'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from pydantic.main.BaseModel:
     |
     |  __fields_set__
     |
     |  model_extra
     |      Get extra fields set during validation.
     |
     |      Returns:
     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `"allow"`.
     |
     |  model_fields_set
     |      Returns the set of fields that have been explicitly set on this model instance.
     |
     |      Returns:
     |          A set of strings representing the fields that have been set,
     |              i.e. that were not filled from defaults.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from pydantic.main.BaseModel:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __pydantic_extra__
     |
     |  __pydantic_fields_set__
     |
     |  __pydantic_private__
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from pydantic.main.BaseModel:
     |
     |  __hash__ = None
     |
     |  __pydantic_root_model__ = False

    class OAuthFlowClientCredentials(OAuthFlow)
     |  OAuthFlowClientCredentials(*, refreshUrl: Optional[str] = None, scopes: Dict[str, str] = {}, tokenUrl: str, **extra_data: Any) -> None
     |
     |  Method resolution order:
     |      OAuthFlowClientCredentials
     |      OAuthFlow
     |      BaseModelWithConfig
     |      pydantic.main.BaseModel
     |      builtins.object
     |
     |  Data and other attributes defined here:
     |
     |  __abstractmethods__ = frozenset()
     |
     |  __annotations__ = {'tokenUrl': <class 'str'>}
     |
     |  __class_vars__ = set()
     |
     |  __private_attributes__ = {}
     |
     |  __pydantic_complete__ = True
     |
     |  __pydantic_core_schema__ = {'cls': <class 'backend.Lib.site-packages.f...
     |
     |  __pydantic_custom_init__ = False
     |
     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...
     |
     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...
     |
     |  __pydantic_parent_namespace__ = {'APIKey': <pydantic._internal._model_...
     |
     |  __pydantic_post_init__ = None
     |
     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(
     |      Model...
     |
     |  __pydantic_validator__ = SchemaValidator(title="OAuthFlowClientCredent...
     |
     |  __signature__ = <Signature (*, refreshUrl: Optional[str] = None,... = ...
     |
     |  model_computed_fields = {}
     |
     |  model_config = {'extra': 'allow'}
     |
     |  model_fields = {'refreshUrl': FieldInfo(annotation=Union[str, NoneType...
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from BaseModelWithConfig:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from pydantic.main.BaseModel:
     |
     |  __copy__(self) -> 'Self'
     |      Returns a shallow copy of the model.
     |
     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'
     |      Returns a deep copy of the model.
     |
     |  __delattr__(self, item: 'str') -> 'Any'
     |      Implement delattr(self, name).
     |
     |  __eq__(self, other: 'Any') -> 'bool'
     |      Return self==value.
     |
     |  __getattr__(self, item: 'str') -> 'Any'
     |
     |  __getstate__(self) -> 'dict[Any, Any]'
     |      Helper for pickle.
     |
     |  __init__(self, /, **data: 'Any') -> 'None'
     |      Create a new model by parsing and validating input data from keyword arguments.
     |
     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be
     |      validated to form a valid model.
     |
     |      `self` is explicitly positional-only to allow `self` as a field name.
     |
     |  __iter__(self) -> 'TupleGenerator'
     |      So `dict(model)` works.
     |
     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation
     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.
     |
     |  __repr__(self) -> 'str'
     |      Return repr(self).
     |
     |  __repr_args__(self) -> '_repr.ReprArgs'
     |
     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation
     |      Name of the instance's class, used in __repr__.
     |
     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation
     |
     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation
     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.
     |
     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'
     |
     |  __str__(self) -> 'str'
     |      Return str(self).
     |
     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Returns a copy of the model.
     |
     |      !!! warning "Deprecated"
     |          This method is now deprecated; use `model_copy` instead.
     |
     |      If you need `include` or `exclude`, use:
     |
     |      ```py
     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)
     |      data = {**data, **(update or {})}
     |      copied = self.model_validate(data)
     |      ```
     |
     |      Args:
     |          include: Optional set or mapping specifying which fields to include in the copied model.
     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.
     |          update: Optional dictionary of field-value pairs to override field values in the copied model.
     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.
     |
     |      Returns:
     |          A copy of the model with included, excluded and updated fields as specified.
     |
     |  dict(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'
     |
     |  json(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'
     |
     |  model_copy(self, *, update: 'dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#model_copy
     |
     |      Returns a copy of the model.
     |
     |      Args:
     |          update: Values to change/add in the new model. Note: the data is not validated
     |              before creating the new model. You should trust this data.
     |          deep: Set to `True` to make a deep copy of the model.
     |
     |      Returns:
     |          New model instance.
     |
     |  model_dump(self, *, mode: "Literal['json', 'python'] | str" = 'python', include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump
     |
     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.
     |
     |      Args:
     |          mode: The mode in which `to_python` should run.
     |              If mode is 'json', the output will only contain JSON serializable types.
     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.
     |          include: A set of fields to include in the output.
     |          exclude: A set of fields to exclude from the output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to use the field's alias in the dictionary key if defined.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A dictionary representation of the model.
     |
     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'str'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump_json
     |
     |      Generates a JSON representation of the model using Pydantic's `to_json` method.
     |
     |      Args:
     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.
     |          include: Field(s) to include in the JSON output.
     |          exclude: Field(s) to exclude from the JSON output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to serialize using field aliases.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A JSON string representation of the model.
     |
     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'
     |      Override this method to perform additional initialization after `__init__` and `model_construct`.
     |      This is useful if you want to do some validation that requires the entire model to be initialized.
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from pydantic.main.BaseModel:
     |
     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'
     |
     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'
     |      Hook into generating the model's CoreSchema.
     |
     |      Args:
     |          source: The class we are generating a schema for.
     |              This will generally be the same as the `cls` argument if this is a classmethod.
     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.
     |
     |      Returns:
     |          A `pydantic-core` `CoreSchema`.
     |
     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'
     |      Hook into generating the model's JSON schema.
     |
     |      Args:
     |          core_schema: A `pydantic-core` CoreSchema.
     |              You can ignore this argument and call the handler with a new CoreSchema,
     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),
     |              or just call the handler with the original schema.
     |          handler: Call into Pydantic's internal JSON schema generation.
     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema
     |              generation fails.
     |              Since this gets called by `BaseModel.model_json_schema` you can override the
     |              `schema_generator` argument to that function to change JSON schema generation globally
     |              for a type.
     |
     |      Returns:
     |          A JSON schema, as a Python object.
     |
     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'
     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`
     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will
     |      be present when this is called.
     |
     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,
     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that
     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.
     |
     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,
     |      any kwargs passed to the class definition that aren't used internally by pydantic.
     |
     |      Args:
     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally
     |              by pydantic.
     |
     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |
     |  from_orm(obj: 'Any') -> 'Self'
     |
     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |      Creates a new instance of the `Model` class with validated data.
     |
     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.
     |      Default values are respected, but no other validation is performed.
     |
     |      !!! note
     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.
     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`
     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.
     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in
     |          an error if extra values are passed, but they will be ignored.
     |
     |      Args:
     |          _fields_set: The set of field names accepted for the Model instance.
     |          values: Trusted or pre-validated data dictionary.
     |
     |      Returns:
     |          A new instance of the `Model` class with validated data.
     |
     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'
     |      Generates a JSON schema for a model class.
     |
     |      Args:
     |          by_alias: Whether to use attribute aliases or not.
     |          ref_template: The reference template.
     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of
     |              `GenerateJsonSchema` with your desired modifications
     |          mode: The mode in which to generate the schema.
     |
     |      Returns:
     |          The JSON schema for the given model class.
     |
     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'
     |      Compute the class name for parametrizations of generic classes.
     |
     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.
     |
     |      Args:
     |          params: Tuple of types of the class. Given a generic class
     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,
     |              the value `(str, int)` would be passed to `params`.
     |
     |      Returns:
     |          String representing the new class where `params` are passed to `cls` as type variables.
     |
     |      Raises:
     |          TypeError: Raised when trying to generate concrete names for non-generic models.
     |
     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'dict[str, Any] | None' = None) -> 'bool | None'
     |      Try to rebuild the pydantic-core schema for the model.
     |
     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during
     |      the initial attempt to build the schema, and automatic rebuilding fails.
     |
     |      Args:
     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.
     |          raise_errors: Whether to raise errors, defaults to `True`.
     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.
     |          _types_namespace: The types namespace, defaults to `None`.
     |
     |      Returns:
     |          Returns `None` if the schema is already "complete" and rebuilding was not required.
     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.
     |
     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate a pydantic model instance.
     |
     |      Args:
     |          obj: The object to validate.
     |          strict: Whether to enforce types strictly.
     |          from_attributes: Whether to extract data from object attributes.
     |          context: Additional context to pass to the validator.
     |
     |      Raises:
     |          ValidationError: If the object could not be validated.
     |
     |      Returns:
     |          The validated model instance.
     |
     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/json/#json-parsing
     |
     |      Validate the given JSON data against the Pydantic model.
     |
     |      Args:
     |          json_data: The JSON data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |      Raises:
     |          ValueError: If `json_data` is not a JSON string.
     |
     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate the given object with string data against the Pydantic model.
     |
     |      Args:
     |          obj: The object containing string data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  parse_obj(obj: 'Any') -> 'Self'
     |
     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'
     |
     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'
     |
     |  update_forward_refs(**localns: 'Any') -> 'None'
     |
     |  validate(value: 'Any') -> 'Self'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from pydantic.main.BaseModel:
     |
     |  __fields_set__
     |
     |  model_extra
     |      Get extra fields set during validation.
     |
     |      Returns:
     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `"allow"`.
     |
     |  model_fields_set
     |      Returns the set of fields that have been explicitly set on this model instance.
     |
     |      Returns:
     |          A set of strings representing the fields that have been set,
     |              i.e. that were not filled from defaults.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from pydantic.main.BaseModel:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __pydantic_extra__
     |
     |  __pydantic_fields_set__
     |
     |  __pydantic_private__
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from pydantic.main.BaseModel:
     |
     |  __hash__ = None
     |
     |  __pydantic_root_model__ = False

    class OAuthFlowImplicit(OAuthFlow)
     |  OAuthFlowImplicit(*, refreshUrl: Optional[str] = None, scopes: Dict[str, str] = {}, authorizationUrl: str, **extra_data: Any) -> None
     |
     |  Method resolution order:
     |      OAuthFlowImplicit
     |      OAuthFlow
     |      BaseModelWithConfig
     |      pydantic.main.BaseModel
     |      builtins.object
     |
     |  Data and other attributes defined here:
     |
     |  __abstractmethods__ = frozenset()
     |
     |  __annotations__ = {'authorizationUrl': <class 'str'>}
     |
     |  __class_vars__ = set()
     |
     |  __private_attributes__ = {}
     |
     |  __pydantic_complete__ = True
     |
     |  __pydantic_core_schema__ = {'cls': <class 'backend.Lib.site-packages.f...
     |
     |  __pydantic_custom_init__ = False
     |
     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...
     |
     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...
     |
     |  __pydantic_parent_namespace__ = {'APIKey': <pydantic._internal._model_...
     |
     |  __pydantic_post_init__ = None
     |
     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(
     |      Model...
     |
     |  __pydantic_validator__ = SchemaValidator(title="OAuthFlowImplicit", va...
     |
     |  __signature__ = <Signature (*, refreshUrl: Optional[str] = None,...uth...
     |
     |  model_computed_fields = {}
     |
     |  model_config = {'extra': 'allow'}
     |
     |  model_fields = {'authorizationUrl': FieldInfo(annotation=str, required...
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from BaseModelWithConfig:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from pydantic.main.BaseModel:
     |
     |  __copy__(self) -> 'Self'
     |      Returns a shallow copy of the model.
     |
     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'
     |      Returns a deep copy of the model.
     |
     |  __delattr__(self, item: 'str') -> 'Any'
     |      Implement delattr(self, name).
     |
     |  __eq__(self, other: 'Any') -> 'bool'
     |      Return self==value.
     |
     |  __getattr__(self, item: 'str') -> 'Any'
     |
     |  __getstate__(self) -> 'dict[Any, Any]'
     |      Helper for pickle.
     |
     |  __init__(self, /, **data: 'Any') -> 'None'
     |      Create a new model by parsing and validating input data from keyword arguments.
     |
     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be
     |      validated to form a valid model.
     |
     |      `self` is explicitly positional-only to allow `self` as a field name.
     |
     |  __iter__(self) -> 'TupleGenerator'
     |      So `dict(model)` works.
     |
     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation
     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.
     |
     |  __repr__(self) -> 'str'
     |      Return repr(self).
     |
     |  __repr_args__(self) -> '_repr.ReprArgs'
     |
     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation
     |      Name of the instance's class, used in __repr__.
     |
     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation
     |
     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation
     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.
     |
     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'
     |
     |  __str__(self) -> 'str'
     |      Return str(self).
     |
     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Returns a copy of the model.
     |
     |      !!! warning "Deprecated"
     |          This method is now deprecated; use `model_copy` instead.
     |
     |      If you need `include` or `exclude`, use:
     |
     |      ```py
     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)
     |      data = {**data, **(update or {})}
     |      copied = self.model_validate(data)
     |      ```
     |
     |      Args:
     |          include: Optional set or mapping specifying which fields to include in the copied model.
     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.
     |          update: Optional dictionary of field-value pairs to override field values in the copied model.
     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.
     |
     |      Returns:
     |          A copy of the model with included, excluded and updated fields as specified.
     |
     |  dict(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'
     |
     |  json(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'
     |
     |  model_copy(self, *, update: 'dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#model_copy
     |
     |      Returns a copy of the model.
     |
     |      Args:
     |          update: Values to change/add in the new model. Note: the data is not validated
     |              before creating the new model. You should trust this data.
     |          deep: Set to `True` to make a deep copy of the model.
     |
     |      Returns:
     |          New model instance.
     |
     |  model_dump(self, *, mode: "Literal['json', 'python'] | str" = 'python', include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump
     |
     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.
     |
     |      Args:
     |          mode: The mode in which `to_python` should run.
     |              If mode is 'json', the output will only contain JSON serializable types.
     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.
     |          include: A set of fields to include in the output.
     |          exclude: A set of fields to exclude from the output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to use the field's alias in the dictionary key if defined.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A dictionary representation of the model.
     |
     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'str'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump_json
     |
     |      Generates a JSON representation of the model using Pydantic's `to_json` method.
     |
     |      Args:
     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.
     |          include: Field(s) to include in the JSON output.
     |          exclude: Field(s) to exclude from the JSON output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to serialize using field aliases.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A JSON string representation of the model.
     |
     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'
     |      Override this method to perform additional initialization after `__init__` and `model_construct`.
     |      This is useful if you want to do some validation that requires the entire model to be initialized.
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from pydantic.main.BaseModel:
     |
     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'
     |
     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'
     |      Hook into generating the model's CoreSchema.
     |
     |      Args:
     |          source: The class we are generating a schema for.
     |              This will generally be the same as the `cls` argument if this is a classmethod.
     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.
     |
     |      Returns:
     |          A `pydantic-core` `CoreSchema`.
     |
     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'
     |      Hook into generating the model's JSON schema.
     |
     |      Args:
     |          core_schema: A `pydantic-core` CoreSchema.
     |              You can ignore this argument and call the handler with a new CoreSchema,
     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),
     |              or just call the handler with the original schema.
     |          handler: Call into Pydantic's internal JSON schema generation.
     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema
     |              generation fails.
     |              Since this gets called by `BaseModel.model_json_schema` you can override the
     |              `schema_generator` argument to that function to change JSON schema generation globally
     |              for a type.
     |
     |      Returns:
     |          A JSON schema, as a Python object.
     |
     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'
     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`
     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will
     |      be present when this is called.
     |
     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,
     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that
     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.
     |
     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,
     |      any kwargs passed to the class definition that aren't used internally by pydantic.
     |
     |      Args:
     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally
     |              by pydantic.
     |
     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |
     |  from_orm(obj: 'Any') -> 'Self'
     |
     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |      Creates a new instance of the `Model` class with validated data.
     |
     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.
     |      Default values are respected, but no other validation is performed.
     |
     |      !!! note
     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.
     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`
     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.
     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in
     |          an error if extra values are passed, but they will be ignored.
     |
     |      Args:
     |          _fields_set: The set of field names accepted for the Model instance.
     |          values: Trusted or pre-validated data dictionary.
     |
     |      Returns:
     |          A new instance of the `Model` class with validated data.
     |
     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'
     |      Generates a JSON schema for a model class.
     |
     |      Args:
     |          by_alias: Whether to use attribute aliases or not.
     |          ref_template: The reference template.
     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of
     |              `GenerateJsonSchema` with your desired modifications
     |          mode: The mode in which to generate the schema.
     |
     |      Returns:
     |          The JSON schema for the given model class.
     |
     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'
     |      Compute the class name for parametrizations of generic classes.
     |
     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.
     |
     |      Args:
     |          params: Tuple of types of the class. Given a generic class
     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,
     |              the value `(str, int)` would be passed to `params`.
     |
     |      Returns:
     |          String representing the new class where `params` are passed to `cls` as type variables.
     |
     |      Raises:
     |          TypeError: Raised when trying to generate concrete names for non-generic models.
     |
     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'dict[str, Any] | None' = None) -> 'bool | None'
     |      Try to rebuild the pydantic-core schema for the model.
     |
     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during
     |      the initial attempt to build the schema, and automatic rebuilding fails.
     |
     |      Args:
     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.
     |          raise_errors: Whether to raise errors, defaults to `True`.
     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.
     |          _types_namespace: The types namespace, defaults to `None`.
     |
     |      Returns:
     |          Returns `None` if the schema is already "complete" and rebuilding was not required.
     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.
     |
     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate a pydantic model instance.
     |
     |      Args:
     |          obj: The object to validate.
     |          strict: Whether to enforce types strictly.
     |          from_attributes: Whether to extract data from object attributes.
     |          context: Additional context to pass to the validator.
     |
     |      Raises:
     |          ValidationError: If the object could not be validated.
     |
     |      Returns:
     |          The validated model instance.
     |
     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/json/#json-parsing
     |
     |      Validate the given JSON data against the Pydantic model.
     |
     |      Args:
     |          json_data: The JSON data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |      Raises:
     |          ValueError: If `json_data` is not a JSON string.
     |
     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate the given object with string data against the Pydantic model.
     |
     |      Args:
     |          obj: The object containing string data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  parse_obj(obj: 'Any') -> 'Self'
     |
     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'
     |
     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'
     |
     |  update_forward_refs(**localns: 'Any') -> 'None'
     |
     |  validate(value: 'Any') -> 'Self'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from pydantic.main.BaseModel:
     |
     |  __fields_set__
     |
     |  model_extra
     |      Get extra fields set during validation.
     |
     |      Returns:
     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `"allow"`.
     |
     |  model_fields_set
     |      Returns the set of fields that have been explicitly set on this model instance.
     |
     |      Returns:
     |          A set of strings representing the fields that have been set,
     |              i.e. that were not filled from defaults.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from pydantic.main.BaseModel:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __pydantic_extra__
     |
     |  __pydantic_fields_set__
     |
     |  __pydantic_private__
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from pydantic.main.BaseModel:
     |
     |  __hash__ = None
     |
     |  __pydantic_root_model__ = False

    class OAuthFlowPassword(OAuthFlow)
     |  OAuthFlowPassword(*, refreshUrl: Optional[str] = None, scopes: Dict[str, str] = {}, tokenUrl: str, **extra_data: Any) -> None
     |
     |  Method resolution order:
     |      OAuthFlowPassword
     |      OAuthFlow
     |      BaseModelWithConfig
     |      pydantic.main.BaseModel
     |      builtins.object
     |
     |  Data and other attributes defined here:
     |
     |  __abstractmethods__ = frozenset()
     |
     |  __annotations__ = {'tokenUrl': <class 'str'>}
     |
     |  __class_vars__ = set()
     |
     |  __private_attributes__ = {}
     |
     |  __pydantic_complete__ = True
     |
     |  __pydantic_core_schema__ = {'cls': <class 'backend.Lib.site-packages.f...
     |
     |  __pydantic_custom_init__ = False
     |
     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...
     |
     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...
     |
     |  __pydantic_parent_namespace__ = {'APIKey': <pydantic._internal._model_...
     |
     |  __pydantic_post_init__ = None
     |
     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(
     |      Model...
     |
     |  __pydantic_validator__ = SchemaValidator(title="OAuthFlowPassword", va...
     |
     |  __signature__ = <Signature (*, refreshUrl: Optional[str] = None,... = ...
     |
     |  model_computed_fields = {}
     |
     |  model_config = {'extra': 'allow'}
     |
     |  model_fields = {'refreshUrl': FieldInfo(annotation=Union[str, NoneType...
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from BaseModelWithConfig:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from pydantic.main.BaseModel:
     |
     |  __copy__(self) -> 'Self'
     |      Returns a shallow copy of the model.
     |
     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'
     |      Returns a deep copy of the model.
     |
     |  __delattr__(self, item: 'str') -> 'Any'
     |      Implement delattr(self, name).
     |
     |  __eq__(self, other: 'Any') -> 'bool'
     |      Return self==value.
     |
     |  __getattr__(self, item: 'str') -> 'Any'
     |
     |  __getstate__(self) -> 'dict[Any, Any]'
     |      Helper for pickle.
     |
     |  __init__(self, /, **data: 'Any') -> 'None'
     |      Create a new model by parsing and validating input data from keyword arguments.
     |
     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be
     |      validated to form a valid model.
     |
     |      `self` is explicitly positional-only to allow `self` as a field name.
     |
     |  __iter__(self) -> 'TupleGenerator'
     |      So `dict(model)` works.
     |
     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation
     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.
     |
     |  __repr__(self) -> 'str'
     |      Return repr(self).
     |
     |  __repr_args__(self) -> '_repr.ReprArgs'
     |
     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation
     |      Name of the instance's class, used in __repr__.
     |
     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation
     |
     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation
     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.
     |
     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'
     |
     |  __str__(self) -> 'str'
     |      Return str(self).
     |
     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Returns a copy of the model.
     |
     |      !!! warning "Deprecated"
     |          This method is now deprecated; use `model_copy` instead.
     |
     |      If you need `include` or `exclude`, use:
     |
     |      ```py
     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)
     |      data = {**data, **(update or {})}
     |      copied = self.model_validate(data)
     |      ```
     |
     |      Args:
     |          include: Optional set or mapping specifying which fields to include in the copied model.
     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.
     |          update: Optional dictionary of field-value pairs to override field values in the copied model.
     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.
     |
     |      Returns:
     |          A copy of the model with included, excluded and updated fields as specified.
     |
     |  dict(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'
     |
     |  json(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'
     |
     |  model_copy(self, *, update: 'dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#model_copy
     |
     |      Returns a copy of the model.
     |
     |      Args:
     |          update: Values to change/add in the new model. Note: the data is not validated
     |              before creating the new model. You should trust this data.
     |          deep: Set to `True` to make a deep copy of the model.
     |
     |      Returns:
     |          New model instance.
     |
     |  model_dump(self, *, mode: "Literal['json', 'python'] | str" = 'python', include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump
     |
     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.
     |
     |      Args:
     |          mode: The mode in which `to_python` should run.
     |              If mode is 'json', the output will only contain JSON serializable types.
     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.
     |          include: A set of fields to include in the output.
     |          exclude: A set of fields to exclude from the output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to use the field's alias in the dictionary key if defined.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A dictionary representation of the model.
     |
     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'str'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump_json
     |
     |      Generates a JSON representation of the model using Pydantic's `to_json` method.
     |
     |      Args:
     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.
     |          include: Field(s) to include in the JSON output.
     |          exclude: Field(s) to exclude from the JSON output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to serialize using field aliases.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A JSON string representation of the model.
     |
     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'
     |      Override this method to perform additional initialization after `__init__` and `model_construct`.
     |      This is useful if you want to do some validation that requires the entire model to be initialized.
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from pydantic.main.BaseModel:
     |
     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'
     |
     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'
     |      Hook into generating the model's CoreSchema.
     |
     |      Args:
     |          source: The class we are generating a schema for.
     |              This will generally be the same as the `cls` argument if this is a classmethod.
     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.
     |
     |      Returns:
     |          A `pydantic-core` `CoreSchema`.
     |
     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'
     |      Hook into generating the model's JSON schema.
     |
     |      Args:
     |          core_schema: A `pydantic-core` CoreSchema.
     |              You can ignore this argument and call the handler with a new CoreSchema,
     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),
     |              or just call the handler with the original schema.
     |          handler: Call into Pydantic's internal JSON schema generation.
     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema
     |              generation fails.
     |              Since this gets called by `BaseModel.model_json_schema` you can override the
     |              `schema_generator` argument to that function to change JSON schema generation globally
     |              for a type.
     |
     |      Returns:
     |          A JSON schema, as a Python object.
     |
     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'
     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`
     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will
     |      be present when this is called.
     |
     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,
     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that
     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.
     |
     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,
     |      any kwargs passed to the class definition that aren't used internally by pydantic.
     |
     |      Args:
     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally
     |              by pydantic.
     |
     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |
     |  from_orm(obj: 'Any') -> 'Self'
     |
     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |      Creates a new instance of the `Model` class with validated data.
     |
     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.
     |      Default values are respected, but no other validation is performed.
     |
     |      !!! note
     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.
     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`
     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.
     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in
     |          an error if extra values are passed, but they will be ignored.
     |
     |      Args:
     |          _fields_set: The set of field names accepted for the Model instance.
     |          values: Trusted or pre-validated data dictionary.
     |
     |      Returns:
     |          A new instance of the `Model` class with validated data.
     |
     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'
     |      Generates a JSON schema for a model class.
     |
     |      Args:
     |          by_alias: Whether to use attribute aliases or not.
     |          ref_template: The reference template.
     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of
     |              `GenerateJsonSchema` with your desired modifications
     |          mode: The mode in which to generate the schema.
     |
     |      Returns:
     |          The JSON schema for the given model class.
     |
     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'
     |      Compute the class name for parametrizations of generic classes.
     |
     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.
     |
     |      Args:
     |          params: Tuple of types of the class. Given a generic class
     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,
     |              the value `(str, int)` would be passed to `params`.
     |
     |      Returns:
     |          String representing the new class where `params` are passed to `cls` as type variables.
     |
     |      Raises:
     |          TypeError: Raised when trying to generate concrete names for non-generic models.
     |
     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'dict[str, Any] | None' = None) -> 'bool | None'
     |      Try to rebuild the pydantic-core schema for the model.
     |
     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during
     |      the initial attempt to build the schema, and automatic rebuilding fails.
     |
     |      Args:
     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.
     |          raise_errors: Whether to raise errors, defaults to `True`.
     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.
     |          _types_namespace: The types namespace, defaults to `None`.
     |
     |      Returns:
     |          Returns `None` if the schema is already "complete" and rebuilding was not required.
     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.
     |
     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate a pydantic model instance.
     |
     |      Args:
     |          obj: The object to validate.
     |          strict: Whether to enforce types strictly.
     |          from_attributes: Whether to extract data from object attributes.
     |          context: Additional context to pass to the validator.
     |
     |      Raises:
     |          ValidationError: If the object could not be validated.
     |
     |      Returns:
     |          The validated model instance.
     |
     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/json/#json-parsing
     |
     |      Validate the given JSON data against the Pydantic model.
     |
     |      Args:
     |          json_data: The JSON data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |      Raises:
     |          ValueError: If `json_data` is not a JSON string.
     |
     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate the given object with string data against the Pydantic model.
     |
     |      Args:
     |          obj: The object containing string data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  parse_obj(obj: 'Any') -> 'Self'
     |
     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'
     |
     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'
     |
     |  update_forward_refs(**localns: 'Any') -> 'None'
     |
     |  validate(value: 'Any') -> 'Self'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from pydantic.main.BaseModel:
     |
     |  __fields_set__
     |
     |  model_extra
     |      Get extra fields set during validation.
     |
     |      Returns:
     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `"allow"`.
     |
     |  model_fields_set
     |      Returns the set of fields that have been explicitly set on this model instance.
     |
     |      Returns:
     |          A set of strings representing the fields that have been set,
     |              i.e. that were not filled from defaults.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from pydantic.main.BaseModel:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __pydantic_extra__
     |
     |  __pydantic_fields_set__
     |
     |  __pydantic_private__
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from pydantic.main.BaseModel:
     |
     |  __hash__ = None
     |
     |  __pydantic_root_model__ = False

    class OAuthFlows(BaseModelWithConfig)
     |  OAuthFlows(*, implicit: Optional[backend.Lib.site-packages.fastapi.openapi.models.OAuthFlowImplicit] = None, password: Optional[backend.Lib.site-packages.fastapi.openapi.models.OAuthFlowPassword] = None, clientCredentials: Optional[backend.Lib.site-packages.fastapi.openapi.models.OAuthFlowClientCredentials] = None, authorizationCode: Optional[backend.Lib.site-packages.fastapi.openapi.models.OAuthFlowAuthorizationCode] = None, **extra_data: Any) -> None
     |
     |  Method resolution order:
     |      OAuthFlows
     |      BaseModelWithConfig
     |      pydantic.main.BaseModel
     |      builtins.object
     |
     |  Data and other attributes defined here:
     |
     |  __abstractmethods__ = frozenset()
     |
     |  __annotations__ = {'authorizationCode': typing.Optional[backend.Lib.si...
     |
     |  __class_vars__ = set()
     |
     |  __private_attributes__ = {}
     |
     |  __pydantic_complete__ = True
     |
     |  __pydantic_core_schema__ = {'cls': <class 'backend.Lib.site-packages.f...
     |
     |  __pydantic_custom_init__ = False
     |
     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...
     |
     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...
     |
     |  __pydantic_parent_namespace__ = {'APIKey': <pydantic._internal._model_...
     |
     |  __pydantic_post_init__ = None
     |
     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(
     |      Model...
     |
     |  __pydantic_validator__ = SchemaValidator(title="OAuthFlows", validator...
     |
     |  __signature__ = <Signature (*, implicit: Optional[backend.Lib.si...riz...
     |
     |  model_computed_fields = {}
     |
     |  model_config = {'extra': 'allow'}
     |
     |  model_fields = {'authorizationCode': FieldInfo(annotation=Union[OAuthF...
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from BaseModelWithConfig:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from pydantic.main.BaseModel:
     |
     |  __copy__(self) -> 'Self'
     |      Returns a shallow copy of the model.
     |
     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'
     |      Returns a deep copy of the model.
     |
     |  __delattr__(self, item: 'str') -> 'Any'
     |      Implement delattr(self, name).
     |
     |  __eq__(self, other: 'Any') -> 'bool'
     |      Return self==value.
     |
     |  __getattr__(self, item: 'str') -> 'Any'
     |
     |  __getstate__(self) -> 'dict[Any, Any]'
     |      Helper for pickle.
     |
     |  __init__(self, /, **data: 'Any') -> 'None'
     |      Create a new model by parsing and validating input data from keyword arguments.
     |
     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be
     |      validated to form a valid model.
     |
     |      `self` is explicitly positional-only to allow `self` as a field name.
     |
     |  __iter__(self) -> 'TupleGenerator'
     |      So `dict(model)` works.
     |
     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation
     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.
     |
     |  __repr__(self) -> 'str'
     |      Return repr(self).
     |
     |  __repr_args__(self) -> '_repr.ReprArgs'
     |
     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation
     |      Name of the instance's class, used in __repr__.
     |
     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation
     |
     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation
     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.
     |
     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'
     |
     |  __str__(self) -> 'str'
     |      Return str(self).
     |
     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Returns a copy of the model.
     |
     |      !!! warning "Deprecated"
     |          This method is now deprecated; use `model_copy` instead.
     |
     |      If you need `include` or `exclude`, use:
     |
     |      ```py
     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)
     |      data = {**data, **(update or {})}
     |      copied = self.model_validate(data)
     |      ```
     |
     |      Args:
     |          include: Optional set or mapping specifying which fields to include in the copied model.
     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.
     |          update: Optional dictionary of field-value pairs to override field values in the copied model.
     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.
     |
     |      Returns:
     |          A copy of the model with included, excluded and updated fields as specified.
     |
     |  dict(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'
     |
     |  json(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'
     |
     |  model_copy(self, *, update: 'dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#model_copy
     |
     |      Returns a copy of the model.
     |
     |      Args:
     |          update: Values to change/add in the new model. Note: the data is not validated
     |              before creating the new model. You should trust this data.
     |          deep: Set to `True` to make a deep copy of the model.
     |
     |      Returns:
     |          New model instance.
     |
     |  model_dump(self, *, mode: "Literal['json', 'python'] | str" = 'python', include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump
     |
     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.
     |
     |      Args:
     |          mode: The mode in which `to_python` should run.
     |              If mode is 'json', the output will only contain JSON serializable types.
     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.
     |          include: A set of fields to include in the output.
     |          exclude: A set of fields to exclude from the output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to use the field's alias in the dictionary key if defined.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A dictionary representation of the model.
     |
     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'str'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump_json
     |
     |      Generates a JSON representation of the model using Pydantic's `to_json` method.
     |
     |      Args:
     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.
     |          include: Field(s) to include in the JSON output.
     |          exclude: Field(s) to exclude from the JSON output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to serialize using field aliases.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A JSON string representation of the model.
     |
     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'
     |      Override this method to perform additional initialization after `__init__` and `model_construct`.
     |      This is useful if you want to do some validation that requires the entire model to be initialized.
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from pydantic.main.BaseModel:
     |
     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'
     |
     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'
     |      Hook into generating the model's CoreSchema.
     |
     |      Args:
     |          source: The class we are generating a schema for.
     |              This will generally be the same as the `cls` argument if this is a classmethod.
     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.
     |
     |      Returns:
     |          A `pydantic-core` `CoreSchema`.
     |
     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'
     |      Hook into generating the model's JSON schema.
     |
     |      Args:
     |          core_schema: A `pydantic-core` CoreSchema.
     |              You can ignore this argument and call the handler with a new CoreSchema,
     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),
     |              or just call the handler with the original schema.
     |          handler: Call into Pydantic's internal JSON schema generation.
     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema
     |              generation fails.
     |              Since this gets called by `BaseModel.model_json_schema` you can override the
     |              `schema_generator` argument to that function to change JSON schema generation globally
     |              for a type.
     |
     |      Returns:
     |          A JSON schema, as a Python object.
     |
     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'
     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`
     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will
     |      be present when this is called.
     |
     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,
     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that
     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.
     |
     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,
     |      any kwargs passed to the class definition that aren't used internally by pydantic.
     |
     |      Args:
     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally
     |              by pydantic.
     |
     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |
     |  from_orm(obj: 'Any') -> 'Self'
     |
     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |      Creates a new instance of the `Model` class with validated data.
     |
     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.
     |      Default values are respected, but no other validation is performed.
     |
     |      !!! note
     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.
     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`
     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.
     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in
     |          an error if extra values are passed, but they will be ignored.
     |
     |      Args:
     |          _fields_set: The set of field names accepted for the Model instance.
     |          values: Trusted or pre-validated data dictionary.
     |
     |      Returns:
     |          A new instance of the `Model` class with validated data.
     |
     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'
     |      Generates a JSON schema for a model class.
     |
     |      Args:
     |          by_alias: Whether to use attribute aliases or not.
     |          ref_template: The reference template.
     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of
     |              `GenerateJsonSchema` with your desired modifications
     |          mode: The mode in which to generate the schema.
     |
     |      Returns:
     |          The JSON schema for the given model class.
     |
     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'
     |      Compute the class name for parametrizations of generic classes.
     |
     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.
     |
     |      Args:
     |          params: Tuple of types of the class. Given a generic class
     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,
     |              the value `(str, int)` would be passed to `params`.
     |
     |      Returns:
     |          String representing the new class where `params` are passed to `cls` as type variables.
     |
     |      Raises:
     |          TypeError: Raised when trying to generate concrete names for non-generic models.
     |
     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'dict[str, Any] | None' = None) -> 'bool | None'
     |      Try to rebuild the pydantic-core schema for the model.
     |
     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during
     |      the initial attempt to build the schema, and automatic rebuilding fails.
     |
     |      Args:
     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.
     |          raise_errors: Whether to raise errors, defaults to `True`.
     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.
     |          _types_namespace: The types namespace, defaults to `None`.
     |
     |      Returns:
     |          Returns `None` if the schema is already "complete" and rebuilding was not required.
     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.
     |
     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate a pydantic model instance.
     |
     |      Args:
     |          obj: The object to validate.
     |          strict: Whether to enforce types strictly.
     |          from_attributes: Whether to extract data from object attributes.
     |          context: Additional context to pass to the validator.
     |
     |      Raises:
     |          ValidationError: If the object could not be validated.
     |
     |      Returns:
     |          The validated model instance.
     |
     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/json/#json-parsing
     |
     |      Validate the given JSON data against the Pydantic model.
     |
     |      Args:
     |          json_data: The JSON data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |      Raises:
     |          ValueError: If `json_data` is not a JSON string.
     |
     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate the given object with string data against the Pydantic model.
     |
     |      Args:
     |          obj: The object containing string data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  parse_obj(obj: 'Any') -> 'Self'
     |
     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'
     |
     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'
     |
     |  update_forward_refs(**localns: 'Any') -> 'None'
     |
     |  validate(value: 'Any') -> 'Self'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from pydantic.main.BaseModel:
     |
     |  __fields_set__
     |
     |  model_extra
     |      Get extra fields set during validation.
     |
     |      Returns:
     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `"allow"`.
     |
     |  model_fields_set
     |      Returns the set of fields that have been explicitly set on this model instance.
     |
     |      Returns:
     |          A set of strings representing the fields that have been set,
     |              i.e. that were not filled from defaults.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from pydantic.main.BaseModel:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __pydantic_extra__
     |
     |  __pydantic_fields_set__
     |
     |  __pydantic_private__
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from pydantic.main.BaseModel:
     |
     |  __hash__ = None
     |
     |  __pydantic_root_model__ = False

    class OpenAPI(BaseModelWithConfig)
     |  OpenAPI(*, openapi: str, info: backend.Lib.site-packages.fastapi.openapi.models.Info, jsonSchemaDialect: Optional[str] = None, servers: Optional[List[backend.Lib.site-packages.fastapi.openapi.models.Server]] = None, paths: Optional[Dict[str, Union[backend.Lib.site-packages.fastapi.openapi.models.PathItem, Any]]] = None, webhooks: Optional[Dict[str, Union[backend.Lib.site-packages.fastapi.openapi.models.PathItem, backend.Lib.site-packages.fastapi.openapi.models.Reference]]] = None, components: Optional[backend.Lib.site-packages.fastapi.openapi.models.Components] = None, security: Optional[List[Dict[str, List[str]]]] = None, tags: Optional[List[backend.Lib.site-packages.fastapi.openapi.models.Tag]] = None, externalDocs: Optional[backend.Lib.site-packages.fastapi.openapi.models.ExternalDocumentation] = None, **extra_data: Any) -> None
     |
     |  Method resolution order:
     |      OpenAPI
     |      BaseModelWithConfig
     |      pydantic.main.BaseModel
     |      builtins.object
     |
     |  Data and other attributes defined here:
     |
     |  __abstractmethods__ = frozenset()
     |
     |  __annotations__ = {'components': typing.Optional[backend.Lib.site-pack...
     |
     |  __class_vars__ = set()
     |
     |  __private_attributes__ = {}
     |
     |  __pydantic_complete__ = True
     |
     |  __pydantic_core_schema__ = {'definitions': [{'cls': <class 'backend.Li...
     |
     |  __pydantic_custom_init__ = False
     |
     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...
     |
     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...
     |
     |  __pydantic_parent_namespace__ = {'APIKey': <pydantic._internal._model_...
     |
     |  __pydantic_post_init__ = None
     |
     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(
     |      Model...
     |
     |  __pydantic_validator__ = SchemaValidator(title="OpenAPI", validator=Mo...
     |
     |  __signature__ = <Signature (*, openapi: str, info: backend.Lib.s...ocu...
     |
     |  model_computed_fields = {}
     |
     |  model_config = {'extra': 'allow'}
     |
     |  model_fields = {'components': FieldInfo(annotation=Union[Components, N...
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from BaseModelWithConfig:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from pydantic.main.BaseModel:
     |
     |  __copy__(self) -> 'Self'
     |      Returns a shallow copy of the model.
     |
     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'
     |      Returns a deep copy of the model.
     |
     |  __delattr__(self, item: 'str') -> 'Any'
     |      Implement delattr(self, name).
     |
     |  __eq__(self, other: 'Any') -> 'bool'
     |      Return self==value.
     |
     |  __getattr__(self, item: 'str') -> 'Any'
     |
     |  __getstate__(self) -> 'dict[Any, Any]'
     |      Helper for pickle.
     |
     |  __init__(self, /, **data: 'Any') -> 'None'
     |      Create a new model by parsing and validating input data from keyword arguments.
     |
     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be
     |      validated to form a valid model.
     |
     |      `self` is explicitly positional-only to allow `self` as a field name.
     |
     |  __iter__(self) -> 'TupleGenerator'
     |      So `dict(model)` works.
     |
     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation
     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.
     |
     |  __repr__(self) -> 'str'
     |      Return repr(self).
     |
     |  __repr_args__(self) -> '_repr.ReprArgs'
     |
     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation
     |      Name of the instance's class, used in __repr__.
     |
     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation
     |
     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation
     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.
     |
     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'
     |
     |  __str__(self) -> 'str'
     |      Return str(self).
     |
     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Returns a copy of the model.
     |
     |      !!! warning "Deprecated"
     |          This method is now deprecated; use `model_copy` instead.
     |
     |      If you need `include` or `exclude`, use:
     |
     |      ```py
     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)
     |      data = {**data, **(update or {})}
     |      copied = self.model_validate(data)
     |      ```
     |
     |      Args:
     |          include: Optional set or mapping specifying which fields to include in the copied model.
     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.
     |          update: Optional dictionary of field-value pairs to override field values in the copied model.
     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.
     |
     |      Returns:
     |          A copy of the model with included, excluded and updated fields as specified.
     |
     |  dict(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'
     |
     |  json(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'
     |
     |  model_copy(self, *, update: 'dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#model_copy
     |
     |      Returns a copy of the model.
     |
     |      Args:
     |          update: Values to change/add in the new model. Note: the data is not validated
     |              before creating the new model. You should trust this data.
     |          deep: Set to `True` to make a deep copy of the model.
     |
     |      Returns:
     |          New model instance.
     |
     |  model_dump(self, *, mode: "Literal['json', 'python'] | str" = 'python', include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump
     |
     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.
     |
     |      Args:
     |          mode: The mode in which `to_python` should run.
     |              If mode is 'json', the output will only contain JSON serializable types.
     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.
     |          include: A set of fields to include in the output.
     |          exclude: A set of fields to exclude from the output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to use the field's alias in the dictionary key if defined.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A dictionary representation of the model.
     |
     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'str'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump_json
     |
     |      Generates a JSON representation of the model using Pydantic's `to_json` method.
     |
     |      Args:
     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.
     |          include: Field(s) to include in the JSON output.
     |          exclude: Field(s) to exclude from the JSON output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to serialize using field aliases.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A JSON string representation of the model.
     |
     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'
     |      Override this method to perform additional initialization after `__init__` and `model_construct`.
     |      This is useful if you want to do some validation that requires the entire model to be initialized.
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from pydantic.main.BaseModel:
     |
     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'
     |
     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'
     |      Hook into generating the model's CoreSchema.
     |
     |      Args:
     |          source: The class we are generating a schema for.
     |              This will generally be the same as the `cls` argument if this is a classmethod.
     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.
     |
     |      Returns:
     |          A `pydantic-core` `CoreSchema`.
     |
     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'
     |      Hook into generating the model's JSON schema.
     |
     |      Args:
     |          core_schema: A `pydantic-core` CoreSchema.
     |              You can ignore this argument and call the handler with a new CoreSchema,
     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),
     |              or just call the handler with the original schema.
     |          handler: Call into Pydantic's internal JSON schema generation.
     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema
     |              generation fails.
     |              Since this gets called by `BaseModel.model_json_schema` you can override the
     |              `schema_generator` argument to that function to change JSON schema generation globally
     |              for a type.
     |
     |      Returns:
     |          A JSON schema, as a Python object.
     |
     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'
     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`
     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will
     |      be present when this is called.
     |
     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,
     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that
     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.
     |
     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,
     |      any kwargs passed to the class definition that aren't used internally by pydantic.
     |
     |      Args:
     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally
     |              by pydantic.
     |
     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |
     |  from_orm(obj: 'Any') -> 'Self'
     |
     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |      Creates a new instance of the `Model` class with validated data.
     |
     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.
     |      Default values are respected, but no other validation is performed.
     |
     |      !!! note
     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.
     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`
     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.
     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in
     |          an error if extra values are passed, but they will be ignored.
     |
     |      Args:
     |          _fields_set: The set of field names accepted for the Model instance.
     |          values: Trusted or pre-validated data dictionary.
     |
     |      Returns:
     |          A new instance of the `Model` class with validated data.
     |
     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'
     |      Generates a JSON schema for a model class.
     |
     |      Args:
     |          by_alias: Whether to use attribute aliases or not.
     |          ref_template: The reference template.
     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of
     |              `GenerateJsonSchema` with your desired modifications
     |          mode: The mode in which to generate the schema.
     |
     |      Returns:
     |          The JSON schema for the given model class.
     |
     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'
     |      Compute the class name for parametrizations of generic classes.
     |
     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.
     |
     |      Args:
     |          params: Tuple of types of the class. Given a generic class
     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,
     |              the value `(str, int)` would be passed to `params`.
     |
     |      Returns:
     |          String representing the new class where `params` are passed to `cls` as type variables.
     |
     |      Raises:
     |          TypeError: Raised when trying to generate concrete names for non-generic models.
     |
     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'dict[str, Any] | None' = None) -> 'bool | None'
     |      Try to rebuild the pydantic-core schema for the model.
     |
     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during
     |      the initial attempt to build the schema, and automatic rebuilding fails.
     |
     |      Args:
     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.
     |          raise_errors: Whether to raise errors, defaults to `True`.
     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.
     |          _types_namespace: The types namespace, defaults to `None`.
     |
     |      Returns:
     |          Returns `None` if the schema is already "complete" and rebuilding was not required.
     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.
     |
     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate a pydantic model instance.
     |
     |      Args:
     |          obj: The object to validate.
     |          strict: Whether to enforce types strictly.
     |          from_attributes: Whether to extract data from object attributes.
     |          context: Additional context to pass to the validator.
     |
     |      Raises:
     |          ValidationError: If the object could not be validated.
     |
     |      Returns:
     |          The validated model instance.
     |
     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/json/#json-parsing
     |
     |      Validate the given JSON data against the Pydantic model.
     |
     |      Args:
     |          json_data: The JSON data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |      Raises:
     |          ValueError: If `json_data` is not a JSON string.
     |
     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate the given object with string data against the Pydantic model.
     |
     |      Args:
     |          obj: The object containing string data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  parse_obj(obj: 'Any') -> 'Self'
     |
     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'
     |
     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'
     |
     |  update_forward_refs(**localns: 'Any') -> 'None'
     |
     |  validate(value: 'Any') -> 'Self'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from pydantic.main.BaseModel:
     |
     |  __fields_set__
     |
     |  model_extra
     |      Get extra fields set during validation.
     |
     |      Returns:
     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `"allow"`.
     |
     |  model_fields_set
     |      Returns the set of fields that have been explicitly set on this model instance.
     |
     |      Returns:
     |          A set of strings representing the fields that have been set,
     |              i.e. that were not filled from defaults.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from pydantic.main.BaseModel:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __pydantic_extra__
     |
     |  __pydantic_fields_set__
     |
     |  __pydantic_private__
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from pydantic.main.BaseModel:
     |
     |  __hash__ = None
     |
     |  __pydantic_root_model__ = False

    class OpenIdConnect(SecurityBase)
     |  OpenIdConnect(*, type: backend.Lib.site-packages.fastapi.openapi.models.SecuritySchemeType = <SecuritySchemeType.openIdConnect: 'openIdConnect'>, description: Optional[str] = None, openIdConnectUrl: str, **extra_data: Any) -> None
     |
     |  Method resolution order:
     |      OpenIdConnect
     |      SecurityBase
     |      BaseModelWithConfig
     |      pydantic.main.BaseModel
     |      builtins.object
     |
     |  Data and other attributes defined here:
     |
     |  __abstractmethods__ = frozenset()
     |
     |  __annotations__ = {'openIdConnectUrl': <class 'str'>, 'type_': <enum '...
     |
     |  __class_vars__ = set()
     |
     |  __private_attributes__ = {}
     |
     |  __pydantic_complete__ = True
     |
     |  __pydantic_core_schema__ = {'cls': <class 'backend.Lib.site-packages.f...
     |
     |  __pydantic_custom_init__ = False
     |
     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...
     |
     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...
     |
     |  __pydantic_parent_namespace__ = {'APIKey': <pydantic._internal._model_...
     |
     |  __pydantic_post_init__ = None
     |
     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(
     |      Model...
     |
     |  __pydantic_validator__ = SchemaValidator(title="OpenIdConnect", valida...
     |
     |  __signature__ = <Signature (*, type: backend.Lib.site-packages.f...pen...
     |
     |  model_computed_fields = {}
     |
     |  model_config = {'extra': 'allow'}
     |
     |  model_fields = {'description': FieldInfo(annotation=Union[str, NoneTyp...
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from BaseModelWithConfig:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from pydantic.main.BaseModel:
     |
     |  __copy__(self) -> 'Self'
     |      Returns a shallow copy of the model.
     |
     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'
     |      Returns a deep copy of the model.
     |
     |  __delattr__(self, item: 'str') -> 'Any'
     |      Implement delattr(self, name).
     |
     |  __eq__(self, other: 'Any') -> 'bool'
     |      Return self==value.
     |
     |  __getattr__(self, item: 'str') -> 'Any'
     |
     |  __getstate__(self) -> 'dict[Any, Any]'
     |      Helper for pickle.
     |
     |  __init__(self, /, **data: 'Any') -> 'None'
     |      Create a new model by parsing and validating input data from keyword arguments.
     |
     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be
     |      validated to form a valid model.
     |
     |      `self` is explicitly positional-only to allow `self` as a field name.
     |
     |  __iter__(self) -> 'TupleGenerator'
     |      So `dict(model)` works.
     |
     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation
     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.
     |
     |  __repr__(self) -> 'str'
     |      Return repr(self).
     |
     |  __repr_args__(self) -> '_repr.ReprArgs'
     |
     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation
     |      Name of the instance's class, used in __repr__.
     |
     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation
     |
     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation
     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.
     |
     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'
     |
     |  __str__(self) -> 'str'
     |      Return str(self).
     |
     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Returns a copy of the model.
     |
     |      !!! warning "Deprecated"
     |          This method is now deprecated; use `model_copy` instead.
     |
     |      If you need `include` or `exclude`, use:
     |
     |      ```py
     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)
     |      data = {**data, **(update or {})}
     |      copied = self.model_validate(data)
     |      ```
     |
     |      Args:
     |          include: Optional set or mapping specifying which fields to include in the copied model.
     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.
     |          update: Optional dictionary of field-value pairs to override field values in the copied model.
     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.
     |
     |      Returns:
     |          A copy of the model with included, excluded and updated fields as specified.
     |
     |  dict(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'
     |
     |  json(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'
     |
     |  model_copy(self, *, update: 'dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#model_copy
     |
     |      Returns a copy of the model.
     |
     |      Args:
     |          update: Values to change/add in the new model. Note: the data is not validated
     |              before creating the new model. You should trust this data.
     |          deep: Set to `True` to make a deep copy of the model.
     |
     |      Returns:
     |          New model instance.
     |
     |  model_dump(self, *, mode: "Literal['json', 'python'] | str" = 'python', include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump
     |
     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.
     |
     |      Args:
     |          mode: The mode in which `to_python` should run.
     |              If mode is 'json', the output will only contain JSON serializable types.
     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.
     |          include: A set of fields to include in the output.
     |          exclude: A set of fields to exclude from the output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to use the field's alias in the dictionary key if defined.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A dictionary representation of the model.
     |
     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'str'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump_json
     |
     |      Generates a JSON representation of the model using Pydantic's `to_json` method.
     |
     |      Args:
     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.
     |          include: Field(s) to include in the JSON output.
     |          exclude: Field(s) to exclude from the JSON output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to serialize using field aliases.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A JSON string representation of the model.
     |
     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'
     |      Override this method to perform additional initialization after `__init__` and `model_construct`.
     |      This is useful if you want to do some validation that requires the entire model to be initialized.
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from pydantic.main.BaseModel:
     |
     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'
     |
     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'
     |      Hook into generating the model's CoreSchema.
     |
     |      Args:
     |          source: The class we are generating a schema for.
     |              This will generally be the same as the `cls` argument if this is a classmethod.
     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.
     |
     |      Returns:
     |          A `pydantic-core` `CoreSchema`.
     |
     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'
     |      Hook into generating the model's JSON schema.
     |
     |      Args:
     |          core_schema: A `pydantic-core` CoreSchema.
     |              You can ignore this argument and call the handler with a new CoreSchema,
     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),
     |              or just call the handler with the original schema.
     |          handler: Call into Pydantic's internal JSON schema generation.
     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema
     |              generation fails.
     |              Since this gets called by `BaseModel.model_json_schema` you can override the
     |              `schema_generator` argument to that function to change JSON schema generation globally
     |              for a type.
     |
     |      Returns:
     |          A JSON schema, as a Python object.
     |
     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'
     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`
     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will
     |      be present when this is called.
     |
     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,
     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that
     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.
     |
     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,
     |      any kwargs passed to the class definition that aren't used internally by pydantic.
     |
     |      Args:
     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally
     |              by pydantic.
     |
     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |
     |  from_orm(obj: 'Any') -> 'Self'
     |
     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |      Creates a new instance of the `Model` class with validated data.
     |
     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.
     |      Default values are respected, but no other validation is performed.
     |
     |      !!! note
     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.
     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`
     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.
     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in
     |          an error if extra values are passed, but they will be ignored.
     |
     |      Args:
     |          _fields_set: The set of field names accepted for the Model instance.
     |          values: Trusted or pre-validated data dictionary.
     |
     |      Returns:
     |          A new instance of the `Model` class with validated data.
     |
     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'
     |      Generates a JSON schema for a model class.
     |
     |      Args:
     |          by_alias: Whether to use attribute aliases or not.
     |          ref_template: The reference template.
     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of
     |              `GenerateJsonSchema` with your desired modifications
     |          mode: The mode in which to generate the schema.
     |
     |      Returns:
     |          The JSON schema for the given model class.
     |
     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'
     |      Compute the class name for parametrizations of generic classes.
     |
     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.
     |
     |      Args:
     |          params: Tuple of types of the class. Given a generic class
     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,
     |              the value `(str, int)` would be passed to `params`.
     |
     |      Returns:
     |          String representing the new class where `params` are passed to `cls` as type variables.
     |
     |      Raises:
     |          TypeError: Raised when trying to generate concrete names for non-generic models.
     |
     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'dict[str, Any] | None' = None) -> 'bool | None'
     |      Try to rebuild the pydantic-core schema for the model.
     |
     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during
     |      the initial attempt to build the schema, and automatic rebuilding fails.
     |
     |      Args:
     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.
     |          raise_errors: Whether to raise errors, defaults to `True`.
     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.
     |          _types_namespace: The types namespace, defaults to `None`.
     |
     |      Returns:
     |          Returns `None` if the schema is already "complete" and rebuilding was not required.
     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.
     |
     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate a pydantic model instance.
     |
     |      Args:
     |          obj: The object to validate.
     |          strict: Whether to enforce types strictly.
     |          from_attributes: Whether to extract data from object attributes.
     |          context: Additional context to pass to the validator.
     |
     |      Raises:
     |          ValidationError: If the object could not be validated.
     |
     |      Returns:
     |          The validated model instance.
     |
     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/json/#json-parsing
     |
     |      Validate the given JSON data against the Pydantic model.
     |
     |      Args:
     |          json_data: The JSON data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |      Raises:
     |          ValueError: If `json_data` is not a JSON string.
     |
     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate the given object with string data against the Pydantic model.
     |
     |      Args:
     |          obj: The object containing string data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  parse_obj(obj: 'Any') -> 'Self'
     |
     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'
     |
     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'
     |
     |  update_forward_refs(**localns: 'Any') -> 'None'
     |
     |  validate(value: 'Any') -> 'Self'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from pydantic.main.BaseModel:
     |
     |  __fields_set__
     |
     |  model_extra
     |      Get extra fields set during validation.
     |
     |      Returns:
     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `"allow"`.
     |
     |  model_fields_set
     |      Returns the set of fields that have been explicitly set on this model instance.
     |
     |      Returns:
     |          A set of strings representing the fields that have been set,
     |              i.e. that were not filled from defaults.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from pydantic.main.BaseModel:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __pydantic_extra__
     |
     |  __pydantic_fields_set__
     |
     |  __pydantic_private__
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from pydantic.main.BaseModel:
     |
     |  __hash__ = None
     |
     |  __pydantic_root_model__ = False

    class Operation(BaseModelWithConfig)
     |  Operation(*, tags: Optional[List[str]] = None, summary: Optional[str] = None, description: Optional[str] = None, externalDocs: Optional[backend.Lib.site-packages.fastapi.openapi.models.ExternalDocumentation] = None, operationId: Optional[str] = None, parameters: Optional[List[Union[backend.Lib.site-packages.fastapi.openapi.models.Parameter, backend.Lib.site-packages.fastapi.openapi.models.Reference]]] = None, requestBody: Union[backend.Lib.site-packages.fastapi.openapi.models.RequestBody, backend.Lib.site-packages.fastapi.openapi.models.Reference, NoneType] = None, responses: Optional[Dict[str, Union[backend.Lib.site-packages.fastapi.openapi.models.Response, Any]]] = None, callbacks: Optional[Dict[str, Union[Dict[str, backend.Lib.site-packages.fastapi.openapi.models.PathItem], backend.Lib.site-packages.fastapi.openapi.models.Reference]]] = None, deprecated: Optional[bool] = None, security: Optional[List[Dict[str, List[str]]]] = None, servers: Optional[List[backend.Lib.site-packages.fastapi.openapi.models.Server]] = None, **extra_data: Any) -> None
     |
     |  Method resolution order:
     |      Operation
     |      BaseModelWithConfig
     |      pydantic.main.BaseModel
     |      builtins.object
     |
     |  Data and other attributes defined here:
     |
     |  __abstractmethods__ = frozenset()
     |
     |  __annotations__ = {'callbacks': typing.Optional[typing.Dict[str, typin...
     |
     |  __class_vars__ = set()
     |
     |  __private_attributes__ = {}
     |
     |  __pydantic_complete__ = True
     |
     |  __pydantic_core_schema__ = {'definitions': [{'cls': <class 'backend.Li...
     |
     |  __pydantic_custom_init__ = False
     |
     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...
     |
     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...
     |
     |  __pydantic_parent_namespace__ = {'Annotated': <pydantic._internal._mod...
     |
     |  __pydantic_post_init__ = None
     |
     |  __pydantic_serializer__ = SchemaSerializer(serializer=Recursive(
     |      D...
     |
     |  __pydantic_validator__ = SchemaValidator(title="Operation", validator=...
     |
     |  __signature__ = <Signature (*, tags: Optional[List[str]] = None,...del...
     |
     |  model_computed_fields = {}
     |
     |  model_config = {'extra': 'allow'}
     |
     |  model_fields = {'callbacks': FieldInfo(annotation=Union[Dict[str, Unio...
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from BaseModelWithConfig:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from pydantic.main.BaseModel:
     |
     |  __copy__(self) -> 'Self'
     |      Returns a shallow copy of the model.
     |
     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'
     |      Returns a deep copy of the model.
     |
     |  __delattr__(self, item: 'str') -> 'Any'
     |      Implement delattr(self, name).
     |
     |  __eq__(self, other: 'Any') -> 'bool'
     |      Return self==value.
     |
     |  __getattr__(self, item: 'str') -> 'Any'
     |
     |  __getstate__(self) -> 'dict[Any, Any]'
     |      Helper for pickle.
     |
     |  __init__(self, /, **data: 'Any') -> 'None'
     |      Create a new model by parsing and validating input data from keyword arguments.
     |
     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be
     |      validated to form a valid model.
     |
     |      `self` is explicitly positional-only to allow `self` as a field name.
     |
     |  __iter__(self) -> 'TupleGenerator'
     |      So `dict(model)` works.
     |
     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation
     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.
     |
     |  __repr__(self) -> 'str'
     |      Return repr(self).
     |
     |  __repr_args__(self) -> '_repr.ReprArgs'
     |
     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation
     |      Name of the instance's class, used in __repr__.
     |
     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation
     |
     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation
     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.
     |
     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'
     |
     |  __str__(self) -> 'str'
     |      Return str(self).
     |
     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Returns a copy of the model.
     |
     |      !!! warning "Deprecated"
     |          This method is now deprecated; use `model_copy` instead.
     |
     |      If you need `include` or `exclude`, use:
     |
     |      ```py
     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)
     |      data = {**data, **(update or {})}
     |      copied = self.model_validate(data)
     |      ```
     |
     |      Args:
     |          include: Optional set or mapping specifying which fields to include in the copied model.
     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.
     |          update: Optional dictionary of field-value pairs to override field values in the copied model.
     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.
     |
     |      Returns:
     |          A copy of the model with included, excluded and updated fields as specified.
     |
     |  dict(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'
     |
     |  json(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'
     |
     |  model_copy(self, *, update: 'dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#model_copy
     |
     |      Returns a copy of the model.
     |
     |      Args:
     |          update: Values to change/add in the new model. Note: the data is not validated
     |              before creating the new model. You should trust this data.
     |          deep: Set to `True` to make a deep copy of the model.
     |
     |      Returns:
     |          New model instance.
     |
     |  model_dump(self, *, mode: "Literal['json', 'python'] | str" = 'python', include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump
     |
     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.
     |
     |      Args:
     |          mode: The mode in which `to_python` should run.
     |              If mode is 'json', the output will only contain JSON serializable types.
     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.
     |          include: A set of fields to include in the output.
     |          exclude: A set of fields to exclude from the output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to use the field's alias in the dictionary key if defined.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A dictionary representation of the model.
     |
     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'str'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump_json
     |
     |      Generates a JSON representation of the model using Pydantic's `to_json` method.
     |
     |      Args:
     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.
     |          include: Field(s) to include in the JSON output.
     |          exclude: Field(s) to exclude from the JSON output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to serialize using field aliases.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A JSON string representation of the model.
     |
     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'
     |      Override this method to perform additional initialization after `__init__` and `model_construct`.
     |      This is useful if you want to do some validation that requires the entire model to be initialized.
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from pydantic.main.BaseModel:
     |
     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'
     |
     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'
     |      Hook into generating the model's CoreSchema.
     |
     |      Args:
     |          source: The class we are generating a schema for.
     |              This will generally be the same as the `cls` argument if this is a classmethod.
     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.
     |
     |      Returns:
     |          A `pydantic-core` `CoreSchema`.
     |
     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'
     |      Hook into generating the model's JSON schema.
     |
     |      Args:
     |          core_schema: A `pydantic-core` CoreSchema.
     |              You can ignore this argument and call the handler with a new CoreSchema,
     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),
     |              or just call the handler with the original schema.
     |          handler: Call into Pydantic's internal JSON schema generation.
     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema
     |              generation fails.
     |              Since this gets called by `BaseModel.model_json_schema` you can override the
     |              `schema_generator` argument to that function to change JSON schema generation globally
     |              for a type.
     |
     |      Returns:
     |          A JSON schema, as a Python object.
     |
     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'
     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`
     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will
     |      be present when this is called.
     |
     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,
     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that
     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.
     |
     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,
     |      any kwargs passed to the class definition that aren't used internally by pydantic.
     |
     |      Args:
     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally
     |              by pydantic.
     |
     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |
     |  from_orm(obj: 'Any') -> 'Self'
     |
     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |      Creates a new instance of the `Model` class with validated data.
     |
     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.
     |      Default values are respected, but no other validation is performed.
     |
     |      !!! note
     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.
     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`
     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.
     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in
     |          an error if extra values are passed, but they will be ignored.
     |
     |      Args:
     |          _fields_set: The set of field names accepted for the Model instance.
     |          values: Trusted or pre-validated data dictionary.
     |
     |      Returns:
     |          A new instance of the `Model` class with validated data.
     |
     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'
     |      Generates a JSON schema for a model class.
     |
     |      Args:
     |          by_alias: Whether to use attribute aliases or not.
     |          ref_template: The reference template.
     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of
     |              `GenerateJsonSchema` with your desired modifications
     |          mode: The mode in which to generate the schema.
     |
     |      Returns:
     |          The JSON schema for the given model class.
     |
     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'
     |      Compute the class name for parametrizations of generic classes.
     |
     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.
     |
     |      Args:
     |          params: Tuple of types of the class. Given a generic class
     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,
     |              the value `(str, int)` would be passed to `params`.
     |
     |      Returns:
     |          String representing the new class where `params` are passed to `cls` as type variables.
     |
     |      Raises:
     |          TypeError: Raised when trying to generate concrete names for non-generic models.
     |
     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'dict[str, Any] | None' = None) -> 'bool | None'
     |      Try to rebuild the pydantic-core schema for the model.
     |
     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during
     |      the initial attempt to build the schema, and automatic rebuilding fails.
     |
     |      Args:
     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.
     |          raise_errors: Whether to raise errors, defaults to `True`.
     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.
     |          _types_namespace: The types namespace, defaults to `None`.
     |
     |      Returns:
     |          Returns `None` if the schema is already "complete" and rebuilding was not required.
     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.
     |
     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate a pydantic model instance.
     |
     |      Args:
     |          obj: The object to validate.
     |          strict: Whether to enforce types strictly.
     |          from_attributes: Whether to extract data from object attributes.
     |          context: Additional context to pass to the validator.
     |
     |      Raises:
     |          ValidationError: If the object could not be validated.
     |
     |      Returns:
     |          The validated model instance.
     |
     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/json/#json-parsing
     |
     |      Validate the given JSON data against the Pydantic model.
     |
     |      Args:
     |          json_data: The JSON data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |      Raises:
     |          ValueError: If `json_data` is not a JSON string.
     |
     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate the given object with string data against the Pydantic model.
     |
     |      Args:
     |          obj: The object containing string data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  parse_obj(obj: 'Any') -> 'Self'
     |
     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'
     |
     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'
     |
     |  update_forward_refs(**localns: 'Any') -> 'None'
     |
     |  validate(value: 'Any') -> 'Self'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from pydantic.main.BaseModel:
     |
     |  __fields_set__
     |
     |  model_extra
     |      Get extra fields set during validation.
     |
     |      Returns:
     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `"allow"`.
     |
     |  model_fields_set
     |      Returns the set of fields that have been explicitly set on this model instance.
     |
     |      Returns:
     |          A set of strings representing the fields that have been set,
     |              i.e. that were not filled from defaults.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from pydantic.main.BaseModel:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __pydantic_extra__
     |
     |  __pydantic_fields_set__
     |
     |  __pydantic_private__
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from pydantic.main.BaseModel:
     |
     |  __hash__ = None
     |
     |  __pydantic_root_model__ = False

    class Parameter(ParameterBase)
     |  Parameter(**extra_data: Any) -> None
     |
     |  Method resolution order:
     |      Parameter
     |      ParameterBase
     |      BaseModelWithConfig
     |      pydantic.main.BaseModel
     |      builtins.object
     |
     |  Data and other attributes defined here:
     |
     |  __abstractmethods__ = frozenset()
     |
     |  __annotations__ = {'in_': <enum 'ParameterInType'>, 'name': <class 'st...
     |
     |  __class_vars__ = set()
     |
     |  __private_attributes__ = {}
     |
     |  __pydantic_complete__ = True
     |
     |  __pydantic_core_schema__ = {'definitions': [{'cls': <class 'backend.Li...
     |
     |  __pydantic_custom_init__ = False
     |
     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...
     |
     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...
     |
     |  __pydantic_parent_namespace__ = {'Annotated': <pydantic._internal._mod...
     |
     |  __pydantic_post_init__ = None
     |
     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(
     |      Model...
     |
     |  __pydantic_validator__ = SchemaValidator(title="Parameter", validator=...
     |
     |  __signature__ = <Signature (*, description: Optional[str] = None...del...
     |
     |  model_computed_fields = {}
     |
     |  model_config = {'extra': 'allow'}
     |
     |  model_fields = {'allowReserved': FieldInfo(annotation=Union[bool, None...
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from BaseModelWithConfig:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from pydantic.main.BaseModel:
     |
     |  __copy__(self) -> 'Self'
     |      Returns a shallow copy of the model.
     |
     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'
     |      Returns a deep copy of the model.
     |
     |  __delattr__(self, item: 'str') -> 'Any'
     |      Implement delattr(self, name).
     |
     |  __eq__(self, other: 'Any') -> 'bool'
     |      Return self==value.
     |
     |  __getattr__(self, item: 'str') -> 'Any'
     |
     |  __getstate__(self) -> 'dict[Any, Any]'
     |      Helper for pickle.
     |
     |  __init__(self, /, **data: 'Any') -> 'None'
     |      Create a new model by parsing and validating input data from keyword arguments.
     |
     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be
     |      validated to form a valid model.
     |
     |      `self` is explicitly positional-only to allow `self` as a field name.
     |
     |  __iter__(self) -> 'TupleGenerator'
     |      So `dict(model)` works.
     |
     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation
     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.
     |
     |  __repr__(self) -> 'str'
     |      Return repr(self).
     |
     |  __repr_args__(self) -> '_repr.ReprArgs'
     |
     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation
     |      Name of the instance's class, used in __repr__.
     |
     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation
     |
     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation
     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.
     |
     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'
     |
     |  __str__(self) -> 'str'
     |      Return str(self).
     |
     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Returns a copy of the model.
     |
     |      !!! warning "Deprecated"
     |          This method is now deprecated; use `model_copy` instead.
     |
     |      If you need `include` or `exclude`, use:
     |
     |      ```py
     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)
     |      data = {**data, **(update or {})}
     |      copied = self.model_validate(data)
     |      ```
     |
     |      Args:
     |          include: Optional set or mapping specifying which fields to include in the copied model.
     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.
     |          update: Optional dictionary of field-value pairs to override field values in the copied model.
     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.
     |
     |      Returns:
     |          A copy of the model with included, excluded and updated fields as specified.
     |
     |  dict(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'
     |
     |  json(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'
     |
     |  model_copy(self, *, update: 'dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#model_copy
     |
     |      Returns a copy of the model.
     |
     |      Args:
     |          update: Values to change/add in the new model. Note: the data is not validated
     |              before creating the new model. You should trust this data.
     |          deep: Set to `True` to make a deep copy of the model.
     |
     |      Returns:
     |          New model instance.
     |
     |  model_dump(self, *, mode: "Literal['json', 'python'] | str" = 'python', include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump
     |
     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.
     |
     |      Args:
     |          mode: The mode in which `to_python` should run.
     |              If mode is 'json', the output will only contain JSON serializable types.
     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.
     |          include: A set of fields to include in the output.
     |          exclude: A set of fields to exclude from the output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to use the field's alias in the dictionary key if defined.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A dictionary representation of the model.
     |
     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'str'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump_json
     |
     |      Generates a JSON representation of the model using Pydantic's `to_json` method.
     |
     |      Args:
     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.
     |          include: Field(s) to include in the JSON output.
     |          exclude: Field(s) to exclude from the JSON output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to serialize using field aliases.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A JSON string representation of the model.
     |
     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'
     |      Override this method to perform additional initialization after `__init__` and `model_construct`.
     |      This is useful if you want to do some validation that requires the entire model to be initialized.
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from pydantic.main.BaseModel:
     |
     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'
     |
     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'
     |      Hook into generating the model's CoreSchema.
     |
     |      Args:
     |          source: The class we are generating a schema for.
     |              This will generally be the same as the `cls` argument if this is a classmethod.
     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.
     |
     |      Returns:
     |          A `pydantic-core` `CoreSchema`.
     |
     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'
     |      Hook into generating the model's JSON schema.
     |
     |      Args:
     |          core_schema: A `pydantic-core` CoreSchema.
     |              You can ignore this argument and call the handler with a new CoreSchema,
     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),
     |              or just call the handler with the original schema.
     |          handler: Call into Pydantic's internal JSON schema generation.
     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema
     |              generation fails.
     |              Since this gets called by `BaseModel.model_json_schema` you can override the
     |              `schema_generator` argument to that function to change JSON schema generation globally
     |              for a type.
     |
     |      Returns:
     |          A JSON schema, as a Python object.
     |
     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'
     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`
     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will
     |      be present when this is called.
     |
     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,
     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that
     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.
     |
     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,
     |      any kwargs passed to the class definition that aren't used internally by pydantic.
     |
     |      Args:
     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally
     |              by pydantic.
     |
     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |
     |  from_orm(obj: 'Any') -> 'Self'
     |
     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |      Creates a new instance of the `Model` class with validated data.
     |
     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.
     |      Default values are respected, but no other validation is performed.
     |
     |      !!! note
     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.
     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`
     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.
     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in
     |          an error if extra values are passed, but they will be ignored.
     |
     |      Args:
     |          _fields_set: The set of field names accepted for the Model instance.
     |          values: Trusted or pre-validated data dictionary.
     |
     |      Returns:
     |          A new instance of the `Model` class with validated data.
     |
     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'
     |      Generates a JSON schema for a model class.
     |
     |      Args:
     |          by_alias: Whether to use attribute aliases or not.
     |          ref_template: The reference template.
     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of
     |              `GenerateJsonSchema` with your desired modifications
     |          mode: The mode in which to generate the schema.
     |
     |      Returns:
     |          The JSON schema for the given model class.
     |
     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'
     |      Compute the class name for parametrizations of generic classes.
     |
     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.
     |
     |      Args:
     |          params: Tuple of types of the class. Given a generic class
     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,
     |              the value `(str, int)` would be passed to `params`.
     |
     |      Returns:
     |          String representing the new class where `params` are passed to `cls` as type variables.
     |
     |      Raises:
     |          TypeError: Raised when trying to generate concrete names for non-generic models.
     |
     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'dict[str, Any] | None' = None) -> 'bool | None'
     |      Try to rebuild the pydantic-core schema for the model.
     |
     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during
     |      the initial attempt to build the schema, and automatic rebuilding fails.
     |
     |      Args:
     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.
     |          raise_errors: Whether to raise errors, defaults to `True`.
     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.
     |          _types_namespace: The types namespace, defaults to `None`.
     |
     |      Returns:
     |          Returns `None` if the schema is already "complete" and rebuilding was not required.
     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.
     |
     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate a pydantic model instance.
     |
     |      Args:
     |          obj: The object to validate.
     |          strict: Whether to enforce types strictly.
     |          from_attributes: Whether to extract data from object attributes.
     |          context: Additional context to pass to the validator.
     |
     |      Raises:
     |          ValidationError: If the object could not be validated.
     |
     |      Returns:
     |          The validated model instance.
     |
     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/json/#json-parsing
     |
     |      Validate the given JSON data against the Pydantic model.
     |
     |      Args:
     |          json_data: The JSON data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |      Raises:
     |          ValueError: If `json_data` is not a JSON string.
     |
     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate the given object with string data against the Pydantic model.
     |
     |      Args:
     |          obj: The object containing string data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  parse_obj(obj: 'Any') -> 'Self'
     |
     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'
     |
     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'
     |
     |  update_forward_refs(**localns: 'Any') -> 'None'
     |
     |  validate(value: 'Any') -> 'Self'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from pydantic.main.BaseModel:
     |
     |  __fields_set__
     |
     |  model_extra
     |      Get extra fields set during validation.
     |
     |      Returns:
     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `"allow"`.
     |
     |  model_fields_set
     |      Returns the set of fields that have been explicitly set on this model instance.
     |
     |      Returns:
     |          A set of strings representing the fields that have been set,
     |              i.e. that were not filled from defaults.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from pydantic.main.BaseModel:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __pydantic_extra__
     |
     |  __pydantic_fields_set__
     |
     |  __pydantic_private__
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from pydantic.main.BaseModel:
     |
     |  __hash__ = None
     |
     |  __pydantic_root_model__ = False

    class ParameterBase(BaseModelWithConfig)
     |  ParameterBase(**extra_data: Any) -> None
     |
     |  Method resolution order:
     |      ParameterBase
     |      BaseModelWithConfig
     |      pydantic.main.BaseModel
     |      builtins.object
     |
     |  Data and other attributes defined here:
     |
     |  __abstractmethods__ = frozenset()
     |
     |  __annotations__ = {'allowReserved': typing.Optional[bool], 'content': ...
     |
     |  __class_vars__ = set()
     |
     |  __private_attributes__ = {}
     |
     |  __pydantic_complete__ = True
     |
     |  __pydantic_core_schema__ = {'definitions': [{'cls': <class 'backend.Li...
     |
     |  __pydantic_custom_init__ = False
     |
     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...
     |
     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...
     |
     |  __pydantic_parent_namespace__ = {'Annotated': <pydantic._internal._mod...
     |
     |  __pydantic_post_init__ = None
     |
     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(
     |      Model...
     |
     |  __pydantic_validator__ = SchemaValidator(title="ParameterBase", valida...
     |
     |  __signature__ = <Signature (*, description: Optional[str] = None...s.M...
     |
     |  model_computed_fields = {}
     |
     |  model_config = {'extra': 'allow'}
     |
     |  model_fields = {'allowReserved': FieldInfo(annotation=Union[bool, None...
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from BaseModelWithConfig:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from pydantic.main.BaseModel:
     |
     |  __copy__(self) -> 'Self'
     |      Returns a shallow copy of the model.
     |
     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'
     |      Returns a deep copy of the model.
     |
     |  __delattr__(self, item: 'str') -> 'Any'
     |      Implement delattr(self, name).
     |
     |  __eq__(self, other: 'Any') -> 'bool'
     |      Return self==value.
     |
     |  __getattr__(self, item: 'str') -> 'Any'
     |
     |  __getstate__(self) -> 'dict[Any, Any]'
     |      Helper for pickle.
     |
     |  __init__(self, /, **data: 'Any') -> 'None'
     |      Create a new model by parsing and validating input data from keyword arguments.
     |
     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be
     |      validated to form a valid model.
     |
     |      `self` is explicitly positional-only to allow `self` as a field name.
     |
     |  __iter__(self) -> 'TupleGenerator'
     |      So `dict(model)` works.
     |
     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation
     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.
     |
     |  __repr__(self) -> 'str'
     |      Return repr(self).
     |
     |  __repr_args__(self) -> '_repr.ReprArgs'
     |
     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation
     |      Name of the instance's class, used in __repr__.
     |
     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation
     |
     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation
     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.
     |
     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'
     |
     |  __str__(self) -> 'str'
     |      Return str(self).
     |
     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Returns a copy of the model.
     |
     |      !!! warning "Deprecated"
     |          This method is now deprecated; use `model_copy` instead.
     |
     |      If you need `include` or `exclude`, use:
     |
     |      ```py
     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)
     |      data = {**data, **(update or {})}
     |      copied = self.model_validate(data)
     |      ```
     |
     |      Args:
     |          include: Optional set or mapping specifying which fields to include in the copied model.
     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.
     |          update: Optional dictionary of field-value pairs to override field values in the copied model.
     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.
     |
     |      Returns:
     |          A copy of the model with included, excluded and updated fields as specified.
     |
     |  dict(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'
     |
     |  json(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'
     |
     |  model_copy(self, *, update: 'dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#model_copy
     |
     |      Returns a copy of the model.
     |
     |      Args:
     |          update: Values to change/add in the new model. Note: the data is not validated
     |              before creating the new model. You should trust this data.
     |          deep: Set to `True` to make a deep copy of the model.
     |
     |      Returns:
     |          New model instance.
     |
     |  model_dump(self, *, mode: "Literal['json', 'python'] | str" = 'python', include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump
     |
     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.
     |
     |      Args:
     |          mode: The mode in which `to_python` should run.
     |              If mode is 'json', the output will only contain JSON serializable types.
     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.
     |          include: A set of fields to include in the output.
     |          exclude: A set of fields to exclude from the output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to use the field's alias in the dictionary key if defined.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A dictionary representation of the model.
     |
     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'str'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump_json
     |
     |      Generates a JSON representation of the model using Pydantic's `to_json` method.
     |
     |      Args:
     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.
     |          include: Field(s) to include in the JSON output.
     |          exclude: Field(s) to exclude from the JSON output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to serialize using field aliases.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A JSON string representation of the model.
     |
     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'
     |      Override this method to perform additional initialization after `__init__` and `model_construct`.
     |      This is useful if you want to do some validation that requires the entire model to be initialized.
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from pydantic.main.BaseModel:
     |
     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'
     |
     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'
     |      Hook into generating the model's CoreSchema.
     |
     |      Args:
     |          source: The class we are generating a schema for.
     |              This will generally be the same as the `cls` argument if this is a classmethod.
     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.
     |
     |      Returns:
     |          A `pydantic-core` `CoreSchema`.
     |
     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'
     |      Hook into generating the model's JSON schema.
     |
     |      Args:
     |          core_schema: A `pydantic-core` CoreSchema.
     |              You can ignore this argument and call the handler with a new CoreSchema,
     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),
     |              or just call the handler with the original schema.
     |          handler: Call into Pydantic's internal JSON schema generation.
     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema
     |              generation fails.
     |              Since this gets called by `BaseModel.model_json_schema` you can override the
     |              `schema_generator` argument to that function to change JSON schema generation globally
     |              for a type.
     |
     |      Returns:
     |          A JSON schema, as a Python object.
     |
     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'
     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`
     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will
     |      be present when this is called.
     |
     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,
     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that
     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.
     |
     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,
     |      any kwargs passed to the class definition that aren't used internally by pydantic.
     |
     |      Args:
     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally
     |              by pydantic.
     |
     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |
     |  from_orm(obj: 'Any') -> 'Self'
     |
     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |      Creates a new instance of the `Model` class with validated data.
     |
     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.
     |      Default values are respected, but no other validation is performed.
     |
     |      !!! note
     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.
     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`
     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.
     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in
     |          an error if extra values are passed, but they will be ignored.
     |
     |      Args:
     |          _fields_set: The set of field names accepted for the Model instance.
     |          values: Trusted or pre-validated data dictionary.
     |
     |      Returns:
     |          A new instance of the `Model` class with validated data.
     |
     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'
     |      Generates a JSON schema for a model class.
     |
     |      Args:
     |          by_alias: Whether to use attribute aliases or not.
     |          ref_template: The reference template.
     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of
     |              `GenerateJsonSchema` with your desired modifications
     |          mode: The mode in which to generate the schema.
     |
     |      Returns:
     |          The JSON schema for the given model class.
     |
     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'
     |      Compute the class name for parametrizations of generic classes.
     |
     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.
     |
     |      Args:
     |          params: Tuple of types of the class. Given a generic class
     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,
     |              the value `(str, int)` would be passed to `params`.
     |
     |      Returns:
     |          String representing the new class where `params` are passed to `cls` as type variables.
     |
     |      Raises:
     |          TypeError: Raised when trying to generate concrete names for non-generic models.
     |
     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'dict[str, Any] | None' = None) -> 'bool | None'
     |      Try to rebuild the pydantic-core schema for the model.
     |
     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during
     |      the initial attempt to build the schema, and automatic rebuilding fails.
     |
     |      Args:
     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.
     |          raise_errors: Whether to raise errors, defaults to `True`.
     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.
     |          _types_namespace: The types namespace, defaults to `None`.
     |
     |      Returns:
     |          Returns `None` if the schema is already "complete" and rebuilding was not required.
     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.
     |
     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate a pydantic model instance.
     |
     |      Args:
     |          obj: The object to validate.
     |          strict: Whether to enforce types strictly.
     |          from_attributes: Whether to extract data from object attributes.
     |          context: Additional context to pass to the validator.
     |
     |      Raises:
     |          ValidationError: If the object could not be validated.
     |
     |      Returns:
     |          The validated model instance.
     |
     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/json/#json-parsing
     |
     |      Validate the given JSON data against the Pydantic model.
     |
     |      Args:
     |          json_data: The JSON data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |      Raises:
     |          ValueError: If `json_data` is not a JSON string.
     |
     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate the given object with string data against the Pydantic model.
     |
     |      Args:
     |          obj: The object containing string data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  parse_obj(obj: 'Any') -> 'Self'
     |
     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'
     |
     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'
     |
     |  update_forward_refs(**localns: 'Any') -> 'None'
     |
     |  validate(value: 'Any') -> 'Self'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from pydantic.main.BaseModel:
     |
     |  __fields_set__
     |
     |  model_extra
     |      Get extra fields set during validation.
     |
     |      Returns:
     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `"allow"`.
     |
     |  model_fields_set
     |      Returns the set of fields that have been explicitly set on this model instance.
     |
     |      Returns:
     |          A set of strings representing the fields that have been set,
     |              i.e. that were not filled from defaults.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from pydantic.main.BaseModel:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __pydantic_extra__
     |
     |  __pydantic_fields_set__
     |
     |  __pydantic_private__
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from pydantic.main.BaseModel:
     |
     |  __hash__ = None
     |
     |  __pydantic_root_model__ = False

    class ParameterInType(enum.Enum)
     |  ParameterInType(*values)
     |
     |  Method resolution order:
     |      ParameterInType
     |      enum.Enum
     |      builtins.object
     |
     |  Data and other attributes defined here:
     |
     |  cookie = <ParameterInType.cookie: 'cookie'>
     |
     |  header = <ParameterInType.header: 'header'>
     |
     |  path = <ParameterInType.path: 'path'>
     |
     |  query = <ParameterInType.query: 'query'>
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from enum.Enum:
     |
     |  name
     |      The name of the Enum member.
     |
     |  value
     |      The value of the Enum member.
     |
     |  ----------------------------------------------------------------------
     |  Static methods inherited from enum.EnumType:
     |
     |  __contains__(value)
     |      Return True if `value` is in `cls`.
     |
     |      `value` is in `cls` if:
     |      1) `value` is a member of `cls`, or
     |      2) `value` is the value of one of the `cls`'s members.
     |
     |  __getitem__(name)
     |      Return the member matching `name`.
     |
     |  __iter__()
     |      Return members in definition order.
     |
     |  __len__()
     |      Return the number of members (no aliases)
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from enum.EnumType:
     |
     |  __members__
     |      Returns a mapping of member name->value.
     |
     |      This mapping lists all enum members, including aliases. Note that this
     |      is a read-only view of the internal mapping.

    class PathItem(BaseModelWithConfig)
     |  PathItem(*, ref: Optional[str] = None, summary: Optional[str] = None, description: Optional[str] = None, get: Optional[backend.Lib.site-packages.fastapi.openapi.models.Operation] = None, put: Optional[backend.Lib.site-packages.fastapi.openapi.models.Operation] = None, post: Optional[backend.Lib.site-packages.fastapi.openapi.models.Operation] = None, delete: Optional[backend.Lib.site-packages.fastapi.openapi.models.Operation] = None, options: Optional[backend.Lib.site-packages.fastapi.openapi.models.Operation] = None, head: Optional[backend.Lib.site-packages.fastapi.openapi.models.Operation] = None, patch: Optional[backend.Lib.site-packages.fastapi.openapi.models.Operation] = None, trace: Optional[backend.Lib.site-packages.fastapi.openapi.models.Operation] = None, servers: Optional[List[backend.Lib.site-packages.fastapi.openapi.models.Server]] = None, parameters: Optional[List[Union[backend.Lib.site-packages.fastapi.openapi.models.Parameter, backend.Lib.site-packages.fastapi.openapi.models.Reference]]] = None, **extra_data: Any) -> None
     |
     |  Method resolution order:
     |      PathItem
     |      BaseModelWithConfig
     |      pydantic.main.BaseModel
     |      builtins.object
     |
     |  Data and other attributes defined here:
     |
     |  __abstractmethods__ = frozenset()
     |
     |  __annotations__ = {'delete': typing.Optional[backend.Lib.site-packages...
     |
     |  __class_vars__ = set()
     |
     |  __private_attributes__ = {}
     |
     |  __pydantic_complete__ = True
     |
     |  __pydantic_core_schema__ = {'definitions': [{'cls': <class 'backend.Li...
     |
     |  __pydantic_custom_init__ = False
     |
     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...
     |
     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...
     |
     |  __pydantic_parent_namespace__ = {'Annotated': <pydantic._internal._mod...
     |
     |  __pydantic_post_init__ = None
     |
     |  __pydantic_serializer__ = SchemaSerializer(serializer=Recursive(
     |      D...
     |
     |  __pydantic_validator__ = SchemaValidator(title="PathItem", validator=D...
     |
     |  __signature__ = <Signature (*, ref: Optional[str] = None, summar....Re...
     |
     |  model_computed_fields = {}
     |
     |  model_config = {'extra': 'allow'}
     |
     |  model_fields = {'delete': FieldInfo(annotation=Union[Operation, NoneTy...
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from BaseModelWithConfig:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from pydantic.main.BaseModel:
     |
     |  __copy__(self) -> 'Self'
     |      Returns a shallow copy of the model.
     |
     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'
     |      Returns a deep copy of the model.
     |
     |  __delattr__(self, item: 'str') -> 'Any'
     |      Implement delattr(self, name).
     |
     |  __eq__(self, other: 'Any') -> 'bool'
     |      Return self==value.
     |
     |  __getattr__(self, item: 'str') -> 'Any'
     |
     |  __getstate__(self) -> 'dict[Any, Any]'
     |      Helper for pickle.
     |
     |  __init__(self, /, **data: 'Any') -> 'None'
     |      Create a new model by parsing and validating input data from keyword arguments.
     |
     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be
     |      validated to form a valid model.
     |
     |      `self` is explicitly positional-only to allow `self` as a field name.
     |
     |  __iter__(self) -> 'TupleGenerator'
     |      So `dict(model)` works.
     |
     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation
     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.
     |
     |  __repr__(self) -> 'str'
     |      Return repr(self).
     |
     |  __repr_args__(self) -> '_repr.ReprArgs'
     |
     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation
     |      Name of the instance's class, used in __repr__.
     |
     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation
     |
     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation
     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.
     |
     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'
     |
     |  __str__(self) -> 'str'
     |      Return str(self).
     |
     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Returns a copy of the model.
     |
     |      !!! warning "Deprecated"
     |          This method is now deprecated; use `model_copy` instead.
     |
     |      If you need `include` or `exclude`, use:
     |
     |      ```py
     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)
     |      data = {**data, **(update or {})}
     |      copied = self.model_validate(data)
     |      ```
     |
     |      Args:
     |          include: Optional set or mapping specifying which fields to include in the copied model.
     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.
     |          update: Optional dictionary of field-value pairs to override field values in the copied model.
     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.
     |
     |      Returns:
     |          A copy of the model with included, excluded and updated fields as specified.
     |
     |  dict(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'
     |
     |  json(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'
     |
     |  model_copy(self, *, update: 'dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#model_copy
     |
     |      Returns a copy of the model.
     |
     |      Args:
     |          update: Values to change/add in the new model. Note: the data is not validated
     |              before creating the new model. You should trust this data.
     |          deep: Set to `True` to make a deep copy of the model.
     |
     |      Returns:
     |          New model instance.
     |
     |  model_dump(self, *, mode: "Literal['json', 'python'] | str" = 'python', include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump
     |
     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.
     |
     |      Args:
     |          mode: The mode in which `to_python` should run.
     |              If mode is 'json', the output will only contain JSON serializable types.
     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.
     |          include: A set of fields to include in the output.
     |          exclude: A set of fields to exclude from the output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to use the field's alias in the dictionary key if defined.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A dictionary representation of the model.
     |
     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'str'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump_json
     |
     |      Generates a JSON representation of the model using Pydantic's `to_json` method.
     |
     |      Args:
     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.
     |          include: Field(s) to include in the JSON output.
     |          exclude: Field(s) to exclude from the JSON output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to serialize using field aliases.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A JSON string representation of the model.
     |
     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'
     |      Override this method to perform additional initialization after `__init__` and `model_construct`.
     |      This is useful if you want to do some validation that requires the entire model to be initialized.
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from pydantic.main.BaseModel:
     |
     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'
     |
     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'
     |      Hook into generating the model's CoreSchema.
     |
     |      Args:
     |          source: The class we are generating a schema for.
     |              This will generally be the same as the `cls` argument if this is a classmethod.
     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.
     |
     |      Returns:
     |          A `pydantic-core` `CoreSchema`.
     |
     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'
     |      Hook into generating the model's JSON schema.
     |
     |      Args:
     |          core_schema: A `pydantic-core` CoreSchema.
     |              You can ignore this argument and call the handler with a new CoreSchema,
     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),
     |              or just call the handler with the original schema.
     |          handler: Call into Pydantic's internal JSON schema generation.
     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema
     |              generation fails.
     |              Since this gets called by `BaseModel.model_json_schema` you can override the
     |              `schema_generator` argument to that function to change JSON schema generation globally
     |              for a type.
     |
     |      Returns:
     |          A JSON schema, as a Python object.
     |
     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'
     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`
     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will
     |      be present when this is called.
     |
     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,
     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that
     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.
     |
     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,
     |      any kwargs passed to the class definition that aren't used internally by pydantic.
     |
     |      Args:
     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally
     |              by pydantic.
     |
     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |
     |  from_orm(obj: 'Any') -> 'Self'
     |
     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |      Creates a new instance of the `Model` class with validated data.
     |
     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.
     |      Default values are respected, but no other validation is performed.
     |
     |      !!! note
     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.
     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`
     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.
     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in
     |          an error if extra values are passed, but they will be ignored.
     |
     |      Args:
     |          _fields_set: The set of field names accepted for the Model instance.
     |          values: Trusted or pre-validated data dictionary.
     |
     |      Returns:
     |          A new instance of the `Model` class with validated data.
     |
     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'
     |      Generates a JSON schema for a model class.
     |
     |      Args:
     |          by_alias: Whether to use attribute aliases or not.
     |          ref_template: The reference template.
     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of
     |              `GenerateJsonSchema` with your desired modifications
     |          mode: The mode in which to generate the schema.
     |
     |      Returns:
     |          The JSON schema for the given model class.
     |
     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'
     |      Compute the class name for parametrizations of generic classes.
     |
     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.
     |
     |      Args:
     |          params: Tuple of types of the class. Given a generic class
     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,
     |              the value `(str, int)` would be passed to `params`.
     |
     |      Returns:
     |          String representing the new class where `params` are passed to `cls` as type variables.
     |
     |      Raises:
     |          TypeError: Raised when trying to generate concrete names for non-generic models.
     |
     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'dict[str, Any] | None' = None) -> 'bool | None'
     |      Try to rebuild the pydantic-core schema for the model.
     |
     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during
     |      the initial attempt to build the schema, and automatic rebuilding fails.
     |
     |      Args:
     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.
     |          raise_errors: Whether to raise errors, defaults to `True`.
     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.
     |          _types_namespace: The types namespace, defaults to `None`.
     |
     |      Returns:
     |          Returns `None` if the schema is already "complete" and rebuilding was not required.
     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.
     |
     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate a pydantic model instance.
     |
     |      Args:
     |          obj: The object to validate.
     |          strict: Whether to enforce types strictly.
     |          from_attributes: Whether to extract data from object attributes.
     |          context: Additional context to pass to the validator.
     |
     |      Raises:
     |          ValidationError: If the object could not be validated.
     |
     |      Returns:
     |          The validated model instance.
     |
     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/json/#json-parsing
     |
     |      Validate the given JSON data against the Pydantic model.
     |
     |      Args:
     |          json_data: The JSON data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |      Raises:
     |          ValueError: If `json_data` is not a JSON string.
     |
     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate the given object with string data against the Pydantic model.
     |
     |      Args:
     |          obj: The object containing string data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  parse_obj(obj: 'Any') -> 'Self'
     |
     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'
     |
     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'
     |
     |  update_forward_refs(**localns: 'Any') -> 'None'
     |
     |  validate(value: 'Any') -> 'Self'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from pydantic.main.BaseModel:
     |
     |  __fields_set__
     |
     |  model_extra
     |      Get extra fields set during validation.
     |
     |      Returns:
     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `"allow"`.
     |
     |  model_fields_set
     |      Returns the set of fields that have been explicitly set on this model instance.
     |
     |      Returns:
     |          A set of strings representing the fields that have been set,
     |              i.e. that were not filled from defaults.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from pydantic.main.BaseModel:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __pydantic_extra__
     |
     |  __pydantic_fields_set__
     |
     |  __pydantic_private__
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from pydantic.main.BaseModel:
     |
     |  __hash__ = None
     |
     |  __pydantic_root_model__ = False

    class Reference(pydantic.main.BaseModel)
     |  Reference(*, ref: str) -> None
     |
     |  Method resolution order:
     |      Reference
     |      pydantic.main.BaseModel
     |      builtins.object
     |
     |  Data descriptors defined here:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  __abstractmethods__ = frozenset()
     |
     |  __annotations__ = {'ref': <class 'str'>}
     |
     |  __class_vars__ = set()
     |
     |  __private_attributes__ = {}
     |
     |  __pydantic_complete__ = True
     |
     |  __pydantic_core_schema__ = {'cls': <class 'backend.Lib.site-packages.f...
     |
     |  __pydantic_custom_init__ = False
     |
     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...
     |
     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...
     |
     |  __pydantic_parent_namespace__ = {'Annotated': <pydantic._internal._mod...
     |
     |  __pydantic_post_init__ = None
     |
     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(
     |      Model...
     |
     |  __pydantic_validator__ = SchemaValidator(title="Reference", validator=...
     |
     |  __signature__ = <Signature (*, ref: str) -> None>
     |
     |  model_computed_fields = {}
     |
     |  model_config = {}
     |
     |  model_fields = {'ref': FieldInfo(annotation=str, required=True, alias=...
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from pydantic.main.BaseModel:
     |
     |  __copy__(self) -> 'Self'
     |      Returns a shallow copy of the model.
     |
     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'
     |      Returns a deep copy of the model.
     |
     |  __delattr__(self, item: 'str') -> 'Any'
     |      Implement delattr(self, name).
     |
     |  __eq__(self, other: 'Any') -> 'bool'
     |      Return self==value.
     |
     |  __getattr__(self, item: 'str') -> 'Any'
     |
     |  __getstate__(self) -> 'dict[Any, Any]'
     |      Helper for pickle.
     |
     |  __init__(self, /, **data: 'Any') -> 'None'
     |      Create a new model by parsing and validating input data from keyword arguments.
     |
     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be
     |      validated to form a valid model.
     |
     |      `self` is explicitly positional-only to allow `self` as a field name.
     |
     |  __iter__(self) -> 'TupleGenerator'
     |      So `dict(model)` works.
     |
     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation
     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.
     |
     |  __repr__(self) -> 'str'
     |      Return repr(self).
     |
     |  __repr_args__(self) -> '_repr.ReprArgs'
     |
     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation
     |      Name of the instance's class, used in __repr__.
     |
     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation
     |
     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation
     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.
     |
     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'
     |
     |  __str__(self) -> 'str'
     |      Return str(self).
     |
     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Returns a copy of the model.
     |
     |      !!! warning "Deprecated"
     |          This method is now deprecated; use `model_copy` instead.
     |
     |      If you need `include` or `exclude`, use:
     |
     |      ```py
     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)
     |      data = {**data, **(update or {})}
     |      copied = self.model_validate(data)
     |      ```
     |
     |      Args:
     |          include: Optional set or mapping specifying which fields to include in the copied model.
     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.
     |          update: Optional dictionary of field-value pairs to override field values in the copied model.
     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.
     |
     |      Returns:
     |          A copy of the model with included, excluded and updated fields as specified.
     |
     |  dict(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'
     |
     |  json(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'
     |
     |  model_copy(self, *, update: 'dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#model_copy
     |
     |      Returns a copy of the model.
     |
     |      Args:
     |          update: Values to change/add in the new model. Note: the data is not validated
     |              before creating the new model. You should trust this data.
     |          deep: Set to `True` to make a deep copy of the model.
     |
     |      Returns:
     |          New model instance.
     |
     |  model_dump(self, *, mode: "Literal['json', 'python'] | str" = 'python', include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump
     |
     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.
     |
     |      Args:
     |          mode: The mode in which `to_python` should run.
     |              If mode is 'json', the output will only contain JSON serializable types.
     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.
     |          include: A set of fields to include in the output.
     |          exclude: A set of fields to exclude from the output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to use the field's alias in the dictionary key if defined.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A dictionary representation of the model.
     |
     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'str'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump_json
     |
     |      Generates a JSON representation of the model using Pydantic's `to_json` method.
     |
     |      Args:
     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.
     |          include: Field(s) to include in the JSON output.
     |          exclude: Field(s) to exclude from the JSON output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to serialize using field aliases.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A JSON string representation of the model.
     |
     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'
     |      Override this method to perform additional initialization after `__init__` and `model_construct`.
     |      This is useful if you want to do some validation that requires the entire model to be initialized.
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from pydantic.main.BaseModel:
     |
     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'
     |
     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'
     |      Hook into generating the model's CoreSchema.
     |
     |      Args:
     |          source: The class we are generating a schema for.
     |              This will generally be the same as the `cls` argument if this is a classmethod.
     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.
     |
     |      Returns:
     |          A `pydantic-core` `CoreSchema`.
     |
     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'
     |      Hook into generating the model's JSON schema.
     |
     |      Args:
     |          core_schema: A `pydantic-core` CoreSchema.
     |              You can ignore this argument and call the handler with a new CoreSchema,
     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),
     |              or just call the handler with the original schema.
     |          handler: Call into Pydantic's internal JSON schema generation.
     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema
     |              generation fails.
     |              Since this gets called by `BaseModel.model_json_schema` you can override the
     |              `schema_generator` argument to that function to change JSON schema generation globally
     |              for a type.
     |
     |      Returns:
     |          A JSON schema, as a Python object.
     |
     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'
     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`
     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will
     |      be present when this is called.
     |
     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,
     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that
     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.
     |
     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,
     |      any kwargs passed to the class definition that aren't used internally by pydantic.
     |
     |      Args:
     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally
     |              by pydantic.
     |
     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |
     |  from_orm(obj: 'Any') -> 'Self'
     |
     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |      Creates a new instance of the `Model` class with validated data.
     |
     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.
     |      Default values are respected, but no other validation is performed.
     |
     |      !!! note
     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.
     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`
     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.
     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in
     |          an error if extra values are passed, but they will be ignored.
     |
     |      Args:
     |          _fields_set: The set of field names accepted for the Model instance.
     |          values: Trusted or pre-validated data dictionary.
     |
     |      Returns:
     |          A new instance of the `Model` class with validated data.
     |
     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'
     |      Generates a JSON schema for a model class.
     |
     |      Args:
     |          by_alias: Whether to use attribute aliases or not.
     |          ref_template: The reference template.
     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of
     |              `GenerateJsonSchema` with your desired modifications
     |          mode: The mode in which to generate the schema.
     |
     |      Returns:
     |          The JSON schema for the given model class.
     |
     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'
     |      Compute the class name for parametrizations of generic classes.
     |
     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.
     |
     |      Args:
     |          params: Tuple of types of the class. Given a generic class
     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,
     |              the value `(str, int)` would be passed to `params`.
     |
     |      Returns:
     |          String representing the new class where `params` are passed to `cls` as type variables.
     |
     |      Raises:
     |          TypeError: Raised when trying to generate concrete names for non-generic models.
     |
     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'dict[str, Any] | None' = None) -> 'bool | None'
     |      Try to rebuild the pydantic-core schema for the model.
     |
     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during
     |      the initial attempt to build the schema, and automatic rebuilding fails.
     |
     |      Args:
     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.
     |          raise_errors: Whether to raise errors, defaults to `True`.
     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.
     |          _types_namespace: The types namespace, defaults to `None`.
     |
     |      Returns:
     |          Returns `None` if the schema is already "complete" and rebuilding was not required.
     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.
     |
     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate a pydantic model instance.
     |
     |      Args:
     |          obj: The object to validate.
     |          strict: Whether to enforce types strictly.
     |          from_attributes: Whether to extract data from object attributes.
     |          context: Additional context to pass to the validator.
     |
     |      Raises:
     |          ValidationError: If the object could not be validated.
     |
     |      Returns:
     |          The validated model instance.
     |
     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/json/#json-parsing
     |
     |      Validate the given JSON data against the Pydantic model.
     |
     |      Args:
     |          json_data: The JSON data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |      Raises:
     |          ValueError: If `json_data` is not a JSON string.
     |
     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate the given object with string data against the Pydantic model.
     |
     |      Args:
     |          obj: The object containing string data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  parse_obj(obj: 'Any') -> 'Self'
     |
     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'
     |
     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'
     |
     |  update_forward_refs(**localns: 'Any') -> 'None'
     |
     |  validate(value: 'Any') -> 'Self'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from pydantic.main.BaseModel:
     |
     |  __fields_set__
     |
     |  model_extra
     |      Get extra fields set during validation.
     |
     |      Returns:
     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `"allow"`.
     |
     |  model_fields_set
     |      Returns the set of fields that have been explicitly set on this model instance.
     |
     |      Returns:
     |          A set of strings representing the fields that have been set,
     |              i.e. that were not filled from defaults.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from pydantic.main.BaseModel:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __pydantic_extra__
     |
     |  __pydantic_fields_set__
     |
     |  __pydantic_private__
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from pydantic.main.BaseModel:
     |
     |  __hash__ = None
     |
     |  __pydantic_root_model__ = False

    class RequestBody(BaseModelWithConfig)
     |  RequestBody(*, description: Optional[str] = None, content: Dict[str, backend.Lib.site-packages.fastapi.openapi.models.MediaType], required: Optional[bool] = None, **extra_data: Any) -> None
     |
     |  Method resolution order:
     |      RequestBody
     |      BaseModelWithConfig
     |      pydantic.main.BaseModel
     |      builtins.object
     |
     |  Data and other attributes defined here:
     |
     |  __abstractmethods__ = frozenset()
     |
     |  __annotations__ = {'content': typing.Dict[str, backend.Lib.site-packag...
     |
     |  __class_vars__ = set()
     |
     |  __private_attributes__ = {}
     |
     |  __pydantic_complete__ = True
     |
     |  __pydantic_core_schema__ = {'definitions': [{'cls': <class 'backend.Li...
     |
     |  __pydantic_custom_init__ = False
     |
     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...
     |
     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...
     |
     |  __pydantic_parent_namespace__ = {'Annotated': <pydantic._internal._mod...
     |
     |  __pydantic_post_init__ = None
     |
     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(
     |      Model...
     |
     |  __pydantic_validator__ = SchemaValidator(title="RequestBody", validato...
     |
     |  __signature__ = <Signature (*, description: Optional[str] = None...pti...
     |
     |  model_computed_fields = {}
     |
     |  model_config = {'extra': 'allow'}
     |
     |  model_fields = {'content': FieldInfo(annotation=Dict[str, MediaType], ...
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from BaseModelWithConfig:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from pydantic.main.BaseModel:
     |
     |  __copy__(self) -> 'Self'
     |      Returns a shallow copy of the model.
     |
     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'
     |      Returns a deep copy of the model.
     |
     |  __delattr__(self, item: 'str') -> 'Any'
     |      Implement delattr(self, name).
     |
     |  __eq__(self, other: 'Any') -> 'bool'
     |      Return self==value.
     |
     |  __getattr__(self, item: 'str') -> 'Any'
     |
     |  __getstate__(self) -> 'dict[Any, Any]'
     |      Helper for pickle.
     |
     |  __init__(self, /, **data: 'Any') -> 'None'
     |      Create a new model by parsing and validating input data from keyword arguments.
     |
     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be
     |      validated to form a valid model.
     |
     |      `self` is explicitly positional-only to allow `self` as a field name.
     |
     |  __iter__(self) -> 'TupleGenerator'
     |      So `dict(model)` works.
     |
     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation
     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.
     |
     |  __repr__(self) -> 'str'
     |      Return repr(self).
     |
     |  __repr_args__(self) -> '_repr.ReprArgs'
     |
     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation
     |      Name of the instance's class, used in __repr__.
     |
     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation
     |
     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation
     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.
     |
     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'
     |
     |  __str__(self) -> 'str'
     |      Return str(self).
     |
     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Returns a copy of the model.
     |
     |      !!! warning "Deprecated"
     |          This method is now deprecated; use `model_copy` instead.
     |
     |      If you need `include` or `exclude`, use:
     |
     |      ```py
     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)
     |      data = {**data, **(update or {})}
     |      copied = self.model_validate(data)
     |      ```
     |
     |      Args:
     |          include: Optional set or mapping specifying which fields to include in the copied model.
     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.
     |          update: Optional dictionary of field-value pairs to override field values in the copied model.
     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.
     |
     |      Returns:
     |          A copy of the model with included, excluded and updated fields as specified.
     |
     |  dict(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'
     |
     |  json(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'
     |
     |  model_copy(self, *, update: 'dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#model_copy
     |
     |      Returns a copy of the model.
     |
     |      Args:
     |          update: Values to change/add in the new model. Note: the data is not validated
     |              before creating the new model. You should trust this data.
     |          deep: Set to `True` to make a deep copy of the model.
     |
     |      Returns:
     |          New model instance.
     |
     |  model_dump(self, *, mode: "Literal['json', 'python'] | str" = 'python', include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump
     |
     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.
     |
     |      Args:
     |          mode: The mode in which `to_python` should run.
     |              If mode is 'json', the output will only contain JSON serializable types.
     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.
     |          include: A set of fields to include in the output.
     |          exclude: A set of fields to exclude from the output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to use the field's alias in the dictionary key if defined.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A dictionary representation of the model.
     |
     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'str'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump_json
     |
     |      Generates a JSON representation of the model using Pydantic's `to_json` method.
     |
     |      Args:
     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.
     |          include: Field(s) to include in the JSON output.
     |          exclude: Field(s) to exclude from the JSON output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to serialize using field aliases.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A JSON string representation of the model.
     |
     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'
     |      Override this method to perform additional initialization after `__init__` and `model_construct`.
     |      This is useful if you want to do some validation that requires the entire model to be initialized.
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from pydantic.main.BaseModel:
     |
     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'
     |
     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'
     |      Hook into generating the model's CoreSchema.
     |
     |      Args:
     |          source: The class we are generating a schema for.
     |              This will generally be the same as the `cls` argument if this is a classmethod.
     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.
     |
     |      Returns:
     |          A `pydantic-core` `CoreSchema`.
     |
     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'
     |      Hook into generating the model's JSON schema.
     |
     |      Args:
     |          core_schema: A `pydantic-core` CoreSchema.
     |              You can ignore this argument and call the handler with a new CoreSchema,
     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),
     |              or just call the handler with the original schema.
     |          handler: Call into Pydantic's internal JSON schema generation.
     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema
     |              generation fails.
     |              Since this gets called by `BaseModel.model_json_schema` you can override the
     |              `schema_generator` argument to that function to change JSON schema generation globally
     |              for a type.
     |
     |      Returns:
     |          A JSON schema, as a Python object.
     |
     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'
     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`
     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will
     |      be present when this is called.
     |
     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,
     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that
     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.
     |
     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,
     |      any kwargs passed to the class definition that aren't used internally by pydantic.
     |
     |      Args:
     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally
     |              by pydantic.
     |
     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |
     |  from_orm(obj: 'Any') -> 'Self'
     |
     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |      Creates a new instance of the `Model` class with validated data.
     |
     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.
     |      Default values are respected, but no other validation is performed.
     |
     |      !!! note
     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.
     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`
     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.
     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in
     |          an error if extra values are passed, but they will be ignored.
     |
     |      Args:
     |          _fields_set: The set of field names accepted for the Model instance.
     |          values: Trusted or pre-validated data dictionary.
     |
     |      Returns:
     |          A new instance of the `Model` class with validated data.
     |
     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'
     |      Generates a JSON schema for a model class.
     |
     |      Args:
     |          by_alias: Whether to use attribute aliases or not.
     |          ref_template: The reference template.
     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of
     |              `GenerateJsonSchema` with your desired modifications
     |          mode: The mode in which to generate the schema.
     |
     |      Returns:
     |          The JSON schema for the given model class.
     |
     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'
     |      Compute the class name for parametrizations of generic classes.
     |
     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.
     |
     |      Args:
     |          params: Tuple of types of the class. Given a generic class
     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,
     |              the value `(str, int)` would be passed to `params`.
     |
     |      Returns:
     |          String representing the new class where `params` are passed to `cls` as type variables.
     |
     |      Raises:
     |          TypeError: Raised when trying to generate concrete names for non-generic models.
     |
     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'dict[str, Any] | None' = None) -> 'bool | None'
     |      Try to rebuild the pydantic-core schema for the model.
     |
     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during
     |      the initial attempt to build the schema, and automatic rebuilding fails.
     |
     |      Args:
     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.
     |          raise_errors: Whether to raise errors, defaults to `True`.
     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.
     |          _types_namespace: The types namespace, defaults to `None`.
     |
     |      Returns:
     |          Returns `None` if the schema is already "complete" and rebuilding was not required.
     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.
     |
     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate a pydantic model instance.
     |
     |      Args:
     |          obj: The object to validate.
     |          strict: Whether to enforce types strictly.
     |          from_attributes: Whether to extract data from object attributes.
     |          context: Additional context to pass to the validator.
     |
     |      Raises:
     |          ValidationError: If the object could not be validated.
     |
     |      Returns:
     |          The validated model instance.
     |
     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/json/#json-parsing
     |
     |      Validate the given JSON data against the Pydantic model.
     |
     |      Args:
     |          json_data: The JSON data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |      Raises:
     |          ValueError: If `json_data` is not a JSON string.
     |
     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate the given object with string data against the Pydantic model.
     |
     |      Args:
     |          obj: The object containing string data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  parse_obj(obj: 'Any') -> 'Self'
     |
     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'
     |
     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'
     |
     |  update_forward_refs(**localns: 'Any') -> 'None'
     |
     |  validate(value: 'Any') -> 'Self'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from pydantic.main.BaseModel:
     |
     |  __fields_set__
     |
     |  model_extra
     |      Get extra fields set during validation.
     |
     |      Returns:
     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `"allow"`.
     |
     |  model_fields_set
     |      Returns the set of fields that have been explicitly set on this model instance.
     |
     |      Returns:
     |          A set of strings representing the fields that have been set,
     |              i.e. that were not filled from defaults.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from pydantic.main.BaseModel:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __pydantic_extra__
     |
     |  __pydantic_fields_set__
     |
     |  __pydantic_private__
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from pydantic.main.BaseModel:
     |
     |  __hash__ = None
     |
     |  __pydantic_root_model__ = False

    class Response(BaseModelWithConfig)
     |  Response(*, description: str, headers: Optional[Dict[str, Union[backend.Lib.site-packages.fastapi.openapi.models.Header, backend.Lib.site-packages.fastapi.openapi.models.Reference]]] = None, content: Optional[Dict[str, backend.Lib.site-packages.fastapi.openapi.models.MediaType]] = None, links: Optional[Dict[str, Union[backend.Lib.site-packages.fastapi.openapi.models.Link, backend.Lib.site-packages.fastapi.openapi.models.Reference]]] = None, **extra_data: Any) -> None
     |
     |  Method resolution order:
     |      Response
     |      BaseModelWithConfig
     |      pydantic.main.BaseModel
     |      builtins.object
     |
     |  Data and other attributes defined here:
     |
     |  __abstractmethods__ = frozenset()
     |
     |  __annotations__ = {'content': typing.Optional[typing.Dict[str, backend...
     |
     |  __class_vars__ = set()
     |
     |  __private_attributes__ = {}
     |
     |  __pydantic_complete__ = True
     |
     |  __pydantic_core_schema__ = {'definitions': [{'cls': <class 'backend.Li...
     |
     |  __pydantic_custom_init__ = False
     |
     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...
     |
     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...
     |
     |  __pydantic_parent_namespace__ = {'Annotated': <pydantic._internal._mod...
     |
     |  __pydantic_post_init__ = None
     |
     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(
     |      Model...
     |
     |  __pydantic_validator__ = SchemaValidator(title="Response", validator=M...
     |
     |  __signature__ = <Signature (*, description: str, headers: Option....Re...
     |
     |  model_computed_fields = {}
     |
     |  model_config = {'extra': 'allow'}
     |
     |  model_fields = {'content': FieldInfo(annotation=Union[Dict[str, MediaT...
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from BaseModelWithConfig:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from pydantic.main.BaseModel:
     |
     |  __copy__(self) -> 'Self'
     |      Returns a shallow copy of the model.
     |
     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'
     |      Returns a deep copy of the model.
     |
     |  __delattr__(self, item: 'str') -> 'Any'
     |      Implement delattr(self, name).
     |
     |  __eq__(self, other: 'Any') -> 'bool'
     |      Return self==value.
     |
     |  __getattr__(self, item: 'str') -> 'Any'
     |
     |  __getstate__(self) -> 'dict[Any, Any]'
     |      Helper for pickle.
     |
     |  __init__(self, /, **data: 'Any') -> 'None'
     |      Create a new model by parsing and validating input data from keyword arguments.
     |
     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be
     |      validated to form a valid model.
     |
     |      `self` is explicitly positional-only to allow `self` as a field name.
     |
     |  __iter__(self) -> 'TupleGenerator'
     |      So `dict(model)` works.
     |
     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation
     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.
     |
     |  __repr__(self) -> 'str'
     |      Return repr(self).
     |
     |  __repr_args__(self) -> '_repr.ReprArgs'
     |
     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation
     |      Name of the instance's class, used in __repr__.
     |
     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation
     |
     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation
     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.
     |
     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'
     |
     |  __str__(self) -> 'str'
     |      Return str(self).
     |
     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Returns a copy of the model.
     |
     |      !!! warning "Deprecated"
     |          This method is now deprecated; use `model_copy` instead.
     |
     |      If you need `include` or `exclude`, use:
     |
     |      ```py
     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)
     |      data = {**data, **(update or {})}
     |      copied = self.model_validate(data)
     |      ```
     |
     |      Args:
     |          include: Optional set or mapping specifying which fields to include in the copied model.
     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.
     |          update: Optional dictionary of field-value pairs to override field values in the copied model.
     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.
     |
     |      Returns:
     |          A copy of the model with included, excluded and updated fields as specified.
     |
     |  dict(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'
     |
     |  json(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'
     |
     |  model_copy(self, *, update: 'dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#model_copy
     |
     |      Returns a copy of the model.
     |
     |      Args:
     |          update: Values to change/add in the new model. Note: the data is not validated
     |              before creating the new model. You should trust this data.
     |          deep: Set to `True` to make a deep copy of the model.
     |
     |      Returns:
     |          New model instance.
     |
     |  model_dump(self, *, mode: "Literal['json', 'python'] | str" = 'python', include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump
     |
     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.
     |
     |      Args:
     |          mode: The mode in which `to_python` should run.
     |              If mode is 'json', the output will only contain JSON serializable types.
     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.
     |          include: A set of fields to include in the output.
     |          exclude: A set of fields to exclude from the output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to use the field's alias in the dictionary key if defined.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A dictionary representation of the model.
     |
     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'str'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump_json
     |
     |      Generates a JSON representation of the model using Pydantic's `to_json` method.
     |
     |      Args:
     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.
     |          include: Field(s) to include in the JSON output.
     |          exclude: Field(s) to exclude from the JSON output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to serialize using field aliases.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A JSON string representation of the model.
     |
     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'
     |      Override this method to perform additional initialization after `__init__` and `model_construct`.
     |      This is useful if you want to do some validation that requires the entire model to be initialized.
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from pydantic.main.BaseModel:
     |
     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'
     |
     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'
     |      Hook into generating the model's CoreSchema.
     |
     |      Args:
     |          source: The class we are generating a schema for.
     |              This will generally be the same as the `cls` argument if this is a classmethod.
     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.
     |
     |      Returns:
     |          A `pydantic-core` `CoreSchema`.
     |
     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'
     |      Hook into generating the model's JSON schema.
     |
     |      Args:
     |          core_schema: A `pydantic-core` CoreSchema.
     |              You can ignore this argument and call the handler with a new CoreSchema,
     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),
     |              or just call the handler with the original schema.
     |          handler: Call into Pydantic's internal JSON schema generation.
     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema
     |              generation fails.
     |              Since this gets called by `BaseModel.model_json_schema` you can override the
     |              `schema_generator` argument to that function to change JSON schema generation globally
     |              for a type.
     |
     |      Returns:
     |          A JSON schema, as a Python object.
     |
     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'
     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`
     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will
     |      be present when this is called.
     |
     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,
     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that
     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.
     |
     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,
     |      any kwargs passed to the class definition that aren't used internally by pydantic.
     |
     |      Args:
     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally
     |              by pydantic.
     |
     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |
     |  from_orm(obj: 'Any') -> 'Self'
     |
     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |      Creates a new instance of the `Model` class with validated data.
     |
     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.
     |      Default values are respected, but no other validation is performed.
     |
     |      !!! note
     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.
     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`
     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.
     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in
     |          an error if extra values are passed, but they will be ignored.
     |
     |      Args:
     |          _fields_set: The set of field names accepted for the Model instance.
     |          values: Trusted or pre-validated data dictionary.
     |
     |      Returns:
     |          A new instance of the `Model` class with validated data.
     |
     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'
     |      Generates a JSON schema for a model class.
     |
     |      Args:
     |          by_alias: Whether to use attribute aliases or not.
     |          ref_template: The reference template.
     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of
     |              `GenerateJsonSchema` with your desired modifications
     |          mode: The mode in which to generate the schema.
     |
     |      Returns:
     |          The JSON schema for the given model class.
     |
     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'
     |      Compute the class name for parametrizations of generic classes.
     |
     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.
     |
     |      Args:
     |          params: Tuple of types of the class. Given a generic class
     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,
     |              the value `(str, int)` would be passed to `params`.
     |
     |      Returns:
     |          String representing the new class where `params` are passed to `cls` as type variables.
     |
     |      Raises:
     |          TypeError: Raised when trying to generate concrete names for non-generic models.
     |
     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'dict[str, Any] | None' = None) -> 'bool | None'
     |      Try to rebuild the pydantic-core schema for the model.
     |
     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during
     |      the initial attempt to build the schema, and automatic rebuilding fails.
     |
     |      Args:
     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.
     |          raise_errors: Whether to raise errors, defaults to `True`.
     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.
     |          _types_namespace: The types namespace, defaults to `None`.
     |
     |      Returns:
     |          Returns `None` if the schema is already "complete" and rebuilding was not required.
     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.
     |
     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate a pydantic model instance.
     |
     |      Args:
     |          obj: The object to validate.
     |          strict: Whether to enforce types strictly.
     |          from_attributes: Whether to extract data from object attributes.
     |          context: Additional context to pass to the validator.
     |
     |      Raises:
     |          ValidationError: If the object could not be validated.
     |
     |      Returns:
     |          The validated model instance.
     |
     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/json/#json-parsing
     |
     |      Validate the given JSON data against the Pydantic model.
     |
     |      Args:
     |          json_data: The JSON data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |      Raises:
     |          ValueError: If `json_data` is not a JSON string.
     |
     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate the given object with string data against the Pydantic model.
     |
     |      Args:
     |          obj: The object containing string data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  parse_obj(obj: 'Any') -> 'Self'
     |
     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'
     |
     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'
     |
     |  update_forward_refs(**localns: 'Any') -> 'None'
     |
     |  validate(value: 'Any') -> 'Self'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from pydantic.main.BaseModel:
     |
     |  __fields_set__
     |
     |  model_extra
     |      Get extra fields set during validation.
     |
     |      Returns:
     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `"allow"`.
     |
     |  model_fields_set
     |      Returns the set of fields that have been explicitly set on this model instance.
     |
     |      Returns:
     |          A set of strings representing the fields that have been set,
     |              i.e. that were not filled from defaults.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from pydantic.main.BaseModel:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __pydantic_extra__
     |
     |  __pydantic_fields_set__
     |
     |  __pydantic_private__
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from pydantic.main.BaseModel:
     |
     |  __hash__ = None
     |
     |  __pydantic_root_model__ = False

    class Schema(BaseModelWithConfig)
     |  Schema(*, schema_: Optional[str] = None, vocabulary: Optional[str] = None, id: Optional[str] = None, anchor: Optional[str] = None, dynamicAnchor: Optional[str] = None, ref: Optional[str] = None, dynamicRef: Optional[str] = None, defs: Optional[Dict[str, Union[backend.Lib.site-packages.fastapi.openapi.models.Schema, bool]]] = None, comment: Optional[str] = None, allOf: Optional[List[Union[backend.Lib.site-packages.fastapi.openapi.models.Schema, bool]]] = None, anyOf: Optional[List[Union[backend.Lib.site-packages.fastapi.openapi.models.Schema, bool]]] = None, oneOf: Optional[List[Union[backend.Lib.site-packages.fastapi.openapi.models.Schema, bool]]] = None, not_: Union[backend.Lib.site-packages.fastapi.openapi.models.Schema, bool, NoneType] = None, if_: Union[backend.Lib.site-packages.fastapi.openapi.models.Schema, bool, NoneType] = None, then: Union[backend.Lib.site-packages.fastapi.openapi.models.Schema, bool, NoneType] = None, else_: Union[backend.Lib.site-packages.fastapi.openapi.models.Schema, bool, NoneType] = None, dependentSchemas: Optional[Dict[str, Union[backend.Lib.site-packages.fastapi.openapi.models.Schema, bool]]] = None, prefixItems: Optional[List[Union[backend.Lib.site-packages.fastapi.openapi.models.Schema, bool]]] = None, items: Union[backend.Lib.site-packages.fastapi.openapi.models.Schema, bool, List[Union[backend.Lib.site-packages.fastapi.openapi.models.Schema, bool]], NoneType] = None, contains: Union[backend.Lib.site-packages.fastapi.openapi.models.Schema, bool, NoneType] = None, properties: Optional[Dict[str, Union[backend.Lib.site-packages.fastapi.openapi.models.Schema, bool]]] = None, patternProperties: Optional[Dict[str, Union[backend.Lib.site-packages.fastapi.openapi.models.Schema, bool]]] = None, additionalProperties: Union[backend.Lib.site-packages.fastapi.openapi.models.Schema, bool, NoneType] = None, propertyNames: Union[backend.Lib.site-packages.fastapi.openapi.models.Schema, bool, NoneType] = None, unevaluatedItems: Union[backend.Lib.site-packages.fastapi.openapi.models.Schema, bool, NoneType] = None, unevaluatedProperties: Union[backend.Lib.site-packages.fastapi.openapi.models.Schema, bool, NoneType] = None, type: Optional[str] = None, enum: Optional[List[Any]] = None, const: Optional[Any] = None, multipleOf: Annotated[Optional[float], Gt(gt=0)] = None, maximum: Optional[float] = None, exclusiveMaximum: Optional[float] = None, minimum: Optional[float] = None, exclusiveMinimum: Optional[float] = None, maxLength: Annotated[Optional[int], Ge(ge=0)] = None, minLength: Annotated[Optional[int], Ge(ge=0)] = None, pattern: Optional[str] = None, maxItems: Annotated[Optional[int], Ge(ge=0)] = None, minItems: Annotated[Optional[int], Ge(ge=0)] = None, uniqueItems: Optional[bool] = None, maxContains: Annotated[Optional[int], Ge(ge=0)] = None, minContains: Annotated[Optional[int], Ge(ge=0)] = None, maxProperties: Annotated[Optional[int], Ge(ge=0)] = None, minProperties: Annotated[Optional[int], Ge(ge=0)] = None, required: Optional[List[str]] = None, dependentRequired: Optional[Dict[str, Set[str]]] = None, format: Optional[str] = None, contentEncoding: Optional[str] = None, contentMediaType: Optional[str] = None, contentSchema: Union[backend.Lib.site-packages.fastapi.openapi.models.Schema, bool, NoneType] = None, title: Optional[str] = None, description: Optional[str] = None, default: Optional[Any] = None, deprecated: Optional[bool] = None, readOnly: Optional[bool] = None, writeOnly: Optional[bool] = None, examples: Optional[List[Any]] = None, discriminator: Optional[backend.Lib.site-packages.fastapi.openapi.models.Discriminator] = None, xml: Optional[backend.Lib.site-packages.fastapi.openapi.models.XML] = None, externalDocs: Optional[backend.Lib.site-packages.fastapi.openapi.models.ExternalDocumentation] = None, example: Optional[Any] = None, **extra_data: Any) -> None
     |
     |  Method resolution order:
     |      Schema
     |      BaseModelWithConfig
     |      pydantic.main.BaseModel
     |      builtins.object
     |
     |  Data descriptors defined here:
     |
     |  example
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  __abstractmethods__ = frozenset()
     |
     |  __annotations__ = {'additionalProperties': typing.Optional[ForwardRef(...
     |
     |  __class_vars__ = set()
     |
     |  __private_attributes__ = {}
     |
     |  __pydantic_complete__ = True
     |
     |  __pydantic_core_schema__ = {'definitions': [{'cls': <class 'backend.Li...
     |
     |  __pydantic_custom_init__ = False
     |
     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...
     |
     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...
     |
     |  __pydantic_parent_namespace__ = {'Annotated': <pydantic._internal._mod...
     |
     |  __pydantic_post_init__ = None
     |
     |  __pydantic_serializer__ = SchemaSerializer(serializer=Recursive(
     |      D...
     |
     |  __pydantic_validator__ = SchemaValidator(title="Schema", validator=Def...
     |
     |  __signature__ = <Signature (*, schema_: Optional[str] = None, vo...Opt...
     |
     |  model_computed_fields = {}
     |
     |  model_config = {'extra': 'allow'}
     |
     |  model_fields = {'additionalProperties': FieldInfo(annotation=Union[Sch...
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from BaseModelWithConfig:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from pydantic.main.BaseModel:
     |
     |  __copy__(self) -> 'Self'
     |      Returns a shallow copy of the model.
     |
     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'
     |      Returns a deep copy of the model.
     |
     |  __delattr__(self, item: 'str') -> 'Any'
     |      Implement delattr(self, name).
     |
     |  __eq__(self, other: 'Any') -> 'bool'
     |      Return self==value.
     |
     |  __getattr__(self, item: 'str') -> 'Any'
     |
     |  __getstate__(self) -> 'dict[Any, Any]'
     |      Helper for pickle.
     |
     |  __init__(self, /, **data: 'Any') -> 'None'
     |      Create a new model by parsing and validating input data from keyword arguments.
     |
     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be
     |      validated to form a valid model.
     |
     |      `self` is explicitly positional-only to allow `self` as a field name.
     |
     |  __iter__(self) -> 'TupleGenerator'
     |      So `dict(model)` works.
     |
     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation
     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.
     |
     |  __repr__(self) -> 'str'
     |      Return repr(self).
     |
     |  __repr_args__(self) -> '_repr.ReprArgs'
     |
     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation
     |      Name of the instance's class, used in __repr__.
     |
     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation
     |
     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation
     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.
     |
     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'
     |
     |  __str__(self) -> 'str'
     |      Return str(self).
     |
     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Returns a copy of the model.
     |
     |      !!! warning "Deprecated"
     |          This method is now deprecated; use `model_copy` instead.
     |
     |      If you need `include` or `exclude`, use:
     |
     |      ```py
     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)
     |      data = {**data, **(update or {})}
     |      copied = self.model_validate(data)
     |      ```
     |
     |      Args:
     |          include: Optional set or mapping specifying which fields to include in the copied model.
     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.
     |          update: Optional dictionary of field-value pairs to override field values in the copied model.
     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.
     |
     |      Returns:
     |          A copy of the model with included, excluded and updated fields as specified.
     |
     |  dict(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'
     |
     |  json(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'
     |
     |  model_copy(self, *, update: 'dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#model_copy
     |
     |      Returns a copy of the model.
     |
     |      Args:
     |          update: Values to change/add in the new model. Note: the data is not validated
     |              before creating the new model. You should trust this data.
     |          deep: Set to `True` to make a deep copy of the model.
     |
     |      Returns:
     |          New model instance.
     |
     |  model_dump(self, *, mode: "Literal['json', 'python'] | str" = 'python', include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump
     |
     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.
     |
     |      Args:
     |          mode: The mode in which `to_python` should run.
     |              If mode is 'json', the output will only contain JSON serializable types.
     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.
     |          include: A set of fields to include in the output.
     |          exclude: A set of fields to exclude from the output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to use the field's alias in the dictionary key if defined.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A dictionary representation of the model.
     |
     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'str'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump_json
     |
     |      Generates a JSON representation of the model using Pydantic's `to_json` method.
     |
     |      Args:
     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.
     |          include: Field(s) to include in the JSON output.
     |          exclude: Field(s) to exclude from the JSON output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to serialize using field aliases.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A JSON string representation of the model.
     |
     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'
     |      Override this method to perform additional initialization after `__init__` and `model_construct`.
     |      This is useful if you want to do some validation that requires the entire model to be initialized.
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from pydantic.main.BaseModel:
     |
     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'
     |
     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'
     |      Hook into generating the model's CoreSchema.
     |
     |      Args:
     |          source: The class we are generating a schema for.
     |              This will generally be the same as the `cls` argument if this is a classmethod.
     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.
     |
     |      Returns:
     |          A `pydantic-core` `CoreSchema`.
     |
     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'
     |      Hook into generating the model's JSON schema.
     |
     |      Args:
     |          core_schema: A `pydantic-core` CoreSchema.
     |              You can ignore this argument and call the handler with a new CoreSchema,
     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),
     |              or just call the handler with the original schema.
     |          handler: Call into Pydantic's internal JSON schema generation.
     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema
     |              generation fails.
     |              Since this gets called by `BaseModel.model_json_schema` you can override the
     |              `schema_generator` argument to that function to change JSON schema generation globally
     |              for a type.
     |
     |      Returns:
     |          A JSON schema, as a Python object.
     |
     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'
     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`
     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will
     |      be present when this is called.
     |
     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,
     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that
     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.
     |
     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,
     |      any kwargs passed to the class definition that aren't used internally by pydantic.
     |
     |      Args:
     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally
     |              by pydantic.
     |
     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |
     |  from_orm(obj: 'Any') -> 'Self'
     |
     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |      Creates a new instance of the `Model` class with validated data.
     |
     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.
     |      Default values are respected, but no other validation is performed.
     |
     |      !!! note
     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.
     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`
     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.
     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in
     |          an error if extra values are passed, but they will be ignored.
     |
     |      Args:
     |          _fields_set: The set of field names accepted for the Model instance.
     |          values: Trusted or pre-validated data dictionary.
     |
     |      Returns:
     |          A new instance of the `Model` class with validated data.
     |
     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'
     |      Generates a JSON schema for a model class.
     |
     |      Args:
     |          by_alias: Whether to use attribute aliases or not.
     |          ref_template: The reference template.
     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of
     |              `GenerateJsonSchema` with your desired modifications
     |          mode: The mode in which to generate the schema.
     |
     |      Returns:
     |          The JSON schema for the given model class.
     |
     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'
     |      Compute the class name for parametrizations of generic classes.
     |
     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.
     |
     |      Args:
     |          params: Tuple of types of the class. Given a generic class
     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,
     |              the value `(str, int)` would be passed to `params`.
     |
     |      Returns:
     |          String representing the new class where `params` are passed to `cls` as type variables.
     |
     |      Raises:
     |          TypeError: Raised when trying to generate concrete names for non-generic models.
     |
     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'dict[str, Any] | None' = None) -> 'bool | None'
     |      Try to rebuild the pydantic-core schema for the model.
     |
     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during
     |      the initial attempt to build the schema, and automatic rebuilding fails.
     |
     |      Args:
     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.
     |          raise_errors: Whether to raise errors, defaults to `True`.
     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.
     |          _types_namespace: The types namespace, defaults to `None`.
     |
     |      Returns:
     |          Returns `None` if the schema is already "complete" and rebuilding was not required.
     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.
     |
     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate a pydantic model instance.
     |
     |      Args:
     |          obj: The object to validate.
     |          strict: Whether to enforce types strictly.
     |          from_attributes: Whether to extract data from object attributes.
     |          context: Additional context to pass to the validator.
     |
     |      Raises:
     |          ValidationError: If the object could not be validated.
     |
     |      Returns:
     |          The validated model instance.
     |
     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/json/#json-parsing
     |
     |      Validate the given JSON data against the Pydantic model.
     |
     |      Args:
     |          json_data: The JSON data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |      Raises:
     |          ValueError: If `json_data` is not a JSON string.
     |
     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate the given object with string data against the Pydantic model.
     |
     |      Args:
     |          obj: The object containing string data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  parse_obj(obj: 'Any') -> 'Self'
     |
     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'
     |
     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'
     |
     |  update_forward_refs(**localns: 'Any') -> 'None'
     |
     |  validate(value: 'Any') -> 'Self'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from pydantic.main.BaseModel:
     |
     |  __fields_set__
     |
     |  model_extra
     |      Get extra fields set during validation.
     |
     |      Returns:
     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `"allow"`.
     |
     |  model_fields_set
     |      Returns the set of fields that have been explicitly set on this model instance.
     |
     |      Returns:
     |          A set of strings representing the fields that have been set,
     |              i.e. that were not filled from defaults.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from pydantic.main.BaseModel:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __pydantic_extra__
     |
     |  __pydantic_fields_set__
     |
     |  __pydantic_private__
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from pydantic.main.BaseModel:
     |
     |  __hash__ = None
     |
     |  __pydantic_root_model__ = False

    class SecurityBase(BaseModelWithConfig)
     |  SecurityBase(*, type: backend.Lib.site-packages.fastapi.openapi.models.SecuritySchemeType, description: Optional[str] = None, **extra_data: Any) -> None
     |
     |  Method resolution order:
     |      SecurityBase
     |      BaseModelWithConfig
     |      pydantic.main.BaseModel
     |      builtins.object
     |
     |  Data and other attributes defined here:
     |
     |  __abstractmethods__ = frozenset()
     |
     |  __annotations__ = {'description': typing.Optional[str], 'type_': <enum...
     |
     |  __class_vars__ = set()
     |
     |  __private_attributes__ = {}
     |
     |  __pydantic_complete__ = True
     |
     |  __pydantic_core_schema__ = {'cls': <class 'backend.Lib.site-packages.f...
     |
     |  __pydantic_custom_init__ = False
     |
     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...
     |
     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...
     |
     |  __pydantic_parent_namespace__ = {'Annotated': <pydantic._internal._mod...
     |
     |  __pydantic_post_init__ = None
     |
     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(
     |      Model...
     |
     |  __pydantic_validator__ = SchemaValidator(title="SecurityBase", validat...
     |
     |  __signature__ = <Signature (*, type: backend.Lib.site-packages.f...Opt...
     |
     |  model_computed_fields = {}
     |
     |  model_config = {'extra': 'allow'}
     |
     |  model_fields = {'description': FieldInfo(annotation=Union[str, NoneTyp...
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from BaseModelWithConfig:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from pydantic.main.BaseModel:
     |
     |  __copy__(self) -> 'Self'
     |      Returns a shallow copy of the model.
     |
     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'
     |      Returns a deep copy of the model.
     |
     |  __delattr__(self, item: 'str') -> 'Any'
     |      Implement delattr(self, name).
     |
     |  __eq__(self, other: 'Any') -> 'bool'
     |      Return self==value.
     |
     |  __getattr__(self, item: 'str') -> 'Any'
     |
     |  __getstate__(self) -> 'dict[Any, Any]'
     |      Helper for pickle.
     |
     |  __init__(self, /, **data: 'Any') -> 'None'
     |      Create a new model by parsing and validating input data from keyword arguments.
     |
     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be
     |      validated to form a valid model.
     |
     |      `self` is explicitly positional-only to allow `self` as a field name.
     |
     |  __iter__(self) -> 'TupleGenerator'
     |      So `dict(model)` works.
     |
     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation
     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.
     |
     |  __repr__(self) -> 'str'
     |      Return repr(self).
     |
     |  __repr_args__(self) -> '_repr.ReprArgs'
     |
     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation
     |      Name of the instance's class, used in __repr__.
     |
     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation
     |
     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation
     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.
     |
     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'
     |
     |  __str__(self) -> 'str'
     |      Return str(self).
     |
     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Returns a copy of the model.
     |
     |      !!! warning "Deprecated"
     |          This method is now deprecated; use `model_copy` instead.
     |
     |      If you need `include` or `exclude`, use:
     |
     |      ```py
     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)
     |      data = {**data, **(update or {})}
     |      copied = self.model_validate(data)
     |      ```
     |
     |      Args:
     |          include: Optional set or mapping specifying which fields to include in the copied model.
     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.
     |          update: Optional dictionary of field-value pairs to override field values in the copied model.
     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.
     |
     |      Returns:
     |          A copy of the model with included, excluded and updated fields as specified.
     |
     |  dict(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'
     |
     |  json(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'
     |
     |  model_copy(self, *, update: 'dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#model_copy
     |
     |      Returns a copy of the model.
     |
     |      Args:
     |          update: Values to change/add in the new model. Note: the data is not validated
     |              before creating the new model. You should trust this data.
     |          deep: Set to `True` to make a deep copy of the model.
     |
     |      Returns:
     |          New model instance.
     |
     |  model_dump(self, *, mode: "Literal['json', 'python'] | str" = 'python', include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump
     |
     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.
     |
     |      Args:
     |          mode: The mode in which `to_python` should run.
     |              If mode is 'json', the output will only contain JSON serializable types.
     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.
     |          include: A set of fields to include in the output.
     |          exclude: A set of fields to exclude from the output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to use the field's alias in the dictionary key if defined.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A dictionary representation of the model.
     |
     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'str'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump_json
     |
     |      Generates a JSON representation of the model using Pydantic's `to_json` method.
     |
     |      Args:
     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.
     |          include: Field(s) to include in the JSON output.
     |          exclude: Field(s) to exclude from the JSON output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to serialize using field aliases.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A JSON string representation of the model.
     |
     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'
     |      Override this method to perform additional initialization after `__init__` and `model_construct`.
     |      This is useful if you want to do some validation that requires the entire model to be initialized.
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from pydantic.main.BaseModel:
     |
     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'
     |
     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'
     |      Hook into generating the model's CoreSchema.
     |
     |      Args:
     |          source: The class we are generating a schema for.
     |              This will generally be the same as the `cls` argument if this is a classmethod.
     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.
     |
     |      Returns:
     |          A `pydantic-core` `CoreSchema`.
     |
     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'
     |      Hook into generating the model's JSON schema.
     |
     |      Args:
     |          core_schema: A `pydantic-core` CoreSchema.
     |              You can ignore this argument and call the handler with a new CoreSchema,
     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),
     |              or just call the handler with the original schema.
     |          handler: Call into Pydantic's internal JSON schema generation.
     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema
     |              generation fails.
     |              Since this gets called by `BaseModel.model_json_schema` you can override the
     |              `schema_generator` argument to that function to change JSON schema generation globally
     |              for a type.
     |
     |      Returns:
     |          A JSON schema, as a Python object.
     |
     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'
     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`
     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will
     |      be present when this is called.
     |
     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,
     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that
     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.
     |
     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,
     |      any kwargs passed to the class definition that aren't used internally by pydantic.
     |
     |      Args:
     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally
     |              by pydantic.
     |
     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |
     |  from_orm(obj: 'Any') -> 'Self'
     |
     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |      Creates a new instance of the `Model` class with validated data.
     |
     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.
     |      Default values are respected, but no other validation is performed.
     |
     |      !!! note
     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.
     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`
     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.
     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in
     |          an error if extra values are passed, but they will be ignored.
     |
     |      Args:
     |          _fields_set: The set of field names accepted for the Model instance.
     |          values: Trusted or pre-validated data dictionary.
     |
     |      Returns:
     |          A new instance of the `Model` class with validated data.
     |
     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'
     |      Generates a JSON schema for a model class.
     |
     |      Args:
     |          by_alias: Whether to use attribute aliases or not.
     |          ref_template: The reference template.
     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of
     |              `GenerateJsonSchema` with your desired modifications
     |          mode: The mode in which to generate the schema.
     |
     |      Returns:
     |          The JSON schema for the given model class.
     |
     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'
     |      Compute the class name for parametrizations of generic classes.
     |
     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.
     |
     |      Args:
     |          params: Tuple of types of the class. Given a generic class
     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,
     |              the value `(str, int)` would be passed to `params`.
     |
     |      Returns:
     |          String representing the new class where `params` are passed to `cls` as type variables.
     |
     |      Raises:
     |          TypeError: Raised when trying to generate concrete names for non-generic models.
     |
     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'dict[str, Any] | None' = None) -> 'bool | None'
     |      Try to rebuild the pydantic-core schema for the model.
     |
     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during
     |      the initial attempt to build the schema, and automatic rebuilding fails.
     |
     |      Args:
     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.
     |          raise_errors: Whether to raise errors, defaults to `True`.
     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.
     |          _types_namespace: The types namespace, defaults to `None`.
     |
     |      Returns:
     |          Returns `None` if the schema is already "complete" and rebuilding was not required.
     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.
     |
     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate a pydantic model instance.
     |
     |      Args:
     |          obj: The object to validate.
     |          strict: Whether to enforce types strictly.
     |          from_attributes: Whether to extract data from object attributes.
     |          context: Additional context to pass to the validator.
     |
     |      Raises:
     |          ValidationError: If the object could not be validated.
     |
     |      Returns:
     |          The validated model instance.
     |
     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/json/#json-parsing
     |
     |      Validate the given JSON data against the Pydantic model.
     |
     |      Args:
     |          json_data: The JSON data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |      Raises:
     |          ValueError: If `json_data` is not a JSON string.
     |
     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate the given object with string data against the Pydantic model.
     |
     |      Args:
     |          obj: The object containing string data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  parse_obj(obj: 'Any') -> 'Self'
     |
     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'
     |
     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'
     |
     |  update_forward_refs(**localns: 'Any') -> 'None'
     |
     |  validate(value: 'Any') -> 'Self'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from pydantic.main.BaseModel:
     |
     |  __fields_set__
     |
     |  model_extra
     |      Get extra fields set during validation.
     |
     |      Returns:
     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `"allow"`.
     |
     |  model_fields_set
     |      Returns the set of fields that have been explicitly set on this model instance.
     |
     |      Returns:
     |          A set of strings representing the fields that have been set,
     |              i.e. that were not filled from defaults.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from pydantic.main.BaseModel:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __pydantic_extra__
     |
     |  __pydantic_fields_set__
     |
     |  __pydantic_private__
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from pydantic.main.BaseModel:
     |
     |  __hash__ = None
     |
     |  __pydantic_root_model__ = False

    class SecuritySchemeType(enum.Enum)
     |  SecuritySchemeType(*values)
     |
     |  Method resolution order:
     |      SecuritySchemeType
     |      enum.Enum
     |      builtins.object
     |
     |  Data and other attributes defined here:
     |
     |  apiKey = <SecuritySchemeType.apiKey: 'apiKey'>
     |
     |  http = <SecuritySchemeType.http: 'http'>
     |
     |  oauth2 = <SecuritySchemeType.oauth2: 'oauth2'>
     |
     |  openIdConnect = <SecuritySchemeType.openIdConnect: 'openIdConnect'>
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from enum.Enum:
     |
     |  name
     |      The name of the Enum member.
     |
     |  value
     |      The value of the Enum member.
     |
     |  ----------------------------------------------------------------------
     |  Static methods inherited from enum.EnumType:
     |
     |  __contains__(value)
     |      Return True if `value` is in `cls`.
     |
     |      `value` is in `cls` if:
     |      1) `value` is a member of `cls`, or
     |      2) `value` is the value of one of the `cls`'s members.
     |
     |  __getitem__(name)
     |      Return the member matching `name`.
     |
     |  __iter__()
     |      Return members in definition order.
     |
     |  __len__()
     |      Return the number of members (no aliases)
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from enum.EnumType:
     |
     |  __members__
     |      Returns a mapping of member name->value.
     |
     |      This mapping lists all enum members, including aliases. Note that this
     |      is a read-only view of the internal mapping.

    class Server(BaseModelWithConfig)
     |  Server(*, url: Union[pydantic_core._pydantic_core.Url, str], description: Optional[str] = None, variables: Optional[Dict[str, backend.Lib.site-packages.fastapi.openapi.models.ServerVariable]] = None, **extra_data: Any) -> None
     |
     |  Method resolution order:
     |      Server
     |      BaseModelWithConfig
     |      pydantic.main.BaseModel
     |      builtins.object
     |
     |  Data and other attributes defined here:
     |
     |  __abstractmethods__ = frozenset()
     |
     |  __annotations__ = {'description': typing.Optional[str], 'url': typing....
     |
     |  __class_vars__ = set()
     |
     |  __private_attributes__ = {}
     |
     |  __pydantic_complete__ = True
     |
     |  __pydantic_core_schema__ = {'cls': <class 'backend.Lib.site-packages.f...
     |
     |  __pydantic_custom_init__ = False
     |
     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...
     |
     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...
     |
     |  __pydantic_parent_namespace__ = {'Annotated': <pydantic._internal._mod...
     |
     |  __pydantic_post_init__ = None
     |
     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(
     |      Model...
     |
     |  __pydantic_validator__ = SchemaValidator(title="Server", validator=Mod...
     |
     |  __signature__ = <Signature (*, url: Union[pydantic_core._pydanti...ver...
     |
     |  model_computed_fields = {}
     |
     |  model_config = {'extra': 'allow'}
     |
     |  model_fields = {'description': FieldInfo(annotation=Union[str, NoneTyp...
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from BaseModelWithConfig:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from pydantic.main.BaseModel:
     |
     |  __copy__(self) -> 'Self'
     |      Returns a shallow copy of the model.
     |
     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'
     |      Returns a deep copy of the model.
     |
     |  __delattr__(self, item: 'str') -> 'Any'
     |      Implement delattr(self, name).
     |
     |  __eq__(self, other: 'Any') -> 'bool'
     |      Return self==value.
     |
     |  __getattr__(self, item: 'str') -> 'Any'
     |
     |  __getstate__(self) -> 'dict[Any, Any]'
     |      Helper for pickle.
     |
     |  __init__(self, /, **data: 'Any') -> 'None'
     |      Create a new model by parsing and validating input data from keyword arguments.
     |
     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be
     |      validated to form a valid model.
     |
     |      `self` is explicitly positional-only to allow `self` as a field name.
     |
     |  __iter__(self) -> 'TupleGenerator'
     |      So `dict(model)` works.
     |
     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation
     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.
     |
     |  __repr__(self) -> 'str'
     |      Return repr(self).
     |
     |  __repr_args__(self) -> '_repr.ReprArgs'
     |
     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation
     |      Name of the instance's class, used in __repr__.
     |
     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation
     |
     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation
     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.
     |
     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'
     |
     |  __str__(self) -> 'str'
     |      Return str(self).
     |
     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Returns a copy of the model.
     |
     |      !!! warning "Deprecated"
     |          This method is now deprecated; use `model_copy` instead.
     |
     |      If you need `include` or `exclude`, use:
     |
     |      ```py
     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)
     |      data = {**data, **(update or {})}
     |      copied = self.model_validate(data)
     |      ```
     |
     |      Args:
     |          include: Optional set or mapping specifying which fields to include in the copied model.
     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.
     |          update: Optional dictionary of field-value pairs to override field values in the copied model.
     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.
     |
     |      Returns:
     |          A copy of the model with included, excluded and updated fields as specified.
     |
     |  dict(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'
     |
     |  json(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'
     |
     |  model_copy(self, *, update: 'dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#model_copy
     |
     |      Returns a copy of the model.
     |
     |      Args:
     |          update: Values to change/add in the new model. Note: the data is not validated
     |              before creating the new model. You should trust this data.
     |          deep: Set to `True` to make a deep copy of the model.
     |
     |      Returns:
     |          New model instance.
     |
     |  model_dump(self, *, mode: "Literal['json', 'python'] | str" = 'python', include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump
     |
     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.
     |
     |      Args:
     |          mode: The mode in which `to_python` should run.
     |              If mode is 'json', the output will only contain JSON serializable types.
     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.
     |          include: A set of fields to include in the output.
     |          exclude: A set of fields to exclude from the output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to use the field's alias in the dictionary key if defined.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A dictionary representation of the model.
     |
     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'str'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump_json
     |
     |      Generates a JSON representation of the model using Pydantic's `to_json` method.
     |
     |      Args:
     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.
     |          include: Field(s) to include in the JSON output.
     |          exclude: Field(s) to exclude from the JSON output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to serialize using field aliases.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A JSON string representation of the model.
     |
     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'
     |      Override this method to perform additional initialization after `__init__` and `model_construct`.
     |      This is useful if you want to do some validation that requires the entire model to be initialized.
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from pydantic.main.BaseModel:
     |
     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'
     |
     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'
     |      Hook into generating the model's CoreSchema.
     |
     |      Args:
     |          source: The class we are generating a schema for.
     |              This will generally be the same as the `cls` argument if this is a classmethod.
     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.
     |
     |      Returns:
     |          A `pydantic-core` `CoreSchema`.
     |
     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'
     |      Hook into generating the model's JSON schema.
     |
     |      Args:
     |          core_schema: A `pydantic-core` CoreSchema.
     |              You can ignore this argument and call the handler with a new CoreSchema,
     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),
     |              or just call the handler with the original schema.
     |          handler: Call into Pydantic's internal JSON schema generation.
     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema
     |              generation fails.
     |              Since this gets called by `BaseModel.model_json_schema` you can override the
     |              `schema_generator` argument to that function to change JSON schema generation globally
     |              for a type.
     |
     |      Returns:
     |          A JSON schema, as a Python object.
     |
     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'
     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`
     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will
     |      be present when this is called.
     |
     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,
     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that
     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.
     |
     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,
     |      any kwargs passed to the class definition that aren't used internally by pydantic.
     |
     |      Args:
     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally
     |              by pydantic.
     |
     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |
     |  from_orm(obj: 'Any') -> 'Self'
     |
     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |      Creates a new instance of the `Model` class with validated data.
     |
     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.
     |      Default values are respected, but no other validation is performed.
     |
     |      !!! note
     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.
     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`
     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.
     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in
     |          an error if extra values are passed, but they will be ignored.
     |
     |      Args:
     |          _fields_set: The set of field names accepted for the Model instance.
     |          values: Trusted or pre-validated data dictionary.
     |
     |      Returns:
     |          A new instance of the `Model` class with validated data.
     |
     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'
     |      Generates a JSON schema for a model class.
     |
     |      Args:
     |          by_alias: Whether to use attribute aliases or not.
     |          ref_template: The reference template.
     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of
     |              `GenerateJsonSchema` with your desired modifications
     |          mode: The mode in which to generate the schema.
     |
     |      Returns:
     |          The JSON schema for the given model class.
     |
     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'
     |      Compute the class name for parametrizations of generic classes.
     |
     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.
     |
     |      Args:
     |          params: Tuple of types of the class. Given a generic class
     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,
     |              the value `(str, int)` would be passed to `params`.
     |
     |      Returns:
     |          String representing the new class where `params` are passed to `cls` as type variables.
     |
     |      Raises:
     |          TypeError: Raised when trying to generate concrete names for non-generic models.
     |
     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'dict[str, Any] | None' = None) -> 'bool | None'
     |      Try to rebuild the pydantic-core schema for the model.
     |
     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during
     |      the initial attempt to build the schema, and automatic rebuilding fails.
     |
     |      Args:
     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.
     |          raise_errors: Whether to raise errors, defaults to `True`.
     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.
     |          _types_namespace: The types namespace, defaults to `None`.
     |
     |      Returns:
     |          Returns `None` if the schema is already "complete" and rebuilding was not required.
     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.
     |
     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate a pydantic model instance.
     |
     |      Args:
     |          obj: The object to validate.
     |          strict: Whether to enforce types strictly.
     |          from_attributes: Whether to extract data from object attributes.
     |          context: Additional context to pass to the validator.
     |
     |      Raises:
     |          ValidationError: If the object could not be validated.
     |
     |      Returns:
     |          The validated model instance.
     |
     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/json/#json-parsing
     |
     |      Validate the given JSON data against the Pydantic model.
     |
     |      Args:
     |          json_data: The JSON data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |      Raises:
     |          ValueError: If `json_data` is not a JSON string.
     |
     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate the given object with string data against the Pydantic model.
     |
     |      Args:
     |          obj: The object containing string data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  parse_obj(obj: 'Any') -> 'Self'
     |
     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'
     |
     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'
     |
     |  update_forward_refs(**localns: 'Any') -> 'None'
     |
     |  validate(value: 'Any') -> 'Self'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from pydantic.main.BaseModel:
     |
     |  __fields_set__
     |
     |  model_extra
     |      Get extra fields set during validation.
     |
     |      Returns:
     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `"allow"`.
     |
     |  model_fields_set
     |      Returns the set of fields that have been explicitly set on this model instance.
     |
     |      Returns:
     |          A set of strings representing the fields that have been set,
     |              i.e. that were not filled from defaults.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from pydantic.main.BaseModel:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __pydantic_extra__
     |
     |  __pydantic_fields_set__
     |
     |  __pydantic_private__
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from pydantic.main.BaseModel:
     |
     |  __hash__ = None
     |
     |  __pydantic_root_model__ = False

    class ServerVariable(BaseModelWithConfig)
     |  ServerVariable(*, enum: Annotated[Optional[List[str]], MinLen(min_length=1)] = None, default: str, description: Optional[str] = None, **extra_data: Any) -> None
     |
     |  Method resolution order:
     |      ServerVariable
     |      BaseModelWithConfig
     |      pydantic.main.BaseModel
     |      builtins.object
     |
     |  Data and other attributes defined here:
     |
     |  __abstractmethods__ = frozenset()
     |
     |  __annotations__ = {'default': <class 'str'>, 'description': typing.Opt...
     |
     |  __class_vars__ = set()
     |
     |  __private_attributes__ = {}
     |
     |  __pydantic_complete__ = True
     |
     |  __pydantic_core_schema__ = {'cls': <class 'backend.Lib.site-packages.f...
     |
     |  __pydantic_custom_init__ = False
     |
     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...
     |
     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...
     |
     |  __pydantic_parent_namespace__ = {'Annotated': <pydantic._internal._mod...
     |
     |  __pydantic_post_init__ = None
     |
     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(
     |      Model...
     |
     |  __pydantic_validator__ = SchemaValidator(title="ServerVariable", valid...
     |
     |  __signature__ = <Signature (*, enum: Annotated[Optional[List[str...Opt...
     |
     |  model_computed_fields = {}
     |
     |  model_config = {'extra': 'allow'}
     |
     |  model_fields = {'default': FieldInfo(annotation=str, required=True), '...
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from BaseModelWithConfig:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from pydantic.main.BaseModel:
     |
     |  __copy__(self) -> 'Self'
     |      Returns a shallow copy of the model.
     |
     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'
     |      Returns a deep copy of the model.
     |
     |  __delattr__(self, item: 'str') -> 'Any'
     |      Implement delattr(self, name).
     |
     |  __eq__(self, other: 'Any') -> 'bool'
     |      Return self==value.
     |
     |  __getattr__(self, item: 'str') -> 'Any'
     |
     |  __getstate__(self) -> 'dict[Any, Any]'
     |      Helper for pickle.
     |
     |  __init__(self, /, **data: 'Any') -> 'None'
     |      Create a new model by parsing and validating input data from keyword arguments.
     |
     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be
     |      validated to form a valid model.
     |
     |      `self` is explicitly positional-only to allow `self` as a field name.
     |
     |  __iter__(self) -> 'TupleGenerator'
     |      So `dict(model)` works.
     |
     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation
     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.
     |
     |  __repr__(self) -> 'str'
     |      Return repr(self).
     |
     |  __repr_args__(self) -> '_repr.ReprArgs'
     |
     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation
     |      Name of the instance's class, used in __repr__.
     |
     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation
     |
     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation
     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.
     |
     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'
     |
     |  __str__(self) -> 'str'
     |      Return str(self).
     |
     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Returns a copy of the model.
     |
     |      !!! warning "Deprecated"
     |          This method is now deprecated; use `model_copy` instead.
     |
     |      If you need `include` or `exclude`, use:
     |
     |      ```py
     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)
     |      data = {**data, **(update or {})}
     |      copied = self.model_validate(data)
     |      ```
     |
     |      Args:
     |          include: Optional set or mapping specifying which fields to include in the copied model.
     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.
     |          update: Optional dictionary of field-value pairs to override field values in the copied model.
     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.
     |
     |      Returns:
     |          A copy of the model with included, excluded and updated fields as specified.
     |
     |  dict(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'
     |
     |  json(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'
     |
     |  model_copy(self, *, update: 'dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#model_copy
     |
     |      Returns a copy of the model.
     |
     |      Args:
     |          update: Values to change/add in the new model. Note: the data is not validated
     |              before creating the new model. You should trust this data.
     |          deep: Set to `True` to make a deep copy of the model.
     |
     |      Returns:
     |          New model instance.
     |
     |  model_dump(self, *, mode: "Literal['json', 'python'] | str" = 'python', include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump
     |
     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.
     |
     |      Args:
     |          mode: The mode in which `to_python` should run.
     |              If mode is 'json', the output will only contain JSON serializable types.
     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.
     |          include: A set of fields to include in the output.
     |          exclude: A set of fields to exclude from the output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to use the field's alias in the dictionary key if defined.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A dictionary representation of the model.
     |
     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'str'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump_json
     |
     |      Generates a JSON representation of the model using Pydantic's `to_json` method.
     |
     |      Args:
     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.
     |          include: Field(s) to include in the JSON output.
     |          exclude: Field(s) to exclude from the JSON output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to serialize using field aliases.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A JSON string representation of the model.
     |
     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'
     |      Override this method to perform additional initialization after `__init__` and `model_construct`.
     |      This is useful if you want to do some validation that requires the entire model to be initialized.
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from pydantic.main.BaseModel:
     |
     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'
     |
     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'
     |      Hook into generating the model's CoreSchema.
     |
     |      Args:
     |          source: The class we are generating a schema for.
     |              This will generally be the same as the `cls` argument if this is a classmethod.
     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.
     |
     |      Returns:
     |          A `pydantic-core` `CoreSchema`.
     |
     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'
     |      Hook into generating the model's JSON schema.
     |
     |      Args:
     |          core_schema: A `pydantic-core` CoreSchema.
     |              You can ignore this argument and call the handler with a new CoreSchema,
     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),
     |              or just call the handler with the original schema.
     |          handler: Call into Pydantic's internal JSON schema generation.
     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema
     |              generation fails.
     |              Since this gets called by `BaseModel.model_json_schema` you can override the
     |              `schema_generator` argument to that function to change JSON schema generation globally
     |              for a type.
     |
     |      Returns:
     |          A JSON schema, as a Python object.
     |
     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'
     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`
     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will
     |      be present when this is called.
     |
     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,
     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that
     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.
     |
     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,
     |      any kwargs passed to the class definition that aren't used internally by pydantic.
     |
     |      Args:
     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally
     |              by pydantic.
     |
     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |
     |  from_orm(obj: 'Any') -> 'Self'
     |
     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |      Creates a new instance of the `Model` class with validated data.
     |
     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.
     |      Default values are respected, but no other validation is performed.
     |
     |      !!! note
     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.
     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`
     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.
     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in
     |          an error if extra values are passed, but they will be ignored.
     |
     |      Args:
     |          _fields_set: The set of field names accepted for the Model instance.
     |          values: Trusted or pre-validated data dictionary.
     |
     |      Returns:
     |          A new instance of the `Model` class with validated data.
     |
     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'
     |      Generates a JSON schema for a model class.
     |
     |      Args:
     |          by_alias: Whether to use attribute aliases or not.
     |          ref_template: The reference template.
     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of
     |              `GenerateJsonSchema` with your desired modifications
     |          mode: The mode in which to generate the schema.
     |
     |      Returns:
     |          The JSON schema for the given model class.
     |
     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'
     |      Compute the class name for parametrizations of generic classes.
     |
     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.
     |
     |      Args:
     |          params: Tuple of types of the class. Given a generic class
     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,
     |              the value `(str, int)` would be passed to `params`.
     |
     |      Returns:
     |          String representing the new class where `params` are passed to `cls` as type variables.
     |
     |      Raises:
     |          TypeError: Raised when trying to generate concrete names for non-generic models.
     |
     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'dict[str, Any] | None' = None) -> 'bool | None'
     |      Try to rebuild the pydantic-core schema for the model.
     |
     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during
     |      the initial attempt to build the schema, and automatic rebuilding fails.
     |
     |      Args:
     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.
     |          raise_errors: Whether to raise errors, defaults to `True`.
     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.
     |          _types_namespace: The types namespace, defaults to `None`.
     |
     |      Returns:
     |          Returns `None` if the schema is already "complete" and rebuilding was not required.
     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.
     |
     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate a pydantic model instance.
     |
     |      Args:
     |          obj: The object to validate.
     |          strict: Whether to enforce types strictly.
     |          from_attributes: Whether to extract data from object attributes.
     |          context: Additional context to pass to the validator.
     |
     |      Raises:
     |          ValidationError: If the object could not be validated.
     |
     |      Returns:
     |          The validated model instance.
     |
     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/json/#json-parsing
     |
     |      Validate the given JSON data against the Pydantic model.
     |
     |      Args:
     |          json_data: The JSON data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |      Raises:
     |          ValueError: If `json_data` is not a JSON string.
     |
     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate the given object with string data against the Pydantic model.
     |
     |      Args:
     |          obj: The object containing string data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  parse_obj(obj: 'Any') -> 'Self'
     |
     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'
     |
     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'
     |
     |  update_forward_refs(**localns: 'Any') -> 'None'
     |
     |  validate(value: 'Any') -> 'Self'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from pydantic.main.BaseModel:
     |
     |  __fields_set__
     |
     |  model_extra
     |      Get extra fields set during validation.
     |
     |      Returns:
     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `"allow"`.
     |
     |  model_fields_set
     |      Returns the set of fields that have been explicitly set on this model instance.
     |
     |      Returns:
     |          A set of strings representing the fields that have been set,
     |              i.e. that were not filled from defaults.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from pydantic.main.BaseModel:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __pydantic_extra__
     |
     |  __pydantic_fields_set__
     |
     |  __pydantic_private__
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from pydantic.main.BaseModel:
     |
     |  __hash__ = None
     |
     |  __pydantic_root_model__ = False

    class Tag(BaseModelWithConfig)
     |  Tag(*, name: str, description: Optional[str] = None, externalDocs: Optional[backend.Lib.site-packages.fastapi.openapi.models.ExternalDocumentation] = None, **extra_data: Any) -> None
     |
     |  Method resolution order:
     |      Tag
     |      BaseModelWithConfig
     |      pydantic.main.BaseModel
     |      builtins.object
     |
     |  Data and other attributes defined here:
     |
     |  __abstractmethods__ = frozenset()
     |
     |  __annotations__ = {'description': typing.Optional[str], 'externalDocs'...
     |
     |  __class_vars__ = set()
     |
     |  __private_attributes__ = {}
     |
     |  __pydantic_complete__ = True
     |
     |  __pydantic_core_schema__ = {'cls': <class 'backend.Lib.site-packages.f...
     |
     |  __pydantic_custom_init__ = False
     |
     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...
     |
     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...
     |
     |  __pydantic_parent_namespace__ = {'APIKey': <pydantic._internal._model_...
     |
     |  __pydantic_post_init__ = None
     |
     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(
     |      Model...
     |
     |  __pydantic_validator__ = SchemaValidator(title="Tag", validator=Model(...
     |
     |  __signature__ = <Signature (*, name: str, description: Optional[...ocu...
     |
     |  model_computed_fields = {}
     |
     |  model_config = {'extra': 'allow'}
     |
     |  model_fields = {'description': FieldInfo(annotation=Union[str, NoneTyp...
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from BaseModelWithConfig:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from pydantic.main.BaseModel:
     |
     |  __copy__(self) -> 'Self'
     |      Returns a shallow copy of the model.
     |
     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'
     |      Returns a deep copy of the model.
     |
     |  __delattr__(self, item: 'str') -> 'Any'
     |      Implement delattr(self, name).
     |
     |  __eq__(self, other: 'Any') -> 'bool'
     |      Return self==value.
     |
     |  __getattr__(self, item: 'str') -> 'Any'
     |
     |  __getstate__(self) -> 'dict[Any, Any]'
     |      Helper for pickle.
     |
     |  __init__(self, /, **data: 'Any') -> 'None'
     |      Create a new model by parsing and validating input data from keyword arguments.
     |
     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be
     |      validated to form a valid model.
     |
     |      `self` is explicitly positional-only to allow `self` as a field name.
     |
     |  __iter__(self) -> 'TupleGenerator'
     |      So `dict(model)` works.
     |
     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation
     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.
     |
     |  __repr__(self) -> 'str'
     |      Return repr(self).
     |
     |  __repr_args__(self) -> '_repr.ReprArgs'
     |
     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation
     |      Name of the instance's class, used in __repr__.
     |
     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation
     |
     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation
     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.
     |
     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'
     |
     |  __str__(self) -> 'str'
     |      Return str(self).
     |
     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Returns a copy of the model.
     |
     |      !!! warning "Deprecated"
     |          This method is now deprecated; use `model_copy` instead.
     |
     |      If you need `include` or `exclude`, use:
     |
     |      ```py
     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)
     |      data = {**data, **(update or {})}
     |      copied = self.model_validate(data)
     |      ```
     |
     |      Args:
     |          include: Optional set or mapping specifying which fields to include in the copied model.
     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.
     |          update: Optional dictionary of field-value pairs to override field values in the copied model.
     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.
     |
     |      Returns:
     |          A copy of the model with included, excluded and updated fields as specified.
     |
     |  dict(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'
     |
     |  json(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'
     |
     |  model_copy(self, *, update: 'dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#model_copy
     |
     |      Returns a copy of the model.
     |
     |      Args:
     |          update: Values to change/add in the new model. Note: the data is not validated
     |              before creating the new model. You should trust this data.
     |          deep: Set to `True` to make a deep copy of the model.
     |
     |      Returns:
     |          New model instance.
     |
     |  model_dump(self, *, mode: "Literal['json', 'python'] | str" = 'python', include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump
     |
     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.
     |
     |      Args:
     |          mode: The mode in which `to_python` should run.
     |              If mode is 'json', the output will only contain JSON serializable types.
     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.
     |          include: A set of fields to include in the output.
     |          exclude: A set of fields to exclude from the output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to use the field's alias in the dictionary key if defined.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A dictionary representation of the model.
     |
     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'str'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump_json
     |
     |      Generates a JSON representation of the model using Pydantic's `to_json` method.
     |
     |      Args:
     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.
     |          include: Field(s) to include in the JSON output.
     |          exclude: Field(s) to exclude from the JSON output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to serialize using field aliases.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A JSON string representation of the model.
     |
     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'
     |      Override this method to perform additional initialization after `__init__` and `model_construct`.
     |      This is useful if you want to do some validation that requires the entire model to be initialized.
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from pydantic.main.BaseModel:
     |
     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'
     |
     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'
     |      Hook into generating the model's CoreSchema.
     |
     |      Args:
     |          source: The class we are generating a schema for.
     |              This will generally be the same as the `cls` argument if this is a classmethod.
     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.
     |
     |      Returns:
     |          A `pydantic-core` `CoreSchema`.
     |
     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'
     |      Hook into generating the model's JSON schema.
     |
     |      Args:
     |          core_schema: A `pydantic-core` CoreSchema.
     |              You can ignore this argument and call the handler with a new CoreSchema,
     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),
     |              or just call the handler with the original schema.
     |          handler: Call into Pydantic's internal JSON schema generation.
     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema
     |              generation fails.
     |              Since this gets called by `BaseModel.model_json_schema` you can override the
     |              `schema_generator` argument to that function to change JSON schema generation globally
     |              for a type.
     |
     |      Returns:
     |          A JSON schema, as a Python object.
     |
     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'
     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`
     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will
     |      be present when this is called.
     |
     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,
     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that
     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.
     |
     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,
     |      any kwargs passed to the class definition that aren't used internally by pydantic.
     |
     |      Args:
     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally
     |              by pydantic.
     |
     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |
     |  from_orm(obj: 'Any') -> 'Self'
     |
     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |      Creates a new instance of the `Model` class with validated data.
     |
     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.
     |      Default values are respected, but no other validation is performed.
     |
     |      !!! note
     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.
     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`
     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.
     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in
     |          an error if extra values are passed, but they will be ignored.
     |
     |      Args:
     |          _fields_set: The set of field names accepted for the Model instance.
     |          values: Trusted or pre-validated data dictionary.
     |
     |      Returns:
     |          A new instance of the `Model` class with validated data.
     |
     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'
     |      Generates a JSON schema for a model class.
     |
     |      Args:
     |          by_alias: Whether to use attribute aliases or not.
     |          ref_template: The reference template.
     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of
     |              `GenerateJsonSchema` with your desired modifications
     |          mode: The mode in which to generate the schema.
     |
     |      Returns:
     |          The JSON schema for the given model class.
     |
     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'
     |      Compute the class name for parametrizations of generic classes.
     |
     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.
     |
     |      Args:
     |          params: Tuple of types of the class. Given a generic class
     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,
     |              the value `(str, int)` would be passed to `params`.
     |
     |      Returns:
     |          String representing the new class where `params` are passed to `cls` as type variables.
     |
     |      Raises:
     |          TypeError: Raised when trying to generate concrete names for non-generic models.
     |
     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'dict[str, Any] | None' = None) -> 'bool | None'
     |      Try to rebuild the pydantic-core schema for the model.
     |
     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during
     |      the initial attempt to build the schema, and automatic rebuilding fails.
     |
     |      Args:
     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.
     |          raise_errors: Whether to raise errors, defaults to `True`.
     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.
     |          _types_namespace: The types namespace, defaults to `None`.
     |
     |      Returns:
     |          Returns `None` if the schema is already "complete" and rebuilding was not required.
     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.
     |
     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate a pydantic model instance.
     |
     |      Args:
     |          obj: The object to validate.
     |          strict: Whether to enforce types strictly.
     |          from_attributes: Whether to extract data from object attributes.
     |          context: Additional context to pass to the validator.
     |
     |      Raises:
     |          ValidationError: If the object could not be validated.
     |
     |      Returns:
     |          The validated model instance.
     |
     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/json/#json-parsing
     |
     |      Validate the given JSON data against the Pydantic model.
     |
     |      Args:
     |          json_data: The JSON data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |      Raises:
     |          ValueError: If `json_data` is not a JSON string.
     |
     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate the given object with string data against the Pydantic model.
     |
     |      Args:
     |          obj: The object containing string data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  parse_obj(obj: 'Any') -> 'Self'
     |
     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'
     |
     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'
     |
     |  update_forward_refs(**localns: 'Any') -> 'None'
     |
     |  validate(value: 'Any') -> 'Self'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from pydantic.main.BaseModel:
     |
     |  __fields_set__
     |
     |  model_extra
     |      Get extra fields set during validation.
     |
     |      Returns:
     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `"allow"`.
     |
     |  model_fields_set
     |      Returns the set of fields that have been explicitly set on this model instance.
     |
     |      Returns:
     |          A set of strings representing the fields that have been set,
     |              i.e. that were not filled from defaults.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from pydantic.main.BaseModel:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __pydantic_extra__
     |
     |  __pydantic_fields_set__
     |
     |  __pydantic_private__
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from pydantic.main.BaseModel:
     |
     |  __hash__ = None
     |
     |  __pydantic_root_model__ = False

    class XML(BaseModelWithConfig)
     |  XML(*, name: Optional[str] = None, namespace: Optional[str] = None, prefix: Optional[str] = None, attribute: Optional[bool] = None, wrapped: Optional[bool] = None, **extra_data: Any) -> None
     |
     |  Method resolution order:
     |      XML
     |      BaseModelWithConfig
     |      pydantic.main.BaseModel
     |      builtins.object
     |
     |  Data and other attributes defined here:
     |
     |  __abstractmethods__ = frozenset()
     |
     |  __annotations__ = {'attribute': typing.Optional[bool], 'name': typing....
     |
     |  __class_vars__ = set()
     |
     |  __private_attributes__ = {}
     |
     |  __pydantic_complete__ = True
     |
     |  __pydantic_core_schema__ = {'cls': <class 'backend.Lib.site-packages.f...
     |
     |  __pydantic_custom_init__ = False
     |
     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...
     |
     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...
     |
     |  __pydantic_parent_namespace__ = {'Annotated': <pydantic._internal._mod...
     |
     |  __pydantic_post_init__ = None
     |
     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(
     |      Model...
     |
     |  __pydantic_validator__ = SchemaValidator(title="XML", validator=Model(...
     |
     |  __signature__ = <Signature (*, name: Optional[str] = None, names...pti...
     |
     |  model_computed_fields = {}
     |
     |  model_config = {'extra': 'allow'}
     |
     |  model_fields = {'attribute': FieldInfo(annotation=Union[bool, NoneType...
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from BaseModelWithConfig:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from pydantic.main.BaseModel:
     |
     |  __copy__(self) -> 'Self'
     |      Returns a shallow copy of the model.
     |
     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'
     |      Returns a deep copy of the model.
     |
     |  __delattr__(self, item: 'str') -> 'Any'
     |      Implement delattr(self, name).
     |
     |  __eq__(self, other: 'Any') -> 'bool'
     |      Return self==value.
     |
     |  __getattr__(self, item: 'str') -> 'Any'
     |
     |  __getstate__(self) -> 'dict[Any, Any]'
     |      Helper for pickle.
     |
     |  __init__(self, /, **data: 'Any') -> 'None'
     |      Create a new model by parsing and validating input data from keyword arguments.
     |
     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be
     |      validated to form a valid model.
     |
     |      `self` is explicitly positional-only to allow `self` as a field name.
     |
     |  __iter__(self) -> 'TupleGenerator'
     |      So `dict(model)` works.
     |
     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation
     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.
     |
     |  __repr__(self) -> 'str'
     |      Return repr(self).
     |
     |  __repr_args__(self) -> '_repr.ReprArgs'
     |
     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation
     |      Name of the instance's class, used in __repr__.
     |
     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation
     |
     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation
     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.
     |
     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'
     |
     |  __str__(self) -> 'str'
     |      Return str(self).
     |
     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Returns a copy of the model.
     |
     |      !!! warning "Deprecated"
     |          This method is now deprecated; use `model_copy` instead.
     |
     |      If you need `include` or `exclude`, use:
     |
     |      ```py
     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)
     |      data = {**data, **(update or {})}
     |      copied = self.model_validate(data)
     |      ```
     |
     |      Args:
     |          include: Optional set or mapping specifying which fields to include in the copied model.
     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.
     |          update: Optional dictionary of field-value pairs to override field values in the copied model.
     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.
     |
     |      Returns:
     |          A copy of the model with included, excluded and updated fields as specified.
     |
     |  dict(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'
     |
     |  json(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'
     |
     |  model_copy(self, *, update: 'dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#model_copy
     |
     |      Returns a copy of the model.
     |
     |      Args:
     |          update: Values to change/add in the new model. Note: the data is not validated
     |              before creating the new model. You should trust this data.
     |          deep: Set to `True` to make a deep copy of the model.
     |
     |      Returns:
     |          New model instance.
     |
     |  model_dump(self, *, mode: "Literal['json', 'python'] | str" = 'python', include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump
     |
     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.
     |
     |      Args:
     |          mode: The mode in which `to_python` should run.
     |              If mode is 'json', the output will only contain JSON serializable types.
     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.
     |          include: A set of fields to include in the output.
     |          exclude: A set of fields to exclude from the output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to use the field's alias in the dictionary key if defined.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A dictionary representation of the model.
     |
     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'str'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump_json
     |
     |      Generates a JSON representation of the model using Pydantic's `to_json` method.
     |
     |      Args:
     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.
     |          include: Field(s) to include in the JSON output.
     |          exclude: Field(s) to exclude from the JSON output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to serialize using field aliases.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A JSON string representation of the model.
     |
     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'
     |      Override this method to perform additional initialization after `__init__` and `model_construct`.
     |      This is useful if you want to do some validation that requires the entire model to be initialized.
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from pydantic.main.BaseModel:
     |
     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'
     |
     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'
     |      Hook into generating the model's CoreSchema.
     |
     |      Args:
     |          source: The class we are generating a schema for.
     |              This will generally be the same as the `cls` argument if this is a classmethod.
     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.
     |
     |      Returns:
     |          A `pydantic-core` `CoreSchema`.
     |
     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'
     |      Hook into generating the model's JSON schema.
     |
     |      Args:
     |          core_schema: A `pydantic-core` CoreSchema.
     |              You can ignore this argument and call the handler with a new CoreSchema,
     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),
     |              or just call the handler with the original schema.
     |          handler: Call into Pydantic's internal JSON schema generation.
     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema
     |              generation fails.
     |              Since this gets called by `BaseModel.model_json_schema` you can override the
     |              `schema_generator` argument to that function to change JSON schema generation globally
     |              for a type.
     |
     |      Returns:
     |          A JSON schema, as a Python object.
     |
     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'
     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`
     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will
     |      be present when this is called.
     |
     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,
     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that
     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.
     |
     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,
     |      any kwargs passed to the class definition that aren't used internally by pydantic.
     |
     |      Args:
     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally
     |              by pydantic.
     |
     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |
     |  from_orm(obj: 'Any') -> 'Self'
     |
     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |      Creates a new instance of the `Model` class with validated data.
     |
     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.
     |      Default values are respected, but no other validation is performed.
     |
     |      !!! note
     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.
     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`
     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.
     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in
     |          an error if extra values are passed, but they will be ignored.
     |
     |      Args:
     |          _fields_set: The set of field names accepted for the Model instance.
     |          values: Trusted or pre-validated data dictionary.
     |
     |      Returns:
     |          A new instance of the `Model` class with validated data.
     |
     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'
     |      Generates a JSON schema for a model class.
     |
     |      Args:
     |          by_alias: Whether to use attribute aliases or not.
     |          ref_template: The reference template.
     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of
     |              `GenerateJsonSchema` with your desired modifications
     |          mode: The mode in which to generate the schema.
     |
     |      Returns:
     |          The JSON schema for the given model class.
     |
     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'
     |      Compute the class name for parametrizations of generic classes.
     |
     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.
     |
     |      Args:
     |          params: Tuple of types of the class. Given a generic class
     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,
     |              the value `(str, int)` would be passed to `params`.
     |
     |      Returns:
     |          String representing the new class where `params` are passed to `cls` as type variables.
     |
     |      Raises:
     |          TypeError: Raised when trying to generate concrete names for non-generic models.
     |
     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'dict[str, Any] | None' = None) -> 'bool | None'
     |      Try to rebuild the pydantic-core schema for the model.
     |
     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during
     |      the initial attempt to build the schema, and automatic rebuilding fails.
     |
     |      Args:
     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.
     |          raise_errors: Whether to raise errors, defaults to `True`.
     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.
     |          _types_namespace: The types namespace, defaults to `None`.
     |
     |      Returns:
     |          Returns `None` if the schema is already "complete" and rebuilding was not required.
     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.
     |
     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate a pydantic model instance.
     |
     |      Args:
     |          obj: The object to validate.
     |          strict: Whether to enforce types strictly.
     |          from_attributes: Whether to extract data from object attributes.
     |          context: Additional context to pass to the validator.
     |
     |      Raises:
     |          ValidationError: If the object could not be validated.
     |
     |      Returns:
     |          The validated model instance.
     |
     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/json/#json-parsing
     |
     |      Validate the given JSON data against the Pydantic model.
     |
     |      Args:
     |          json_data: The JSON data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |      Raises:
     |          ValueError: If `json_data` is not a JSON string.
     |
     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate the given object with string data against the Pydantic model.
     |
     |      Args:
     |          obj: The object containing string data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  parse_obj(obj: 'Any') -> 'Self'
     |
     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'
     |
     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'
     |
     |  update_forward_refs(**localns: 'Any') -> 'None'
     |
     |  validate(value: 'Any') -> 'Self'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from pydantic.main.BaseModel:
     |
     |  __fields_set__
     |
     |  model_extra
     |      Get extra fields set during validation.
     |
     |      Returns:
     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `"allow"`.
     |
     |  model_fields_set
     |      Returns the set of fields that have been explicitly set on this model instance.
     |
     |      Returns:
     |          A set of strings representing the fields that have been set,
     |              i.e. that were not filled from defaults.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from pydantic.main.BaseModel:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __pydantic_extra__
     |
     |  __pydantic_fields_set__
     |
     |  __pydantic_private__
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from pydantic.main.BaseModel:
     |
     |  __hash__ = None
     |
     |  __pydantic_root_model__ = False

DATA
    Callable = typing.Callable
        Deprecated alias to collections.abc.Callable.

        Callable[[int], str] signifies a function that takes a single
        parameter of type int and returns a str.

        The subscription syntax must always be used with exactly two
        values: the argument list and the return type.
        The argument list must be a list of types, a ParamSpec,
        Concatenate or ellipsis. The return type must be a single type.

        There is no syntax to indicate optional or keyword arguments;
        such function types are rarely used as callback types.

    CoreSchema = typing.Union[pydantic_core.core_schema.AnySchema...enceSc...
    Dict = typing.Dict
        A generic version of dict.

    Iterable = typing.Iterable
        A generic version of collections.abc.Iterable.

    JsonSchemaValue = typing.Dict[str, typing.Any]
    List = typing.List
        A generic version of list.

    Literal = typing.Literal
        Special typing form to define literal types (a.k.a. value types).

        This form can be used to indicate to type checkers that the corresponding
        variable or function parameter has a value equivalent to the provided
        literal (or one of several literals)::

            def validate_simple(data: Any) -> Literal[True]:  # always returns True
                ...

            MODE = Literal['r', 'rb', 'w', 'wb']
            def open_helper(file: str, mode: MODE) -> str:
                ...

            open_helper('/some/path', 'r')  # Passes type check
            open_helper('/other/path', 'typo')  # Error in type checker

        Literal[...] cannot be subclassed. At runtime, an arbitrary value
        is allowed as type argument to Literal[...], but type checkers may
        impose restrictions.

    Optional = typing.Optional
        Optional[X] is equivalent to Union[X, None].

    PYDANTIC_V2 = True
    SchemaOrBool = typing.Union[backend.Lib.site-packages.fastapi.openapi....
    SecurityScheme = typing.Union[backend.Lib.site-packages.fastapi.o....s...
    Set = typing.Set
        A generic version of set.

    Type = typing.Type
        Deprecated alias to builtins.type.

        builtins.type or typing.Type can be used to annotate class objects.
        For example, suppose we have the following classes::

            class User: ...  # Abstract base for User classes
            class BasicUser(User): ...
            class ProUser(User): ...
            class TeamUser(User): ...

        And a function that takes a class argument that's a subclass of
        User and returns an instance of the corresponding class::

            def new_user[U](user_class: Type[U]) -> U:
                user = user_class()
                # (Here we could write the user object to a database)
                return user

            joe = new_user(BasicUser)

        At this point the type checker knows that joe has type BasicUser.

    Union = typing.Union
        Union type; Union[X, Y] means either X or Y.

        On Python 3.10 and higher, the | operator
        can also be used to denote unions;
        X | Y means the same thing to the type checker as Union[X, Y].

        To define a union, use e.g. Union[int, str]. Details:
        - The arguments must be types and there must be at least one.
        - None as an argument is a special case and is replaced by
          type(None).
        - Unions of unions are flattened, e.g.::

            assert Union[Union[int, str], float] == Union[int, str, float]

        - Unions of a single argument vanish, e.g.::

            assert Union[int] == int  # The constructor actually returns int

        - Redundant arguments are skipped, e.g.::

            assert Union[int, str, int] == Union[int, str]

        - When comparing unions, the argument order is ignored, e.g.::

            assert Union[int, str] == Union[str, int]

        - You cannot subclass or instantiate a union.
        - You can use Optional[X] as a shorthand for Union[X, None].

    logger = <Logger fastapi (WARNING)>

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\backend\lib\site-packages\fastapi\openapi\models.py



================================================================================
Help on module backend.Lib.site-packages.fastapi.openapi.utils in backend.Lib.site-packages.fastapi.openapi:

NAME
    backend.Lib.site-packages.fastapi.openapi.utils

FUNCTIONS
    generate_operation_id(*, route: fastapi.routing.APIRoute, method: str) -> str

    generate_operation_summary(*, route: fastapi.routing.APIRoute, method: str) -> str

    get_fields_from_routes(routes: Sequence[starlette.routing.BaseRoute]) -> List[fastapi._compat.ModelField]

    get_openapi(*, title: str, version: str, openapi_version: str = '3.1.0', summary: Optional[str] = None, description: Optional[str] = None, routes: Sequence[starlette.routing.BaseRoute], webhooks: Optional[Sequence[starlette.routing.BaseRoute]] = None, tags: Optional[List[Dict[str, Any]]] = None, servers: Optional[List[Dict[str, Union[Any, str]]]] = None, terms_of_service: Optional[str] = None, contact: Optional[Dict[str, Union[Any, str]]] = None, license_info: Optional[Dict[str, Union[Any, str]]] = None, separate_input_output_schemas: bool = True) -> Dict[str, Any]

    get_openapi_operation_metadata(*, route: fastapi.routing.APIRoute, method: str, operation_ids: Set[str]) -> Dict[str, Any]

    get_openapi_operation_parameters(*, all_route_params: Sequence[fastapi._compat.ModelField], schema_generator: pydantic.json_schema.GenerateJsonSchema, model_name_map: Dict[Union[Type[pydantic.main.BaseModel], Type[enum.Enum]], str], field_mapping: Dict[Tuple[fastapi._compat.ModelField, Literal['validation', 'serialization']], Dict[str, Any]], separate_input_output_schemas: bool = True) -> List[Dict[str, Any]]

    get_openapi_operation_request_body(*, body_field: Optional[fastapi._compat.ModelField], schema_generator: pydantic.json_schema.GenerateJsonSchema, model_name_map: Dict[Union[Type[pydantic.main.BaseModel], Type[enum.Enum]], str], field_mapping: Dict[Tuple[fastapi._compat.ModelField, Literal['validation', 'serialization']], Dict[str, Any]], separate_input_output_schemas: bool = True) -> Optional[Dict[str, Any]]

    get_openapi_path(*, route: fastapi.routing.APIRoute, operation_ids: Set[str], schema_generator: pydantic.json_schema.GenerateJsonSchema, model_name_map: Dict[Union[Type[pydantic.main.BaseModel], Type[enum.Enum]], str], field_mapping: Dict[Tuple[fastapi._compat.ModelField, Literal['validation', 'serialization']], Dict[str, Any]], separate_input_output_schemas: bool = True) -> Tuple[Dict[str, Any], Dict[str, Any], Dict[str, Any]]

    get_openapi_security_definitions(flat_dependant: fastapi.dependencies.models.Dependant) -> Tuple[Dict[str, Any], List[Dict[str, Any]]]

DATA
    Dict = typing.Dict
        A generic version of dict.

    HTTP_422_UNPROCESSABLE_ENTITY = 422
    JsonSchemaValue = typing.Dict[str, typing.Any]
    List = typing.List
        A generic version of list.

    Literal = typing.Literal
        Special typing form to define literal types (a.k.a. value types).

        This form can be used to indicate to type checkers that the corresponding
        variable or function parameter has a value equivalent to the provided
        literal (or one of several literals)::

            def validate_simple(data: Any) -> Literal[True]:  # always returns True
                ...

            MODE = Literal['r', 'rb', 'w', 'wb']
            def open_helper(file: str, mode: MODE) -> str:
                ...

            open_helper('/some/path', 'r')  # Passes type check
            open_helper('/other/path', 'typo')  # Error in type checker

        Literal[...] cannot be subclassed. At runtime, an arbitrary value
        is allowed as type argument to Literal[...], but type checkers may
        impose restrictions.

    METHODS_WITH_BODY = {'DELETE', 'GET', 'HEAD', 'PATCH', 'POST', 'PUT'}
    ModelNameMap = typing.Dict[typing.Union[typing.Type[pydantic.main.Base...
    Optional = typing.Optional
        Optional[X] is equivalent to Union[X, None].

    REF_PREFIX = '#/components/schemas/'
    REF_TEMPLATE = '#/components/schemas/{model}'
    Sequence = typing.Sequence
        A generic version of collections.abc.Sequence.

    Set = typing.Set
        A generic version of set.

    Tuple = typing.Tuple
        Deprecated alias to builtins.tuple.

        Tuple[X, Y] is the cross-product type of X and Y.

        Example: Tuple[T1, T2] is a tuple of two elements corresponding
        to type variables T1 and T2.  Tuple[int, float, str] is a tuple
        of an int, a float and a string.

        To specify a variable-length tuple of homogeneous type, use Tuple[T, ...].

    Type = typing.Type
        Deprecated alias to builtins.type.

        builtins.type or typing.Type can be used to annotate class objects.
        For example, suppose we have the following classes::

            class User: ...  # Abstract base for User classes
            class BasicUser(User): ...
            class ProUser(User): ...
            class TeamUser(User): ...

        And a function that takes a class argument that's a subclass of
        User and returns an instance of the corresponding class::

            def new_user[U](user_class: Type[U]) -> U:
                user = user_class()
                # (Here we could write the user object to a database)
                return user

            joe = new_user(BasicUser)

        At this point the type checker knows that joe has type BasicUser.

    Undefined = PydanticUndefined
    Union = typing.Union
        Union type; Union[X, Y] means either X or Y.

        On Python 3.10 and higher, the | operator
        can also be used to denote unions;
        X | Y means the same thing to the type checker as Union[X, Y].

        To define a union, use e.g. Union[int, str]. Details:
        - The arguments must be types and there must be at least one.
        - None as an argument is a special case and is replaced by
          type(None).
        - Unions of unions are flattened, e.g.::

            assert Union[Union[int, str], float] == Union[int, str, float]

        - Unions of a single argument vanish, e.g.::

            assert Union[int] == int  # The constructor actually returns int

        - Redundant arguments are skipped, e.g.::

            assert Union[int, str, int] == Union[int, str]

        - When comparing unions, the argument order is ignored, e.g.::

            assert Union[int, str] == Union[str, int]

        - You cannot subclass or instantiate a union.
        - You can use Optional[X] as a shorthand for Union[X, None].

    __annotations__ = {'status_code_ranges': typing.Dict[str, str]}
    status_code_ranges = {'1XX': 'Information', '2XX': 'Success', '3XX': '...
    validation_error_definition = {'properties': {'loc': {'items': {'anyOf...
    validation_error_response_definition = {'properties': {'detail': {'ite...

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\backend\lib\site-packages\fastapi\openapi\utils.py



================================================================================
Help on module backend.Lib.site-packages.fastapi.security.utils in backend.Lib.site-packages.fastapi.security:

NAME
    backend.Lib.site-packages.fastapi.security.utils

FUNCTIONS
    get_authorization_scheme_param(authorization_header_value: Optional[str]) -> Tuple[str, str]

DATA
    Optional = typing.Optional
        Optional[X] is equivalent to Union[X, None].

    Tuple = typing.Tuple
        Deprecated alias to builtins.tuple.

        Tuple[X, Y] is the cross-product type of X and Y.

        Example: Tuple[T1, T2] is a tuple of two elements corresponding
        to type variables T1 and T2.  Tuple[int, float, str] is a tuple
        of an int, a float and a string.

        To specify a variable-length tuple of homogeneous type, use Tuple[T, ...].

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\backend\lib\site-packages\fastapi\security\utils.py



================================================================================
Help on module backend.Lib.site-packages.firebase_admin.auth in backend.Lib.site-packages.firebase_admin:

NAME
    backend.Lib.site-packages.firebase_admin.auth - Firebase Authentication module.

DESCRIPTION
    This module contains functions for minting and verifying JWTs used for
    authenticating against Firebase services. It also provides functions for
    creating and managing user accounts in Firebase projects.

CLASSES
    builtins.object
        firebase_admin._auth_client.Client
        firebase_admin._auth_providers.ListProviderConfigsPage
        firebase_admin._auth_providers.ProviderConfig
            firebase_admin._auth_providers.OIDCProviderConfig
            firebase_admin._auth_providers.SAMLProviderConfig
        firebase_admin._user_identifier.UserIdentifier
            firebase_admin._user_identifier.EmailIdentifier
            firebase_admin._user_identifier.PhoneIdentifier
            firebase_admin._user_identifier.ProviderIdentifier
            firebase_admin._user_identifier.UidIdentifier
        firebase_admin._user_import.ErrorInfo
        firebase_admin._user_import.ImportUserRecord
        firebase_admin._user_import.UserImportHash
        firebase_admin._user_import.UserImportResult
        firebase_admin._user_import.UserProvider
        firebase_admin._user_mgt.ActionCodeSettings
        firebase_admin._user_mgt.DeleteUsersResult
        firebase_admin._user_mgt.GetUsersResult
        firebase_admin._user_mgt.ListUsersPage
        firebase_admin._user_mgt.UserInfo
            firebase_admin._user_mgt.UserRecord
                firebase_admin._user_mgt.ExportedUserRecord
        firebase_admin._user_mgt.UserMetadata
    firebase_admin.exceptions.AlreadyExistsError(firebase_admin.exceptions.FirebaseError)
        firebase_admin._auth_utils.EmailAlreadyExistsError
        firebase_admin._auth_utils.PhoneNumberAlreadyExistsError
        firebase_admin._auth_utils.UidAlreadyExistsError
    firebase_admin.exceptions.InvalidArgumentError(firebase_admin.exceptions.FirebaseError)
        firebase_admin._auth_utils.InvalidDynamicLinkDomainError
        firebase_admin._auth_utils.InvalidIdTokenError
            firebase_admin._token_gen.ExpiredIdTokenError
            firebase_admin._token_gen.RevokedIdTokenError
        firebase_admin._auth_utils.UserDisabledError
        firebase_admin._token_gen.InvalidSessionCookieError
            firebase_admin._token_gen.ExpiredSessionCookieError
            firebase_admin._token_gen.RevokedSessionCookieError
    firebase_admin.exceptions.NotFoundError(firebase_admin.exceptions.FirebaseError)
        firebase_admin._auth_utils.ConfigurationNotFoundError
        firebase_admin._auth_utils.EmailNotFoundError
        firebase_admin._auth_utils.UserNotFoundError
    firebase_admin.exceptions.PermissionDeniedError(firebase_admin.exceptions.FirebaseError)
        firebase_admin._auth_utils.InsufficientPermissionError
    firebase_admin.exceptions.ResourceExhaustedError(firebase_admin.exceptions.FirebaseError)
        firebase_admin._auth_utils.ResetPasswordExceedLimitError
        firebase_admin._auth_utils.TooManyAttemptsTryLaterError
    firebase_admin.exceptions.UnknownError(firebase_admin.exceptions.FirebaseError)
        firebase_admin._auth_utils.UnexpectedResponseError
        firebase_admin._token_gen.CertificateFetchError
        firebase_admin._token_gen.TokenSignError

    class ActionCodeSettings(builtins.object)
     |  ActionCodeSettings(url, handle_code_in_app=None, dynamic_link_domain=None, ios_bundle_id=None, android_package_name=None, android_install_app=None, android_minimum_version=None)
     |
     |  Contains required continue/state URL with optional Android and iOS settings.
     |  Used when invoking the email action link generation APIs.
     |
     |  Methods defined here:
     |
     |  __init__(self, url, handle_code_in_app=None, dynamic_link_domain=None, ios_bundle_id=None, android_package_name=None, android_install_app=None, android_minimum_version=None)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

    class CertificateFetchError(firebase_admin.exceptions.UnknownError)
     |  CertificateFetchError(message, cause)
     |
     |  Failed to fetch some public key certificates required to verify a token.
     |
     |  Method resolution order:
     |      CertificateFetchError
     |      firebase_admin.exceptions.UnknownError
     |      firebase_admin.exceptions.FirebaseError
     |      builtins.Exception
     |      builtins.BaseException
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, message, cause)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  cause
     |
     |  code
     |
     |  http_response
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Static methods inherited from builtins.Exception:
     |
     |  __new__(*args, **kwargs) class method of builtins.Exception
     |      Create and return a new object.  See help(type) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.BaseException:
     |
     |  __delattr__(self, name, /)
     |      Implement delattr(self, name).
     |
     |  __getattribute__(self, name, /)
     |      Return getattr(self, name).
     |
     |  __reduce__(...)
     |      Helper for pickle.
     |
     |  __repr__(self, /)
     |      Return repr(self).
     |
     |  __setattr__(self, name, value, /)
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(...)
     |
     |  __str__(self, /)
     |      Return str(self).
     |
     |  add_note(...)
     |      Exception.add_note(note) --
     |      add a note to the exception
     |
     |  with_traceback(...)
     |      Exception.with_traceback(tb) --
     |      set self.__traceback__ to tb and return self.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from builtins.BaseException:
     |
     |  __cause__
     |      exception cause
     |
     |  __context__
     |      exception context
     |
     |  __dict__
     |
     |  __suppress_context__
     |
     |  __traceback__
     |
     |  args

    class Client(builtins.object)
     |  Client(app, tenant_id=None)
     |
     |  Firebase Authentication client scoped to a specific tenant.
     |
     |  Methods defined here:
     |
     |  __init__(self, app, tenant_id=None)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  create_custom_token(self, uid, developer_claims=None)
     |      Builds and signs a Firebase custom auth token.
     |
     |      Args:
     |          uid: ID of the user for whom the token is created.
     |          developer_claims: A dictionary of claims to be included in the token
     |              (optional).
     |
     |      Returns:
     |          bytes: A token minted from the input parameters.
     |
     |      Raises:
     |          ValueError: If input parameters are invalid.
     |          TokenSignError: If an error occurs while signing the token using the remote IAM service.
     |
     |  create_oidc_provider_config(self, provider_id, client_id, issuer, display_name=None, enabled=None, client_secret=None, id_token_response_type=None, code_response_type=None)
     |      Creates a new OIDC provider config from the given parameters.
     |
     |      OIDC provider support requires Google Cloud's Identity Platform (GCIP). To learn more about
     |      GCIP, including pricing and features, see https://cloud.google.com/identity-platform.
     |
     |      Args:
     |          provider_id: Provider ID string. Must have the prefix ``oidc.``.
     |          client_id: Client ID of the new config.
     |          issuer: Issuer of the new config. Must be a valid URL.
     |          display_name: The user-friendly display name to the current configuration (optional).
     |              This name is also used as the provider label in the Cloud Console.
     |          enabled: A boolean indicating whether the provider configuration is enabled or disabled
     |              (optional). A user cannot sign in using a disabled provider.
     |          client_secret: A string which sets the client secret for the new provider.
     |              This is required for the code flow.
     |          code_response_type: A boolean which sets whether to enable the code response flow for
     |              the new provider.  By default, this is not enabled if no response type is
     |              specified. A client secret must be set for this response type.
     |              Having both the code and ID token response flows is currently not supported.
     |          id_token_response_type: A boolean which sets whether to enable the ID token response
     |              flow for the new provider. By default, this is enabled if no response type is
     |              specified.
     |              Having both the code and ID token response flows is currently not supported.
     |
     |      Returns:
     |          OIDCProviderConfig: The newly created OIDC provider config instance.
     |
     |      Raises:
     |          ValueError: If any of the specified input parameters are invalid.
     |          FirebaseError: If an error occurs while creating the new OIDC provider config.
     |
     |  create_saml_provider_config(self, provider_id, idp_entity_id, sso_url, x509_certificates, rp_entity_id, callback_url, display_name=None, enabled=None)
     |      Creates a new SAML provider config from the given parameters.
     |
     |      SAML provider support requires Google Cloud's Identity Platform (GCIP). To learn more about
     |      GCIP, including pricing and features, see https://cloud.google.com/identity-platform.
     |
     |      Args:
     |          provider_id: Provider ID string. Must have the prefix ``saml.``.
     |          idp_entity_id: The SAML IdP entity identifier.
     |          sso_url: The SAML IdP SSO URL. Must be a valid URL.
     |          x509_certificates: The list of SAML IdP X.509 certificates issued by CA for this
     |              provider. Multiple certificates are accepted to prevent outages during IdP key
     |              rotation (for example ADFS rotates every 10 days). When the Auth server receives a
     |              SAML response, it will match the SAML response with the certificate on record.
     |              Otherwise the response is rejected. Developers are expected to manage the
     |              certificate updates as keys are rotated.
     |          rp_entity_id: The SAML relying party (service provider) entity ID. This is defined by
     |              the developer but needs to be provided to the SAML IdP.
     |          callback_url: Callback URL string. This is fixed and must always be the same as the
     |              OAuth redirect URL provisioned by Firebase Auth, unless a custom authDomain is
     |              used.
     |          display_name: The user-friendly display name to the current configuration (optional).
     |              This name is also used as the provider label in the Cloud Console.
     |          enabled: A boolean indicating whether the provider configuration is enabled or disabled
     |              (optional). A user cannot sign in using a disabled provider.
     |
     |      Returns:
     |          SAMLProviderConfig: The newly created SAML provider config instance.
     |
     |      Raises:
     |          ValueError: If any of the specified input parameters are invalid.
     |          FirebaseError: If an error occurs while creating the new SAML provider config.
     |
     |  create_user(self, **kwargs)
     |      Creates a new user account with the specified properties.
     |
     |      Args:
     |          **kwargs: A series of keyword arguments (optional).
     |
     |      Keyword Args:
     |          uid: User ID to assign to the newly created user (optional).
     |          display_name: The user's display name (optional).
     |          email: The user's primary email (optional).
     |          email_verified: A boolean indicating whether or not the user's primary email is
     |              verified (optional).
     |          phone_number: The user's primary phone number (optional).
     |          photo_url: The user's photo URL (optional).
     |          password: The user's raw, unhashed password. (optional).
     |          disabled: A boolean indicating whether or not the user account is disabled (optional).
     |
     |      Returns:
     |          UserRecord: A UserRecord instance for the newly created user.
     |
     |      Raises:
     |          ValueError: If the specified user properties are invalid.
     |          FirebaseError: If an error occurs while creating the user account.
     |
     |  delete_oidc_provider_config(self, provider_id)
     |      Deletes the ``OIDCProviderConfig`` with the given ID.
     |
     |      Args:
     |          provider_id: Provider ID string.
     |
     |      Raises:
     |          ValueError: If the provider ID is invalid, empty or does not have ``oidc.`` prefix.
     |          ConfigurationNotFoundError: If no OIDC provider is available with the given identifier.
     |          FirebaseError: If an error occurs while deleting the OIDC provider.
     |
     |  delete_saml_provider_config(self, provider_id)
     |      Deletes the ``SAMLProviderConfig`` with the given ID.
     |
     |      Args:
     |          provider_id: Provider ID string.
     |
     |      Raises:
     |          ValueError: If the provider ID is invalid, empty or does not have ``saml.`` prefix.
     |          ConfigurationNotFoundError: If no SAML provider is available with the given identifier.
     |          FirebaseError: If an error occurs while deleting the SAML provider.
     |
     |  delete_user(self, uid)
     |      Deletes the user identified by the specified user ID.
     |
     |      Args:
     |          uid: A user ID string.
     |
     |      Raises:
     |          ValueError: If the user ID is None, empty or malformed.
     |          FirebaseError: If an error occurs while deleting the user account.
     |
     |  delete_users(self, uids)
     |      Deletes the users specified by the given identifiers.
     |
     |      Deleting a non-existing user does not generate an error (the method is
     |      idempotent.) Non-existing users are considered to be successfully
     |      deleted and are therefore included in the
     |      `DeleteUserResult.success_count` value.
     |
     |      A maximum of 1000 identifiers may be supplied. If more than 1000
     |      identifiers are supplied, this method raises a `ValueError`.
     |
     |      Args:
     |          uids: A list of strings indicating the uids of the users to be deleted.
     |              Must have <= 1000 entries.
     |
     |      Returns:
     |          DeleteUsersResult: The total number of successful/failed deletions, as
     |          well as the array of errors that correspond to the failed
     |          deletions.
     |
     |      Raises:
     |          ValueError: If any of the identifiers are invalid or if more than 1000
     |              identifiers are specified.
     |
     |  generate_email_verification_link(self, email, action_code_settings=None)
     |      Generates the out-of-band email action link for email verification flows for the
     |      specified email address.
     |
     |      Args:
     |          email: The email of the user to be verified.
     |          action_code_settings: ``ActionCodeSettings`` instance (optional). Defines whether
     |              the link is to be handled by a mobile app and the additional state information to
     |              be passed in the deep link.
     |
     |      Returns:
     |          link: The email verification link created by the API
     |
     |      Raises:
     |          ValueError: If the provided arguments are invalid
     |          UserNotFoundError: If no user exists for the specified email address.
     |          FirebaseError: If an error occurs while generating the link
     |
     |  generate_password_reset_link(self, email, action_code_settings=None)
     |      Generates the out-of-band email action link for password reset flows for the specified
     |      email address.
     |
     |      Args:
     |          email: The email of the user whose password is to be reset.
     |          action_code_settings: ``ActionCodeSettings`` instance (optional). Defines whether
     |              the link is to be handled by a mobile app and the additional state information to
     |              be passed in the deep link.
     |
     |      Returns:
     |          link: The password reset link created by the API
     |
     |      Raises:
     |          ValueError: If the provided arguments are invalid
     |          EmailNotFoundError: If no user exists for the specified email address.
     |          FirebaseError: If an error occurs while generating the link
     |
     |  generate_sign_in_with_email_link(self, email, action_code_settings)
     |      Generates the out-of-band email action link for email link sign-in flows, using the
     |      action code settings provided.
     |
     |      Args:
     |          email: The email of the user signing in.
     |          action_code_settings: ``ActionCodeSettings`` instance. Defines whether
     |              the link is to be handled by a mobile app and the additional state information to be
     |              passed in the deep link.
     |
     |      Returns:
     |          link: The email sign-in link created by the API
     |
     |      Raises:
     |          ValueError: If the provided arguments are invalid
     |          FirebaseError: If an error occurs while generating the link
     |
     |  get_oidc_provider_config(self, provider_id)
     |      Returns the ``OIDCProviderConfig`` with the given ID.
     |
     |      Args:
     |          provider_id: Provider ID string.
     |
     |      Returns:
     |          SAMLProviderConfig: An OIDC provider config instance.
     |
     |      Raises:
     |          ValueError: If the provider ID is invalid, empty or does not have ``oidc.`` prefix.
     |          ConfigurationNotFoundError: If no OIDC provider is available with the given identifier.
     |          FirebaseError: If an error occurs while retrieving the OIDC provider.
     |
     |  get_saml_provider_config(self, provider_id)
     |      Returns the ``SAMLProviderConfig`` with the given ID.
     |
     |      Args:
     |          provider_id: Provider ID string.
     |
     |      Returns:
     |          SAMLProviderConfig: A SAML provider config instance.
     |
     |      Raises:
     |          ValueError: If the provider ID is invalid, empty or does not have ``saml.`` prefix.
     |          ConfigurationNotFoundError: If no SAML provider is available with the given identifier.
     |          FirebaseError: If an error occurs while retrieving the SAML provider.
     |
     |  get_user(self, uid)
     |      Gets the user data corresponding to the specified user ID.
     |
     |      Args:
     |          uid: A user ID string.
     |
     |      Returns:
     |          UserRecord: A user record instance.
     |
     |      Raises:
     |          ValueError: If the user ID is None, empty or malformed.
     |          UserNotFoundError: If the specified user ID does not exist.
     |          FirebaseError: If an error occurs while retrieving the user.
     |
     |  get_user_by_email(self, email)
     |      Gets the user data corresponding to the specified user email.
     |
     |      Args:
     |          email: A user email address string.
     |
     |      Returns:
     |          UserRecord: A user record instance.
     |
     |      Raises:
     |          ValueError: If the email is None, empty or malformed.
     |          UserNotFoundError: If no user exists for the specified email address.
     |          FirebaseError: If an error occurs while retrieving the user.
     |
     |  get_user_by_phone_number(self, phone_number)
     |      Gets the user data corresponding to the specified phone number.
     |
     |      Args:
     |          phone_number: A phone number string.
     |
     |      Returns:
     |          UserRecord: A user record instance.
     |
     |      Raises:
     |          ValueError: If the phone number is ``None``, empty or malformed.
     |          UserNotFoundError: If no user exists for the specified phone number.
     |          FirebaseError: If an error occurs while retrieving the user.
     |
     |  get_users(self, identifiers)
     |      Gets the user data corresponding to the specified identifiers.
     |
     |      There are no ordering guarantees; in particular, the nth entry in the
     |      result list is not guaranteed to correspond to the nth entry in the input
     |      parameters list.
     |
     |      A maximum of 100 identifiers may be supplied. If more than 100
     |      identifiers are supplied, this method raises a `ValueError`.
     |
     |      Args:
     |          identifiers (list[Identifier]): A list of ``Identifier`` instances used
     |              to indicate which user records should be returned. Must have <= 100
     |              entries.
     |
     |      Returns:
     |          GetUsersResult: A ``GetUsersResult`` instance corresponding to the
     |          specified identifiers.
     |
     |      Raises:
     |          ValueError: If any of the identifiers are invalid or if more than 100
     |              identifiers are specified.
     |
     |  import_users(self, users, hash_alg=None)
     |      Imports the specified list of users into Firebase Auth.
     |
     |      At most 1000 users can be imported at a time. This operation is optimized for bulk imports
     |      and ignores checks on identifier uniqueness, which could result in duplications. The
     |      ``hash_alg`` parameter must be specified when importing users with passwords. Refer to the
     |      ``UserImportHash`` class for supported hash algorithms.
     |
     |      Args:
     |          users: A list of ``ImportUserRecord`` instances to import. Length of the list must not
     |              exceed 1000.
     |          hash_alg: A ``UserImportHash`` object (optional). Required when importing users with
     |              passwords.
     |
     |      Returns:
     |          UserImportResult: An object summarizing the result of the import operation.
     |
     |      Raises:
     |          ValueError: If the provided arguments are invalid.
     |          FirebaseError: If an error occurs while importing users.
     |
     |  list_oidc_provider_configs(self, page_token=None, max_results=100)
     |      Retrieves a page of OIDC provider configs from a Firebase project.
     |
     |      The ``page_token`` argument governs the starting point of the page. The ``max_results``
     |      argument governs the maximum number of configs that may be included in the returned
     |      page. This function never returns ``None``. If there are no OIDC configs in the Firebase
     |      project, this returns an empty page.
     |
     |      Args:
     |          page_token: A non-empty page token string, which indicates the starting point of the
     |              page (optional). Defaults to ``None``, which will retrieve the first page of users.
     |          max_results: A positive integer indicating the maximum number of users to include in
     |              the returned page (optional). Defaults to 100, which is also the maximum number
     |              allowed.
     |
     |      Returns:
     |          ListProviderConfigsPage: A page of OIDC provider config instances.
     |
     |      Raises:
     |          ValueError: If ``max_results`` or ``page_token`` are invalid.
     |          FirebaseError: If an error occurs while retrieving the OIDC provider configs.
     |
     |  list_saml_provider_configs(self, page_token=None, max_results=100)
     |      Retrieves a page of SAML provider configs from a Firebase project.
     |
     |      The ``page_token`` argument governs the starting point of the page. The ``max_results``
     |      argument governs the maximum number of configs that may be included in the returned
     |      page. This function never returns ``None``. If there are no SAML configs in the Firebase
     |      project, this returns an empty page.
     |
     |      Args:
     |          page_token: A non-empty page token string, which indicates the starting point of the
     |              page (optional). Defaults to ``None``, which will retrieve the first page of users.
     |          max_results: A positive integer indicating the maximum number of users to include in
     |              the returned page (optional). Defaults to 100, which is also the maximum number
     |              allowed.
     |
     |      Returns:
     |          ListProviderConfigsPage: A page of SAML provider config instances.
     |
     |      Raises:
     |          ValueError: If ``max_results`` or ``page_token`` are invalid.
     |          FirebaseError: If an error occurs while retrieving the SAML provider configs.
     |
     |  list_users(self, page_token=None, max_results=1000)
     |      Retrieves a page of user accounts from a Firebase project.
     |
     |      The ``page_token`` argument governs the starting point of the page. The ``max_results``
     |      argument governs the maximum number of user accounts that may be included in the returned
     |      page. This function never returns ``None``. If there are no user accounts in the Firebase
     |      project, this returns an empty page.
     |
     |      Args:
     |          page_token: A non-empty page token string, which indicates the starting point of the
     |              page (optional). Defaults to ``None``, which will retrieve the first page of users.
     |          max_results: A positive integer indicating the maximum number of users to include in
     |              the returned page (optional). Defaults to 1000, which is also the maximum number
     |              allowed.
     |
     |      Returns:
     |          ListUsersPage: A page of user accounts.
     |
     |      Raises:
     |          ValueError: If max_results or page_token are invalid.
     |          FirebaseError: If an error occurs while retrieving the user accounts.
     |
     |  revoke_refresh_tokens(self, uid)
     |      Revokes all refresh tokens for an existing user.
     |
     |      This method updates the user's ``tokens_valid_after_timestamp`` to the current UTC
     |      in seconds since the epoch. It is important that the server on which this is called has its
     |      clock set correctly and synchronized.
     |
     |      While this revokes all sessions for a specified user and disables any new ID tokens for
     |      existing sessions from getting minted, existing ID tokens may remain active until their
     |      natural expiration (one hour). To verify that ID tokens are revoked, use
     |      ``verify_id_token(idToken, check_revoked=True)``.
     |
     |      Args:
     |          uid: A user ID string.
     |
     |      Raises:
     |          ValueError: If the user ID is None, empty or malformed.
     |          FirebaseError: If an error occurs while revoking the refresh token.
     |
     |  set_custom_user_claims(self, uid, custom_claims)
     |      Sets additional claims on an existing user account.
     |
     |      Custom claims set via this function can be used to define user roles and privilege levels.
     |      These claims propagate to all the devices where the user is already signed in (after token
     |      expiration or when token refresh is forced), and next time the user signs in. The claims
     |      can be accessed via the user's ID token JWT. If a reserved OIDC claim is specified (sub,
     |      iat, iss, etc), an error is thrown. Claims payload must also not be larger then 1000
     |      characters when serialized into a JSON string.
     |
     |      Args:
     |          uid: A user ID string.
     |          custom_claims: A dictionary or a JSON string of custom claims. Pass None to unset any
     |              claims set previously.
     |
     |      Raises:
     |          ValueError: If the specified user ID or the custom claims are invalid.
     |          FirebaseError: If an error occurs while updating the user account.
     |
     |  update_oidc_provider_config(self, provider_id, client_id=None, issuer=None, display_name=None, enabled=None, client_secret=None, id_token_response_type=None, code_response_type=None)
     |      Updates an existing OIDC provider config with the given parameters.
     |
     |      Args:
     |          provider_id: Provider ID string. Must have the prefix ``oidc.``.
     |          client_id: Client ID of the new config (optional).
     |          issuer: Issuer of the new config (optional). Must be a valid URL.
     |          display_name: The user-friendly display name to the current configuration (optional).
     |              Pass ``auth.DELETE_ATTRIBUTE`` to delete the current display name.
     |          enabled: A boolean indicating whether the provider configuration is enabled or disabled
     |              (optional).
     |          client_secret: A string which sets the client secret for the new provider.
     |              This is required for the code flow.
     |          code_response_type: A boolean which sets whether to enable the code response flow for
     |              the new provider. By default, this is not enabled if no response type is specified.
     |              A client secret must be set for this response type.
     |              Having both the code and ID token response flows is currently not supported.
     |          id_token_response_type: A boolean which sets whether to enable the ID token response
     |              flow for the new provider. By default, this is enabled if no response type is
     |              specified.
     |              Having both the code and ID token response flows is currently not supported.
     |
     |      Returns:
     |          OIDCProviderConfig: The updated OIDC provider config instance.
     |
     |      Raises:
     |          ValueError: If any of the specified input parameters are invalid.
     |          FirebaseError: If an error occurs while updating the OIDC provider config.
     |
     |  update_saml_provider_config(self, provider_id, idp_entity_id=None, sso_url=None, x509_certificates=None, rp_entity_id=None, callback_url=None, display_name=None, enabled=None)
     |      Updates an existing SAML provider config with the given parameters.
     |
     |      Args:
     |          provider_id: Provider ID string. Must have the prefix ``saml.``.
     |          idp_entity_id: The SAML IdP entity identifier (optional).
     |          sso_url: The SAML IdP SSO URL. Must be a valid URL (optional).
     |          x509_certificates: The list of SAML IdP X.509 certificates issued by CA for this
     |              provider  (optional).
     |          rp_entity_id: The SAML relying party entity ID (optional).
     |          callback_url: Callback URL string  (optional).
     |          display_name: The user-friendly display name of the current configuration (optional).
     |              Pass ``auth.DELETE_ATTRIBUTE`` to delete the current display name.
     |          enabled: A boolean indicating whether the provider configuration is enabled or disabled
     |              (optional).
     |
     |      Returns:
     |          SAMLProviderConfig: The updated SAML provider config instance.
     |
     |      Raises:
     |          ValueError: If any of the specified input parameters are invalid.
     |          FirebaseError: If an error occurs while updating the SAML provider config.
     |
     |  update_user(self, uid, **kwargs)
     |      Updates an existing user account with the specified properties.
     |
     |      Args:
     |          uid: A user ID string.
     |          **kwargs: A series of keyword arguments (optional).
     |
     |      Keyword Args:
     |          display_name: The user's display name (optional). Can be removed by explicitly passing
     |              ``auth.DELETE_ATTRIBUTE``.
     |          email: The user's primary email (optional).
     |          email_verified: A boolean indicating whether or not the user's primary email is
     |              verified (optional).
     |          phone_number: The user's primary phone number (optional). Can be removed by explicitly
     |              passing ``auth.DELETE_ATTRIBUTE``.
     |          photo_url: The user's photo URL (optional). Can be removed by explicitly passing
     |              ``auth.DELETE_ATTRIBUTE``.
     |          password: The user's raw, unhashed password. (optional).
     |          disabled: A boolean indicating whether or not the user account is disabled (optional).
     |          custom_claims: A dictionary or a JSON string contining the custom claims to be set on
     |              the user account (optional). To remove all custom claims, pass
     |              ``auth.DELETE_ATTRIBUTE``.
     |          valid_since: An integer signifying the seconds since the epoch (optional). This field
     |              is set by ``revoke_refresh_tokens`` and it is discouraged to set this field
     |              directly.
     |          providers_to_delete: The list of provider IDs to unlink,
     |              eg: 'google.com', 'password', etc.
     |
     |      Returns:
     |          UserRecord: An updated UserRecord instance for the user.
     |
     |      Raises:
     |          ValueError: If the specified user ID or properties are invalid.
     |          FirebaseError: If an error occurs while updating the user account.
     |
     |  verify_id_token(self, id_token, check_revoked=False, clock_skew_seconds=0)
     |      Verifies the signature and data for the provided JWT.
     |
     |      Accepts a signed token string, verifies that it is current, was issued
     |      to this project, and that it was correctly signed by Google.
     |
     |      Args:
     |          id_token: A string of the encoded JWT.
     |          check_revoked: Boolean, If true, checks whether the token has been revoked or
     |              the user disabled (optional).
     |          clock_skew_seconds: The number of seconds to tolerate when checking the token.
     |              Must be between 0-60. Defaults to 0.
     |
     |      Returns:
     |          dict: A dictionary of key-value pairs parsed from the decoded JWT.
     |
     |      Raises:
     |          ValueError: If ``id_token`` is a not a string or is empty.
     |          InvalidIdTokenError: If ``id_token`` is not a valid Firebase ID token.
     |          ExpiredIdTokenError: If the specified ID token has expired.
     |          RevokedIdTokenError: If ``check_revoked`` is ``True`` and the ID token has been
     |              revoked.
     |          TenantIdMismatchError: If ``id_token`` belongs to a tenant that is different than
     |              this ``Client`` instance.
     |          CertificateFetchError: If an error occurs while fetching the public key certificates
     |              required to verify the ID token.
     |          UserDisabledError: If ``check_revoked`` is ``True`` and the corresponding user
     |              record is disabled.
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties defined here:
     |
     |  tenant_id
     |      Tenant ID associated with this client.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

    class ConfigurationNotFoundError(firebase_admin.exceptions.NotFoundError)
     |  ConfigurationNotFoundError(message, cause=None, http_response=None)
     |
     |  No auth provider found for the specified identifier.
     |
     |  Method resolution order:
     |      ConfigurationNotFoundError
     |      firebase_admin.exceptions.NotFoundError
     |      firebase_admin.exceptions.FirebaseError
     |      builtins.Exception
     |      builtins.BaseException
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, message, cause=None, http_response=None)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  default_message = 'No auth provider found for the given identifier'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  cause
     |
     |  code
     |
     |  http_response
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Static methods inherited from builtins.Exception:
     |
     |  __new__(*args, **kwargs) class method of builtins.Exception
     |      Create and return a new object.  See help(type) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.BaseException:
     |
     |  __delattr__(self, name, /)
     |      Implement delattr(self, name).
     |
     |  __getattribute__(self, name, /)
     |      Return getattr(self, name).
     |
     |  __reduce__(...)
     |      Helper for pickle.
     |
     |  __repr__(self, /)
     |      Return repr(self).
     |
     |  __setattr__(self, name, value, /)
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(...)
     |
     |  __str__(self, /)
     |      Return str(self).
     |
     |  add_note(...)
     |      Exception.add_note(note) --
     |      add a note to the exception
     |
     |  with_traceback(...)
     |      Exception.with_traceback(tb) --
     |      set self.__traceback__ to tb and return self.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from builtins.BaseException:
     |
     |  __cause__
     |      exception cause
     |
     |  __context__
     |      exception context
     |
     |  __dict__
     |
     |  __suppress_context__
     |
     |  __traceback__
     |
     |  args

    class DeleteUsersResult(builtins.object)
     |  DeleteUsersResult(result, total)
     |
     |  Represents the result of the ``auth.delete_users()`` API.
     |
     |  Methods defined here:
     |
     |  __init__(self, result, total)
     |      Constructs a `DeleteUsersResult` object.
     |
     |      Args:
     |        result: The proto response, wrapped in a
     |          `BatchDeleteAccountsResponse` instance.
     |        total: Total integer number of deletion attempts.
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties defined here:
     |
     |  errors
     |      A list of `auth.ErrorInfo` instances describing the errors that
     |      were encountered during the deletion. Length of this list is equal to
     |      `failure_count`.
     |
     |  failure_count
     |      Returns the number of users that failed to be deleted (possibly
     |      zero).
     |
     |  success_count
     |      Returns the number of users that were deleted successfully (possibly
     |      zero).
     |
     |      Users that did not exist prior to calling `delete_users()` are
     |      considered to be successfully deleted.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

    class EmailAlreadyExistsError(firebase_admin.exceptions.AlreadyExistsError)
     |  EmailAlreadyExistsError(message, cause, http_response)
     |
     |  The user with the provided email already exists.
     |
     |  Method resolution order:
     |      EmailAlreadyExistsError
     |      firebase_admin.exceptions.AlreadyExistsError
     |      firebase_admin.exceptions.FirebaseError
     |      builtins.Exception
     |      builtins.BaseException
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, message, cause, http_response)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  default_message = 'The user with the provided email already exists'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  cause
     |
     |  code
     |
     |  http_response
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Static methods inherited from builtins.Exception:
     |
     |  __new__(*args, **kwargs) class method of builtins.Exception
     |      Create and return a new object.  See help(type) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.BaseException:
     |
     |  __delattr__(self, name, /)
     |      Implement delattr(self, name).
     |
     |  __getattribute__(self, name, /)
     |      Return getattr(self, name).
     |
     |  __reduce__(...)
     |      Helper for pickle.
     |
     |  __repr__(self, /)
     |      Return repr(self).
     |
     |  __setattr__(self, name, value, /)
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(...)
     |
     |  __str__(self, /)
     |      Return str(self).
     |
     |  add_note(...)
     |      Exception.add_note(note) --
     |      add a note to the exception
     |
     |  with_traceback(...)
     |      Exception.with_traceback(tb) --
     |      set self.__traceback__ to tb and return self.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from builtins.BaseException:
     |
     |  __cause__
     |      exception cause
     |
     |  __context__
     |      exception context
     |
     |  __dict__
     |
     |  __suppress_context__
     |
     |  __traceback__
     |
     |  args

    class EmailIdentifier(UserIdentifier)
     |  EmailIdentifier(email)
     |
     |  Used for looking up an account by email.
     |
     |  See ``auth.get_user()``.
     |
     |  Method resolution order:
     |      EmailIdentifier
     |      UserIdentifier
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, email)
     |      Constructs a new `EmailIdentifier` object.
     |
     |      Args:
     |          email: A user email address string.
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties defined here:
     |
     |  email
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from UserIdentifier:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

    class EmailNotFoundError(firebase_admin.exceptions.NotFoundError)
     |  EmailNotFoundError(message, cause=None, http_response=None)
     |
     |  No user record found for the specified email.
     |
     |  Method resolution order:
     |      EmailNotFoundError
     |      firebase_admin.exceptions.NotFoundError
     |      firebase_admin.exceptions.FirebaseError
     |      builtins.Exception
     |      builtins.BaseException
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, message, cause=None, http_response=None)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  default_message = 'No user record found for the given email'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  cause
     |
     |  code
     |
     |  http_response
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Static methods inherited from builtins.Exception:
     |
     |  __new__(*args, **kwargs) class method of builtins.Exception
     |      Create and return a new object.  See help(type) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.BaseException:
     |
     |  __delattr__(self, name, /)
     |      Implement delattr(self, name).
     |
     |  __getattribute__(self, name, /)
     |      Return getattr(self, name).
     |
     |  __reduce__(...)
     |      Helper for pickle.
     |
     |  __repr__(self, /)
     |      Return repr(self).
     |
     |  __setattr__(self, name, value, /)
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(...)
     |
     |  __str__(self, /)
     |      Return str(self).
     |
     |  add_note(...)
     |      Exception.add_note(note) --
     |      add a note to the exception
     |
     |  with_traceback(...)
     |      Exception.with_traceback(tb) --
     |      set self.__traceback__ to tb and return self.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from builtins.BaseException:
     |
     |  __cause__
     |      exception cause
     |
     |  __context__
     |      exception context
     |
     |  __dict__
     |
     |  __suppress_context__
     |
     |  __traceback__
     |
     |  args

    class ErrorInfo(builtins.object)
     |  ErrorInfo(error)
     |
     |  Represents an error encountered while performing a batch operation such
     |  as importing users or deleting multiple user accounts.
     |
     |  Methods defined here:
     |
     |  __init__(self, error)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties defined here:
     |
     |  index
     |
     |  reason
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

    class ExpiredIdTokenError(firebase_admin._auth_utils.InvalidIdTokenError)
     |  ExpiredIdTokenError(message, cause)
     |
     |  The provided ID token is expired.
     |
     |  Method resolution order:
     |      ExpiredIdTokenError
     |      firebase_admin._auth_utils.InvalidIdTokenError
     |      firebase_admin.exceptions.InvalidArgumentError
     |      firebase_admin.exceptions.FirebaseError
     |      builtins.Exception
     |      builtins.BaseException
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, message, cause)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from firebase_admin._auth_utils.InvalidIdTokenError:
     |
     |  default_message = 'The provided ID token is invalid'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  cause
     |
     |  code
     |
     |  http_response
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Static methods inherited from builtins.Exception:
     |
     |  __new__(*args, **kwargs) class method of builtins.Exception
     |      Create and return a new object.  See help(type) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.BaseException:
     |
     |  __delattr__(self, name, /)
     |      Implement delattr(self, name).
     |
     |  __getattribute__(self, name, /)
     |      Return getattr(self, name).
     |
     |  __reduce__(...)
     |      Helper for pickle.
     |
     |  __repr__(self, /)
     |      Return repr(self).
     |
     |  __setattr__(self, name, value, /)
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(...)
     |
     |  __str__(self, /)
     |      Return str(self).
     |
     |  add_note(...)
     |      Exception.add_note(note) --
     |      add a note to the exception
     |
     |  with_traceback(...)
     |      Exception.with_traceback(tb) --
     |      set self.__traceback__ to tb and return self.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from builtins.BaseException:
     |
     |  __cause__
     |      exception cause
     |
     |  __context__
     |      exception context
     |
     |  __dict__
     |
     |  __suppress_context__
     |
     |  __traceback__
     |
     |  args

    class ExpiredSessionCookieError(InvalidSessionCookieError)
     |  ExpiredSessionCookieError(message, cause)
     |
     |  The provided session cookie is expired.
     |
     |  Method resolution order:
     |      ExpiredSessionCookieError
     |      InvalidSessionCookieError
     |      firebase_admin.exceptions.InvalidArgumentError
     |      firebase_admin.exceptions.FirebaseError
     |      builtins.Exception
     |      builtins.BaseException
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, message, cause)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  cause
     |
     |  code
     |
     |  http_response
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Static methods inherited from builtins.Exception:
     |
     |  __new__(*args, **kwargs) class method of builtins.Exception
     |      Create and return a new object.  See help(type) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.BaseException:
     |
     |  __delattr__(self, name, /)
     |      Implement delattr(self, name).
     |
     |  __getattribute__(self, name, /)
     |      Return getattr(self, name).
     |
     |  __reduce__(...)
     |      Helper for pickle.
     |
     |  __repr__(self, /)
     |      Return repr(self).
     |
     |  __setattr__(self, name, value, /)
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(...)
     |
     |  __str__(self, /)
     |      Return str(self).
     |
     |  add_note(...)
     |      Exception.add_note(note) --
     |      add a note to the exception
     |
     |  with_traceback(...)
     |      Exception.with_traceback(tb) --
     |      set self.__traceback__ to tb and return self.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from builtins.BaseException:
     |
     |  __cause__
     |      exception cause
     |
     |  __context__
     |      exception context
     |
     |  __dict__
     |
     |  __suppress_context__
     |
     |  __traceback__
     |
     |  args

    class ExportedUserRecord(UserRecord)
     |  ExportedUserRecord(data)
     |
     |  Contains metadata associated with a user including password hash and salt.
     |
     |  Method resolution order:
     |      ExportedUserRecord
     |      UserRecord
     |      UserInfo
     |      builtins.object
     |
     |  Readonly properties defined here:
     |
     |  password_hash
     |      The user's password hash as a base64-encoded string.
     |
     |      If the Firebase Auth hashing algorithm (SCRYPT) was used to create the user account, this
     |      is the base64-encoded password hash of the user. If a different hashing algorithm was
     |      used to create this user, as is typical when migrating from another Auth system, this
     |      is an empty string. If no password is set, or if the service account doesn't have permission
     |      to read the password, then this is ``None``.
     |
     |  password_salt
     |      The user's password salt as a base64-encoded string.
     |
     |      If the Firebase Auth hashing algorithm (SCRYPT) was used to create the user account, this
     |      is the base64-encoded password salt of the user. If a different hashing algorithm was
     |      used to create this user, as is typical when migrating from another Auth system, this is
     |      an empty string. If no password is set, or if the service account doesn't have permission to
     |      read the password, then this is ``None``.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from UserRecord:
     |
     |  __init__(self, data)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from UserRecord:
     |
     |  custom_claims
     |      Returns any custom claims set on this user account.
     |
     |      Returns:
     |        dict: A dictionary of claims or None.
     |
     |  disabled
     |      Returns whether this user account is disabled.
     |
     |      Returns:
     |        bool: True if the user account is disabled, and False otherwise.
     |
     |  display_name
     |      Returns the display name of this user.
     |
     |      Returns:
     |        string: A display name string or None.
     |
     |  email
     |      Returns the email address associated with this user.
     |
     |      Returns:
     |        string: An email address string or None.
     |
     |  email_verified
     |      Returns whether the email address of this user has been verified.
     |
     |      Returns:
     |        bool: True if the email has been verified, and False otherwise.
     |
     |  phone_number
     |      Returns the phone number associated with this user.
     |
     |      Returns:
     |        string: A phone number string or None.
     |
     |  photo_url
     |      Returns the photo URL of this user.
     |
     |      Returns:
     |        string: A URL string or None.
     |
     |  provider_data
     |      Returns a list of UserInfo instances.
     |
     |      Each object represents an identity from an identity provider that is linked to this user.
     |
     |      Returns:
     |        list: A list of UserInfo objects, which may be empty.
     |
     |  provider_id
     |      Returns the provider ID of this user.
     |
     |      Returns:
     |        string: A constant provider ID value.
     |
     |  tenant_id
     |      Returns the tenant ID of this user.
     |
     |      Returns:
     |        string: A tenant ID string or None.
     |
     |  tokens_valid_after_timestamp
     |      Returns the time, in milliseconds since the epoch, before which tokens are invalid.
     |
     |      Note: this is truncated to 1 second accuracy.
     |
     |      Returns:
     |          int: Timestamp in milliseconds since the epoch, truncated to the second.
     |          All tokens issued before that time are considered revoked.
     |
     |  uid
     |      Returns the user ID of this user.
     |
     |      Returns:
     |        string: A user ID string. This value is never None or empty.
     |
     |  user_metadata
     |      Returns additional metadata associated with this user.
     |
     |      Returns:
     |        UserMetadata: A UserMetadata instance. Does not return None.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from UserInfo:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

    class GetUsersResult(builtins.object)
     |  GetUsersResult(users, not_found)
     |
     |  Represents the result of the ``auth.get_users()`` API.
     |
     |  Methods defined here:
     |
     |  __init__(self, users, not_found)
     |      Constructs a `GetUsersResult` object.
     |
     |      Args:
     |          users: List of `UserRecord` instances.
     |          not_found: List of `UserIdentifier` instances.
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties defined here:
     |
     |  not_found
     |      Set of `UserIdentifier` instances that were requested, but not
     |      found.
     |
     |  users
     |      Set of `UserRecord` instances, corresponding to the set of users
     |      that were requested. Only users that were found are listed here. The
     |      result set is unordered.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

    class ImportUserRecord(builtins.object)
     |  ImportUserRecord(uid, email=None, email_verified=None, display_name=None, phone_number=None, photo_url=None, disabled=None, user_metadata=None, provider_data=None, custom_claims=None, password_hash=None, password_salt=None)
     |
     |  Represents a user account to be imported to Firebase Auth.
     |
     |  Must specify the ``uid`` field at a minimum. A sequence of ``ImportUserRecord`` objects can be
     |  passed to the ``auth.import_users()`` function, in order to import those users into Firebase
     |  Auth in bulk. If the ``password_hash`` is set on a user, a hash configuration must be
     |  specified when calling ``import_users()``.
     |
     |  Args:
     |      uid: User's unique ID. Must be a non-empty string not longer than 128 characters.
     |      email: User's email address (optional).
     |      email_verified: A boolean indicating whether the user's email has been verified (optional).
     |      display_name: User's display name (optional).
     |      phone_number: User's phone number (optional).
     |      photo_url: User's photo URL (optional).
     |      disabled: A boolean indicating whether this user account has been disabled (optional).
     |      user_metadata: An ``auth.UserMetadata`` instance with additional user metadata (optional).
     |      provider_data: A list of ``auth.UserProvider`` instances (optional).
     |      custom_claims: A ``dict`` of custom claims to be set on the user account (optional).
     |      password_hash: User's password hash as a ``bytes`` sequence (optional).
     |      password_salt: User's password salt as a ``bytes`` sequence (optional).
     |
     |  Raises:
     |      ValueError: If provided arguments are invalid.
     |
     |  Methods defined here:
     |
     |  __init__(self, uid, email=None, email_verified=None, display_name=None, phone_number=None, photo_url=None, disabled=None, user_metadata=None, provider_data=None, custom_claims=None, password_hash=None, password_salt=None)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  to_dict(self)
     |      Returns a dict representation of the user. For internal use only.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  custom_claims
     |
     |  display_name
     |
     |  email
     |
     |  password_hash
     |
     |  password_salt
     |
     |  phone_number
     |
     |  photo_url
     |
     |  provider_data
     |
     |  uid
     |
     |  user_metadata

    class InsufficientPermissionError(firebase_admin.exceptions.PermissionDeniedError)
     |  InsufficientPermissionError(message, cause, http_response)
     |
     |  The credential used to initialize the SDK lacks required permissions.
     |
     |  Method resolution order:
     |      InsufficientPermissionError
     |      firebase_admin.exceptions.PermissionDeniedError
     |      firebase_admin.exceptions.FirebaseError
     |      builtins.Exception
     |      builtins.BaseException
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, message, cause, http_response)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  default_message = 'The credential used to initialize the SDK has in......
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  cause
     |
     |  code
     |
     |  http_response
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Static methods inherited from builtins.Exception:
     |
     |  __new__(*args, **kwargs) class method of builtins.Exception
     |      Create and return a new object.  See help(type) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.BaseException:
     |
     |  __delattr__(self, name, /)
     |      Implement delattr(self, name).
     |
     |  __getattribute__(self, name, /)
     |      Return getattr(self, name).
     |
     |  __reduce__(...)
     |      Helper for pickle.
     |
     |  __repr__(self, /)
     |      Return repr(self).
     |
     |  __setattr__(self, name, value, /)
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(...)
     |
     |  __str__(self, /)
     |      Return str(self).
     |
     |  add_note(...)
     |      Exception.add_note(note) --
     |      add a note to the exception
     |
     |  with_traceback(...)
     |      Exception.with_traceback(tb) --
     |      set self.__traceback__ to tb and return self.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from builtins.BaseException:
     |
     |  __cause__
     |      exception cause
     |
     |  __context__
     |      exception context
     |
     |  __dict__
     |
     |  __suppress_context__
     |
     |  __traceback__
     |
     |  args

    class InvalidDynamicLinkDomainError(firebase_admin.exceptions.InvalidArgumentError)
     |  InvalidDynamicLinkDomainError(message, cause, http_response)
     |
     |  Dynamic link domain in ActionCodeSettings is not authorized.
     |
     |  Method resolution order:
     |      InvalidDynamicLinkDomainError
     |      firebase_admin.exceptions.InvalidArgumentError
     |      firebase_admin.exceptions.FirebaseError
     |      builtins.Exception
     |      builtins.BaseException
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, message, cause, http_response)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  default_message = 'Dynamic link domain specified in ActionCodeSettings...
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  cause
     |
     |  code
     |
     |  http_response
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Static methods inherited from builtins.Exception:
     |
     |  __new__(*args, **kwargs) class method of builtins.Exception
     |      Create and return a new object.  See help(type) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.BaseException:
     |
     |  __delattr__(self, name, /)
     |      Implement delattr(self, name).
     |
     |  __getattribute__(self, name, /)
     |      Return getattr(self, name).
     |
     |  __reduce__(...)
     |      Helper for pickle.
     |
     |  __repr__(self, /)
     |      Return repr(self).
     |
     |  __setattr__(self, name, value, /)
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(...)
     |
     |  __str__(self, /)
     |      Return str(self).
     |
     |  add_note(...)
     |      Exception.add_note(note) --
     |      add a note to the exception
     |
     |  with_traceback(...)
     |      Exception.with_traceback(tb) --
     |      set self.__traceback__ to tb and return self.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from builtins.BaseException:
     |
     |  __cause__
     |      exception cause
     |
     |  __context__
     |      exception context
     |
     |  __dict__
     |
     |  __suppress_context__
     |
     |  __traceback__
     |
     |  args

    class InvalidIdTokenError(firebase_admin.exceptions.InvalidArgumentError)
     |  InvalidIdTokenError(message, cause=None, http_response=None)
     |
     |  The provided ID token is not a valid Firebase ID token.
     |
     |  Method resolution order:
     |      InvalidIdTokenError
     |      firebase_admin.exceptions.InvalidArgumentError
     |      firebase_admin.exceptions.FirebaseError
     |      builtins.Exception
     |      builtins.BaseException
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, message, cause=None, http_response=None)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  default_message = 'The provided ID token is invalid'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  cause
     |
     |  code
     |
     |  http_response
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Static methods inherited from builtins.Exception:
     |
     |  __new__(*args, **kwargs) class method of builtins.Exception
     |      Create and return a new object.  See help(type) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.BaseException:
     |
     |  __delattr__(self, name, /)
     |      Implement delattr(self, name).
     |
     |  __getattribute__(self, name, /)
     |      Return getattr(self, name).
     |
     |  __reduce__(...)
     |      Helper for pickle.
     |
     |  __repr__(self, /)
     |      Return repr(self).
     |
     |  __setattr__(self, name, value, /)
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(...)
     |
     |  __str__(self, /)
     |      Return str(self).
     |
     |  add_note(...)
     |      Exception.add_note(note) --
     |      add a note to the exception
     |
     |  with_traceback(...)
     |      Exception.with_traceback(tb) --
     |      set self.__traceback__ to tb and return self.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from builtins.BaseException:
     |
     |  __cause__
     |      exception cause
     |
     |  __context__
     |      exception context
     |
     |  __dict__
     |
     |  __suppress_context__
     |
     |  __traceback__
     |
     |  args

    class InvalidSessionCookieError(firebase_admin.exceptions.InvalidArgumentError)
     |  InvalidSessionCookieError(message, cause=None)
     |
     |  The provided string is not a valid Firebase session cookie.
     |
     |  Method resolution order:
     |      InvalidSessionCookieError
     |      firebase_admin.exceptions.InvalidArgumentError
     |      firebase_admin.exceptions.FirebaseError
     |      builtins.Exception
     |      builtins.BaseException
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, message, cause=None)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  cause
     |
     |  code
     |
     |  http_response
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Static methods inherited from builtins.Exception:
     |
     |  __new__(*args, **kwargs) class method of builtins.Exception
     |      Create and return a new object.  See help(type) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.BaseException:
     |
     |  __delattr__(self, name, /)
     |      Implement delattr(self, name).
     |
     |  __getattribute__(self, name, /)
     |      Return getattr(self, name).
     |
     |  __reduce__(...)
     |      Helper for pickle.
     |
     |  __repr__(self, /)
     |      Return repr(self).
     |
     |  __setattr__(self, name, value, /)
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(...)
     |
     |  __str__(self, /)
     |      Return str(self).
     |
     |  add_note(...)
     |      Exception.add_note(note) --
     |      add a note to the exception
     |
     |  with_traceback(...)
     |      Exception.with_traceback(tb) --
     |      set self.__traceback__ to tb and return self.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from builtins.BaseException:
     |
     |  __cause__
     |      exception cause
     |
     |  __context__
     |      exception context
     |
     |  __dict__
     |
     |  __suppress_context__
     |
     |  __traceback__
     |
     |  args

    class ListProviderConfigsPage(builtins.object)
     |  ListProviderConfigsPage(download, page_token, max_results)
     |
     |  Represents a page of AuthProviderConfig instances retrieved from a Firebase project.
     |
     |  Provides methods for traversing the provider configs included in this page, as well as
     |  retrieving subsequent pages. The iterator returned by ``iterate_all()`` can be used to iterate
     |  through all provider configs in the Firebase project starting from this page.
     |
     |  Methods defined here:
     |
     |  __init__(self, download, page_token, max_results)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  get_next_page(self)
     |      Retrieves the next page of provider configs, if available.
     |
     |      Returns:
     |          ListProviderConfigsPage: Next page of provider configs, or None if this is the last
     |          page.
     |
     |  iterate_all(self)
     |      Retrieves an iterator for provider configs.
     |
     |      Returned iterator will iterate through all the provider configs in the Firebase project
     |      starting from this page. The iterator will never buffer more than one page of configs
     |      in memory at a time.
     |
     |      Returns:
     |          iterator: An iterator of AuthProviderConfig instances.
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties defined here:
     |
     |  has_next_page
     |      A boolean indicating whether more pages are available.
     |
     |  next_page_token
     |      Page token string for the next page (empty string indicates no more pages).
     |
     |  provider_configs
     |      A list of ``AuthProviderConfig`` instances available in this page.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

    class ListUsersPage(builtins.object)
     |  ListUsersPage(download, page_token, max_results)
     |
     |  Represents a page of user records exported from a Firebase project.
     |
     |  Provides methods for traversing the user accounts included in this page, as well as retrieving
     |  subsequent pages of users. The iterator returned by ``iterate_all()`` can be used to iterate
     |  through all users in the Firebase project starting from this page.
     |
     |  Methods defined here:
     |
     |  __init__(self, download, page_token, max_results)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  get_next_page(self)
     |      Retrieves the next page of user accounts, if available.
     |
     |      Returns:
     |          ListUsersPage: Next page of users, or None if this is the last page.
     |
     |  iterate_all(self)
     |      Retrieves an iterator for user accounts.
     |
     |      Returned iterator will iterate through all the user accounts in the Firebase project
     |      starting from this page. The iterator will never buffer more than one page of users
     |      in memory at a time.
     |
     |      Returns:
     |          iterator: An iterator of ExportedUserRecord instances.
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties defined here:
     |
     |  has_next_page
     |      A boolean indicating whether more pages are available.
     |
     |  next_page_token
     |      Page token string for the next page (empty string indicates no more pages).
     |
     |  users
     |      A list of ``ExportedUserRecord`` instances available in this page.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

    class OIDCProviderConfig(ProviderConfig)
     |  OIDCProviderConfig(data)
     |
     |  Represents the OIDC auth provider configuration.
     |
     |  See https://openid.net/specs/openid-connect-core-1_0-final.html.
     |
     |  Method resolution order:
     |      OIDCProviderConfig
     |      ProviderConfig
     |      builtins.object
     |
     |  Readonly properties defined here:
     |
     |  client_id
     |
     |  client_secret
     |
     |  code_response_type
     |
     |  id_token_response_type
     |
     |  issuer
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from ProviderConfig:
     |
     |  __init__(self, data)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from ProviderConfig:
     |
     |  display_name
     |
     |  enabled
     |
     |  provider_id
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from ProviderConfig:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

    class PhoneIdentifier(UserIdentifier)
     |  PhoneIdentifier(phone_number)
     |
     |  Used for looking up an account by phone number.
     |
     |  See ``auth.get_user()``.
     |
     |  Method resolution order:
     |      PhoneIdentifier
     |      UserIdentifier
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, phone_number)
     |      Constructs a new `PhoneIdentifier` object.
     |
     |      Args:
     |          phone_number: A phone number string.
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties defined here:
     |
     |  phone_number
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from UserIdentifier:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

    class PhoneNumberAlreadyExistsError(firebase_admin.exceptions.AlreadyExistsError)
     |  PhoneNumberAlreadyExistsError(message, cause, http_response)
     |
     |  The user with the provided phone number already exists.
     |
     |  Method resolution order:
     |      PhoneNumberAlreadyExistsError
     |      firebase_admin.exceptions.AlreadyExistsError
     |      firebase_admin.exceptions.FirebaseError
     |      builtins.Exception
     |      builtins.BaseException
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, message, cause, http_response)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  default_message = 'The user with the provided phone number already exi...
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  cause
     |
     |  code
     |
     |  http_response
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Static methods inherited from builtins.Exception:
     |
     |  __new__(*args, **kwargs) class method of builtins.Exception
     |      Create and return a new object.  See help(type) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.BaseException:
     |
     |  __delattr__(self, name, /)
     |      Implement delattr(self, name).
     |
     |  __getattribute__(self, name, /)
     |      Return getattr(self, name).
     |
     |  __reduce__(...)
     |      Helper for pickle.
     |
     |  __repr__(self, /)
     |      Return repr(self).
     |
     |  __setattr__(self, name, value, /)
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(...)
     |
     |  __str__(self, /)
     |      Return str(self).
     |
     |  add_note(...)
     |      Exception.add_note(note) --
     |      add a note to the exception
     |
     |  with_traceback(...)
     |      Exception.with_traceback(tb) --
     |      set self.__traceback__ to tb and return self.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from builtins.BaseException:
     |
     |  __cause__
     |      exception cause
     |
     |  __context__
     |      exception context
     |
     |  __dict__
     |
     |  __suppress_context__
     |
     |  __traceback__
     |
     |  args

    class ProviderConfig(builtins.object)
     |  ProviderConfig(data)
     |
     |  Parent type for all authentication provider config types.
     |
     |  Methods defined here:
     |
     |  __init__(self, data)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties defined here:
     |
     |  display_name
     |
     |  enabled
     |
     |  provider_id
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

    class ProviderIdentifier(UserIdentifier)
     |  ProviderIdentifier(provider_id, provider_uid)
     |
     |  Used for looking up an account by provider.
     |
     |  See ``auth.get_user()``.
     |
     |  Method resolution order:
     |      ProviderIdentifier
     |      UserIdentifier
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, provider_id, provider_uid)
     |      Constructs a new `ProviderIdentifier` object.
     |
     |      Args:
     |          provider_id: A provider ID string.
     |          provider_uid: A provider UID string.
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties defined here:
     |
     |  provider_id
     |
     |  provider_uid
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from UserIdentifier:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

    class ResetPasswordExceedLimitError(firebase_admin.exceptions.ResourceExhaustedError)
     |  ResetPasswordExceedLimitError(message, cause=None, http_response=None)
     |
     |  Reset password emails exceeded their limits.
     |
     |  Method resolution order:
     |      ResetPasswordExceedLimitError
     |      firebase_admin.exceptions.ResourceExhaustedError
     |      firebase_admin.exceptions.FirebaseError
     |      builtins.Exception
     |      builtins.BaseException
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, message, cause=None, http_response=None)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  cause
     |
     |  code
     |
     |  http_response
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Static methods inherited from builtins.Exception:
     |
     |  __new__(*args, **kwargs) class method of builtins.Exception
     |      Create and return a new object.  See help(type) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.BaseException:
     |
     |  __delattr__(self, name, /)
     |      Implement delattr(self, name).
     |
     |  __getattribute__(self, name, /)
     |      Return getattr(self, name).
     |
     |  __reduce__(...)
     |      Helper for pickle.
     |
     |  __repr__(self, /)
     |      Return repr(self).
     |
     |  __setattr__(self, name, value, /)
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(...)
     |
     |  __str__(self, /)
     |      Return str(self).
     |
     |  add_note(...)
     |      Exception.add_note(note) --
     |      add a note to the exception
     |
     |  with_traceback(...)
     |      Exception.with_traceback(tb) --
     |      set self.__traceback__ to tb and return self.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from builtins.BaseException:
     |
     |  __cause__
     |      exception cause
     |
     |  __context__
     |      exception context
     |
     |  __dict__
     |
     |  __suppress_context__
     |
     |  __traceback__
     |
     |  args

    class RevokedIdTokenError(firebase_admin._auth_utils.InvalidIdTokenError)
     |  RevokedIdTokenError(message)
     |
     |  The provided ID token has been revoked.
     |
     |  Method resolution order:
     |      RevokedIdTokenError
     |      firebase_admin._auth_utils.InvalidIdTokenError
     |      firebase_admin.exceptions.InvalidArgumentError
     |      firebase_admin.exceptions.FirebaseError
     |      builtins.Exception
     |      builtins.BaseException
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, message)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from firebase_admin._auth_utils.InvalidIdTokenError:
     |
     |  default_message = 'The provided ID token is invalid'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  cause
     |
     |  code
     |
     |  http_response
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Static methods inherited from builtins.Exception:
     |
     |  __new__(*args, **kwargs) class method of builtins.Exception
     |      Create and return a new object.  See help(type) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.BaseException:
     |
     |  __delattr__(self, name, /)
     |      Implement delattr(self, name).
     |
     |  __getattribute__(self, name, /)
     |      Return getattr(self, name).
     |
     |  __reduce__(...)
     |      Helper for pickle.
     |
     |  __repr__(self, /)
     |      Return repr(self).
     |
     |  __setattr__(self, name, value, /)
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(...)
     |
     |  __str__(self, /)
     |      Return str(self).
     |
     |  add_note(...)
     |      Exception.add_note(note) --
     |      add a note to the exception
     |
     |  with_traceback(...)
     |      Exception.with_traceback(tb) --
     |      set self.__traceback__ to tb and return self.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from builtins.BaseException:
     |
     |  __cause__
     |      exception cause
     |
     |  __context__
     |      exception context
     |
     |  __dict__
     |
     |  __suppress_context__
     |
     |  __traceback__
     |
     |  args

    class RevokedSessionCookieError(InvalidSessionCookieError)
     |  RevokedSessionCookieError(message)
     |
     |  The provided session cookie has been revoked.
     |
     |  Method resolution order:
     |      RevokedSessionCookieError
     |      InvalidSessionCookieError
     |      firebase_admin.exceptions.InvalidArgumentError
     |      firebase_admin.exceptions.FirebaseError
     |      builtins.Exception
     |      builtins.BaseException
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, message)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  cause
     |
     |  code
     |
     |  http_response
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Static methods inherited from builtins.Exception:
     |
     |  __new__(*args, **kwargs) class method of builtins.Exception
     |      Create and return a new object.  See help(type) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.BaseException:
     |
     |  __delattr__(self, name, /)
     |      Implement delattr(self, name).
     |
     |  __getattribute__(self, name, /)
     |      Return getattr(self, name).
     |
     |  __reduce__(...)
     |      Helper for pickle.
     |
     |  __repr__(self, /)
     |      Return repr(self).
     |
     |  __setattr__(self, name, value, /)
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(...)
     |
     |  __str__(self, /)
     |      Return str(self).
     |
     |  add_note(...)
     |      Exception.add_note(note) --
     |      add a note to the exception
     |
     |  with_traceback(...)
     |      Exception.with_traceback(tb) --
     |      set self.__traceback__ to tb and return self.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from builtins.BaseException:
     |
     |  __cause__
     |      exception cause
     |
     |  __context__
     |      exception context
     |
     |  __dict__
     |
     |  __suppress_context__
     |
     |  __traceback__
     |
     |  args

    class SAMLProviderConfig(ProviderConfig)
     |  SAMLProviderConfig(data)
     |
     |  Represents he SAML auth provider configuration.
     |
     |  See http://docs.oasis-open.org/security/saml/Post2.0/sstc-saml-tech-overview-2.0.html.
     |
     |  Method resolution order:
     |      SAMLProviderConfig
     |      ProviderConfig
     |      builtins.object
     |
     |  Readonly properties defined here:
     |
     |  callback_url
     |
     |  idp_entity_id
     |
     |  rp_entity_id
     |
     |  sso_url
     |
     |  x509_certificates
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from ProviderConfig:
     |
     |  __init__(self, data)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from ProviderConfig:
     |
     |  display_name
     |
     |  enabled
     |
     |  provider_id
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from ProviderConfig:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

    class TokenSignError(firebase_admin.exceptions.UnknownError)
     |  TokenSignError(message, cause)
     |
     |  Unexpected error while signing a Firebase custom token.
     |
     |  Method resolution order:
     |      TokenSignError
     |      firebase_admin.exceptions.UnknownError
     |      firebase_admin.exceptions.FirebaseError
     |      builtins.Exception
     |      builtins.BaseException
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, message, cause)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  cause
     |
     |  code
     |
     |  http_response
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Static methods inherited from builtins.Exception:
     |
     |  __new__(*args, **kwargs) class method of builtins.Exception
     |      Create and return a new object.  See help(type) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.BaseException:
     |
     |  __delattr__(self, name, /)
     |      Implement delattr(self, name).
     |
     |  __getattribute__(self, name, /)
     |      Return getattr(self, name).
     |
     |  __reduce__(...)
     |      Helper for pickle.
     |
     |  __repr__(self, /)
     |      Return repr(self).
     |
     |  __setattr__(self, name, value, /)
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(...)
     |
     |  __str__(self, /)
     |      Return str(self).
     |
     |  add_note(...)
     |      Exception.add_note(note) --
     |      add a note to the exception
     |
     |  with_traceback(...)
     |      Exception.with_traceback(tb) --
     |      set self.__traceback__ to tb and return self.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from builtins.BaseException:
     |
     |  __cause__
     |      exception cause
     |
     |  __context__
     |      exception context
     |
     |  __dict__
     |
     |  __suppress_context__
     |
     |  __traceback__
     |
     |  args

    class TooManyAttemptsTryLaterError(firebase_admin.exceptions.ResourceExhaustedError)
     |  TooManyAttemptsTryLaterError(message, cause=None, http_response=None)
     |
     |  Rate limited because of too many attempts.
     |
     |  Method resolution order:
     |      TooManyAttemptsTryLaterError
     |      firebase_admin.exceptions.ResourceExhaustedError
     |      firebase_admin.exceptions.FirebaseError
     |      builtins.Exception
     |      builtins.BaseException
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, message, cause=None, http_response=None)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  cause
     |
     |  code
     |
     |  http_response
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Static methods inherited from builtins.Exception:
     |
     |  __new__(*args, **kwargs) class method of builtins.Exception
     |      Create and return a new object.  See help(type) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.BaseException:
     |
     |  __delattr__(self, name, /)
     |      Implement delattr(self, name).
     |
     |  __getattribute__(self, name, /)
     |      Return getattr(self, name).
     |
     |  __reduce__(...)
     |      Helper for pickle.
     |
     |  __repr__(self, /)
     |      Return repr(self).
     |
     |  __setattr__(self, name, value, /)
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(...)
     |
     |  __str__(self, /)
     |      Return str(self).
     |
     |  add_note(...)
     |      Exception.add_note(note) --
     |      add a note to the exception
     |
     |  with_traceback(...)
     |      Exception.with_traceback(tb) --
     |      set self.__traceback__ to tb and return self.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from builtins.BaseException:
     |
     |  __cause__
     |      exception cause
     |
     |  __context__
     |      exception context
     |
     |  __dict__
     |
     |  __suppress_context__
     |
     |  __traceback__
     |
     |  args

    class UidAlreadyExistsError(firebase_admin.exceptions.AlreadyExistsError)
     |  UidAlreadyExistsError(message, cause, http_response)
     |
     |  The user with the provided uid already exists.
     |
     |  Method resolution order:
     |      UidAlreadyExistsError
     |      firebase_admin.exceptions.AlreadyExistsError
     |      firebase_admin.exceptions.FirebaseError
     |      builtins.Exception
     |      builtins.BaseException
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, message, cause, http_response)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  default_message = 'The user with the provided uid already exists'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  cause
     |
     |  code
     |
     |  http_response
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Static methods inherited from builtins.Exception:
     |
     |  __new__(*args, **kwargs) class method of builtins.Exception
     |      Create and return a new object.  See help(type) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.BaseException:
     |
     |  __delattr__(self, name, /)
     |      Implement delattr(self, name).
     |
     |  __getattribute__(self, name, /)
     |      Return getattr(self, name).
     |
     |  __reduce__(...)
     |      Helper for pickle.
     |
     |  __repr__(self, /)
     |      Return repr(self).
     |
     |  __setattr__(self, name, value, /)
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(...)
     |
     |  __str__(self, /)
     |      Return str(self).
     |
     |  add_note(...)
     |      Exception.add_note(note) --
     |      add a note to the exception
     |
     |  with_traceback(...)
     |      Exception.with_traceback(tb) --
     |      set self.__traceback__ to tb and return self.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from builtins.BaseException:
     |
     |  __cause__
     |      exception cause
     |
     |  __context__
     |      exception context
     |
     |  __dict__
     |
     |  __suppress_context__
     |
     |  __traceback__
     |
     |  args

    class UidIdentifier(UserIdentifier)
     |  UidIdentifier(uid)
     |
     |  Used for looking up an account by uid.
     |
     |  See ``auth.get_user()``.
     |
     |  Method resolution order:
     |      UidIdentifier
     |      UserIdentifier
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, uid)
     |      Constructs a new `UidIdentifier` object.
     |
     |      Args:
     |          uid: A user ID string.
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties defined here:
     |
     |  uid
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from UserIdentifier:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

    class UnexpectedResponseError(firebase_admin.exceptions.UnknownError)
     |  UnexpectedResponseError(message, cause=None, http_response=None)
     |
     |  Backend service responded with an unexpected or malformed response.
     |
     |  Method resolution order:
     |      UnexpectedResponseError
     |      firebase_admin.exceptions.UnknownError
     |      firebase_admin.exceptions.FirebaseError
     |      builtins.Exception
     |      builtins.BaseException
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, message, cause=None, http_response=None)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  cause
     |
     |  code
     |
     |  http_response
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Static methods inherited from builtins.Exception:
     |
     |  __new__(*args, **kwargs) class method of builtins.Exception
     |      Create and return a new object.  See help(type) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.BaseException:
     |
     |  __delattr__(self, name, /)
     |      Implement delattr(self, name).
     |
     |  __getattribute__(self, name, /)
     |      Return getattr(self, name).
     |
     |  __reduce__(...)
     |      Helper for pickle.
     |
     |  __repr__(self, /)
     |      Return repr(self).
     |
     |  __setattr__(self, name, value, /)
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(...)
     |
     |  __str__(self, /)
     |      Return str(self).
     |
     |  add_note(...)
     |      Exception.add_note(note) --
     |      add a note to the exception
     |
     |  with_traceback(...)
     |      Exception.with_traceback(tb) --
     |      set self.__traceback__ to tb and return self.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from builtins.BaseException:
     |
     |  __cause__
     |      exception cause
     |
     |  __context__
     |      exception context
     |
     |  __dict__
     |
     |  __suppress_context__
     |
     |  __traceback__
     |
     |  args

    class UserDisabledError(firebase_admin.exceptions.InvalidArgumentError)
     |  UserDisabledError(message, cause=None, http_response=None)
     |
     |  An operation failed due to a user record being disabled.
     |
     |  Method resolution order:
     |      UserDisabledError
     |      firebase_admin.exceptions.InvalidArgumentError
     |      firebase_admin.exceptions.FirebaseError
     |      builtins.Exception
     |      builtins.BaseException
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, message, cause=None, http_response=None)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  default_message = 'The user record is disabled'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  cause
     |
     |  code
     |
     |  http_response
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Static methods inherited from builtins.Exception:
     |
     |  __new__(*args, **kwargs) class method of builtins.Exception
     |      Create and return a new object.  See help(type) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.BaseException:
     |
     |  __delattr__(self, name, /)
     |      Implement delattr(self, name).
     |
     |  __getattribute__(self, name, /)
     |      Return getattr(self, name).
     |
     |  __reduce__(...)
     |      Helper for pickle.
     |
     |  __repr__(self, /)
     |      Return repr(self).
     |
     |  __setattr__(self, name, value, /)
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(...)
     |
     |  __str__(self, /)
     |      Return str(self).
     |
     |  add_note(...)
     |      Exception.add_note(note) --
     |      add a note to the exception
     |
     |  with_traceback(...)
     |      Exception.with_traceback(tb) --
     |      set self.__traceback__ to tb and return self.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from builtins.BaseException:
     |
     |  __cause__
     |      exception cause
     |
     |  __context__
     |      exception context
     |
     |  __dict__
     |
     |  __suppress_context__
     |
     |  __traceback__
     |
     |  args

    class UserIdentifier(builtins.object)
     |  Identifies a user to be looked up.
     |
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

    class UserImportHash(builtins.object)
     |  UserImportHash(name, data=None)
     |
     |  Represents a hash algorithm used to hash user passwords.
     |
     |  An instance of this class must be specified when importing users with passwords via the
     |  ``auth.import_users()`` API. Use one of the provided class methods to obtain new
     |  instances when required. Refer to `documentation`_ for more details.
     |
     |  .. _documentation: https://firebase.google.com/docs/auth/admin/import-users
     |
     |  Methods defined here:
     |
     |  __init__(self, name, data=None)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  to_dict(self)
     |
     |  ----------------------------------------------------------------------
     |  Class methods defined here:
     |
     |  bcrypt()
     |      Creates a new Bcrypt algorithm instance.
     |
     |      Returns:
     |          UserImportHash: A new ``UserImportHash``.
     |
     |  hmac_md5(key)
     |      Creates a new HMAC MD5 algorithm instance.
     |
     |      Args:
     |          key: Signer key as a byte sequence.
     |
     |      Returns:
     |          UserImportHash: A new ``UserImportHash``.
     |
     |  hmac_sha1(key)
     |      Creates a new HMAC SHA1 algorithm instance.
     |
     |      Args:
     |          key: Signer key as a byte sequence.
     |
     |      Returns:
     |          UserImportHash: A new ``UserImportHash``.
     |
     |  hmac_sha256(key)
     |      Creates a new HMAC SHA256 algorithm instance.
     |
     |      Args:
     |          key: Signer key as a byte sequence.
     |
     |      Returns:
     |          UserImportHash: A new ``UserImportHash``.
     |
     |  hmac_sha512(key)
     |      Creates a new HMAC SHA512 algorithm instance.
     |
     |      Args:
     |          key: Signer key as a byte sequence.
     |
     |      Returns:
     |          UserImportHash: A new ``UserImportHash``.
     |
     |  md5(rounds)
     |      Creates a new MD5 algorithm instance.
     |
     |      Args:
     |          rounds: Number of rounds. Must be an integer between 0 and 8192.
     |
     |      Returns:
     |          UserImportHash: A new ``UserImportHash``.
     |
     |  pbkdf2_sha256(rounds)
     |      Creates a new PBKDF2 SHA256 algorithm instance.
     |
     |      Args:
     |          rounds: Number of rounds. Must be an integer between 0 and 120000.
     |
     |      Returns:
     |          UserImportHash: A new ``UserImportHash``.
     |
     |  pbkdf_sha1(rounds)
     |      Creates a new PBKDF SHA1 algorithm instance.
     |
     |      Args:
     |          rounds: Number of rounds. Must be an integer between 0 and 120000.
     |
     |      Returns:
     |          UserImportHash: A new ``UserImportHash``.
     |
     |  scrypt(key, rounds, memory_cost, salt_separator=None)
     |      Creates a new Scrypt algorithm instance.
     |
     |      This is the modified Scrypt algorithm used by Firebase Auth. See ``standard_scrypt()``
     |      function for the standard Scrypt algorith,
     |
     |      Args:
     |          key: Signer key as a byte sequence.
     |          rounds: Number of rounds. Must be an integer between 1 and 8.
     |          memory_cost: Memory cost as an integer between 1 and 14.
     |          salt_separator: Salt separator as a byte sequence (optional).
     |
     |      Returns:
     |          UserImportHash: A new ``UserImportHash``.
     |
     |  sha1(rounds)
     |      Creates a new SHA1 algorithm instance.
     |
     |      Args:
     |          rounds: Number of rounds. Must be an integer between 1 and 8192.
     |
     |      Returns:
     |          UserImportHash: A new ``UserImportHash``.
     |
     |  sha256(rounds)
     |      Creates a new SHA256 algorithm instance.
     |
     |      Args:
     |          rounds: Number of rounds. Must be an integer between 1 and 8192.
     |
     |      Returns:
     |          UserImportHash: A new ``UserImportHash``.
     |
     |  sha512(rounds)
     |      Creates a new SHA512 algorithm instance.
     |
     |      Args:
     |          rounds: Number of rounds. Must be an integer between 1 and 8192.
     |
     |      Returns:
     |          UserImportHash: A new ``UserImportHash``.
     |
     |  standard_scrypt(memory_cost, parallelization, block_size, derived_key_length)
     |      Creates a new standard Scrypt algorithm instance.
     |
     |      Args:
     |          memory_cost: CPU Memory cost as a non-negative integer.
     |          parallelization: Parallelization as a non-negative integer.
     |          block_size: Block size as a non-negative integer.
     |          derived_key_length: Derived key length as a non-negative integer.
     |
     |      Returns:
     |          UserImportHash: A new ``UserImportHash``.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

    class UserImportResult(builtins.object)
     |  UserImportResult(result, total)
     |
     |  Represents the result of a bulk user import operation.
     |
     |  See ``auth.import_users()`` API for more details.
     |
     |  Methods defined here:
     |
     |  __init__(self, result, total)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties defined here:
     |
     |  errors
     |      Returns a list of ``auth.ErrorInfo`` instances describing the errors encountered.
     |
     |  failure_count
     |      Returns the number of users that failed to be imported.
     |
     |  success_count
     |      Returns the number of users successfully imported.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

    class UserInfo(builtins.object)
     |  A collection of standard profile information for a user.
     |
     |  Used to expose profile information returned by an identity provider.
     |
     |  Readonly properties defined here:
     |
     |  display_name
     |      Returns the display name of this user.
     |
     |  email
     |      Returns the email address associated with this user.
     |
     |  phone_number
     |      Returns the phone number associated with this user.
     |
     |  photo_url
     |      Returns the photo URL of this user.
     |
     |  provider_id
     |      Returns the ID of the identity provider.
     |
     |      This can be a short domain name (e.g. google.com), or the identity of an OpenID
     |      identity provider.
     |
     |  uid
     |      Returns the user ID of this user.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

    class UserMetadata(builtins.object)
     |  UserMetadata(creation_timestamp=None, last_sign_in_timestamp=None, last_refresh_timestamp=None)
     |
     |  Contains additional metadata associated with a user account.
     |
     |  Methods defined here:
     |
     |  __init__(self, creation_timestamp=None, last_sign_in_timestamp=None, last_refresh_timestamp=None)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties defined here:
     |
     |  creation_timestamp
     |      Creation timestamp in milliseconds since the epoch.
     |
     |      Returns:
     |        integer: The user creation timestamp in milliseconds since the epoch.
     |
     |  last_refresh_timestamp
     |      The time at which the user was last active (ID token refreshed).
     |
     |      Returns:
     |        integer: Milliseconds since epoch timestamp, or `None` if the user was
     |        never active.
     |
     |  last_sign_in_timestamp
     |      Last sign in timestamp in milliseconds since the epoch.
     |
     |      Returns:
     |        integer: The last sign in timestamp in milliseconds since the epoch.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

    class UserNotFoundError(firebase_admin.exceptions.NotFoundError)
     |  UserNotFoundError(message, cause=None, http_response=None)
     |
     |  No user record found for the specified identifier.
     |
     |  Method resolution order:
     |      UserNotFoundError
     |      firebase_admin.exceptions.NotFoundError
     |      firebase_admin.exceptions.FirebaseError
     |      builtins.Exception
     |      builtins.BaseException
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, message, cause=None, http_response=None)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  default_message = 'No user record found for the given identifier'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  cause
     |
     |  code
     |
     |  http_response
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Static methods inherited from builtins.Exception:
     |
     |  __new__(*args, **kwargs) class method of builtins.Exception
     |      Create and return a new object.  See help(type) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.BaseException:
     |
     |  __delattr__(self, name, /)
     |      Implement delattr(self, name).
     |
     |  __getattribute__(self, name, /)
     |      Return getattr(self, name).
     |
     |  __reduce__(...)
     |      Helper for pickle.
     |
     |  __repr__(self, /)
     |      Return repr(self).
     |
     |  __setattr__(self, name, value, /)
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(...)
     |
     |  __str__(self, /)
     |      Return str(self).
     |
     |  add_note(...)
     |      Exception.add_note(note) --
     |      add a note to the exception
     |
     |  with_traceback(...)
     |      Exception.with_traceback(tb) --
     |      set self.__traceback__ to tb and return self.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from builtins.BaseException:
     |
     |  __cause__
     |      exception cause
     |
     |  __context__
     |      exception context
     |
     |  __dict__
     |
     |  __suppress_context__
     |
     |  __traceback__
     |
     |  args

    class UserProvider(builtins.object)
     |  UserProvider(uid, provider_id, email=None, display_name=None, photo_url=None)
     |
     |  Represents a user identity provider that can be associated with a Firebase user.
     |
     |  One or more providers can be specified in an ``ImportUserRecord`` when importing users via
     |  ``auth.import_users()``.
     |
     |  Args:
     |      uid: User's unique ID assigned by the identity provider.
     |      provider_id: ID of the identity provider. This can be a short domain name or the identifier
     |          of an OpenID identity provider.
     |      email: User's email address (optional).
     |      display_name: User's display name (optional).
     |      photo_url: User's photo URL (optional).
     |
     |  Methods defined here:
     |
     |  __init__(self, uid, provider_id, email=None, display_name=None, photo_url=None)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  to_dict(self)
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  display_name
     |
     |  email
     |
     |  photo_url
     |
     |  provider_id
     |
     |  uid

    class UserRecord(UserInfo)
     |  UserRecord(data)
     |
     |  Contains metadata associated with a Firebase user account.
     |
     |  Method resolution order:
     |      UserRecord
     |      UserInfo
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, data)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties defined here:
     |
     |  custom_claims
     |      Returns any custom claims set on this user account.
     |
     |      Returns:
     |        dict: A dictionary of claims or None.
     |
     |  disabled
     |      Returns whether this user account is disabled.
     |
     |      Returns:
     |        bool: True if the user account is disabled, and False otherwise.
     |
     |  display_name
     |      Returns the display name of this user.
     |
     |      Returns:
     |        string: A display name string or None.
     |
     |  email
     |      Returns the email address associated with this user.
     |
     |      Returns:
     |        string: An email address string or None.
     |
     |  email_verified
     |      Returns whether the email address of this user has been verified.
     |
     |      Returns:
     |        bool: True if the email has been verified, and False otherwise.
     |
     |  phone_number
     |      Returns the phone number associated with this user.
     |
     |      Returns:
     |        string: A phone number string or None.
     |
     |  photo_url
     |      Returns the photo URL of this user.
     |
     |      Returns:
     |        string: A URL string or None.
     |
     |  provider_data
     |      Returns a list of UserInfo instances.
     |
     |      Each object represents an identity from an identity provider that is linked to this user.
     |
     |      Returns:
     |        list: A list of UserInfo objects, which may be empty.
     |
     |  provider_id
     |      Returns the provider ID of this user.
     |
     |      Returns:
     |        string: A constant provider ID value.
     |
     |  tenant_id
     |      Returns the tenant ID of this user.
     |
     |      Returns:
     |        string: A tenant ID string or None.
     |
     |  tokens_valid_after_timestamp
     |      Returns the time, in milliseconds since the epoch, before which tokens are invalid.
     |
     |      Note: this is truncated to 1 second accuracy.
     |
     |      Returns:
     |          int: Timestamp in milliseconds since the epoch, truncated to the second.
     |          All tokens issued before that time are considered revoked.
     |
     |  uid
     |      Returns the user ID of this user.
     |
     |      Returns:
     |        string: A user ID string. This value is never None or empty.
     |
     |  user_metadata
     |      Returns additional metadata associated with this user.
     |
     |      Returns:
     |        UserMetadata: A UserMetadata instance. Does not return None.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from UserInfo:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

FUNCTIONS
    create_custom_token(uid, developer_claims=None, app=None)
        Builds and signs a Firebase custom auth token.

        Args:
            uid: ID of the user for whom the token is created.
            developer_claims: A dictionary of claims to be included in the token
                (optional).
            app: An App instance (optional).

        Returns:
            bytes: A token minted from the input parameters.

        Raises:
            ValueError: If input parameters are invalid.
            TokenSignError: If an error occurs while signing the token using the remote IAM service.

    create_oidc_provider_config(provider_id, client_id, issuer, display_name=None, enabled=None, client_secret=None, id_token_response_type=None, code_response_type=None, app=None)
        Creates a new OIDC provider config from the given parameters.

        OIDC provider support requires Google Cloud's Identity Platform (GCIP). To learn more about
        GCIP, including pricing and features, see https://cloud.google.com/identity-platform.

        Args:
            provider_id: Provider ID string. Must have the prefix ``oidc.``.
            client_id: Client ID of the new config.
            issuer: Issuer of the new config. Must be a valid URL.
            display_name: The user-friendly display name to the current configuration (optional).
                This name is also used as the provider label in the Cloud Console.
            enabled: A boolean indicating whether the provider configuration is enabled or disabled
                (optional). A user cannot sign in using a disabled provider.
            app: An App instance (optional).
            client_secret: A string which sets the client secret for the new provider.
                This is required for the code flow.
            code_response_type: A boolean which sets whether to enable the code response flow for the
                new provider. By default, this is not enabled if no response type is specified.
                A client secret must be set for this response type.
                Having both the code and ID token response flows is currently not supported.
            id_token_response_type: A boolean which sets whether to enable the ID token response flow
                for the new provider. By default, this is enabled if no response type is specified.
                Having both the code and ID token response flows is currently not supported.

        Returns:
            OIDCProviderConfig: The newly created OIDC provider config instance.

        Raises:
            ValueError: If any of the specified input parameters are invalid.
            FirebaseError: If an error occurs while creating the new OIDC provider config.

    create_saml_provider_config(provider_id, idp_entity_id, sso_url, x509_certificates, rp_entity_id, callback_url, display_name=None, enabled=None, app=None)
        Creates a new SAML provider config from the given parameters.

        SAML provider support requires Google Cloud's Identity Platform (GCIP). To learn more about
        GCIP, including pricing and features, see https://cloud.google.com/identity-platform.

        Args:
            provider_id: Provider ID string. Must have the prefix ``saml.``.
            idp_entity_id: The SAML IdP entity identifier.
            sso_url: The SAML IdP SSO URL. Must be a valid URL.
            x509_certificates: The list of SAML IdP X.509 certificates issued by CA for this provider.
                Multiple certificates are accepted to prevent outages during IdP key rotation (for
                example ADFS rotates every 10 days). When the Auth server receives a SAML response, it
                will match the SAML response with the certificate on record. Otherwise the response is
                rejected. Developers are expected to manage the certificate updates as keys are
                rotated.
            rp_entity_id: The SAML relying party (service provider) entity ID. This is defined by the
                developer but needs to be provided to the SAML IdP.
            callback_url: Callback URL string. This is fixed and must always be the same as the OAuth
                redirect URL provisioned by Firebase Auth, unless a custom authDomain is used.
            display_name: The user-friendly display name to the current configuration (optional). This
                name is also used as the provider label in the Cloud Console.
            enabled: A boolean indicating whether the provider configuration is enabled or disabled
                (optional). A user cannot sign in using a disabled provider.
            app: An App instance (optional).

        Returns:
            SAMLProviderConfig: The newly created SAML provider config instance.

        Raises:
            ValueError: If any of the specified input parameters are invalid.
            FirebaseError: If an error occurs while creating the new SAML provider config.

    create_session_cookie(id_token, expires_in, app=None)
        Creates a new Firebase session cookie from the given ID token and options.

        The returned JWT can be set as a server-side session cookie with a custom cookie policy.

        Args:
            id_token: The Firebase ID token to exchange for a session cookie.
            expires_in: Duration until the cookie is expired. This can be specified
                as a numeric seconds value or a ``datetime.timedelta`` instance.
            app: An App instance (optional).

        Returns:
            bytes: A session cookie generated from the input parameters.

        Raises:
            ValueError: If input parameters are invalid.
            FirebaseError: If an error occurs while creating the cookie.

    create_user(**kwargs)
        Creates a new user account with the specified properties.

        Args:
            **kwargs: A series of keyword arguments (optional).

        Keyword Args:
            uid: User ID to assign to the newly created user (optional).
            display_name: The user's display name (optional).
            email: The user's primary email (optional).
            email_verified: A boolean indicating whether or not the user's primary email is
                verified (optional).
            phone_number: The user's primary phone number (optional).
            photo_url: The user's photo URL (optional).
            password: The user's raw, unhashed password. (optional).
            disabled: A boolean indicating whether or not the user account is disabled (optional).
            app: An App instance (optional).

        Returns:
            UserRecord: A user record instance for the newly created user.

        Raises:
            ValueError: If the specified user properties are invalid.
            FirebaseError: If an error occurs while creating the user account.

    delete_oidc_provider_config(provider_id, app=None)
        Deletes the ``OIDCProviderConfig`` with the given ID.

        Args:
            provider_id: Provider ID string.
            app: An App instance (optional).

        Raises:
            ValueError: If the provider ID is invalid, empty or does not have ``oidc.`` prefix.
            ConfigurationNotFoundError: If no OIDC provider is available with the given identifier.
            FirebaseError: If an error occurs while deleting the OIDC provider.

    delete_saml_provider_config(provider_id, app=None)
        Deletes the ``SAMLProviderConfig`` with the given ID.

        Args:
            provider_id: Provider ID string.
            app: An App instance (optional).

        Raises:
            ValueError: If the provider ID is invalid, empty or does not have ``saml.`` prefix.
            ConfigurationNotFoundError: If no SAML provider is available with the given identifier.
            FirebaseError: If an error occurs while deleting the SAML provider.

    delete_user(uid, app=None)
        Deletes the user identified by the specified user ID.

        Args:
            uid: A user ID string.
            app: An App instance (optional).

        Raises:
            ValueError: If the user ID is None, empty or malformed.
            FirebaseError: If an error occurs while deleting the user account.

    delete_users(uids, app=None)
        Deletes the users specified by the given identifiers.

        Deleting a non-existing user does not generate an error (the method is
        idempotent.) Non-existing users are considered to be successfully deleted
        and are therefore included in the `DeleteUserResult.success_count` value.

        A maximum of 1000 identifiers may be supplied. If more than 1000
        identifiers are supplied, this method raises a `ValueError`.

        Args:
            uids: A list of strings indicating the uids of the users to be deleted.
                Must have <= 1000 entries.
            app: An App instance (optional).

        Returns:
            DeleteUsersResult: The total number of successful/failed deletions, as
            well as the array of errors that correspond to the failed deletions.

        Raises:
            ValueError: If any of the identifiers are invalid or if more than 1000
                identifiers are specified.

    generate_email_verification_link(email, action_code_settings=None, app=None)
        Generates the out-of-band email action link for email verification flows for the specified
        email address.

        Args:
            email: The email of the user to be verified.
            action_code_settings: ``ActionCodeSettings`` instance (optional). Defines whether
                the link is to be handled by a mobile app and the additional state information to be
                passed in the deep link.
            app: An App instance (optional).
        Returns:
            link: The email verification link created by the API

        Raises:
            ValueError: If the provided arguments are invalid
            FirebaseError: If an error occurs while generating the link

    generate_password_reset_link(email, action_code_settings=None, app=None)
        Generates the out-of-band email action link for password reset flows for the specified email
        address.

        Args:
            email: The email of the user whose password is to be reset.
            action_code_settings: ``ActionCodeSettings`` instance (optional). Defines whether
                the link is to be handled by a mobile app and the additional state information to be
                passed in the deep link.
            app: An App instance (optional).
        Returns:
            link: The password reset link created by the API

        Raises:
            ValueError: If the provided arguments are invalid
            FirebaseError: If an error occurs while generating the link

    generate_sign_in_with_email_link(email, action_code_settings, app=None)
        Generates the out-of-band email action link for email link sign-in flows, using the action
        code settings provided.

        Args:
            email: The email of the user signing in.
            action_code_settings: ``ActionCodeSettings`` instance. Defines whether
                the link is to be handled by a mobile app and the additional state information to be
                passed in the deep link.
            app: An App instance (optional).

        Returns:
            link: The email sign-in link created by the API

        Raises:
            ValueError: If the provided arguments are invalid
            FirebaseError: If an error occurs while generating the link

    get_oidc_provider_config(provider_id, app=None)
        Returns the ``OIDCProviderConfig`` with the given ID.

        Args:
            provider_id: Provider ID string.
            app: An App instance (optional).

        Returns:
            OIDCProviderConfig: An OIDC provider config instance.

        Raises:
            ValueError: If the provider ID is invalid, empty or does not have ``oidc.`` prefix.
            ConfigurationNotFoundError: If no OIDC provider is available with the given identifier.
            FirebaseError: If an error occurs while retrieving the OIDC provider.

    get_saml_provider_config(provider_id, app=None)
        Returns the ``SAMLProviderConfig`` with the given ID.

        Args:
            provider_id: Provider ID string.
            app: An App instance (optional).

        Returns:
            SAMLProviderConfig: A SAML provider config instance.

        Raises:
            ValueError: If the provider ID is invalid, empty or does not have ``saml.`` prefix.
            ConfigurationNotFoundError: If no SAML provider is available with the given identifier.
            FirebaseError: If an error occurs while retrieving the SAML provider.

    get_user(uid, app=None)
        Gets the user data corresponding to the specified user ID.

        Args:
            uid: A user ID string.
            app: An App instance (optional).

        Returns:
            UserRecord: A user record instance.

        Raises:
            ValueError: If the user ID is None, empty or malformed.
            UserNotFoundError: If the specified user ID does not exist.
            FirebaseError: If an error occurs while retrieving the user.

    get_user_by_email(email, app=None)
        Gets the user data corresponding to the specified user email.

        Args:
            email: A user email address string.
            app: An App instance (optional).

        Returns:
            UserRecord: A user record instance.

        Raises:
            ValueError: If the email is None, empty or malformed.
            UserNotFoundError: If no user exists by the specified email address.
            FirebaseError: If an error occurs while retrieving the user.

    get_user_by_phone_number(phone_number, app=None)
        Gets the user data corresponding to the specified phone number.

        Args:
            phone_number: A phone number string.
            app: An App instance (optional).

        Returns:
            UserRecord: A user record instance.

        Raises:
            ValueError: If the phone number is None, empty or malformed.
            UserNotFoundError: If no user exists by the specified phone number.
            FirebaseError: If an error occurs while retrieving the user.

    get_users(identifiers, app=None)
        Gets the user data corresponding to the specified identifiers.

        There are no ordering guarantees; in particular, the nth entry in the
        result list is not guaranteed to correspond to the nth entry in the input
        parameters list.

        A maximum of 100 identifiers may be supplied. If more than 100
        identifiers are supplied, this method raises a `ValueError`.

        Args:
            identifiers (list[UserIdentifier]): A list of ``UserIdentifier``
                instances used to indicate which user records should be returned.
                Must have <= 100 entries.
            app: An App instance (optional).

        Returns:
            GetUsersResult: A ``GetUsersResult`` instance corresponding to the
            specified identifiers.

        Raises:
            ValueError: If any of the identifiers are invalid or if more than 100
                identifiers are specified.

    import_users(users, hash_alg=None, app=None)
        Imports the specified list of users into Firebase Auth.

        At most 1000 users can be imported at a time. This operation is optimized for bulk imports and
        will ignore checks on identifier uniqueness which could result in duplications. The
        ``hash_alg`` parameter must be specified when importing users with passwords. Refer to the
        ``UserImportHash`` class for supported hash algorithms.

        Args:
            users: A list of ``ImportUserRecord`` instances to import. Length of the list must not
                exceed 1000.
            hash_alg: A ``UserImportHash`` object (optional). Required when importing users with
                passwords.
            app: An App instance (optional).

        Returns:
            UserImportResult: An object summarizing the result of the import operation.

        Raises:
            ValueError: If the provided arguments are invalid.
            FirebaseError: If an error occurs while importing users.

    list_saml_provider_configs(page_token=None, max_results=100, app=None)
        Retrieves a page of SAML provider configs from a Firebase project.

        The ``page_token`` argument governs the starting point of the page. The ``max_results``
        argument governs the maximum number of configs that may be included in the returned
        page. This function never returns ``None``. If there are no SAML configs in the Firebase
        project, this returns an empty page.

        Args:
            page_token: A non-empty page token string, which indicates the starting point of the
                page (optional). Defaults to ``None``, which will retrieve the first page of users.
            max_results: A positive integer indicating the maximum number of users to include in
                the returned page (optional). Defaults to 100, which is also the maximum number
                allowed.
            app: An App instance (optional).

        Returns:
            ListProviderConfigsPage: A page of SAML provider config instances.

        Raises:
            ValueError: If ``max_results`` or ``page_token`` are invalid.
            FirebaseError: If an error occurs while retrieving the SAML provider configs.

    list_users(page_token=None, max_results=1000, app=None)
        Retrieves a page of user accounts from a Firebase project.

        The ``page_token`` argument governs the starting point of the page. The ``max_results``
        argument governs the maximum number of user accounts that may be included in the returned page.
        This function never returns None. If there are no user accounts in the Firebase project, this
        returns an empty page.

        Args:
            page_token: A non-empty page token string, which indicates the starting point of the page
                (optional). Defaults to ``None``, which will retrieve the first page of users.
            max_results: A positive integer indicating the maximum number of users to include in the
                returned page (optional). Defaults to 1000, which is also the maximum number allowed.
            app: An App instance (optional).

        Returns:
            ListUsersPage: A page of user accounts.

        Raises:
            ValueError: If ``max_results`` or ``page_token`` are invalid.
            FirebaseError: If an error occurs while retrieving the user accounts.

    revoke_refresh_tokens(uid, app=None)
        Revokes all refresh tokens for an existing user.

        This function updates the user's ``tokens_valid_after_timestamp`` to the current UTC
        in seconds since the epoch. It is important that the server on which this is called has its
        clock set correctly and synchronized.

        While this revokes all sessions for a specified user and disables any new ID tokens for
        existing sessions from getting minted, existing ID tokens may remain active until their
        natural expiration (one hour). To verify that ID tokens are revoked, use
        ``verify_id_token(idToken, check_revoked=True)``.

        Args:
            uid: A user ID string.
            app: An App instance (optional).

        Raises:
            ValueError: If the user ID is None, empty or malformed.
            FirebaseError: If an error occurs while revoking the refresh token.

    set_custom_user_claims(uid, custom_claims, app=None)
        Sets additional claims on an existing user account.

        Custom claims set via this function can be used to define user roles and privilege levels.
        These claims propagate to all the devices where the user is already signed in (after token
        expiration or when token refresh is forced), and next time the user signs in. The claims
        can be accessed via the user's ID token JWT. If a reserved OIDC claim is specified (sub, iat,
        iss, etc), an error is thrown. Claims payload must also not be larger then 1000 characters
        when serialized into a JSON string.

        Args:
            uid: A user ID string.
            custom_claims: A dictionary or a JSON string of custom claims. Pass None to unset any
                claims set previously.
            app: An App instance (optional).

        Raises:
            ValueError: If the specified user ID or the custom claims are invalid.
            FirebaseError: If an error occurs while updating the user account.

    update_oidc_provider_config(provider_id, client_id=None, issuer=None, display_name=None, enabled=None, client_secret=None, id_token_response_type=None, code_response_type=None, app=None)
        Updates an existing OIDC provider config with the given parameters.

        Args:
            provider_id: Provider ID string. Must have the prefix ``oidc.``.
            client_id: Client ID of the new config (optional).
            issuer: Issuer of the new config (optional). Must be a valid URL.
            display_name: The user-friendly display name of the current configuration (optional).
                Pass ``auth.DELETE_ATTRIBUTE`` to delete the current display name.
            enabled: A boolean indicating whether the provider configuration is enabled or disabled
                (optional).
            app: An App instance (optional).
            client_secret: A string which sets the client secret for the new provider.
                This is required for the code flow.
            code_response_type: A boolean which sets whether to enable the code response flow for the
                new provider. By default, this is not enabled if no response type is specified.
                A client secret must be set for this response type.
                Having both the code and ID token response flows is currently not supported.
            id_token_response_type: A boolean which sets whether to enable the ID token response flow
                for the new provider. By default, this is enabled if no response type is specified.
                Having both the code and ID token response flows is currently not supported.

        Returns:
            OIDCProviderConfig: The updated OIDC provider config instance.

        Raises:
            ValueError: If any of the specified input parameters are invalid.
            FirebaseError: If an error occurs while updating the OIDC provider config.

    update_saml_provider_config(provider_id, idp_entity_id=None, sso_url=None, x509_certificates=None, rp_entity_id=None, callback_url=None, display_name=None, enabled=None, app=None)
        Updates an existing SAML provider config with the given parameters.

        Args:
            provider_id: Provider ID string. Must have the prefix ``saml.``.
            idp_entity_id: The SAML IdP entity identifier (optional).
            sso_url: The SAML IdP SSO URL. Must be a valid URL (optional).
            x509_certificates: The list of SAML IdP X.509 certificates issued by CA for this
                provider  (optional).
            rp_entity_id: The SAML relying party entity ID (optional).
            callback_url: Callback URL string  (optional).
            display_name: The user-friendly display name of the current configuration (optional).
                Pass ``auth.DELETE_ATTRIBUTE`` to delete the current display name.
            enabled: A boolean indicating whether the provider configuration is enabled or disabled
                (optional).
            app: An App instance (optional).

        Returns:
            SAMLProviderConfig: The updated SAML provider config instance.

        Raises:
            ValueError: If any of the specified input parameters are invalid.
            FirebaseError: If an error occurs while updating the SAML provider config.

    update_user(uid, **kwargs)
        Updates an existing user account with the specified properties.

        Args:
            uid: A user ID string.
            **kwargs: A series of keyword arguments (optional).

        Keyword Args:
            display_name: The user's display name (optional). Can be removed by explicitly passing
                ``auth.DELETE_ATTRIBUTE``.
            email: The user's primary email (optional).
            email_verified: A boolean indicating whether or not the user's primary email is
                verified (optional).
            phone_number: The user's primary phone number (optional). Can be removed by explicitly
                passing ``auth.DELETE_ATTRIBUTE``.
            photo_url: The user's photo URL (optional). Can be removed by explicitly passing
                ``auth.DELETE_ATTRIBUTE``.
            password: The user's raw, unhashed password. (optional).
            disabled: A boolean indicating whether or not the user account is disabled (optional).
            custom_claims: A dictionary or a JSON string containing the custom claims to be set on the
                user account (optional). To remove all custom claims, pass ``auth.DELETE_ATTRIBUTE``.
            valid_since: An integer signifying the seconds since the epoch (optional). This field is
                set by ``revoke_refresh_tokens`` and it is discouraged to set this field directly.
            app: An App instance (optional).

        Returns:
            UserRecord: An updated user record instance for the user.

        Raises:
            ValueError: If the specified user ID or properties are invalid.
            FirebaseError: If an error occurs while updating the user account.

    verify_id_token(id_token, app=None, check_revoked=False, clock_skew_seconds=0)
        Verifies the signature and data for the provided JWT.

        Accepts a signed token string, verifies that it is current, and issued
        to this project, and that it was correctly signed by Google.

        Args:
            id_token: A string of the encoded JWT.
            app: An App instance (optional).
            check_revoked: Boolean, If true, checks whether the token has been revoked or
                the user disabled (optional).
            clock_skew_seconds: The number of seconds to tolerate when checking the token.
                Must be between 0-60. Defaults to 0.
        Returns:
            dict: A dictionary of key-value pairs parsed from the decoded JWT.

        Raises:
            ValueError: If ``id_token`` is a not a string or is empty.
            InvalidIdTokenError: If ``id_token`` is not a valid Firebase ID token.
            ExpiredIdTokenError: If the specified ID token has expired.
            RevokedIdTokenError: If ``check_revoked`` is ``True`` and the ID token has been revoked.
            CertificateFetchError: If an error occurs while fetching the public key certificates
                required to verify the ID token.
            UserDisabledError: If ``check_revoked`` is ``True`` and the corresponding user
                record is disabled.

    verify_session_cookie(session_cookie, check_revoked=False, app=None, clock_skew_seconds=0)
        Verifies a Firebase session cookie.

        Accepts a session cookie string, verifies that it is current, and issued
        to this project, and that it was correctly signed by Google.

        Args:
            session_cookie: A session cookie string to verify.
            check_revoked: Boolean, if true, checks whether the cookie has been revoked or the
                user disabled (optional).
            app: An App instance (optional).
            clock_skew_seconds: The number of seconds to tolerate when checking the cookie.

        Returns:
            dict: A dictionary of key-value pairs parsed from the decoded JWT.

        Raises:
            ValueError: If ``session_cookie`` is a not a string or is empty.
            InvalidSessionCookieError: If ``session_cookie`` is not a valid Firebase session cookie.
            ExpiredSessionCookieError: If the specified session cookie has expired.
            RevokedSessionCookieError: If ``check_revoked`` is ``True`` and the cookie has been revoked.
            CertificateFetchError: If an error occurs while fetching the public key certificates
                required to verify the session cookie.
            UserDisabledError: If ``check_revoked`` is ``True`` and the corresponding user
                record is disabled.

DATA
    DELETE_ATTRIBUTE = <firebase_admin._user_mgt.Sentinel object>
    __all__ = ['ActionCodeSettings', 'CertificateFetchError', 'Client', 'C...

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\backend\lib\site-packages\firebase_admin\auth.py



================================================================================
Help on module backend.Lib.site-packages.firebase_admin._auth_utils in backend.Lib.site-packages.firebase_admin:

NAME
    backend.Lib.site-packages.firebase_admin._auth_utils - Firebase auth utils.

CLASSES
    builtins.object
        PageIterator
    firebase_admin.exceptions.AlreadyExistsError(firebase_admin.exceptions.FirebaseError)
        EmailAlreadyExistsError
        PhoneNumberAlreadyExistsError
        UidAlreadyExistsError
    firebase_admin.exceptions.InvalidArgumentError(firebase_admin.exceptions.FirebaseError)
        InvalidDynamicLinkDomainError
        InvalidIdTokenError
        TenantIdMismatchError
        UserDisabledError
    firebase_admin.exceptions.NotFoundError(firebase_admin.exceptions.FirebaseError)
        ConfigurationNotFoundError
        EmailNotFoundError
        TenantNotFoundError
        UserNotFoundError
    firebase_admin.exceptions.PermissionDeniedError(firebase_admin.exceptions.FirebaseError)
        InsufficientPermissionError
    firebase_admin.exceptions.ResourceExhaustedError(firebase_admin.exceptions.FirebaseError)
        ResetPasswordExceedLimitError
        TooManyAttemptsTryLaterError
    firebase_admin.exceptions.UnknownError(firebase_admin.exceptions.FirebaseError)
        UnexpectedResponseError

    class ConfigurationNotFoundError(firebase_admin.exceptions.NotFoundError)
     |  ConfigurationNotFoundError(message, cause=None, http_response=None)
     |
     |  No auth provider found for the specified identifier.
     |
     |  Method resolution order:
     |      ConfigurationNotFoundError
     |      firebase_admin.exceptions.NotFoundError
     |      firebase_admin.exceptions.FirebaseError
     |      builtins.Exception
     |      builtins.BaseException
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, message, cause=None, http_response=None)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  default_message = 'No auth provider found for the given identifier'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  cause
     |
     |  code
     |
     |  http_response
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Static methods inherited from builtins.Exception:
     |
     |  __new__(*args, **kwargs) class method of builtins.Exception
     |      Create and return a new object.  See help(type) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.BaseException:
     |
     |  __delattr__(self, name, /)
     |      Implement delattr(self, name).
     |
     |  __getattribute__(self, name, /)
     |      Return getattr(self, name).
     |
     |  __reduce__(...)
     |      Helper for pickle.
     |
     |  __repr__(self, /)
     |      Return repr(self).
     |
     |  __setattr__(self, name, value, /)
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(...)
     |
     |  __str__(self, /)
     |      Return str(self).
     |
     |  add_note(...)
     |      Exception.add_note(note) --
     |      add a note to the exception
     |
     |  with_traceback(...)
     |      Exception.with_traceback(tb) --
     |      set self.__traceback__ to tb and return self.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from builtins.BaseException:
     |
     |  __cause__
     |      exception cause
     |
     |  __context__
     |      exception context
     |
     |  __dict__
     |
     |  __suppress_context__
     |
     |  __traceback__
     |
     |  args

    class EmailAlreadyExistsError(firebase_admin.exceptions.AlreadyExistsError)
     |  EmailAlreadyExistsError(message, cause, http_response)
     |
     |  The user with the provided email already exists.
     |
     |  Method resolution order:
     |      EmailAlreadyExistsError
     |      firebase_admin.exceptions.AlreadyExistsError
     |      firebase_admin.exceptions.FirebaseError
     |      builtins.Exception
     |      builtins.BaseException
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, message, cause, http_response)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  default_message = 'The user with the provided email already exists'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  cause
     |
     |  code
     |
     |  http_response
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Static methods inherited from builtins.Exception:
     |
     |  __new__(*args, **kwargs) class method of builtins.Exception
     |      Create and return a new object.  See help(type) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.BaseException:
     |
     |  __delattr__(self, name, /)
     |      Implement delattr(self, name).
     |
     |  __getattribute__(self, name, /)
     |      Return getattr(self, name).
     |
     |  __reduce__(...)
     |      Helper for pickle.
     |
     |  __repr__(self, /)
     |      Return repr(self).
     |
     |  __setattr__(self, name, value, /)
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(...)
     |
     |  __str__(self, /)
     |      Return str(self).
     |
     |  add_note(...)
     |      Exception.add_note(note) --
     |      add a note to the exception
     |
     |  with_traceback(...)
     |      Exception.with_traceback(tb) --
     |      set self.__traceback__ to tb and return self.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from builtins.BaseException:
     |
     |  __cause__
     |      exception cause
     |
     |  __context__
     |      exception context
     |
     |  __dict__
     |
     |  __suppress_context__
     |
     |  __traceback__
     |
     |  args

    class EmailNotFoundError(firebase_admin.exceptions.NotFoundError)
     |  EmailNotFoundError(message, cause=None, http_response=None)
     |
     |  No user record found for the specified email.
     |
     |  Method resolution order:
     |      EmailNotFoundError
     |      firebase_admin.exceptions.NotFoundError
     |      firebase_admin.exceptions.FirebaseError
     |      builtins.Exception
     |      builtins.BaseException
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, message, cause=None, http_response=None)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  default_message = 'No user record found for the given email'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  cause
     |
     |  code
     |
     |  http_response
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Static methods inherited from builtins.Exception:
     |
     |  __new__(*args, **kwargs) class method of builtins.Exception
     |      Create and return a new object.  See help(type) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.BaseException:
     |
     |  __delattr__(self, name, /)
     |      Implement delattr(self, name).
     |
     |  __getattribute__(self, name, /)
     |      Return getattr(self, name).
     |
     |  __reduce__(...)
     |      Helper for pickle.
     |
     |  __repr__(self, /)
     |      Return repr(self).
     |
     |  __setattr__(self, name, value, /)
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(...)
     |
     |  __str__(self, /)
     |      Return str(self).
     |
     |  add_note(...)
     |      Exception.add_note(note) --
     |      add a note to the exception
     |
     |  with_traceback(...)
     |      Exception.with_traceback(tb) --
     |      set self.__traceback__ to tb and return self.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from builtins.BaseException:
     |
     |  __cause__
     |      exception cause
     |
     |  __context__
     |      exception context
     |
     |  __dict__
     |
     |  __suppress_context__
     |
     |  __traceback__
     |
     |  args

    class InsufficientPermissionError(firebase_admin.exceptions.PermissionDeniedError)
     |  InsufficientPermissionError(message, cause, http_response)
     |
     |  The credential used to initialize the SDK lacks required permissions.
     |
     |  Method resolution order:
     |      InsufficientPermissionError
     |      firebase_admin.exceptions.PermissionDeniedError
     |      firebase_admin.exceptions.FirebaseError
     |      builtins.Exception
     |      builtins.BaseException
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, message, cause, http_response)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  default_message = 'The credential used to initialize the SDK has in......
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  cause
     |
     |  code
     |
     |  http_response
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Static methods inherited from builtins.Exception:
     |
     |  __new__(*args, **kwargs) class method of builtins.Exception
     |      Create and return a new object.  See help(type) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.BaseException:
     |
     |  __delattr__(self, name, /)
     |      Implement delattr(self, name).
     |
     |  __getattribute__(self, name, /)
     |      Return getattr(self, name).
     |
     |  __reduce__(...)
     |      Helper for pickle.
     |
     |  __repr__(self, /)
     |      Return repr(self).
     |
     |  __setattr__(self, name, value, /)
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(...)
     |
     |  __str__(self, /)
     |      Return str(self).
     |
     |  add_note(...)
     |      Exception.add_note(note) --
     |      add a note to the exception
     |
     |  with_traceback(...)
     |      Exception.with_traceback(tb) --
     |      set self.__traceback__ to tb and return self.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from builtins.BaseException:
     |
     |  __cause__
     |      exception cause
     |
     |  __context__
     |      exception context
     |
     |  __dict__
     |
     |  __suppress_context__
     |
     |  __traceback__
     |
     |  args

    class InvalidDynamicLinkDomainError(firebase_admin.exceptions.InvalidArgumentError)
     |  InvalidDynamicLinkDomainError(message, cause, http_response)
     |
     |  Dynamic link domain in ActionCodeSettings is not authorized.
     |
     |  Method resolution order:
     |      InvalidDynamicLinkDomainError
     |      firebase_admin.exceptions.InvalidArgumentError
     |      firebase_admin.exceptions.FirebaseError
     |      builtins.Exception
     |      builtins.BaseException
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, message, cause, http_response)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  default_message = 'Dynamic link domain specified in ActionCodeSettings...
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  cause
     |
     |  code
     |
     |  http_response
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Static methods inherited from builtins.Exception:
     |
     |  __new__(*args, **kwargs) class method of builtins.Exception
     |      Create and return a new object.  See help(type) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.BaseException:
     |
     |  __delattr__(self, name, /)
     |      Implement delattr(self, name).
     |
     |  __getattribute__(self, name, /)
     |      Return getattr(self, name).
     |
     |  __reduce__(...)
     |      Helper for pickle.
     |
     |  __repr__(self, /)
     |      Return repr(self).
     |
     |  __setattr__(self, name, value, /)
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(...)
     |
     |  __str__(self, /)
     |      Return str(self).
     |
     |  add_note(...)
     |      Exception.add_note(note) --
     |      add a note to the exception
     |
     |  with_traceback(...)
     |      Exception.with_traceback(tb) --
     |      set self.__traceback__ to tb and return self.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from builtins.BaseException:
     |
     |  __cause__
     |      exception cause
     |
     |  __context__
     |      exception context
     |
     |  __dict__
     |
     |  __suppress_context__
     |
     |  __traceback__
     |
     |  args

    class InvalidIdTokenError(firebase_admin.exceptions.InvalidArgumentError)
     |  InvalidIdTokenError(message, cause=None, http_response=None)
     |
     |  The provided ID token is not a valid Firebase ID token.
     |
     |  Method resolution order:
     |      InvalidIdTokenError
     |      firebase_admin.exceptions.InvalidArgumentError
     |      firebase_admin.exceptions.FirebaseError
     |      builtins.Exception
     |      builtins.BaseException
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, message, cause=None, http_response=None)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  default_message = 'The provided ID token is invalid'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  cause
     |
     |  code
     |
     |  http_response
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Static methods inherited from builtins.Exception:
     |
     |  __new__(*args, **kwargs) class method of builtins.Exception
     |      Create and return a new object.  See help(type) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.BaseException:
     |
     |  __delattr__(self, name, /)
     |      Implement delattr(self, name).
     |
     |  __getattribute__(self, name, /)
     |      Return getattr(self, name).
     |
     |  __reduce__(...)
     |      Helper for pickle.
     |
     |  __repr__(self, /)
     |      Return repr(self).
     |
     |  __setattr__(self, name, value, /)
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(...)
     |
     |  __str__(self, /)
     |      Return str(self).
     |
     |  add_note(...)
     |      Exception.add_note(note) --
     |      add a note to the exception
     |
     |  with_traceback(...)
     |      Exception.with_traceback(tb) --
     |      set self.__traceback__ to tb and return self.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from builtins.BaseException:
     |
     |  __cause__
     |      exception cause
     |
     |  __context__
     |      exception context
     |
     |  __dict__
     |
     |  __suppress_context__
     |
     |  __traceback__
     |
     |  args

    class PageIterator(builtins.object)
     |  PageIterator(current_page)
     |
     |  An iterator that allows iterating over a sequence of items, one at a time.
     |
     |  This implementation loads a page of items into memory, and iterates on them. When the whole
     |  page has been traversed, it loads another page. This class never keeps more than one page
     |  of entries in memory.
     |
     |  Methods defined here:
     |
     |  __init__(self, current_page)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  __iter__(self)
     |
     |  __next__(self)
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties defined here:
     |
     |  items
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

    class PhoneNumberAlreadyExistsError(firebase_admin.exceptions.AlreadyExistsError)
     |  PhoneNumberAlreadyExistsError(message, cause, http_response)
     |
     |  The user with the provided phone number already exists.
     |
     |  Method resolution order:
     |      PhoneNumberAlreadyExistsError
     |      firebase_admin.exceptions.AlreadyExistsError
     |      firebase_admin.exceptions.FirebaseError
     |      builtins.Exception
     |      builtins.BaseException
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, message, cause, http_response)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  default_message = 'The user with the provided phone number already exi...
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  cause
     |
     |  code
     |
     |  http_response
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Static methods inherited from builtins.Exception:
     |
     |  __new__(*args, **kwargs) class method of builtins.Exception
     |      Create and return a new object.  See help(type) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.BaseException:
     |
     |  __delattr__(self, name, /)
     |      Implement delattr(self, name).
     |
     |  __getattribute__(self, name, /)
     |      Return getattr(self, name).
     |
     |  __reduce__(...)
     |      Helper for pickle.
     |
     |  __repr__(self, /)
     |      Return repr(self).
     |
     |  __setattr__(self, name, value, /)
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(...)
     |
     |  __str__(self, /)
     |      Return str(self).
     |
     |  add_note(...)
     |      Exception.add_note(note) --
     |      add a note to the exception
     |
     |  with_traceback(...)
     |      Exception.with_traceback(tb) --
     |      set self.__traceback__ to tb and return self.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from builtins.BaseException:
     |
     |  __cause__
     |      exception cause
     |
     |  __context__
     |      exception context
     |
     |  __dict__
     |
     |  __suppress_context__
     |
     |  __traceback__
     |
     |  args

    class ResetPasswordExceedLimitError(firebase_admin.exceptions.ResourceExhaustedError)
     |  ResetPasswordExceedLimitError(message, cause=None, http_response=None)
     |
     |  Reset password emails exceeded their limits.
     |
     |  Method resolution order:
     |      ResetPasswordExceedLimitError
     |      firebase_admin.exceptions.ResourceExhaustedError
     |      firebase_admin.exceptions.FirebaseError
     |      builtins.Exception
     |      builtins.BaseException
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, message, cause=None, http_response=None)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  cause
     |
     |  code
     |
     |  http_response
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Static methods inherited from builtins.Exception:
     |
     |  __new__(*args, **kwargs) class method of builtins.Exception
     |      Create and return a new object.  See help(type) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.BaseException:
     |
     |  __delattr__(self, name, /)
     |      Implement delattr(self, name).
     |
     |  __getattribute__(self, name, /)
     |      Return getattr(self, name).
     |
     |  __reduce__(...)
     |      Helper for pickle.
     |
     |  __repr__(self, /)
     |      Return repr(self).
     |
     |  __setattr__(self, name, value, /)
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(...)
     |
     |  __str__(self, /)
     |      Return str(self).
     |
     |  add_note(...)
     |      Exception.add_note(note) --
     |      add a note to the exception
     |
     |  with_traceback(...)
     |      Exception.with_traceback(tb) --
     |      set self.__traceback__ to tb and return self.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from builtins.BaseException:
     |
     |  __cause__
     |      exception cause
     |
     |  __context__
     |      exception context
     |
     |  __dict__
     |
     |  __suppress_context__
     |
     |  __traceback__
     |
     |  args

    class TenantIdMismatchError(firebase_admin.exceptions.InvalidArgumentError)
     |  TenantIdMismatchError(message)
     |
     |  Missing or invalid tenant ID field in the given JWT.
     |
     |  Method resolution order:
     |      TenantIdMismatchError
     |      firebase_admin.exceptions.InvalidArgumentError
     |      firebase_admin.exceptions.FirebaseError
     |      builtins.Exception
     |      builtins.BaseException
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, message)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  cause
     |
     |  code
     |
     |  http_response
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Static methods inherited from builtins.Exception:
     |
     |  __new__(*args, **kwargs) class method of builtins.Exception
     |      Create and return a new object.  See help(type) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.BaseException:
     |
     |  __delattr__(self, name, /)
     |      Implement delattr(self, name).
     |
     |  __getattribute__(self, name, /)
     |      Return getattr(self, name).
     |
     |  __reduce__(...)
     |      Helper for pickle.
     |
     |  __repr__(self, /)
     |      Return repr(self).
     |
     |  __setattr__(self, name, value, /)
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(...)
     |
     |  __str__(self, /)
     |      Return str(self).
     |
     |  add_note(...)
     |      Exception.add_note(note) --
     |      add a note to the exception
     |
     |  with_traceback(...)
     |      Exception.with_traceback(tb) --
     |      set self.__traceback__ to tb and return self.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from builtins.BaseException:
     |
     |  __cause__
     |      exception cause
     |
     |  __context__
     |      exception context
     |
     |  __dict__
     |
     |  __suppress_context__
     |
     |  __traceback__
     |
     |  args

    class TenantNotFoundError(firebase_admin.exceptions.NotFoundError)
     |  TenantNotFoundError(message, cause=None, http_response=None)
     |
     |  No tenant found for the specified identifier.
     |
     |  Method resolution order:
     |      TenantNotFoundError
     |      firebase_admin.exceptions.NotFoundError
     |      firebase_admin.exceptions.FirebaseError
     |      builtins.Exception
     |      builtins.BaseException
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, message, cause=None, http_response=None)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  default_message = 'No tenant found for the given identifier'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  cause
     |
     |  code
     |
     |  http_response
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Static methods inherited from builtins.Exception:
     |
     |  __new__(*args, **kwargs) class method of builtins.Exception
     |      Create and return a new object.  See help(type) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.BaseException:
     |
     |  __delattr__(self, name, /)
     |      Implement delattr(self, name).
     |
     |  __getattribute__(self, name, /)
     |      Return getattr(self, name).
     |
     |  __reduce__(...)
     |      Helper for pickle.
     |
     |  __repr__(self, /)
     |      Return repr(self).
     |
     |  __setattr__(self, name, value, /)
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(...)
     |
     |  __str__(self, /)
     |      Return str(self).
     |
     |  add_note(...)
     |      Exception.add_note(note) --
     |      add a note to the exception
     |
     |  with_traceback(...)
     |      Exception.with_traceback(tb) --
     |      set self.__traceback__ to tb and return self.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from builtins.BaseException:
     |
     |  __cause__
     |      exception cause
     |
     |  __context__
     |      exception context
     |
     |  __dict__
     |
     |  __suppress_context__
     |
     |  __traceback__
     |
     |  args

    class TooManyAttemptsTryLaterError(firebase_admin.exceptions.ResourceExhaustedError)
     |  TooManyAttemptsTryLaterError(message, cause=None, http_response=None)
     |
     |  Rate limited because of too many attempts.
     |
     |  Method resolution order:
     |      TooManyAttemptsTryLaterError
     |      firebase_admin.exceptions.ResourceExhaustedError
     |      firebase_admin.exceptions.FirebaseError
     |      builtins.Exception
     |      builtins.BaseException
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, message, cause=None, http_response=None)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  cause
     |
     |  code
     |
     |  http_response
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Static methods inherited from builtins.Exception:
     |
     |  __new__(*args, **kwargs) class method of builtins.Exception
     |      Create and return a new object.  See help(type) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.BaseException:
     |
     |  __delattr__(self, name, /)
     |      Implement delattr(self, name).
     |
     |  __getattribute__(self, name, /)
     |      Return getattr(self, name).
     |
     |  __reduce__(...)
     |      Helper for pickle.
     |
     |  __repr__(self, /)
     |      Return repr(self).
     |
     |  __setattr__(self, name, value, /)
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(...)
     |
     |  __str__(self, /)
     |      Return str(self).
     |
     |  add_note(...)
     |      Exception.add_note(note) --
     |      add a note to the exception
     |
     |  with_traceback(...)
     |      Exception.with_traceback(tb) --
     |      set self.__traceback__ to tb and return self.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from builtins.BaseException:
     |
     |  __cause__
     |      exception cause
     |
     |  __context__
     |      exception context
     |
     |  __dict__
     |
     |  __suppress_context__
     |
     |  __traceback__
     |
     |  args

    class UidAlreadyExistsError(firebase_admin.exceptions.AlreadyExistsError)
     |  UidAlreadyExistsError(message, cause, http_response)
     |
     |  The user with the provided uid already exists.
     |
     |  Method resolution order:
     |      UidAlreadyExistsError
     |      firebase_admin.exceptions.AlreadyExistsError
     |      firebase_admin.exceptions.FirebaseError
     |      builtins.Exception
     |      builtins.BaseException
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, message, cause, http_response)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  default_message = 'The user with the provided uid already exists'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  cause
     |
     |  code
     |
     |  http_response
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Static methods inherited from builtins.Exception:
     |
     |  __new__(*args, **kwargs) class method of builtins.Exception
     |      Create and return a new object.  See help(type) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.BaseException:
     |
     |  __delattr__(self, name, /)
     |      Implement delattr(self, name).
     |
     |  __getattribute__(self, name, /)
     |      Return getattr(self, name).
     |
     |  __reduce__(...)
     |      Helper for pickle.
     |
     |  __repr__(self, /)
     |      Return repr(self).
     |
     |  __setattr__(self, name, value, /)
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(...)
     |
     |  __str__(self, /)
     |      Return str(self).
     |
     |  add_note(...)
     |      Exception.add_note(note) --
     |      add a note to the exception
     |
     |  with_traceback(...)
     |      Exception.with_traceback(tb) --
     |      set self.__traceback__ to tb and return self.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from builtins.BaseException:
     |
     |  __cause__
     |      exception cause
     |
     |  __context__
     |      exception context
     |
     |  __dict__
     |
     |  __suppress_context__
     |
     |  __traceback__
     |
     |  args

    class UnexpectedResponseError(firebase_admin.exceptions.UnknownError)
     |  UnexpectedResponseError(message, cause=None, http_response=None)
     |
     |  Backend service responded with an unexpected or malformed response.
     |
     |  Method resolution order:
     |      UnexpectedResponseError
     |      firebase_admin.exceptions.UnknownError
     |      firebase_admin.exceptions.FirebaseError
     |      builtins.Exception
     |      builtins.BaseException
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, message, cause=None, http_response=None)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  cause
     |
     |  code
     |
     |  http_response
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Static methods inherited from builtins.Exception:
     |
     |  __new__(*args, **kwargs) class method of builtins.Exception
     |      Create and return a new object.  See help(type) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.BaseException:
     |
     |  __delattr__(self, name, /)
     |      Implement delattr(self, name).
     |
     |  __getattribute__(self, name, /)
     |      Return getattr(self, name).
     |
     |  __reduce__(...)
     |      Helper for pickle.
     |
     |  __repr__(self, /)
     |      Return repr(self).
     |
     |  __setattr__(self, name, value, /)
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(...)
     |
     |  __str__(self, /)
     |      Return str(self).
     |
     |  add_note(...)
     |      Exception.add_note(note) --
     |      add a note to the exception
     |
     |  with_traceback(...)
     |      Exception.with_traceback(tb) --
     |      set self.__traceback__ to tb and return self.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from builtins.BaseException:
     |
     |  __cause__
     |      exception cause
     |
     |  __context__
     |      exception context
     |
     |  __dict__
     |
     |  __suppress_context__
     |
     |  __traceback__
     |
     |  args

    class UserDisabledError(firebase_admin.exceptions.InvalidArgumentError)
     |  UserDisabledError(message, cause=None, http_response=None)
     |
     |  An operation failed due to a user record being disabled.
     |
     |  Method resolution order:
     |      UserDisabledError
     |      firebase_admin.exceptions.InvalidArgumentError
     |      firebase_admin.exceptions.FirebaseError
     |      builtins.Exception
     |      builtins.BaseException
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, message, cause=None, http_response=None)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  default_message = 'The user record is disabled'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  cause
     |
     |  code
     |
     |  http_response
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Static methods inherited from builtins.Exception:
     |
     |  __new__(*args, **kwargs) class method of builtins.Exception
     |      Create and return a new object.  See help(type) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.BaseException:
     |
     |  __delattr__(self, name, /)
     |      Implement delattr(self, name).
     |
     |  __getattribute__(self, name, /)
     |      Return getattr(self, name).
     |
     |  __reduce__(...)
     |      Helper for pickle.
     |
     |  __repr__(self, /)
     |      Return repr(self).
     |
     |  __setattr__(self, name, value, /)
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(...)
     |
     |  __str__(self, /)
     |      Return str(self).
     |
     |  add_note(...)
     |      Exception.add_note(note) --
     |      add a note to the exception
     |
     |  with_traceback(...)
     |      Exception.with_traceback(tb) --
     |      set self.__traceback__ to tb and return self.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from builtins.BaseException:
     |
     |  __cause__
     |      exception cause
     |
     |  __context__
     |      exception context
     |
     |  __dict__
     |
     |  __suppress_context__
     |
     |  __traceback__
     |
     |  args

    class UserNotFoundError(firebase_admin.exceptions.NotFoundError)
     |  UserNotFoundError(message, cause=None, http_response=None)
     |
     |  No user record found for the specified identifier.
     |
     |  Method resolution order:
     |      UserNotFoundError
     |      firebase_admin.exceptions.NotFoundError
     |      firebase_admin.exceptions.FirebaseError
     |      builtins.Exception
     |      builtins.BaseException
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, message, cause=None, http_response=None)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  default_message = 'No user record found for the given identifier'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  cause
     |
     |  code
     |
     |  http_response
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Static methods inherited from builtins.Exception:
     |
     |  __new__(*args, **kwargs) class method of builtins.Exception
     |      Create and return a new object.  See help(type) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.BaseException:
     |
     |  __delattr__(self, name, /)
     |      Implement delattr(self, name).
     |
     |  __getattribute__(self, name, /)
     |      Return getattr(self, name).
     |
     |  __reduce__(...)
     |      Helper for pickle.
     |
     |  __repr__(self, /)
     |      Return repr(self).
     |
     |  __setattr__(self, name, value, /)
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(...)
     |
     |  __str__(self, /)
     |      Return str(self).
     |
     |  add_note(...)
     |      Exception.add_note(note) --
     |      add a note to the exception
     |
     |  with_traceback(...)
     |      Exception.with_traceback(tb) --
     |      set self.__traceback__ to tb and return self.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from builtins.BaseException:
     |
     |  __cause__
     |      exception cause
     |
     |  __context__
     |      exception context
     |
     |  __dict__
     |
     |  __suppress_context__
     |
     |  __traceback__
     |
     |  args

FUNCTIONS
    build_update_mask(params)
        Creates an update mask list from the given dictionary.

    get_emulator_host()

    handle_auth_backend_error(error)
        Converts a requests error received from the Firebase Auth service into a FirebaseError.

    is_emulated()

    validate_action_type(action_type)

    validate_boolean(value, label)
        Validates that the given value is a boolean.

    validate_bytes(value, label, required=False)

    validate_custom_claims(custom_claims, required=False)
        Validates the specified custom claims.

        Custom claims must be specified as a JSON string. The string must not exceed 1000
        characters, and the parsed JSON payload must not contain reserved JWT claims.

    validate_display_name(display_name, required=False)

    validate_email(email, required=False)

    validate_int(value, label, low=None, high=None)
        Validates that the given value represents an integer.

        There are several ways to represent an integer in Python (e.g. 2, 2L, 2.0). This method allows
        for all such representations except for booleans. Booleans also behave like integers, but
        always translate to 1 and 0. Passing a boolean to an API that expects integers is most likely
        a developer error.

    validate_password(password, required=False)

    validate_phone(phone, required=False)
        Validates the specified phone number.

        Phone number vlidation is very lax here. Backend will enforce E.164 spec compliance, and
        normalize accordingly. Here we check if the number starts with + sign, and contains at
        least one alphanumeric character.

    validate_photo_url(photo_url, required=False)
        Parses and validates the given URL string.

    validate_provider_id(provider_id, required=True)

    validate_provider_ids(provider_ids, required=False)

    validate_provider_uid(provider_uid, required=True)

    validate_string(value, label)
        Validates that the given value is a string.

    validate_timestamp(timestamp, label, required=False)
        Validates the given timestamp value. Timestamps must be positive integers.

    validate_uid(uid, required=False)

DATA
    EMULATOR_HOST_ENV_VAR = 'FIREBASE_AUTH_EMULATOR_HOST'
    MAX_CLAIMS_PAYLOAD_SIZE = 1000
    RESERVED_CLAIMS = {'acr', 'amr', 'at_hash', 'aud', 'auth_time', 'azp',...
    VALID_EMAIL_ACTION_TYPES = {'EMAIL_SIGNIN', 'PASSWORD_RESET', 'VERIFY_...

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\backend\lib\site-packages\firebase_admin\_auth_utils.py



================================================================================
Help on module backend.Lib.site-packages.firebase_admin._gapic_utils in backend.Lib.site-packages.firebase_admin:

NAME
    backend.Lib.site-packages.firebase_admin._gapic_utils - Internal utilities for interacting with Google API client.

FUNCTIONS
    handle_googleapiclient_error(error, message=None, code=None, http_response=None)
        Constructs a ``FirebaseError`` from the given googleapiclient error.

        This method is agnostic of the remote service that produced the error, whether it is a GCP
        service or otherwise. Therefore, this method does not attempt to parse the error response in
        any way.

        Args:
            error: An error raised by the googleapiclient module while making an HTTP call.
            message: A message to be included in the resulting ``FirebaseError`` (optional). If not
                specified the string representation of the ``error`` argument is used as the message.
            code: A GCP error code that will be used to determine the resulting error type (optional).
                If not specified the HTTP status code on the error response is used to determine a
                suitable error code.
            http_response: A requests HTTP response object to associate with the exception (optional).
                If not specified, one will be created from the ``error``.

        Returns:
            FirebaseError: A ``FirebaseError`` that can be raised to the user code.

    handle_platform_error_from_googleapiclient(error, handle_func=None)
        Constructs a ``FirebaseError`` from the given googleapiclient error.

        This can be used to handle errors returned by Google Cloud Platform (GCP) APIs.

        Args:
            error: An error raised by the googleapiclient while making an HTTP call to a GCP API.
            handle_func: A function that can be used to handle platform errors in a custom way. When
                specified, this function will be called with three arguments. It has the same
                signature as ```_handle_func_googleapiclient``, but may return ``None``.

        Returns:
            FirebaseError: A ``FirebaseError`` that can be raised to the user code.

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\backend\lib\site-packages\firebase_admin\_gapic_utils.py



================================================================================
Help on module backend.Lib.site-packages.firebase_admin._messaging_utils in backend.Lib.site-packages.firebase_admin:

NAME
    backend.Lib.site-packages.firebase_admin._messaging_utils - Types and utilities used by the messaging (FCM) module.

CLASSES
    builtins.object
        APNSConfig
        APNSFCMOptions
        APNSPayload
        AndroidConfig
        AndroidFCMOptions
        AndroidNotification
        Aps
        ApsAlert
        CriticalSound
        FCMOptions
        LightSettings
        Notification
        WebpushConfig
        WebpushFCMOptions
        WebpushNotification
        WebpushNotificationAction
    firebase_admin.exceptions.NotFoundError(firebase_admin.exceptions.FirebaseError)
        UnregisteredError
    firebase_admin.exceptions.PermissionDeniedError(firebase_admin.exceptions.FirebaseError)
        SenderIdMismatchError
    firebase_admin.exceptions.ResourceExhaustedError(firebase_admin.exceptions.FirebaseError)
        QuotaExceededError
    firebase_admin.exceptions.UnauthenticatedError(firebase_admin.exceptions.FirebaseError)
        ThirdPartyAuthError

    class APNSConfig(builtins.object)
     |  APNSConfig(headers=None, payload=None, fcm_options=None)
     |
     |  APNS-specific options that can be included in a message.
     |
     |  Refer to `APNS Documentation`_ for more information.
     |
     |  Args:
     |      headers: A dictionary of headers (optional).
     |      payload: A ``messaging.APNSPayload`` to be included in the message (optional).
     |      fcm_options: A ``messaging.APNSFCMOptions`` instance to be included in the message
     |          (optional).
     |
     |  .. _APNS Documentation: https://developer.apple.com/library/content/documentation        /NetworkingInternet/Conceptual/RemoteNotificationsPG/CommunicatingwithAPNs.html
     |
     |  Methods defined here:
     |
     |  __init__(self, headers=None, payload=None, fcm_options=None)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

    class APNSFCMOptions(builtins.object)
     |  APNSFCMOptions(analytics_label=None, image=None)
     |
     |  Options for features provided by the FCM SDK for iOS.
     |
     |  Args:
     |      analytics_label: contains additional options for features provided by the FCM iOS SDK
     |          (optional).
     |      image: contains the URL of an image that is going to be displayed in a notification
     |          (optional).
     |
     |  Methods defined here:
     |
     |  __init__(self, analytics_label=None, image=None)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

    class APNSPayload(builtins.object)
     |  APNSPayload(aps, **kwargs)
     |
     |  Payload of an APNS message.
     |
     |  Args:
     |      aps: A ``messaging.Aps`` instance to be included in the payload.
     |      **kwargs: Arbitrary keyword arguments to be included as custom fields in the payload
     |          (optional).
     |
     |  Methods defined here:
     |
     |  __init__(self, aps, **kwargs)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

    class AndroidConfig(builtins.object)
     |  AndroidConfig(collapse_key=None, priority=None, ttl=None, restricted_package_name=None, data=None, notification=None, fcm_options=None, direct_boot_ok=None)
     |
     |  Android-specific options that can be included in a message.
     |
     |  Args:
     |      collapse_key: Collapse key string for the message (optional). This is an identifier for a
     |          group of messages that can be collapsed, so that only the last message is sent when
     |          delivery can be resumed. A maximum of 4 different collapse keys may be active at a
     |          given time.
     |      priority: Priority of the message (optional). Must be one of ``high`` or ``normal``.
     |      ttl: The time-to-live duration of the message (optional). This can be specified
     |          as a numeric seconds value or a ``datetime.timedelta`` instance.
     |      restricted_package_name: The package name of the application where the registration tokens
     |          must match in order to receive the message (optional).
     |      data: A dictionary of data fields (optional). All keys and values in the dictionary must be
     |          strings. When specified, overrides any data fields set via ``Message.data``.
     |      notification: A ``messaging.AndroidNotification`` to be included in the message (optional).
     |      fcm_options: A ``messaging.AndroidFCMOptions`` to be included in the message (optional).
     |      direct_boot_ok: A boolean indicating whether messages will be allowed to be delivered to
     |          the app while the device is in direct boot mode (optional).
     |
     |  Methods defined here:
     |
     |  __init__(self, collapse_key=None, priority=None, ttl=None, restricted_package_name=None, data=None, notification=None, fcm_options=None, direct_boot_ok=None)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

    class AndroidFCMOptions(builtins.object)
     |  AndroidFCMOptions(analytics_label=None)
     |
     |  Options for features provided by the FCM SDK for Android.
     |
     |  Args:
     |      analytics_label: contains additional options for features provided by the FCM Android SDK
     |          (optional).
     |
     |  Methods defined here:
     |
     |  __init__(self, analytics_label=None)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

    class AndroidNotification(builtins.object)
     |  AndroidNotification(title=None, body=None, icon=None, color=None, sound=None, tag=None, click_action=None, body_loc_key=None, body_loc_args=None, title_loc_key=None, title_loc_args=None, channel_id=None, image=None, ticker=None, sticky=None, event_timestamp=None, local_only=None, priority=None, vibrate_timings_millis=None, default_vibrate_timings=None, default_sound=None, light_settings=None, default_light_settings=None, visibility=None, notification_count=None)
     |
     |  Android-specific notification parameters.
     |
     |  Args:
     |      title: Title of the notification (optional). If specified, overrides the title set via
     |          ``messaging.Notification``.
     |      body: Body of the notification (optional). If specified, overrides the body set via
     |          ``messaging.Notification``.
     |      icon: Icon of the notification (optional).
     |      color: Color of the notification icon expressed in ``#rrggbb`` form (optional).
     |      sound: Sound to be played when the device receives the notification (optional). This is
     |          usually the file name of the sound resource.
     |      tag: Tag of the notification (optional). This is an identifier used to replace existing
     |          notifications in the notification drawer. If not specified, each request creates a new
     |          notification.
     |      click_action: The action associated with a user click on the notification (optional). If
     |          specified, an activity with a matching intent filter is launched when a user clicks on
     |          the notification.
     |      body_loc_key: Key of the body string in the app's string resources to use to localize the
     |          body text (optional).
     |      body_loc_args: A list of resource keys that will be used in place of the format specifiers
     |          in ``body_loc_key`` (optional).
     |      title_loc_key: Key of the title string in the app's string resources to use to localize the
     |          title text (optional).
     |      title_loc_args: A list of resource keys that will be used in place of the format specifiers
     |          in ``title_loc_key`` (optional).
     |      channel_id: channel_id of the notification (optional).
     |      image: Image url of the notification (optional).
     |      ticker: Sets the ``ticker`` text, which is sent to accessibility services. Prior to API
     |          level 21 (Lollipop), sets the text that is displayed in the status bar when the
     |          notification first arrives (optional).
     |      sticky: When set to ``False`` or unset, the notification is automatically dismissed when the
     |          user clicks it in the panel. When set to ``True``, the notification persists even when
     |          the user clicks it (optional).
     |      event_timestamp: For notifications that inform users about events with an absolute time
     |          reference, sets the time that the event in the notification occurred as a
     |          ``datetime.datetime`` instance. If the ``datetime.datetime`` instance is naive, it
     |          defaults to be in the UTC timezone. Notifications in the panel are sorted by this time
     |          (optional).
     |      local_only: Sets whether or not this notification is relevant only to the current device.
     |          Some notifications can be bridged to other devices for remote display, such as a Wear OS
     |          watch. This hint can be set to recommend this notification not be bridged (optional).
     |          See Wear OS guides:
     |          https://developer.android.com/training/wearables/notifications/bridger#existing-method-of-preventing-bridging
     |      priority: Sets the relative priority for this notification. Low-priority notifications may
     |          be hidden from the user in certain situations. Note this priority differs from
     |          ``AndroidMessagePriority``. This priority is processed by the client after the message
     |          has been delivered. Whereas ``AndroidMessagePriority`` is an FCM concept that controls
     |          when the message is delivered (optional). Must be one of ``default``, ``min``, ``low``,
     |          ``high``, ``max`` or ``normal``.
     |      vibrate_timings_millis: Sets the vibration pattern to use. Pass in an array of milliseconds
     |          to turn the vibrator on or off. The first value indicates the duration to wait before
     |          turning the vibrator on. The next value indicates the duration to keep the vibrator on.
     |          Subsequent values alternate between duration to turn the vibrator off and to turn the
     |          vibrator on. If ``vibrate_timings`` is set and ``default_vibrate_timings`` is set to
     |          ``True``, the default value is used instead of the user-specified ``vibrate_timings``.
     |      default_vibrate_timings: If set to ``True``, use the Android framework's default vibrate
     |          pattern for the notification (optional). Default values are specified in ``config.xml``
     |          https://android.googlesource.com/platform/frameworks/base/+/master/core/res/res/values/config.xml.
     |          If ``default_vibrate_timings`` is set to ``True`` and ``vibrate_timings`` is also set,
     |          the default value is used instead of the user-specified ``vibrate_timings``.
     |      default_sound: If set to ``True``, use the Android framework's default sound for the
     |          notification (optional). Default values are specified in ``config.xml``
     |          https://android.googlesource.com/platform/frameworks/base/+/master/core/res/res/values/config.xml
     |      light_settings: Settings to control the notification's LED blinking rate and color if LED is
     |          available on the device. The total blinking time is controlled by the OS (optional).
     |      default_light_settings: If set to ``True``, use the Android framework's default LED light
     |          settings for the notification. Default values are specified in ``config.xml``
     |          https://android.googlesource.com/platform/frameworks/base/+/master/core/res/res/values/config.xml.
     |          If ``default_light_settings`` is set to ``True`` and ``light_settings`` is also set, the
     |          user-specified ``light_settings`` is used instead of the default value.
     |      visibility: Sets the visibility of the notification. Must be either ``private``, ``public``,
     |          or ``secret``. If unspecified, default to ``private``.
     |      notification_count: Sets the number of items this notification represents. May be displayed
     |          as a badge count for Launchers that support badging. See ``NotificationBadge``
     |          https://developer.android.com/training/notify-user/badges. For example, this might be
     |          useful if you're using just one notification to represent multiple new messages but you
     |          want the count here to represent the number of total new messages. If zero or
     |          unspecified, systems that support badging use the default, which is to increment a
     |          number displayed on the long-press menu each time a new notification arrives.
     |
     |  Methods defined here:
     |
     |  __init__(self, title=None, body=None, icon=None, color=None, sound=None, tag=None, click_action=None, body_loc_key=None, body_loc_args=None, title_loc_key=None, title_loc_args=None, channel_id=None, image=None, ticker=None, sticky=None, event_timestamp=None, local_only=None, priority=None, vibrate_timings_millis=None, default_vibrate_timings=None, default_sound=None, light_settings=None, default_light_settings=None, visibility=None, notification_count=None)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

    class Aps(builtins.object)
     |  Aps(alert=None, badge=None, sound=None, content_available=None, category=None, thread_id=None, mutable_content=None, custom_data=None)
     |
     |  Aps dictionary to be included in an APNS payload.
     |
     |  Args:
     |      alert: A string or a ``messaging.ApsAlert`` instance (optional).
     |      badge: A number representing the badge to be displayed with the message (optional).
     |      sound: Name of the sound file to be played with the message or a
     |          ``messaging.CriticalSound`` instance (optional).
     |      content_available: A boolean indicating whether to configure a background update
     |          notification (optional).
     |      category: String identifier representing the message type (optional).
     |      thread_id: An app-specific string identifier for grouping messages (optional).
     |      mutable_content: A boolean indicating whether to support mutating notifications at
     |          the client using app extensions (optional).
     |      custom_data: A dict of custom key-value pairs to be included in the Aps dictionary
     |          (optional).
     |
     |  Methods defined here:
     |
     |  __init__(self, alert=None, badge=None, sound=None, content_available=None, category=None, thread_id=None, mutable_content=None, custom_data=None)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

    class ApsAlert(builtins.object)
     |  ApsAlert(title=None, subtitle=None, body=None, loc_key=None, loc_args=None, title_loc_key=None, title_loc_args=None, action_loc_key=None, launch_image=None, custom_data=None)
     |
     |  An alert that can be included in ``messaging.Aps``.
     |
     |  Args:
     |      title: Title of the alert (optional). If specified, overrides the title set via
     |          ``messaging.Notification``.
     |      subtitle: Subtitle of the alert (optional).
     |      body: Body of the alert (optional). If specified, overrides the body set via
     |          ``messaging.Notification``.
     |      loc_key: Key of the body string in the app's string resources to use to localize the
     |          body text (optional).
     |      loc_args: A list of resource keys that will be used in place of the format specifiers
     |          in ``loc_key`` (optional).
     |      title_loc_key: Key of the title string in the app's string resources to use to localize the
     |          title text (optional).
     |      title_loc_args: A list of resource keys that will be used in place of the format specifiers
     |          in ``title_loc_key`` (optional).
     |      action_loc_key: Key of the text in the app's string resources to use to localize the
     |          action button text (optional).
     |      launch_image: Image for the notification action (optional).
     |      custom_data: A dict of custom key-value pairs to be included in the ApsAlert dictionary
     |          (optional)
     |
     |  Methods defined here:
     |
     |  __init__(self, title=None, subtitle=None, body=None, loc_key=None, loc_args=None, title_loc_key=None, title_loc_args=None, action_loc_key=None, launch_image=None, custom_data=None)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

    class CriticalSound(builtins.object)
     |  CriticalSound(name, critical=None, volume=None)
     |
     |  Critical alert sound configuration that can be included in ``messaging.Aps``.
     |
     |  Args:
     |      name: The name of a sound file in your app's main bundle or in the ``Library/Sounds``
     |          folder of your app's container directory. Specify the string ``default`` to play the
     |          system sound.
     |      critical: Set to ``True`` to set the critical alert flag on the sound configuration
     |          (optional).
     |      volume: The volume for the critical alert's sound. Must be a value between 0.0 (silent)
     |          and 1.0 (full volume) (optional).
     |
     |  Methods defined here:
     |
     |  __init__(self, name, critical=None, volume=None)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

    class FCMOptions(builtins.object)
     |  FCMOptions(analytics_label=None)
     |
     |  Options for features provided by SDK.
     |
     |  Args:
     |      analytics_label: contains additional options to use across all platforms (optional).
     |
     |  Methods defined here:
     |
     |  __init__(self, analytics_label=None)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

    class LightSettings(builtins.object)
     |  LightSettings(color, light_on_duration_millis, light_off_duration_millis)
     |
     |  Represents settings to control notification LED that can be included in a
     |  ``messaging.AndroidNotification``.
     |
     |  Args:
     |      color: Sets the color of the LED in ``#rrggbb`` or ``#rrggbbaa`` format.
     |      light_on_duration_millis: Along with ``light_off_duration``, defines the blink rate of LED
     |          flashes.
     |      light_off_duration_millis: Along with ``light_on_duration``, defines the blink rate of LED
     |          flashes.
     |
     |  Methods defined here:
     |
     |  __init__(self, color, light_on_duration_millis, light_off_duration_millis)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

    class Notification(builtins.object)
     |  Notification(title=None, body=None, image=None)
     |
     |  A notification that can be included in a message.
     |
     |  Args:
     |      title: Title of the notification (optional).
     |      body: Body of the notification (optional).
     |      image: Image url of the notification (optional)
     |
     |  Methods defined here:
     |
     |  __init__(self, title=None, body=None, image=None)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

    class QuotaExceededError(firebase_admin.exceptions.ResourceExhaustedError)
     |  QuotaExceededError(message, cause=None, http_response=None)
     |
     |  Sending limit exceeded for the message target.
     |
     |  Method resolution order:
     |      QuotaExceededError
     |      firebase_admin.exceptions.ResourceExhaustedError
     |      firebase_admin.exceptions.FirebaseError
     |      builtins.Exception
     |      builtins.BaseException
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, message, cause=None, http_response=None)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  cause
     |
     |  code
     |
     |  http_response
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Static methods inherited from builtins.Exception:
     |
     |  __new__(*args, **kwargs) class method of builtins.Exception
     |      Create and return a new object.  See help(type) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.BaseException:
     |
     |  __delattr__(self, name, /)
     |      Implement delattr(self, name).
     |
     |  __getattribute__(self, name, /)
     |      Return getattr(self, name).
     |
     |  __reduce__(...)
     |      Helper for pickle.
     |
     |  __repr__(self, /)
     |      Return repr(self).
     |
     |  __setattr__(self, name, value, /)
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(...)
     |
     |  __str__(self, /)
     |      Return str(self).
     |
     |  add_note(...)
     |      Exception.add_note(note) --
     |      add a note to the exception
     |
     |  with_traceback(...)
     |      Exception.with_traceback(tb) --
     |      set self.__traceback__ to tb and return self.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from builtins.BaseException:
     |
     |  __cause__
     |      exception cause
     |
     |  __context__
     |      exception context
     |
     |  __dict__
     |
     |  __suppress_context__
     |
     |  __traceback__
     |
     |  args

    class SenderIdMismatchError(firebase_admin.exceptions.PermissionDeniedError)
     |  SenderIdMismatchError(message, cause=None, http_response=None)
     |
     |  The authenticated sender ID is different from the sender ID for the registration token.
     |
     |  Method resolution order:
     |      SenderIdMismatchError
     |      firebase_admin.exceptions.PermissionDeniedError
     |      firebase_admin.exceptions.FirebaseError
     |      builtins.Exception
     |      builtins.BaseException
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, message, cause=None, http_response=None)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  cause
     |
     |  code
     |
     |  http_response
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Static methods inherited from builtins.Exception:
     |
     |  __new__(*args, **kwargs) class method of builtins.Exception
     |      Create and return a new object.  See help(type) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.BaseException:
     |
     |  __delattr__(self, name, /)
     |      Implement delattr(self, name).
     |
     |  __getattribute__(self, name, /)
     |      Return getattr(self, name).
     |
     |  __reduce__(...)
     |      Helper for pickle.
     |
     |  __repr__(self, /)
     |      Return repr(self).
     |
     |  __setattr__(self, name, value, /)
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(...)
     |
     |  __str__(self, /)
     |      Return str(self).
     |
     |  add_note(...)
     |      Exception.add_note(note) --
     |      add a note to the exception
     |
     |  with_traceback(...)
     |      Exception.with_traceback(tb) --
     |      set self.__traceback__ to tb and return self.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from builtins.BaseException:
     |
     |  __cause__
     |      exception cause
     |
     |  __context__
     |      exception context
     |
     |  __dict__
     |
     |  __suppress_context__
     |
     |  __traceback__
     |
     |  args

    class ThirdPartyAuthError(firebase_admin.exceptions.UnauthenticatedError)
     |  ThirdPartyAuthError(message, cause=None, http_response=None)
     |
     |  APNs certificate or web push auth key was invalid or missing.
     |
     |  Method resolution order:
     |      ThirdPartyAuthError
     |      firebase_admin.exceptions.UnauthenticatedError
     |      firebase_admin.exceptions.FirebaseError
     |      builtins.Exception
     |      builtins.BaseException
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, message, cause=None, http_response=None)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  cause
     |
     |  code
     |
     |  http_response
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Static methods inherited from builtins.Exception:
     |
     |  __new__(*args, **kwargs) class method of builtins.Exception
     |      Create and return a new object.  See help(type) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.BaseException:
     |
     |  __delattr__(self, name, /)
     |      Implement delattr(self, name).
     |
     |  __getattribute__(self, name, /)
     |      Return getattr(self, name).
     |
     |  __reduce__(...)
     |      Helper for pickle.
     |
     |  __repr__(self, /)
     |      Return repr(self).
     |
     |  __setattr__(self, name, value, /)
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(...)
     |
     |  __str__(self, /)
     |      Return str(self).
     |
     |  add_note(...)
     |      Exception.add_note(note) --
     |      add a note to the exception
     |
     |  with_traceback(...)
     |      Exception.with_traceback(tb) --
     |      set self.__traceback__ to tb and return self.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from builtins.BaseException:
     |
     |  __cause__
     |      exception cause
     |
     |  __context__
     |      exception context
     |
     |  __dict__
     |
     |  __suppress_context__
     |
     |  __traceback__
     |
     |  args

    class UnregisteredError(firebase_admin.exceptions.NotFoundError)
     |  UnregisteredError(message, cause=None, http_response=None)
     |
     |  App instance was unregistered from FCM.
     |
     |  This usually means that the token used is no longer valid and a new one must be used.
     |
     |  Method resolution order:
     |      UnregisteredError
     |      firebase_admin.exceptions.NotFoundError
     |      firebase_admin.exceptions.FirebaseError
     |      builtins.Exception
     |      builtins.BaseException
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, message, cause=None, http_response=None)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  cause
     |
     |  code
     |
     |  http_response
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from firebase_admin.exceptions.FirebaseError:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Static methods inherited from builtins.Exception:
     |
     |  __new__(*args, **kwargs) class method of builtins.Exception
     |      Create and return a new object.  See help(type) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.BaseException:
     |
     |  __delattr__(self, name, /)
     |      Implement delattr(self, name).
     |
     |  __getattribute__(self, name, /)
     |      Return getattr(self, name).
     |
     |  __reduce__(...)
     |      Helper for pickle.
     |
     |  __repr__(self, /)
     |      Return repr(self).
     |
     |  __setattr__(self, name, value, /)
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(...)
     |
     |  __str__(self, /)
     |      Return str(self).
     |
     |  add_note(...)
     |      Exception.add_note(note) --
     |      add a note to the exception
     |
     |  with_traceback(...)
     |      Exception.with_traceback(tb) --
     |      set self.__traceback__ to tb and return self.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from builtins.BaseException:
     |
     |  __cause__
     |      exception cause
     |
     |  __context__
     |      exception context
     |
     |  __dict__
     |
     |  __suppress_context__
     |
     |  __traceback__
     |
     |  args

    class WebpushConfig(builtins.object)
     |  WebpushConfig(headers=None, data=None, notification=None, fcm_options=None)
     |
     |  Webpush-specific options that can be included in a message.
     |
     |  Args:
     |      headers: A dictionary of headers (optional). Refer `Webpush Specification`_ for supported
     |          headers.
     |      data: A dictionary of data fields (optional). All keys and values in the dictionary must be
     |          strings. When specified, overrides any data fields set via ``Message.data``.
     |      notification: A ``messaging.WebpushNotification`` to be included in the message (optional).
     |      fcm_options: A ``messaging.WebpushFCMOptions`` instance to be included in the message
     |          (optional).
     |
     |  .. _Webpush Specification: https://tools.ietf.org/html/rfc8030#section-5
     |
     |  Methods defined here:
     |
     |  __init__(self, headers=None, data=None, notification=None, fcm_options=None)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

    class WebpushFCMOptions(builtins.object)
     |  WebpushFCMOptions(link=None)
     |
     |  Options for features provided by the FCM SDK for Web.
     |
     |  Args:
     |      link: The link to open when the user clicks on the notification. Must be an HTTPS URL
     |          (optional).
     |
     |  Methods defined here:
     |
     |  __init__(self, link=None)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

    class WebpushNotification(builtins.object)
     |  WebpushNotification(title=None, body=None, icon=None, actions=None, badge=None, data=None, direction=None, image=None, language=None, renotify=None, require_interaction=None, silent=None, tag=None, timestamp_millis=None, vibrate=None, custom_data=None)
     |
     |  Webpush-specific notification parameters.
     |
     |  Refer to the `Notification Reference`_ for more information.
     |
     |  Args:
     |      title: Title of the notification (optional). If specified, overrides the title set via
     |          ``messaging.Notification``.
     |      body: Body of the notification (optional). If specified, overrides the body set via
     |          ``messaging.Notification``.
     |      icon: Icon URL of the notification (optional).
     |      actions: A list of ``messaging.WebpushNotificationAction`` instances (optional).
     |      badge: URL of the image used to represent the notification when there is
     |          not enough space to display the notification itself (optional).
     |      data: Any arbitrary JSON data that should be associated with the notification (optional).
     |      direction: The direction in which to display the notification (optional). Must be either
     |          'auto', 'ltr' or 'rtl'.
     |      image: The URL of an image to be displayed in the notification (optional).
     |      language: Notification language (optional).
     |      renotify: A boolean indicating whether the user should be notified after a new
     |          notification replaces an old one (optional).
     |      require_interaction: A boolean indicating whether a notification should remain active
     |          until the user clicks or dismisses it, rather than closing automatically (optional).
     |      silent: ``True`` to indicate that the notification should be silent (optional).
     |      tag: An identifying tag on the notification (optional).
     |      timestamp_millis: A timestamp value in milliseconds on the notification (optional).
     |      vibrate: A vibration pattern for the device's vibration hardware to emit when the
     |          notification fires (optional). The pattern is specified as an integer array.
     |      custom_data: A dict of custom key-value pairs to be included in the notification
     |          (optional)
     |
     |  .. _Notification Reference: https://developer.mozilla.org/en-US/docs/Web/API        /notification/Notification
     |
     |  Methods defined here:
     |
     |  __init__(self, title=None, body=None, icon=None, actions=None, badge=None, data=None, direction=None, image=None, language=None, renotify=None, require_interaction=None, silent=None, tag=None, timestamp_millis=None, vibrate=None, custom_data=None)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

    class WebpushNotificationAction(builtins.object)
     |  WebpushNotificationAction(action, title, icon=None)
     |
     |  An action available to the users when the notification is presented.
     |
     |  Args:
     |      action: Action string.
     |      title: Title string.
     |      icon: Icon URL for the action (optional).
     |
     |  Methods defined here:
     |
     |  __init__(self, action, title, icon=None)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\backend\lib\site-packages\firebase_admin\_messaging_utils.py



================================================================================
Help on module backend.Lib.site-packages.firebase_admin._utils in backend.Lib.site-packages.firebase_admin:

NAME
    backend.Lib.site-packages.firebase_admin._utils - Internal utilities common to all modules.

CLASSES
    google.auth.credentials.Credentials(google.auth._credentials_base._BaseCredentials)
        EmulatorAdminCredentials

    class EmulatorAdminCredentials(google.auth.credentials.Credentials)
     |  Credentials for use with the firebase local emulator.
     |
     |  This is used instead of user-supplied credentials or ADC.  It will silently do nothing when
     |  asked to refresh credentials.
     |
     |  Method resolution order:
     |      EmulatorAdminCredentials
     |      google.auth.credentials.Credentials
     |      google.auth._credentials_base._BaseCredentials
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  refresh(self, request)
     |      Refreshes the access token.
     |
     |      Args:
     |          request (google.auth.transport.Request): The object used to make
     |              HTTP requests.
     |
     |      Raises:
     |          google.auth.exceptions.RefreshError: If the credentials could
     |              not be refreshed.
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  __abstractmethods__ = frozenset()
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from google.auth.credentials.Credentials:
     |
     |  apply(self, headers, token=None)
     |      Apply the token to the authentication header.
     |
     |      Args:
     |          headers (Mapping): The HTTP request headers.
     |          token (Optional[str]): If specified, overrides the current access
     |              token.
     |
     |  before_request(self, request, method, url, headers)
     |      Performs credential-specific before request logic.
     |
     |      Refreshes the credentials if necessary, then calls :meth:`apply` to
     |      apply the token to the authentication header.
     |
     |      Args:
     |          request (google.auth.transport.Request): The object used to make
     |              HTTP requests.
     |          method (str): The request's HTTP method or the RPC method being
     |              invoked.
     |          url (str): The request's URI or the RPC service's URI.
     |          headers (Mapping): The request's headers.
     |
     |  get_cred_info(self)
     |      The credential information JSON.
     |
     |      The credential information will be added to auth related error messages
     |      by client library.
     |
     |      Returns:
     |          Mapping[str, str]: The credential information JSON.
     |
     |  with_non_blocking_refresh(self)
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from google.auth.credentials.Credentials:
     |
     |  expired
     |      Checks if the credentials are expired.
     |
     |      Note that credentials can be invalid but not expired because
     |      Credentials with :attr:`expiry` set to None is considered to never
     |      expire.
     |
     |      .. deprecated:: v2.24.0
     |        Prefer checking :attr:`token_state` instead.
     |
     |  quota_project_id
     |      Project to use for quota and billing purposes.
     |
     |  token_state
     |      See `:obj:`TokenState`
     |
     |  universe_domain
     |      The universe domain value.
     |
     |  valid
     |      Checks the validity of the credentials.
     |
     |      This is True if the credentials have a :attr:`token` and the token
     |      is not :attr:`expired`.
     |
     |      .. deprecated:: v2.24.0
     |        Prefer checking :attr:`token_state` instead.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from google.auth._credentials_base._BaseCredentials:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

FUNCTIONS
    get_app_service(app, name, initializer)

    handle_operation_error(error)
        Constructs a ``FirebaseError`` from the given operation error.

        Args:
            error: An error returned by a long running operation.

        Returns:
            FirebaseError: A ``FirebaseError`` that can be raised to the user code.

    handle_platform_error_from_requests(error, handle_func=None)
        Constructs a ``FirebaseError`` from the given requests error.

        This can be used to handle errors returned by Google Cloud Platform (GCP) APIs.

        Args:
            error: An error raised by the requests module while making an HTTP call to a GCP API.
            handle_func: A function that can be used to handle platform errors in a custom way. When
                specified, this function will be called with three arguments. It has the same
                signature as ```_handle_func_requests``, but may return ``None``.

        Returns:
            FirebaseError: A ``FirebaseError`` that can be raised to the user code.

    handle_requests_error(error, message=None, code=None)
        Constructs a ``FirebaseError`` from the given requests error.

        This method is agnostic of the remote service that produced the error, whether it is a GCP
        service or otherwise. Therefore, this method does not attempt to parse the error response in
        any way.

        Args:
            error: An error raised by the requests module while making an HTTP call.
            message: A message to be included in the resulting ``FirebaseError`` (optional). If not
                specified the string representation of the ``error`` argument is used as the message.
            code: A GCP error code that will be used to determine the resulting error type (optional).
                If not specified the HTTP status code on the error response is used to determine a
                suitable error code.

        Returns:
            FirebaseError: A ``FirebaseError`` that can be raised to the user code.

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\backend\lib\site-packages\firebase_admin\_utils.py



================================================================================
Help on module backend.Lib.site-packages.google.cloud.storage.notification in backend.Lib.site-packages.google.cloud.storage:

NAME
    backend.Lib.site-packages.google.cloud.storage.notification - Configure bucket notification resources to interact with Google Cloud Pub/Sub.

DESCRIPTION
    See [Cloud Pub/Sub Notifications for Google Cloud Storage](https://cloud.google.com/storage/docs/pubsub-notifications)

CLASSES
    builtins.object
        BucketNotification

    class BucketNotification(builtins.object)
     |  BucketNotification(bucket, topic_name=None, topic_project=None, custom_attributes=None, event_types=None, blob_name_prefix=None, payload_format='NONE', notification_id=None)
     |
     |  Represent a single notification resource for a bucket.
     |
     |  See: https://cloud.google.com/storage/docs/json_api/v1/notifications
     |
     |  :type bucket: :class:`google.cloud.storage.bucket.Bucket`
     |  :param bucket: Bucket to which the notification is bound.
     |
     |  :type topic_name: str
     |  :param topic_name:
     |      (Optional) Topic name to which notifications are published.
     |
     |  :type topic_project: str
     |  :param topic_project:
     |      (Optional) Project ID of topic to which notifications are published.
     |      If not passed, uses the project ID of the bucket's client.
     |
     |  :type custom_attributes: dict
     |  :param custom_attributes:
     |      (Optional) Additional attributes passed with notification events.
     |
     |  :type event_types: list(str)
     |  :param event_types:
     |      (Optional) Event types for which notification events are published.
     |
     |  :type blob_name_prefix: str
     |  :param blob_name_prefix:
     |      (Optional) Prefix of blob names for which notification events are
     |      published.
     |
     |  :type payload_format: str
     |  :param payload_format:
     |      (Optional) Format of payload for notification events.
     |
     |  :type notification_id: str
     |  :param notification_id:
     |      (Optional) The ID of the notification.
     |
     |  Methods defined here:
     |
     |  __init__(self, bucket, topic_name=None, topic_project=None, custom_attributes=None, event_types=None, blob_name_prefix=None, payload_format='NONE', notification_id=None)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  create(self, client=None, timeout=60, retry=None)
     |      API wrapper: create the notification.
     |
     |      See:
     |      https://cloud.google.com/storage/docs/json_api/v1/notifications/insert
     |
     |      If :attr:`user_project` is set on the bucket, bills the API request
     |      to that project.
     |
     |      :type client: :class:`~google.cloud.storage.client.Client`
     |      :param client: (Optional) The client to use.  If not passed, falls back
     |                     to the ``client`` stored on the notification's bucket.
     |      :type timeout: float or tuple
     |      :param timeout:
     |          (Optional) The amount of time, in seconds, to wait
     |          for the server response.  See: :ref:`configuring_timeouts`
     |
     |      :type retry: google.api_core.retry.Retry or google.cloud.storage.retry.ConditionalRetryPolicy
     |      :param retry:
     |          (Optional) How to retry the RPC. See: :ref:`configuring_retries`
     |
     |      :raises ValueError: if the notification already exists.
     |
     |  delete(self, client=None, timeout=60, retry=<google.api_core.retry.retry_unary.Retry object at 0x000002086FE7A270>)
     |      Delete this notification.
     |
     |      See:
     |      https://cloud.google.com/storage/docs/json_api/v1/notifications/delete
     |
     |      If :attr:`user_project` is set on the bucket, bills the API request
     |      to that project.
     |
     |      :type client: :class:`~google.cloud.storage.client.Client` or
     |                    ``NoneType``
     |      :param client: (Optional) The client to use.  If not passed, falls back
     |                     to the ``client`` stored on the current bucket.
     |      :type timeout: float or tuple
     |      :param timeout:
     |          (Optional) The amount of time, in seconds, to wait
     |          for the server response.  See: :ref:`configuring_timeouts`
     |
     |      :type retry: google.api_core.retry.Retry or google.cloud.storage.retry.ConditionalRetryPolicy
     |      :param retry:
     |          (Optional) How to retry the RPC. See: :ref:`configuring_retries`
     |
     |      :raises: :class:`google.api_core.exceptions.NotFound`:
     |          if the notification does not exist.
     |      :raises ValueError: if the notification has no ID.
     |
     |  exists(self, client=None, timeout=60, retry=<google.api_core.retry.retry_unary.Retry object at 0x000002086FE7A270>)
     |      Test whether this notification exists.
     |
     |      See:
     |      https://cloud.google.com/storage/docs/json_api/v1/notifications/get
     |
     |      If :attr:`user_project` is set on the bucket, bills the API request
     |      to that project.
     |
     |      :type client: :class:`~google.cloud.storage.client.Client` or
     |                    ``NoneType``
     |      :param client: (Optional) The client to use.  If not passed, falls back
     |                     to the ``client`` stored on the current bucket.
     |      :type timeout: float or tuple
     |      :param timeout:
     |          (Optional) The amount of time, in seconds, to wait
     |          for the server response.  See: :ref:`configuring_timeouts`
     |
     |      :type retry: google.api_core.retry.Retry or google.cloud.storage.retry.ConditionalRetryPolicy
     |      :param retry:
     |          (Optional) How to retry the RPC. See: :ref:`configuring_retries`
     |
     |      :rtype: bool
     |      :returns: True, if the notification exists, else False.
     |      :raises ValueError: if the notification has no ID.
     |
     |  reload(self, client=None, timeout=60, retry=<google.api_core.retry.retry_unary.Retry object at 0x000002086FE7A270>)
     |      Update this notification from the server configuration.
     |
     |      See:
     |      https://cloud.google.com/storage/docs/json_api/v1/notifications/get
     |
     |      If :attr:`user_project` is set on the bucket, bills the API request
     |      to that project.
     |
     |      :type client: :class:`~google.cloud.storage.client.Client` or
     |                    ``NoneType``
     |      :param client: (Optional) The client to use.  If not passed, falls back
     |                     to the ``client`` stored on the current bucket.
     |      :type timeout: float or tuple
     |      :param timeout:
     |          (Optional) The amount of time, in seconds, to wait
     |          for the server response.  See: :ref:`configuring_timeouts`
     |
     |      :type retry: google.api_core.retry.Retry or google.cloud.storage.retry.ConditionalRetryPolicy
     |      :param retry:
     |          (Optional) How to retry the RPC. See: :ref:`configuring_retries`
     |
     |
     |      :raises ValueError: if the notification has no ID.
     |
     |  ----------------------------------------------------------------------
     |  Class methods defined here:
     |
     |  from_api_repr(resource, bucket)
     |      Construct an instance from the JSON repr returned by the server.
     |
     |      See: https://cloud.google.com/storage/docs/json_api/v1/notifications
     |
     |      :type resource: dict
     |      :param resource: JSON repr of the notification
     |
     |      :type bucket: :class:`google.cloud.storage.bucket.Bucket`
     |      :param bucket: Bucket to which the notification is bound.
     |
     |      :rtype: :class:`BucketNotification`
     |      :returns: the new notification instance
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties defined here:
     |
     |  blob_name_prefix
     |      Prefix of blob names for which notification events are published.
     |
     |  bucket
     |      Bucket to which the notification is bound.
     |
     |  client
     |      The client bound to this notfication.
     |
     |  custom_attributes
     |      Custom attributes passed with notification events.
     |
     |  etag
     |      Server-set ETag of notification resource.
     |
     |  event_types
     |      Event types for which notification events are published.
     |
     |  notification_id
     |      Server-set ID of notification resource.
     |
     |  path
     |      The URL path for this notification.
     |
     |  payload_format
     |      Format of payload of notification events.
     |
     |  self_link
     |      Server-set ETag of notification resource.
     |
     |  topic_name
     |      Topic name to which notifications are published.
     |
     |  topic_project
     |      Project ID of topic to which notifications are published.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

DATA
    DEFAULT_RETRY = <google.api_core.retry.retry_unary.Retry object>
    JSON_API_V1_PAYLOAD_FORMAT = 'JSON_API_V1'
    NONE_PAYLOAD_FORMAT = 'NONE'
    OBJECT_ARCHIVE_EVENT_TYPE = 'OBJECT_ARCHIVE'
    OBJECT_DELETE_EVENT_TYPE = 'OBJECT_DELETE'
    OBJECT_FINALIZE_EVENT_TYPE = 'OBJECT_FINALIZE'
    OBJECT_METADATA_UPDATE_EVENT_TYPE = 'OBJECT_METADATA_UPDATE'

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\backend\lib\site-packages\google\cloud\storage\notification.py



================================================================================
Help on module backend.Lib.site-packages.google.oauth2.reauth in backend.Lib.site-packages.google.oauth2:

NAME
    backend.Lib.site-packages.google.oauth2.reauth - A module that provides functions for handling rapt authentication.

DESCRIPTION
    Reauth is a process of obtaining additional authentication (such as password,
    security token, etc.) while refreshing OAuth 2.0 credentials for a user.

    Credentials that use the Reauth flow must have the reauth scope,
    ``https://www.googleapis.com/auth/accounts.reauth``.

    This module provides a high-level function for executing the Reauth process,
    :func:`refresh_grant`, and lower-level helpers for doing the individual
    steps of the reauth process.

    Those steps are:

    1. Obtaining a list of challenges from the reauth server.
    2. Running through each challenge and sending the result back to the reauth
       server.
    3. Refreshing the access token using the returned rapt token.

FUNCTIONS
    get_rapt_token(request, client_id, client_secret, refresh_token, token_uri, scopes=None)
        Given an http request method and refresh_token, get rapt token.

        Args:
            request (google.auth.transport.Request): A callable used to make
                HTTP requests.
            client_id (str): client id to get access token for reauth scope.
            client_secret (str): client secret for the client_id
            refresh_token (str): refresh token to refresh access token
            token_uri (str): uri to refresh access token
            scopes (Optional(Sequence[str])): scopes required by the client application

        Returns:
            str: The rapt token.
        Raises:
            google.auth.exceptions.RefreshError: If reauth failed.

    is_interactive()
        Check if we are in an interractive environment.

        Override this function with a different logic if you are using this library
        outside a CLI.

        If the rapt token needs refreshing, the user needs to answer the challenges.
        If the user is not in an interractive environment, the challenges can not
        be answered and we just wait for timeout for no reason.

        Returns:
            bool: True if is interactive environment, False otherwise.

    refresh_grant(request, token_uri, refresh_token, client_id, client_secret, scopes=None, rapt_token=None, enable_reauth_refresh=False)
        Implements the reauthentication flow.

        Args:
            request (google.auth.transport.Request): A callable used to make
                HTTP requests.
            token_uri (str): The OAuth 2.0 authorizations server's token endpoint
                URI.
            refresh_token (str): The refresh token to use to get a new access
                token.
            client_id (str): The OAuth 2.0 application's client ID.
            client_secret (str): The Oauth 2.0 appliaction's client secret.
            scopes (Optional(Sequence[str])): Scopes to request. If present, all
                scopes must be authorized for the refresh token. Useful if refresh
                token has a wild card scope (e.g.
                'https://www.googleapis.com/auth/any-api').
            rapt_token (Optional(str)): The rapt token for reauth.
            enable_reauth_refresh (Optional[bool]): Whether reauth refresh flow
                should be used. The default value is False. This option is for
                gcloud only, other users should use the default value.

        Returns:
            Tuple[str, Optional[str], Optional[datetime], Mapping[str, str], str]: The
                access token, new refresh token, expiration, the additional data
                returned by the token endpoint, and the rapt token.

        Raises:
            google.auth.exceptions.RefreshError: If the token endpoint returned
                an error.

DATA
    RUN_CHALLENGE_RETRY_LIMIT = 5

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\backend\lib\site-packages\google\oauth2\reauth.py



================================================================================
Help on module backend.Lib.site-packages.google.oauth2.utils in backend.Lib.site-packages.google.oauth2:

NAME
    backend.Lib.site-packages.google.oauth2.utils - OAuth 2.0 Utilities.

DESCRIPTION
    This module provides implementations for various OAuth 2.0 utilities.
    This includes `OAuth error handling`_ and
    `Client authentication for OAuth flows`_.

    OAuth error handling
    --------------------
    This will define interfaces for handling OAuth related error responses as
    stated in `RFC 6749 section 5.2`_.
    This will include a common function to convert these HTTP error responses to a
    :class:`google.auth.exceptions.OAuthError` exception.


    Client authentication for OAuth flows
    -------------------------------------
    We introduce an interface for defining client authentication credentials based
    on `RFC 6749 section 2.3.1`_. This will expose the following
    capabilities:

        * Ability to support basic authentication via request header.
        * Ability to support bearer token authentication via request header.
        * Ability to support client ID / secret authentication via request body.

    .. _RFC 6749 section 2.3.1: https://tools.ietf.org/html/rfc6749#section-2.3.1
    .. _RFC 6749 section 5.2: https://tools.ietf.org/html/rfc6749#section-5.2

CLASSES
    builtins.object
        ClientAuthentication
        OAuthClientAuthHandler
    enum.Enum(builtins.object)
        ClientAuthType

    class ClientAuthType(enum.Enum)
     |  ClientAuthType(*values)
     |
     |  # OAuth client authentication based on
     |  # https://tools.ietf.org/html/rfc6749#section-2.3.
     |
     |  Method resolution order:
     |      ClientAuthType
     |      enum.Enum
     |      builtins.object
     |
     |  Data and other attributes defined here:
     |
     |  basic = <ClientAuthType.basic: 1>
     |
     |  request_body = <ClientAuthType.request_body: 2>
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from enum.Enum:
     |
     |  name
     |      The name of the Enum member.
     |
     |  value
     |      The value of the Enum member.
     |
     |  ----------------------------------------------------------------------
     |  Static methods inherited from enum.EnumType:
     |
     |  __contains__(value)
     |      Return True if `value` is in `cls`.
     |
     |      `value` is in `cls` if:
     |      1) `value` is a member of `cls`, or
     |      2) `value` is the value of one of the `cls`'s members.
     |
     |  __getitem__(name)
     |      Return the member matching `name`.
     |
     |  __iter__()
     |      Return members in definition order.
     |
     |  __len__()
     |      Return the number of members (no aliases)
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from enum.EnumType:
     |
     |  __members__
     |      Returns a mapping of member name->value.
     |
     |      This mapping lists all enum members, including aliases. Note that this
     |      is a read-only view of the internal mapping.

    class ClientAuthentication(builtins.object)
     |  ClientAuthentication(client_auth_type, client_id, client_secret=None)
     |
     |  Defines the client authentication credentials for basic and request-body
     |  types based on https://tools.ietf.org/html/rfc6749#section-2.3.1.
     |
     |  Methods defined here:
     |
     |  __init__(self, client_auth_type, client_id, client_secret=None)
     |      Instantiates a client authentication object containing the client ID
     |      and secret credentials for basic and response-body auth.
     |
     |      Args:
     |          client_auth_type (google.oauth2.oauth_utils.ClientAuthType): The
     |              client authentication type.
     |          client_id (str): The client ID.
     |          client_secret (Optional[str]): The client secret.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

    class OAuthClientAuthHandler(builtins.object)
     |  OAuthClientAuthHandler(client_authentication=None)
     |
     |  Abstract class for handling client authentication in OAuth-based
     |  operations.
     |
     |  Methods defined here:
     |
     |  __init__(self, client_authentication=None)
     |      Instantiates an OAuth client authentication handler.
     |
     |      Args:
     |          client_authentication (Optional[google.oauth2.utils.ClientAuthentication]):
     |              The OAuth client authentication credentials if available.
     |
     |  apply_client_authentication_options(self, headers, request_body=None, bearer_token=None)
     |      Applies client authentication on the OAuth request's headers or POST
     |      body.
     |
     |      Args:
     |          headers (Mapping[str, str]): The HTTP request header.
     |          request_body (Optional[Mapping[str, str]]): The HTTP request body
     |              dictionary. For requests that do not support request body, this
     |              is None and will be ignored.
     |          bearer_token (Optional[str]): The optional bearer token.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  __abstractmethods__ = frozenset()

FUNCTIONS
    handle_error_response(response_body)
        Translates an error response from an OAuth operation into an
        OAuthError exception.

        Args:
            response_body (str): The decoded response data.

        Raises:
            google.auth.exceptions.OAuthError

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\backend\lib\site-packages\google\oauth2\utils.py



================================================================================
Help on module backend.Lib.site-packages.googleapiclient._auth in backend.Lib.site-packages.googleapiclient:

NAME
    backend.Lib.site-packages.googleapiclient._auth - Helpers for authentication using oauth2client or google-auth.

FUNCTIONS
    apply_credentials(credentials, headers)

    authorized_http(credentials)
        Returns an http client that is authorized with the given credentials.

        Args:
            credentials (Union[
                google.auth.credentials.Credentials,
                oauth2client.client.Credentials]): The credentials to use.

        Returns:
            Union[httplib2.Http, google_auth_httplib2.AuthorizedHttp]: An
                authorized http client.

    credentials_from_file(filename, scopes=None, quota_project_id=None)
        Returns credentials loaded from a file.

    default_credentials(scopes=None, quota_project_id=None)
        Returns Application Default Credentials.

    get_credentials_from_http(http)

    is_valid(credentials)

    refresh_credentials(credentials)

    with_scopes(credentials, scopes)
        Scopes the credentials if necessary.

        Args:
            credentials (Union[
                google.auth.credentials.Credentials,
                oauth2client.client.Credentials]): The credentials to scope.
            scopes (Sequence[str]): The list of scopes.

        Returns:
            Union[google.auth.credentials.Credentials,
                oauth2client.client.Credentials]: The scoped credentials.

DATA
    HAS_GOOGLE_AUTH = True
    HAS_OAUTH2CLIENT = False

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\backend\lib\site-packages\googleapiclient\_auth.py



================================================================================
Help on module backend.Lib.site-packages.grpc._auth in backend.Lib.site-packages.grpc:

NAME
    backend.Lib.site-packages.grpc._auth - GRPCAuthMetadataPlugins for standard authentication.

CLASSES
    grpc.AuthMetadataPlugin(abc.ABC)
        AccessTokenAuthMetadataPlugin
        GoogleCallCredentials

    class AccessTokenAuthMetadataPlugin(grpc.AuthMetadataPlugin)
     |  AccessTokenAuthMetadataPlugin(access_token: str)
     |
     |  Metadata wrapper for raw access token credentials.
     |
     |  Method resolution order:
     |      AccessTokenAuthMetadataPlugin
     |      grpc.AuthMetadataPlugin
     |      abc.ABC
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __call__(self, context: grpc.AuthMetadataContext, callback: grpc.AuthMetadataPluginCallback)
     |      Implements authentication by passing metadata to a callback.
     |
     |      This method will be invoked asynchronously in a separate thread.
     |
     |      Args:
     |        context: An AuthMetadataContext providing information on the RPC that
     |          the plugin is being called to authenticate.
     |        callback: An AuthMetadataPluginCallback to be invoked either
     |          synchronously or asynchronously.
     |
     |  __init__(self, access_token: str)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  __abstractmethods__ = frozenset()
     |
     |  __annotations__ = {'_access_token': <class 'str'>}
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from grpc.AuthMetadataPlugin:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

    class GoogleCallCredentials(grpc.AuthMetadataPlugin)
     |  GoogleCallCredentials(credentials: Any)
     |
     |  Metadata wrapper for GoogleCredentials from the oauth2client library.
     |
     |  Method resolution order:
     |      GoogleCallCredentials
     |      grpc.AuthMetadataPlugin
     |      abc.ABC
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __call__(self, context: grpc.AuthMetadataContext, callback: grpc.AuthMetadataPluginCallback)
     |      Implements authentication by passing metadata to a callback.
     |
     |      This method will be invoked asynchronously in a separate thread.
     |
     |      Args:
     |        context: An AuthMetadataContext providing information on the RPC that
     |          the plugin is being called to authenticate.
     |        callback: An AuthMetadataPluginCallback to be invoked either
     |          synchronously or asynchronously.
     |
     |  __init__(self, credentials: Any)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  __abstractmethods__ = frozenset()
     |
     |  __annotations__ = {'_credentials': typing.Any, '_is_jwt': <class 'bool...
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from grpc.AuthMetadataPlugin:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

DATA
    Optional = typing.Optional
        Optional[X] is equivalent to Union[X, None].

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\backend\lib\site-packages\grpc\_auth.py



================================================================================
Help on module backend.Lib.site-packages.grpc.aio._utils in backend.Lib.site-packages.grpc.aio:

NAME
    backend.Lib.site-packages.grpc.aio._utils - Internal utilities used by the gRPC Aio module.

DATA
    Optional = typing.Optional
        Optional[X] is equivalent to Union[X, None].

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\backend\lib\site-packages\grpc\aio\_utils.py



================================================================================
Help on module backend.Lib.site-packages.grpc_status.rpc_status in backend.Lib.site-packages.grpc_status:

NAME
    backend.Lib.site-packages.grpc_status.rpc_status - Reference implementation for status mapping in gRPC Python.

FUNCTIONS
    from_call(call)
        Returns a google.rpc.status.Status message corresponding to a given grpc.Call.

        This is an EXPERIMENTAL API.

        Args:
          call: A grpc.Call instance.

        Returns:
          A google.rpc.status.Status message representing the status of the RPC.

        Raises:
          ValueError: If the gRPC call's code or details are inconsistent with the
            status code and message inside of the google.rpc.status.Status.

    to_status(status)
        Convert a google.rpc.status.Status message to grpc.Status.

        This is an EXPERIMENTAL API.

        Args:
          status: a google.rpc.status.Status message representing the non-OK status
            to terminate the RPC with and communicate it to the client.

        Returns:
          A grpc.Status instance representing the input google.rpc.status.Status message.

DATA
    __all__ = ['from_call', 'to_status', 'aio']

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\backend\lib\site-packages\grpc_status\rpc_status.py



================================================================================
Help on module backend.Lib.site-packages.httpcore._models in backend.Lib.site-packages.httpcore:

NAME
    backend.Lib.site-packages.httpcore._models

CLASSES
    builtins.object
        ByteStream
        httpcore.Origin
        httpcore.Request
        httpcore.Response
        httpcore.URL

    class ByteStream(builtins.object)
     |  ByteStream(content: bytes) -> None
     |
     |  A container for non-streaming content, and that supports both sync and async
     |  stream iteration.
     |
     |  Methods defined here:
     |
     |  async __aiter__(self) -> AsyncIterator[bytes]
     |
     |  __init__(self, content: bytes) -> None
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  __iter__(self) -> Iterator[bytes]
     |
     |  __repr__(self) -> str
     |      Return repr(self).
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

    class Origin(builtins.object)
     |  Origin(scheme: bytes, host: bytes, port: int) -> None
     |
     |  Methods defined here:
     |
     |  __eq__(self, other: Any) -> bool from Origin
     |      Return self==value.
     |
     |  __init__(self, scheme: bytes, host: bytes, port: int) -> None from Origin
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  __str__(self) -> str from Origin
     |      Return str(self).
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  __hash__ = None

    class Request(builtins.object)
     |  Request(method: Union[bytes, str], url: Union[httpcore.URL, bytes, str], *, headers: Union[Sequence[Tuple[Union[bytes, str], Union[bytes, str]]], Mapping[Union[bytes, str], Union[bytes, str]], NoneType] = None, content: Union[bytes, Iterable[bytes], AsyncIterable[bytes], NoneType] = None, extensions: Optional[MutableMapping[str, Any]] = None) -> None
     |
     |  An HTTP request.
     |
     |  Methods defined here:
     |
     |  __init__(self, method: Union[bytes, str], url: Union[httpcore.URL, bytes, str], *, headers: Union[Sequence[Tuple[Union[bytes, str], Union[bytes, str]]], Mapping[Union[bytes, str], Union[bytes, str]], NoneType] = None, content: Union[bytes, Iterable[bytes], AsyncIterable[bytes], NoneType] = None, extensions: Optional[MutableMapping[str, Any]] = None) -> None from Request
     |      Parameters:
     |          method: The HTTP request method, either as a string or bytes.
     |              For example: `GET`.
     |          url: The request URL, either as a `URL` instance, or as a string or bytes.
     |              For example: `"https://www.example.com".`
     |          headers: The HTTP request headers.
     |          content: The content of the request body.
     |          extensions: A dictionary of optional extra information included on
     |              the request. Possible keys include `"timeout"`, and `"trace"`.
     |
     |  __repr__(self) -> str from Request
     |      Return repr(self).
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

    class Response(builtins.object)
     |  Response(status: int, *, headers: Union[Sequence[Tuple[Union[bytes, str], Union[bytes, str]]], Mapping[Union[bytes, str], Union[bytes, str]], NoneType] = None, content: Union[bytes, Iterable[bytes], AsyncIterable[bytes], NoneType] = None, extensions: Optional[MutableMapping[str, Any]] = None) -> None
     |
     |  An HTTP response.
     |
     |  Methods defined here:
     |
     |  __init__(self, status: int, *, headers: Union[Sequence[Tuple[Union[bytes, str], Union[bytes, str]]], Mapping[Union[bytes, str], Union[bytes, str]], NoneType] = None, content: Union[bytes, Iterable[bytes], AsyncIterable[bytes], NoneType] = None, extensions: Optional[MutableMapping[str, Any]] = None) -> None from Response
     |      Parameters:
     |          status: The HTTP status code of the response. For example `200`.
     |          headers: The HTTP response headers.
     |          content: The content of the response body.
     |          extensions: A dictionary of optional extra information included on
     |              the responseself.Possible keys include `"http_version"`,
     |              `"reason_phrase"`, and `"network_stream"`.
     |
     |  __repr__(self) -> str from Response
     |      Return repr(self).
     |
     |  async aclose(self) -> None from Response
     |
     |  async aiter_stream(self) -> AsyncIterator[bytes] from Response
     |
     |  async aread(self) -> bytes from Response
     |
     |  close(self) -> None from Response
     |
     |  iter_stream(self) -> Iterator[bytes] from Response
     |
     |  read(self) -> bytes from Response
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties defined here:
     |
     |  content
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

    class URL(builtins.object)
     |  URL(url: Union[bytes, str] = '', *, scheme: Union[bytes, str] = b'', host: Union[bytes, str] = b'', port: Optional[int] = None, target: Union[bytes, str] = b'') -> None
     |
     |  Represents the URL against which an HTTP request may be made.
     |
     |  The URL may either be specified as a plain string, for convienence:
     |
     |  ```python
     |  url = httpcore.URL("https://www.example.com/")
     |  ```
     |
     |  Or be constructed with explicitily pre-parsed components:
     |
     |  ```python
     |  url = httpcore.URL(scheme=b'https', host=b'www.example.com', port=None, target=b'/')
     |  ```
     |
     |  Using this second more explicit style allows integrations that are using
     |  `httpcore` to pass through URLs that have already been parsed in order to use
     |  libraries such as `rfc-3986` rather than relying on the stdlib. It also ensures
     |  that URL parsing is treated identically at both the networking level and at any
     |  higher layers of abstraction.
     |
     |  The four components are important here, as they allow the URL to be precisely
     |  specified in a pre-parsed format. They also allow certain types of request to
     |  be created that could not otherwise be expressed.
     |
     |  For example, an HTTP request to `http://www.example.com/` forwarded via a proxy
     |  at `http://localhost:8080`...
     |
     |  ```python
     |  # Constructs an HTTP request with a complete URL as the target:
     |  # GET https://www.example.com/ HTTP/1.1
     |  url = httpcore.URL(
     |      scheme=b'http',
     |      host=b'localhost',
     |      port=8080,
     |      target=b'https://www.example.com/'
     |  )
     |  request = httpcore.Request(
     |      method="GET",
     |      url=url
     |  )
     |  ```
     |
     |  Another example is constructing an `OPTIONS *` request...
     |
     |  ```python
     |  # Constructs an 'OPTIONS *' HTTP request:
     |  # OPTIONS * HTTP/1.1
     |  url = httpcore.URL(scheme=b'https', host=b'www.example.com', target=b'*')
     |  request = httpcore.Request(method="OPTIONS", url=url)
     |  ```
     |
     |  This kind of request is not possible to formulate with a URL string,
     |  because the `/` delimiter is always used to demark the target from the
     |  host/port portion of the URL.
     |
     |  For convenience, string-like arguments may be specified either as strings or
     |  as bytes. However, once a request is being issue over-the-wire, the URL
     |  components are always ultimately required to be a bytewise representation.
     |
     |  In order to avoid any ambiguity over character encodings, when strings are used
     |  as arguments, they must be strictly limited to the ASCII range `chr(0)`-`chr(127)`.
     |  If you require a bytewise representation that is outside this range you must
     |  handle the character encoding directly, and pass a bytes instance.
     |
     |  Methods defined here:
     |
     |  __bytes__(self) -> bytes from URL
     |
     |  __eq__(self, other: Any) -> bool from URL
     |      Return self==value.
     |
     |  __init__(self, url: Union[bytes, str] = '', *, scheme: Union[bytes, str] = b'', host: Union[bytes, str] = b'', port: Optional[int] = None, target: Union[bytes, str] = b'') -> None from URL
     |      Parameters:
     |          url: The complete URL as a string or bytes.
     |          scheme: The URL scheme as a string or bytes.
     |              Typically either `"http"` or `"https"`.
     |          host: The URL host as a string or bytes. Such as `"www.example.com"`.
     |          port: The port to connect to. Either an integer or `None`.
     |          target: The target of the HTTP request. Such as `"/items?search=red"`.
     |
     |  __repr__(self) -> str from URL
     |      Return repr(self).
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties defined here:
     |
     |  origin
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  __hash__ = None

FUNCTIONS
    enforce_bytes(value: Union[bytes, str], *, name: str) -> bytes
        Any arguments that are ultimately represented as bytes can be specified
        either as bytes or as strings.

        However we enforce that any string arguments must only contain characters in
        the plain ASCII range. chr(0)...chr(127). If you need to use characters
        outside that range then be precise, and use a byte-wise argument.

    enforce_headers(value: Union[Mapping[Union[bytes, str], Union[bytes, str]], Sequence[Tuple[Union[bytes, str], Union[bytes, str]]], NoneType] = None, *, name: str) -> List[Tuple[bytes, bytes]]
        Convienence function that ensure all items in request or response headers
        are either bytes or strings in the plain ASCII range.

    enforce_stream(value: Union[bytes, Iterable[bytes], AsyncIterable[bytes], NoneType], *, name: str) -> Union[Iterable[bytes], AsyncIterable[bytes]]

    enforce_url(value: Union[ForwardRef('URL'), bytes, str], *, name: str) -> 'URL'
        Type check for URL parameters.

    include_request_headers(headers: List[Tuple[bytes, bytes]], *, url: 'URL', content: Union[NoneType, bytes, Iterable[bytes], AsyncIterable[bytes]]) -> List[Tuple[bytes, bytes]]

DATA
    AsyncIterable = typing.AsyncIterable
        A generic version of collections.abc.AsyncIterable.

    AsyncIterator = typing.AsyncIterator
        A generic version of collections.abc.AsyncIterator.

    DEFAULT_PORTS = {b'ftp': 21, b'http': 80, b'https': 443, b'ws': 80, b'...
    Extensions = typing.MutableMapping[str, typing.Any]
    HeaderTypes = typing.Union[typing.Sequence[typing.Tuple[typing...bytes...
    HeadersAsMapping = typing.Mapping[typing.Union[bytes, str], typing.Uni...
    HeadersAsSequence = typing.Sequence[typing.Tuple[typing.Union[bytes, s...
    Iterable = typing.Iterable
        A generic version of collections.abc.Iterable.

    Iterator = typing.Iterator
        A generic version of collections.abc.Iterator.

    List = typing.List
        A generic version of list.

    Mapping = typing.Mapping
        A generic version of collections.abc.Mapping.

    MutableMapping = typing.MutableMapping
        A generic version of collections.abc.MutableMapping.

    Optional = typing.Optional
        Optional[X] is equivalent to Union[X, None].

    Sequence = typing.Sequence
        A generic version of collections.abc.Sequence.

    Tuple = typing.Tuple
        Deprecated alias to builtins.tuple.

        Tuple[X, Y] is the cross-product type of X and Y.

        Example: Tuple[T1, T2] is a tuple of two elements corresponding
        to type variables T1 and T2.  Tuple[int, float, str] is a tuple
        of an int, a float and a string.

        To specify a variable-length tuple of homogeneous type, use Tuple[T, ...].

    Union = typing.Union
        Union type; Union[X, Y] means either X or Y.

        On Python 3.10 and higher, the | operator
        can also be used to denote unions;
        X | Y means the same thing to the type checker as Union[X, Y].

        To define a union, use e.g. Union[int, str]. Details:
        - The arguments must be types and there must be at least one.
        - None as an argument is a special case and is replaced by
          type(None).
        - Unions of unions are flattened, e.g.::

            assert Union[Union[int, str], float] == Union[int, str, float]

        - Unions of a single argument vanish, e.g.::

            assert Union[int] == int  # The constructor actually returns int

        - Redundant arguments are skipped, e.g.::

            assert Union[int, str, int] == Union[int, str]

        - When comparing unions, the argument order is ignored, e.g.::

            assert Union[int, str] == Union[str, int]

        - You cannot subclass or instantiate a union.
        - You can use Optional[X] as a shorthand for Union[X, None].

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\backend\lib\site-packages\httpcore\_models.py



================================================================================
Help on module backend.Lib.site-packages.httpcore._utils in backend.Lib.site-packages.httpcore:

NAME
    backend.Lib.site-packages.httpcore._utils

FUNCTIONS
    is_socket_readable(sock: Optional[socket.socket]) -> bool
        Return whether a socket, as identifed by its file descriptor, is readable.
        "A socket is readable" means that the read buffer isn't empty, i.e. that calling
        .recv() on it would immediately return some data.

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\backend\lib\site-packages\httpcore\_utils.py



================================================================================
Help on module backend.Lib.site-packages.httplib2.auth in backend.Lib.site-packages.httplib2:

NAME
    backend.Lib.site-packages.httplib2.auth

FUNCTIONS
    unquote lambda s, l, t

DATA
    UNQUOTE_PAIRS = re.compile('\\\\(.)')
    auth_param = {auth-param-name Suppress:('=')} {quoted-string | token}
    auth_param_name = auth-param-name
    authentication_info = Dict:(Group:({auth-param-name Suppress:('=') {qu...
    challenge = {token {Dict:(Group:({auth-param-name Suppress:(...:('=') ...
    params = Dict:(Group:({auth-param-name Suppress:('=') {qu...ame Suppre...
    quoted_string = quoted-string
    scheme = token
    tchar = "!#$%&'*+-.^_`|~0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghij...
    token = token
    token68 = token68
    www_authenticate = Group:({token {Dict:(Group:({auth-param-name Sup......

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\backend\lib\site-packages\httplib2\auth.py



================================================================================
Help on module backend.Lib.site-packages.httpx._auth in backend.Lib.site-packages.httpx:

NAME
    backend.Lib.site-packages.httpx._auth

CLASSES
    builtins.object
        httpx.Auth
            httpx.BasicAuth
            httpx.DigestAuth
            httpx.NetRCAuth

    class Auth(builtins.object)
     |  Base class for all authentication schemes.
     |
     |  To implement a custom authentication scheme, subclass `Auth` and override
     |  the `.auth_flow()` method.
     |
     |  If the authentication scheme does I/O such as disk access or network calls, or uses
     |  synchronization primitives such as locks, you should override `.sync_auth_flow()`
     |  and/or `.async_auth_flow()` instead of `.auth_flow()` to provide specialized
     |  implementations that will be used by `Client` and `AsyncClient` respectively.
     |
     |  Methods defined here:
     |
     |  async async_auth_flow(self, request: 'Request') -> 'typing.AsyncGenerator[Request, Response]' from Auth
     |      Execute the authentication flow asynchronously.
     |
     |      By default, this defers to `.auth_flow()`. You should override this method
     |      when the authentication scheme does I/O and/or uses concurrency primitives.
     |
     |  auth_flow(self, request: 'Request') -> 'typing.Generator[Request, Response, None]' from Auth
     |      Execute the authentication flow.
     |
     |      To dispatch a request, `yield` it:
     |
     |      ```
     |      yield request
     |      ```
     |
     |      The client will `.send()` the response back into the flow generator. You can
     |      access it like so:
     |
     |      ```
     |      response = yield request
     |      ```
     |
     |      A `return` (or reaching the end of the generator) will result in the
     |      client returning the last response obtained from the server.
     |
     |      You can dispatch as many requests as is necessary.
     |
     |  sync_auth_flow(self, request: 'Request') -> 'typing.Generator[Request, Response, None]' from Auth
     |      Execute the authentication flow synchronously.
     |
     |      By default, this defers to `.auth_flow()`. You should override this method
     |      when the authentication scheme does I/O and/or uses concurrency primitives.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  requires_request_body = False
     |
     |  requires_response_body = False

    class BasicAuth(Auth)
     |  BasicAuth(username: 'str | bytes', password: 'str | bytes') -> 'None'
     |
     |  Allows the 'auth' argument to be passed as a (username, password) pair,
     |  and uses HTTP Basic authentication.
     |
     |  Method resolution order:
     |      BasicAuth
     |      Auth
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, username: 'str | bytes', password: 'str | bytes') -> 'None' from BasicAuth
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  auth_flow(self, request: 'Request') -> 'typing.Generator[Request, Response, None]' from BasicAuth
     |      Execute the authentication flow.
     |
     |      To dispatch a request, `yield` it:
     |
     |      ```
     |      yield request
     |      ```
     |
     |      The client will `.send()` the response back into the flow generator. You can
     |      access it like so:
     |
     |      ```
     |      response = yield request
     |      ```
     |
     |      A `return` (or reaching the end of the generator) will result in the
     |      client returning the last response obtained from the server.
     |
     |      You can dispatch as many requests as is necessary.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from Auth:
     |
     |  async async_auth_flow(self, request: 'Request') -> 'typing.AsyncGenerator[Request, Response]' from Auth
     |      Execute the authentication flow asynchronously.
     |
     |      By default, this defers to `.auth_flow()`. You should override this method
     |      when the authentication scheme does I/O and/or uses concurrency primitives.
     |
     |  sync_auth_flow(self, request: 'Request') -> 'typing.Generator[Request, Response, None]' from Auth
     |      Execute the authentication flow synchronously.
     |
     |      By default, this defers to `.auth_flow()`. You should override this method
     |      when the authentication scheme does I/O and/or uses concurrency primitives.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from Auth:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from Auth:
     |
     |  requires_request_body = False
     |
     |  requires_response_body = False

    class DigestAuth(Auth)
     |  DigestAuth(username: 'str | bytes', password: 'str | bytes') -> 'None'
     |
     |  Method resolution order:
     |      DigestAuth
     |      Auth
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, username: 'str | bytes', password: 'str | bytes') -> 'None' from DigestAuth
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  auth_flow(self, request: 'Request') -> 'typing.Generator[Request, Response, None]' from DigestAuth
     |      Execute the authentication flow.
     |
     |      To dispatch a request, `yield` it:
     |
     |      ```
     |      yield request
     |      ```
     |
     |      The client will `.send()` the response back into the flow generator. You can
     |      access it like so:
     |
     |      ```
     |      response = yield request
     |      ```
     |
     |      A `return` (or reaching the end of the generator) will result in the
     |      client returning the last response obtained from the server.
     |
     |      You can dispatch as many requests as is necessary.
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  __annotations__ = {'_ALGORITHM_TO_HASH_FUNCTION': 'dict[str, typing.Ca...
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from Auth:
     |
     |  async async_auth_flow(self, request: 'Request') -> 'typing.AsyncGenerator[Request, Response]' from Auth
     |      Execute the authentication flow asynchronously.
     |
     |      By default, this defers to `.auth_flow()`. You should override this method
     |      when the authentication scheme does I/O and/or uses concurrency primitives.
     |
     |  sync_auth_flow(self, request: 'Request') -> 'typing.Generator[Request, Response, None]' from Auth
     |      Execute the authentication flow synchronously.
     |
     |      By default, this defers to `.auth_flow()`. You should override this method
     |      when the authentication scheme does I/O and/or uses concurrency primitives.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from Auth:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from Auth:
     |
     |  requires_request_body = False
     |
     |  requires_response_body = False

    class NetRCAuth(Auth)
     |  NetRCAuth(file: 'str | None' = None) -> 'None'
     |
     |  Use a 'netrc' file to lookup basic auth credentials based on the url host.
     |
     |  Method resolution order:
     |      NetRCAuth
     |      Auth
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, file: 'str | None' = None) -> 'None' from NetRCAuth
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  auth_flow(self, request: 'Request') -> 'typing.Generator[Request, Response, None]' from NetRCAuth
     |      Execute the authentication flow.
     |
     |      To dispatch a request, `yield` it:
     |
     |      ```
     |      yield request
     |      ```
     |
     |      The client will `.send()` the response back into the flow generator. You can
     |      access it like so:
     |
     |      ```
     |      response = yield request
     |      ```
     |
     |      A `return` (or reaching the end of the generator) will result in the
     |      client returning the last response obtained from the server.
     |
     |      You can dispatch as many requests as is necessary.
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  __annotations__ = {}
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from Auth:
     |
     |  async async_auth_flow(self, request: 'Request') -> 'typing.AsyncGenerator[Request, Response]' from Auth
     |      Execute the authentication flow asynchronously.
     |
     |      By default, this defers to `.auth_flow()`. You should override this method
     |      when the authentication scheme does I/O and/or uses concurrency primitives.
     |
     |  sync_auth_flow(self, request: 'Request') -> 'typing.Generator[Request, Response, None]' from Auth
     |      Execute the authentication flow synchronously.
     |
     |      By default, this defers to `.auth_flow()`. You should override this method
     |      when the authentication scheme does I/O and/or uses concurrency primitives.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from Auth:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from Auth:
     |
     |  requires_request_body = False
     |
     |  requires_response_body = False

DATA
    __all__ = ['Auth', 'BasicAuth', 'DigestAuth', 'NetRCAuth']

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\backend\lib\site-packages\httpx\_auth.py



================================================================================
Help on module backend.Lib.site-packages.httpx._models in backend.Lib.site-packages.httpx:

NAME
    backend.Lib.site-packages.httpx._models

CLASSES
    builtins.object
        httpx.Request
        httpx.Response
    collections.abc.MutableMapping(collections.abc.Mapping)
        httpx.Cookies(collections.abc.MutableMapping, typing.Generic)
        httpx.Headers(collections.abc.MutableMapping, typing.Generic)
    typing.Generic(builtins.object)
        httpx.Cookies(collections.abc.MutableMapping, typing.Generic)
        httpx.Headers(collections.abc.MutableMapping, typing.Generic)

    class Cookies(collections.abc.MutableMapping, typing.Generic)
     |  Cookies(cookies: 'CookieTypes | None' = None) -> 'None'
     |
     |  HTTP Cookies, as a mutable mapping.
     |
     |  Method resolution order:
     |      Cookies
     |      collections.abc.MutableMapping
     |      collections.abc.Mapping
     |      collections.abc.Collection
     |      collections.abc.Sized
     |      collections.abc.Iterable
     |      collections.abc.Container
     |      typing.Generic
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __bool__(self) -> 'bool' from Cookies
     |
     |  __delitem__(self, name: 'str') -> 'None' from Cookies
     |
     |  __getitem__(self, name: 'str') -> 'str' from Cookies
     |
     |  __init__(self, cookies: 'CookieTypes | None' = None) -> 'None' from Cookies
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  __iter__(self) -> 'typing.Iterator[str]' from Cookies
     |
     |  __len__(self) -> 'int' from Cookies
     |
     |  __repr__(self) -> 'str' from Cookies
     |      Return repr(self).
     |
     |  __setitem__(self, name: 'str', value: 'str') -> 'None' from Cookies
     |
     |  clear(self, domain: 'str | None' = None, path: 'str | None' = None) -> 'None' from Cookies
     |      Delete all cookies. Optionally include a domain and path in
     |      order to only delete a subset of all the cookies.
     |
     |  delete(self, name: 'str', domain: 'str | None' = None, path: 'str | None' = None) -> 'None' from Cookies
     |      Delete a cookie by name. May optionally include domain and path
     |      in order to specify exactly which cookie to delete.
     |
     |  extract_cookies(self, response: 'Response') -> 'None' from Cookies
     |      Loads any cookies based on the response `Set-Cookie` headers.
     |
     |  get(self, name: 'str', default: 'str | None' = None, domain: 'str | None' = None, path: 'str | None' = None) -> 'str | None' from Cookies
     |      Get a cookie by name. May optionally include domain and path
     |      in order to specify exactly which cookie to retrieve.
     |
     |  set(self, name: 'str', value: 'str', domain: 'str' = '', path: 'str' = '/') -> 'None' from Cookies
     |      Set a cookie value by name. May optionally include domain and path.
     |
     |  set_cookie_header(self, request: 'Request') -> 'None' from Cookies
     |      Sets an appropriate 'Cookie:' HTTP header on the `Request`.
     |
     |  update(self, cookies: 'CookieTypes | None' = None) -> 'None' from Cookies
     |      D.update([E, ]**F) -> None.  Update D from mapping/iterable E and F.
     |      If E present and has a .keys() method, does:     for k in E: D[k] = E[k]
     |      If E present and lacks .keys() method, does:     for (k, v) in E: D[k] = v
     |      In either case, this is followed by: for k, v in F.items(): D[k] = v
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  __abstractmethods__ = frozenset()
     |
     |  __orig_bases__ = (typing.MutableMapping[str, str],)
     |
     |  __parameters__ = ()
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from collections.abc.MutableMapping:
     |
     |  pop(self, key, default=<object object at 0x000002A120E1C200>)
     |      D.pop(k[,d]) -> v, remove specified key and return the corresponding value.
     |      If key is not found, d is returned if given, otherwise KeyError is raised.
     |
     |  popitem(self)
     |      D.popitem() -> (k, v), remove and return some (key, value) pair
     |      as a 2-tuple; but raise KeyError if D is empty.
     |
     |  setdefault(self, key, default=None)
     |      D.setdefault(k[,d]) -> D.get(k,d), also set D[k]=d if k not in D
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from collections.abc.Mapping:
     |
     |  __contains__(self, key)
     |
     |  __eq__(self, other)
     |      Return self==value.
     |
     |  items(self)
     |      D.items() -> a set-like object providing a view on D's items
     |
     |  keys(self)
     |      D.keys() -> a set-like object providing a view on D's keys
     |
     |  values(self)
     |      D.values() -> an object providing a view on D's values
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from collections.abc.Mapping:
     |
     |  __hash__ = None
     |
     |  __reversed__ = None
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from collections.abc.Collection:
     |
     |  __subclasshook__(C)
     |      Abstract classes can override this to customize issubclass().
     |
     |      This is invoked early on by abc.ABCMeta.__subclasscheck__().
     |      It should return True, False or NotImplemented.  If it returns
     |      NotImplemented, the normal algorithm is used.  Otherwise, it
     |      overrides the normal algorithm (and the outcome is cached).
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from collections.abc.Iterable:
     |
     |  __class_getitem__ = GenericAlias(...)
     |      Represent a PEP 585 generic type
     |
     |      E.g. for t = list[int], t.__origin__ is list and t.__args__ is (int,).
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from typing.Generic:
     |
     |  __init_subclass__(...)
     |      Function to initialize subclasses.

    class Headers(collections.abc.MutableMapping, typing.Generic)
     |  Headers(headers: 'HeaderTypes | None' = None, encoding: 'str | None' = None) -> 'None'
     |
     |  HTTP headers, as a case-insensitive multi-dict.
     |
     |  Method resolution order:
     |      Headers
     |      collections.abc.MutableMapping
     |      collections.abc.Mapping
     |      collections.abc.Collection
     |      collections.abc.Sized
     |      collections.abc.Iterable
     |      collections.abc.Container
     |      typing.Generic
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __contains__(self, key: 'typing.Any') -> 'bool' from Headers
     |
     |  __delitem__(self, key: 'str') -> 'None' from Headers
     |      Remove the header `key`.
     |
     |  __eq__(self, other: 'typing.Any') -> 'bool' from Headers
     |      Return self==value.
     |
     |  __getitem__(self, key: 'str') -> 'str' from Headers
     |      Return a single header value.
     |
     |      If there are multiple headers with the same key, then we concatenate
     |      them with commas. See: https://tools.ietf.org/html/rfc7230#section-3.2.2
     |
     |  __init__(self, headers: 'HeaderTypes | None' = None, encoding: 'str | None' = None) -> 'None' from Headers
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  __iter__(self) -> 'typing.Iterator[typing.Any]' from Headers
     |
     |  __len__(self) -> 'int' from Headers
     |
     |  __repr__(self) -> 'str' from Headers
     |      Return repr(self).
     |
     |  __setitem__(self, key: 'str', value: 'str') -> 'None' from Headers
     |      Set the header `key` to `value`, removing any duplicate entries.
     |      Retains insertion order.
     |
     |  copy(self) -> 'Headers' from Headers
     |
     |  get(self, key: 'str', default: 'typing.Any' = None) -> 'typing.Any' from Headers
     |      Return a header value. If multiple occurrences of the header occur
     |      then concatenate them together with commas.
     |
     |  get_list(self, key: 'str', split_commas: 'bool' = False) -> 'list[str]' from Headers
     |      Return a list of all header values for a given key.
     |      If `split_commas=True` is passed, then any comma separated header
     |      values are split into multiple return strings.
     |
     |  items(self) -> 'typing.ItemsView[str, str]' from Headers
     |      Return `(key, value)` items of headers. Concatenate headers
     |      into a single comma separated value when a key occurs multiple times.
     |
     |  keys(self) -> 'typing.KeysView[str]' from Headers
     |      D.keys() -> a set-like object providing a view on D's keys
     |
     |  multi_items(self) -> 'list[tuple[str, str]]' from Headers
     |      Return a list of `(key, value)` pairs of headers. Allow multiple
     |      occurrences of the same key without concatenating into a single
     |      comma separated value.
     |
     |  update(self, headers: 'HeaderTypes | None' = None) -> 'None' from Headers
     |      D.update([E, ]**F) -> None.  Update D from mapping/iterable E and F.
     |      If E present and has a .keys() method, does:     for k in E: D[k] = E[k]
     |      If E present and lacks .keys() method, does:     for (k, v) in E: D[k] = v
     |      In either case, this is followed by: for k, v in F.items(): D[k] = v
     |
     |  values(self) -> 'typing.ValuesView[str]' from Headers
     |      D.values() -> an object providing a view on D's values
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties defined here:
     |
     |  raw
     |      Returns a list of the raw header items, as byte pairs.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  encoding
     |      Header encoding is mandated as ascii, but we allow fallbacks to utf-8
     |      or iso-8859-1.
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  __abstractmethods__ = frozenset()
     |
     |  __hash__ = None
     |
     |  __orig_bases__ = (typing.MutableMapping[str, str],)
     |
     |  __parameters__ = ()
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from collections.abc.MutableMapping:
     |
     |  clear(self)
     |      D.clear() -> None.  Remove all items from D.
     |
     |  pop(self, key, default=<object object at 0x000002A120E1C200>)
     |      D.pop(k[,d]) -> v, remove specified key and return the corresponding value.
     |      If key is not found, d is returned if given, otherwise KeyError is raised.
     |
     |  popitem(self)
     |      D.popitem() -> (k, v), remove and return some (key, value) pair
     |      as a 2-tuple; but raise KeyError if D is empty.
     |
     |  setdefault(self, key, default=None)
     |      D.setdefault(k[,d]) -> D.get(k,d), also set D[k]=d if k not in D
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from collections.abc.Mapping:
     |
     |  __reversed__ = None
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from collections.abc.Collection:
     |
     |  __subclasshook__(C)
     |      Abstract classes can override this to customize issubclass().
     |
     |      This is invoked early on by abc.ABCMeta.__subclasscheck__().
     |      It should return True, False or NotImplemented.  If it returns
     |      NotImplemented, the normal algorithm is used.  Otherwise, it
     |      overrides the normal algorithm (and the outcome is cached).
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from collections.abc.Iterable:
     |
     |  __class_getitem__ = GenericAlias(...)
     |      Represent a PEP 585 generic type
     |
     |      E.g. for t = list[int], t.__origin__ is list and t.__args__ is (int,).
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from typing.Generic:
     |
     |  __init_subclass__(...)
     |      Function to initialize subclasses.

    class Request(builtins.object)
     |  Request(method: 'str | bytes', url: 'URL | str', *, params: 'QueryParamTypes | None' = None, headers: 'HeaderTypes | None' = None, cookies: 'CookieTypes | None' = None, content: 'RequestContent | None' = None, data: 'RequestData | None' = None, files: 'RequestFiles | None' = None, json: 'typing.Any | None' = None, stream: 'SyncByteStream | AsyncByteStream | None' = None, extensions: 'RequestExtensions | None' = None) -> 'None'
     |
     |  Methods defined here:
     |
     |  __getstate__(self) -> 'dict[str, typing.Any]' from Request
     |      Helper for pickle.
     |
     |  __init__(self, method: 'str | bytes', url: 'URL | str', *, params: 'QueryParamTypes | None' = None, headers: 'HeaderTypes | None' = None, cookies: 'CookieTypes | None' = None, content: 'RequestContent | None' = None, data: 'RequestData | None' = None, files: 'RequestFiles | None' = None, json: 'typing.Any | None' = None, stream: 'SyncByteStream | AsyncByteStream | None' = None, extensions: 'RequestExtensions | None' = None) -> 'None' from Request
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  __repr__(self) -> 'str' from Request
     |      Return repr(self).
     |
     |  __setstate__(self, state: 'dict[str, typing.Any]') -> 'None' from Request
     |
     |  async aread(self) -> 'bytes' from Request
     |      Read and return the request content.
     |
     |  read(self) -> 'bytes' from Request
     |      Read and return the request content.
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties defined here:
     |
     |  content
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

    class Response(builtins.object)
     |  Response(status_code: 'int', *, headers: 'HeaderTypes | None' = None, content: 'ResponseContent | None' = None, text: 'str | None' = None, html: 'str | None' = None, json: 'typing.Any' = None, stream: 'SyncByteStream | AsyncByteStream | None' = None, request: 'Request | None' = None, extensions: 'ResponseExtensions | None' = None, history: 'list[Response] | None' = None, default_encoding: 'str | typing.Callable[[bytes], str]' = 'utf-8') -> 'None'
     |
     |  Methods defined here:
     |
     |  __getstate__(self) -> 'dict[str, typing.Any]' from Response
     |      Helper for pickle.
     |
     |  __init__(self, status_code: 'int', *, headers: 'HeaderTypes | None' = None, content: 'ResponseContent | None' = None, text: 'str | None' = None, html: 'str | None' = None, json: 'typing.Any' = None, stream: 'SyncByteStream | AsyncByteStream | None' = None, request: 'Request | None' = None, extensions: 'ResponseExtensions | None' = None, history: 'list[Response] | None' = None, default_encoding: 'str | typing.Callable[[bytes], str]' = 'utf-8') -> 'None' from Response
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  __repr__(self) -> 'str' from Response
     |      Return repr(self).
     |
     |  __setstate__(self, state: 'dict[str, typing.Any]') -> 'None' from Response
     |
     |  async aclose(self) -> 'None' from Response
     |      Close the response and release the connection.
     |      Automatically called if the response body is read to completion.
     |
     |  async aiter_bytes(self, chunk_size: 'int | None' = None) -> 'typing.AsyncIterator[bytes]' from Response
     |      A byte-iterator over the decoded response content.
     |      This allows us to handle gzip, deflate, brotli, and zstd encoded responses.
     |
     |  async aiter_lines(self) -> 'typing.AsyncIterator[str]' from Response
     |
     |  async aiter_raw(self, chunk_size: 'int | None' = None) -> 'typing.AsyncIterator[bytes]' from Response
     |      A byte-iterator over the raw response content.
     |
     |  async aiter_text(self, chunk_size: 'int | None' = None) -> 'typing.AsyncIterator[str]' from Response
     |      A str-iterator over the decoded response content
     |      that handles both gzip, deflate, etc but also detects the content's
     |      string encoding.
     |
     |  async aread(self) -> 'bytes' from Response
     |      Read and return the response content.
     |
     |  close(self) -> 'None' from Response
     |      Close the response and release the connection.
     |      Automatically called if the response body is read to completion.
     |
     |  iter_bytes(self, chunk_size: 'int | None' = None) -> 'typing.Iterator[bytes]' from Response
     |      A byte-iterator over the decoded response content.
     |      This allows us to handle gzip, deflate, brotli, and zstd encoded responses.
     |
     |  iter_lines(self) -> 'typing.Iterator[str]' from Response
     |
     |  iter_raw(self, chunk_size: 'int | None' = None) -> 'typing.Iterator[bytes]' from Response
     |      A byte-iterator over the raw response content.
     |
     |  iter_text(self, chunk_size: 'int | None' = None) -> 'typing.Iterator[str]' from Response
     |      A str-iterator over the decoded response content
     |      that handles both gzip, deflate, etc but also detects the content's
     |      string encoding.
     |
     |  json(self, **kwargs: 'typing.Any') -> 'typing.Any' from Response
     |
     |  raise_for_status(self) -> 'Response' from Response
     |      Raise the `HTTPStatusError` if one occurred.
     |
     |  read(self) -> 'bytes' from Response
     |      Read and return the response content.
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties defined here:
     |
     |  charset_encoding
     |      Return the encoding, as specified by the Content-Type header.
     |
     |  content
     |
     |  cookies
     |
     |  has_redirect_location
     |      Returns True for 3xx responses with a properly formed URL redirection,
     |      `False` otherwise.
     |
     |  http_version
     |
     |  is_client_error
     |      A property which is `True` for 4xx status codes, `False` otherwise.
     |
     |  is_error
     |      A property which is `True` for 4xx and 5xx status codes, `False` otherwise.
     |
     |  is_informational
     |      A property which is `True` for 1xx status codes, `False` otherwise.
     |
     |  is_redirect
     |      A property which is `True` for 3xx status codes, `False` otherwise.
     |
     |      Note that not all responses with a 3xx status code indicate a URL redirect.
     |
     |      Use `response.has_redirect_location` to determine responses with a properly
     |      formed URL redirection.
     |
     |  is_server_error
     |      A property which is `True` for 5xx status codes, `False` otherwise.
     |
     |  is_success
     |      A property which is `True` for 2xx status codes, `False` otherwise.
     |
     |  links
     |      Returns the parsed header links of the response, if any
     |
     |  num_bytes_downloaded
     |
     |  reason_phrase
     |
     |  text
     |
     |  url
     |      Returns the URL for which the request was made.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  elapsed
     |      Returns the time taken for the complete request/response
     |      cycle to complete.
     |
     |  encoding
     |      Return an encoding to use for decoding the byte content into text.
     |      The priority for determining this is given by...
     |
     |      * `.encoding = <>` has been set explicitly.
     |      * The encoding as specified by the charset parameter in the Content-Type header.
     |      * The encoding as determined by `default_encoding`, which may either be
     |        a string like "utf-8" indicating the encoding to use, or may be a callable
     |        which enables charset autodetection.
     |
     |  request
     |      Returns the request instance associated to the current response.

DATA
    __all__ = ['Cookies', 'Headers', 'Request', 'Response']

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\backend\lib\site-packages\httpx\_models.py



================================================================================
Help on module backend.Lib.site-packages.httpx._utils in backend.Lib.site-packages.httpx:

NAME
    backend.Lib.site-packages.httpx._utils

CLASSES
    builtins.object
        Timer
        URLPattern

    class Timer(builtins.object)
     |  Methods defined here:
     |
     |  async async_elapsed(self) -> 'float'
     |
     |  async async_start(self) -> 'None'
     |
     |  sync_elapsed(self) -> 'float'
     |
     |  sync_start(self) -> 'None'
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

    class URLPattern(builtins.object)
     |  URLPattern(pattern: 'str') -> 'None'
     |
     |  A utility class currently used for making lookups against proxy keys...
     |
     |  # Wildcard matching...
     |  >>> pattern = URLPattern("all://")
     |  >>> pattern.matches(httpx.URL("http://example.com"))
     |  True
     |
     |  # Witch scheme matching...
     |  >>> pattern = URLPattern("https://")
     |  >>> pattern.matches(httpx.URL("https://example.com"))
     |  True
     |  >>> pattern.matches(httpx.URL("http://example.com"))
     |  False
     |
     |  # With domain matching...
     |  >>> pattern = URLPattern("https://example.com")
     |  >>> pattern.matches(httpx.URL("https://example.com"))
     |  True
     |  >>> pattern.matches(httpx.URL("http://example.com"))
     |  False
     |  >>> pattern.matches(httpx.URL("https://other.com"))
     |  False
     |
     |  # Wildcard scheme, with domain matching...
     |  >>> pattern = URLPattern("all://example.com")
     |  >>> pattern.matches(httpx.URL("https://example.com"))
     |  True
     |  >>> pattern.matches(httpx.URL("http://example.com"))
     |  True
     |  >>> pattern.matches(httpx.URL("https://other.com"))
     |  False
     |
     |  # With port matching...
     |  >>> pattern = URLPattern("https://example.com:1234")
     |  >>> pattern.matches(httpx.URL("https://example.com:1234"))
     |  True
     |  >>> pattern.matches(httpx.URL("https://example.com"))
     |  False
     |
     |  Methods defined here:
     |
     |  __eq__(self, other: 'typing.Any') -> 'bool'
     |      Return self==value.
     |
     |  __hash__(self) -> 'int'
     |      Return hash(self).
     |
     |  __init__(self, pattern: 'str') -> 'None'
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  __lt__(self, other: 'URLPattern') -> 'bool'
     |      Return self<value.
     |
     |  matches(self, other: 'URL') -> 'bool'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties defined here:
     |
     |  priority
     |      The priority allows URLPattern instances to be sortable, so that
     |      we can match from most specific to least specific.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

FUNCTIONS
    format_form_param(name: 'str', value: 'str') -> 'bytes'
        Encode a name/value pair within a multipart form.

    get_ca_bundle_from_env() -> 'str | None'

    get_environment_proxies() -> 'dict[str, str | None]'
        Gets proxy information from the environment

    guess_content_type(filename: 'str | None') -> 'str | None'

    is_https_redirect(url: 'URL', location: 'URL') -> 'bool'
        Return 'True' if 'location' is a HTTPS upgrade of 'url'

    is_ipv4_hostname(hostname: 'str') -> 'bool'

    is_ipv6_hostname(hostname: 'str') -> 'bool'

    is_known_encoding(encoding: 'str') -> 'bool'
        Return `True` if `encoding` is a known codec.

    normalize_header_key(value: 'str | bytes', lower: 'bool', encoding: 'str | None' = None) -> 'bytes'
        Coerce str/bytes into a strictly byte-wise HTTP header key.

    normalize_header_value(value: 'str | bytes', encoding: 'str | None' = None) -> 'bytes'
        Coerce str/bytes into a strictly byte-wise HTTP header value.

    obfuscate_sensitive_headers(items: 'typing.Iterable[tuple[typing.AnyStr, typing.AnyStr]]') -> 'typing.Iterator[tuple[typing.AnyStr, typing.AnyStr]]'

    parse_content_type_charset(content_type: 'str') -> 'str | None'

    parse_header_links(value: 'str') -> 'list[dict[str, str]]'
        Returns a list of parsed link headers, for more info see:
        https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Link
        The generic syntax of those is:
        Link: < uri-reference >; param1=value1; param2="value2"
        So for instance:
        Link; '<http:/.../front.jpeg>; type="image/jpeg",<http://.../back.jpeg>;'
        would return
            [
                {"url": "http:/.../front.jpeg", "type": "image/jpeg"},
                {"url": "http://.../back.jpeg"},
            ]
        :param value: HTTP Link entity-header field
        :return: list of parsed link headers

    peek_filelike_length(stream: 'typing.Any') -> 'int | None'
        Given a file-like stream object, return its length in number of bytes
        without reading it into memory.

    port_or_default(url: 'URL') -> 'int | None'

    primitive_value_to_str(value: 'PrimitiveData') -> 'str'
        Coerce a primitive data type into a string value.

        Note that we prefer JSON-style 'true'/'false' for boolean values here.

    same_origin(url: 'URL', other: 'URL') -> 'bool'
        Return 'True' if the given URLs share the same origin.

    to_bytes(value: 'str | bytes', encoding: 'str' = 'utf-8') -> 'bytes'

    to_bytes_or_str(value: 'str', match_type_of: 'typing.AnyStr') -> 'typing.AnyStr'

    to_str(value: 'str | bytes', encoding: 'str' = 'utf-8') -> 'str'

    unquote(value: 'str') -> 'str'

DATA
    PrimitiveData = typing.Union[str, int, float, bool, NoneType]
    SENSITIVE_HEADERS = {'authorization', 'proxy-authorization'}

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\backend\lib\site-packages\httpx\_utils.py



================================================================================
Help on module backend.Lib.site-packages.jose.utils in backend.Lib.site-packages.jose:

NAME
    backend.Lib.site-packages.jose.utils

FUNCTIONS
    base64_to_long(data)

    base64url_decode(input)
        Helper method to base64url_decode a string.

        Args:
            input (str): A base64url_encoded string to decode.

    base64url_encode(input)
        Helper method to base64url_encode a string.

        Args:
            input (str): A base64url_encoded string to encode.

    calculate_at_hash(access_token, hash_alg)
        Helper method for calculating an access token
        hash, as described in http://openid.net/specs/openid-connect-core-1_0.html#CodeIDToken

        Its value is the base64url encoding of the left-most half of the hash of the octets
        of the ASCII representation of the access_token value, where the hash algorithm
        used is the hash algorithm used in the alg Header Parameter of the ID Token's JOSE
        Header. For instance, if the alg is RS256, hash the access_token value with SHA-256,
        then take the left-most 128 bits and base64url encode them. The at_hash value is a
        case sensitive string.

        Args:
            access_token (str): An access token string.
            hash_alg (callable): A callable returning a hash object, e.g. hashlib.sha256

    ensure_binary(s)
        Coerce **s** to bytes.

    int_arr_to_long(arr)

    long_to_base64(data, size=0)

    long_to_bytes(n, blocksize=0)

    timedelta_total_seconds(delta)
        Helper method to determine the total number of seconds
        from a timedelta.

        Args:
            delta (timedelta): A timedelta to convert to seconds.

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\backend\lib\site-packages\jose\utils.py



================================================================================
Help on module backend.Lib.site-packages.jwt.utils in backend.Lib.site-packages.jwt:

NAME
    backend.Lib.site-packages.jwt.utils

FUNCTIONS
    base64url_decode(input: Union[bytes, str]) -> bytes

    base64url_encode(input: bytes) -> bytes

    bytes_from_int(val: int) -> bytes

    bytes_to_number(string: bytes) -> int

    decode_dss_signature(data)

    der_to_raw_signature(der_sig: bytes, curve: 'EllipticCurve') -> bytes

    encode_dss_signature(r, s)

    force_bytes(value: Union[bytes, str]) -> bytes

    from_base64url_uint(val: Union[bytes, str]) -> int

    is_pem_format(key: bytes) -> bool

    is_ssh_key(key: bytes) -> bool

    number_to_bytes(num: int, num_bytes: int) -> bytes

    raw_to_der_signature(raw_sig: bytes, curve: 'EllipticCurve') -> bytes

    to_base64url_uint(val: int) -> bytes

DATA
    Union = typing.Union
        Union type; Union[X, Y] means either X or Y.

        On Python 3.10 and higher, the | operator
        can also be used to denote unions;
        X | Y means the same thing to the type checker as Union[X, Y].

        To define a union, use e.g. Union[int, str]. Details:
        - The arguments must be types and there must be at least one.
        - None as an argument is a special case and is replaced by
          type(None).
        - Unions of unions are flattened, e.g.::

            assert Union[Union[int, str], float] == Union[int, str, float]

        - Unions of a single argument vanish, e.g.::

            assert Union[int] == int  # The constructor actually returns int

        - Redundant arguments are skipped, e.g.::

            assert Union[int, str, int] == Union[int, str]

        - When comparing unions, the argument order is ignored, e.g.::

            assert Union[int, str] == Union[str, int]

        - You cannot subclass or instantiate a union.
        - You can use Optional[X] as a shorthand for Union[X, None].

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\backend\lib\site-packages\jwt\utils.py



================================================================================
Help on module backend.Lib.site-packages.oauthlib.oauth1.rfc5849.utils in backend.Lib.site-packages.oauthlib.oauth1.rfc5849:

NAME
    backend.Lib.site-packages.oauthlib.oauth1.rfc5849.utils

DESCRIPTION
    oauthlib.utils
    ~~~~~~~~~~~~~~

    This module contains utility methods used by various parts of the OAuth
    spec.

FUNCTIONS
    escape(u)
        Escape a unicode string in an OAuth-compatible fashion.

        Per `section 3.6`_ of the spec.

        .. _`section 3.6`: https://tools.ietf.org/html/rfc5849#section-3.6

    filter_oauth_params(params)
        Removes all non oauth parameters from a dict or a list of params.

    filter_params(target)
        Decorator which filters params to remove non-oauth_* parameters

        Assumes the decorated method takes a params dict or list of tuples as its
        first argument.

    parse_authorization_header(authorization_header)
        Parse an OAuth authorization header into a list of 2-tuples

    parse_http_list(u)
        A unicode-safe version of urllib2.parse_http_list

    parse_keqv_list(l)
        A unicode-safe version of urllib2.parse_keqv_list

    unescape(u)

DATA
    UNICODE_ASCII_CHARACTER_SET = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLM...

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\backend\lib\site-packages\oauthlib\oauth1\rfc5849\utils.py



================================================================================
Help on module backend.Lib.site-packages.oauthlib.oauth2.rfc6749.utils in backend.Lib.site-packages.oauthlib.oauth2.rfc6749:

NAME
    backend.Lib.site-packages.oauthlib.oauth2.rfc6749.utils

DESCRIPTION
    oauthlib.utils
    ~~~~~~~~~~~~~~

    This module contains utility methods used by various parts of the OAuth 2 spec.

FUNCTIONS
    escape(u)
        Escape a string in an OAuth-compatible fashion.

        TODO: verify whether this can in fact be used for OAuth 2

    generate_age(issue_time)
        Generate a age parameter for MAC authentication draft 00.

    host_from_uri(uri)
        Extract hostname and port from URI.

        Will use default port for HTTP and HTTPS if none is present in the URI.

    is_secure_transport(uri)
        Check if the uri is over ssl.

    list_to_scope(scope)
        Convert a list of scopes to a space separated string.

    params_from_uri(uri)

    scope_to_list(scope)
        Convert a space separated string to a list of scopes.

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\backend\lib\site-packages\oauthlib\oauth2\rfc6749\utils.py



================================================================================
Help on module backend.Lib.site-packages.packaging.utils in backend.Lib.site-packages.packaging:

NAME
    backend.Lib.site-packages.packaging.utils

DESCRIPTION
    # This file is dual licensed under the terms of the Apache License, Version
    # 2.0, and the BSD License. See the LICENSE file in the root of this repository
    # for complete details.

CLASSES
    builtins.ValueError(builtins.Exception)
        InvalidName
        InvalidSdistFilename
        InvalidWheelFilename

    class InvalidName(builtins.ValueError)
     |  An invalid distribution name; users should refer to the packaging user guide.
     |
     |  Method resolution order:
     |      InvalidName
     |      builtins.ValueError
     |      builtins.Exception
     |      builtins.BaseException
     |      builtins.object
     |
     |  Data descriptors defined here:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.ValueError:
     |
     |  __init__(self, /, *args, **kwargs)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Static methods inherited from builtins.ValueError:
     |
     |  __new__(*args, **kwargs) class method of builtins.ValueError
     |      Create and return a new object.  See help(type) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.BaseException:
     |
     |  __delattr__(self, name, /)
     |      Implement delattr(self, name).
     |
     |  __getattribute__(self, name, /)
     |      Return getattr(self, name).
     |
     |  __reduce__(...)
     |      Helper for pickle.
     |
     |  __repr__(self, /)
     |      Return repr(self).
     |
     |  __setattr__(self, name, value, /)
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(...)
     |
     |  __str__(self, /)
     |      Return str(self).
     |
     |  add_note(...)
     |      Exception.add_note(note) --
     |      add a note to the exception
     |
     |  with_traceback(...)
     |      Exception.with_traceback(tb) --
     |      set self.__traceback__ to tb and return self.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from builtins.BaseException:
     |
     |  __cause__
     |      exception cause
     |
     |  __context__
     |      exception context
     |
     |  __dict__
     |
     |  __suppress_context__
     |
     |  __traceback__
     |
     |  args

    class InvalidSdistFilename(builtins.ValueError)
     |  An invalid sdist filename was found, users should refer to the packaging user guide.
     |
     |  Method resolution order:
     |      InvalidSdistFilename
     |      builtins.ValueError
     |      builtins.Exception
     |      builtins.BaseException
     |      builtins.object
     |
     |  Data descriptors defined here:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.ValueError:
     |
     |  __init__(self, /, *args, **kwargs)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Static methods inherited from builtins.ValueError:
     |
     |  __new__(*args, **kwargs) class method of builtins.ValueError
     |      Create and return a new object.  See help(type) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.BaseException:
     |
     |  __delattr__(self, name, /)
     |      Implement delattr(self, name).
     |
     |  __getattribute__(self, name, /)
     |      Return getattr(self, name).
     |
     |  __reduce__(...)
     |      Helper for pickle.
     |
     |  __repr__(self, /)
     |      Return repr(self).
     |
     |  __setattr__(self, name, value, /)
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(...)
     |
     |  __str__(self, /)
     |      Return str(self).
     |
     |  add_note(...)
     |      Exception.add_note(note) --
     |      add a note to the exception
     |
     |  with_traceback(...)
     |      Exception.with_traceback(tb) --
     |      set self.__traceback__ to tb and return self.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from builtins.BaseException:
     |
     |  __cause__
     |      exception cause
     |
     |  __context__
     |      exception context
     |
     |  __dict__
     |
     |  __suppress_context__
     |
     |  __traceback__
     |
     |  args

    class InvalidWheelFilename(builtins.ValueError)
     |  An invalid wheel filename was found, users should refer to PEP 427.
     |
     |  Method resolution order:
     |      InvalidWheelFilename
     |      builtins.ValueError
     |      builtins.Exception
     |      builtins.BaseException
     |      builtins.object
     |
     |  Data descriptors defined here:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.ValueError:
     |
     |  __init__(self, /, *args, **kwargs)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Static methods inherited from builtins.ValueError:
     |
     |  __new__(*args, **kwargs) class method of builtins.ValueError
     |      Create and return a new object.  See help(type) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.BaseException:
     |
     |  __delattr__(self, name, /)
     |      Implement delattr(self, name).
     |
     |  __getattribute__(self, name, /)
     |      Return getattr(self, name).
     |
     |  __reduce__(...)
     |      Helper for pickle.
     |
     |  __repr__(self, /)
     |      Return repr(self).
     |
     |  __setattr__(self, name, value, /)
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(...)
     |
     |  __str__(self, /)
     |      Return str(self).
     |
     |  add_note(...)
     |      Exception.add_note(note) --
     |      add a note to the exception
     |
     |  with_traceback(...)
     |      Exception.with_traceback(tb) --
     |      set self.__traceback__ to tb and return self.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from builtins.BaseException:
     |
     |  __cause__
     |      exception cause
     |
     |  __context__
     |      exception context
     |
     |  __dict__
     |
     |  __suppress_context__
     |
     |  __traceback__
     |
     |  args

FUNCTIONS
    canonicalize_name(name: 'str', *, validate: 'bool' = False) -> 'NormalizedName'

    canonicalize_version(version: 'Version | str', *, strip_trailing_zero: 'bool' = True) -> 'str'
        This is very similar to Version.__str__, but has one subtle difference
        with the way it handles the release segment.

    is_normalized_name(name: 'str') -> 'bool'

    parse_sdist_filename(filename: 'str') -> 'tuple[NormalizedName, Version]'

    parse_wheel_filename(filename: 'str') -> 'tuple[NormalizedName, Version, BuildTag, frozenset[Tag]]'

DATA
    BuildTag = typing.Union[typing.Tuple[()], typing.Tuple[int, str]]
    NormalizedName = backend.Lib.site-packages.packaging.utils.NormalizedN...
    Tuple = typing.Tuple
        Deprecated alias to builtins.tuple.

        Tuple[X, Y] is the cross-product type of X and Y.

        Example: Tuple[T1, T2] is a tuple of two elements corresponding
        to type variables T1 and T2.  Tuple[int, float, str] is a tuple
        of an int, a float and a string.

        To specify a variable-length tuple of homogeneous type, use Tuple[T, ...].

    Union = typing.Union
        Union type; Union[X, Y] means either X or Y.

        On Python 3.10 and higher, the | operator
        can also be used to denote unions;
        X | Y means the same thing to the type checker as Union[X, Y].

        To define a union, use e.g. Union[int, str]. Details:
        - The arguments must be types and there must be at least one.
        - None as an argument is a special case and is replaced by
          type(None).
        - Unions of unions are flattened, e.g.::

            assert Union[Union[int, str], float] == Union[int, str, float]

        - Unions of a single argument vanish, e.g.::

            assert Union[int] == int  # The constructor actually returns int

        - Redundant arguments are skipped, e.g.::

            assert Union[int, str, int] == Union[int, str]

        - When comparing unions, the argument order is ignored, e.g.::

            assert Union[int, str] == Union[str, int]

        - You cannot subclass or instantiate a union.
        - You can use Optional[X] as a shorthand for Union[X, None].

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\backend\lib\site-packages\packaging\utils.py



================================================================================
Help on module backend.Lib.site-packages.passlib.ext.django.utils in backend.Lib.site-packages.passlib.ext.django:

NAME
    backend.Lib.site-packages.passlib.ext.django.utils - passlib.ext.django.utils - helper functions used by this plugin

CLASSES
    builtins.object
        quirks

    class quirks(builtins.object)
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  empty_is_usable_password = False
     |
     |  invalid_is_usable_password = False
     |
     |  none_causes_check_password_error = False

FUNCTIONS
    get_preset_config(name)
        Returns configuration string for one of the preset strings
        supported by the ``PASSLIB_CONFIG`` setting.
        Currently supported presets:

        * ``"passlib-default"`` - default config used by this release of passlib.
        * ``"django-default"`` - config matching currently installed django version.
        * ``"django-latest"`` - config matching newest django version (currently same as ``"django-1.6"``).
        * ``"django-1.0"`` - config used by stock Django 1.0 - 1.3 installs
        * ``"django-1.4"`` - config used by stock Django 1.4 installs
        * ``"django-1.6"`` - config used by stock Django 1.6 installs

DATA
    DJANGO_VERSION = ()
    MIN_DJANGO_VERSION = (1, 8)
    __all__ = ['DJANGO_VERSION', 'MIN_DJANGO_VERSION', 'get_preset_config'...

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\backend\lib\site-packages\passlib\ext\django\utils.py



================================================================================
Help on module backend.Lib.site-packages.passlib.tests.test_utils in backend.Lib.site-packages.passlib.tests:

NAME
    backend.Lib.site-packages.passlib.tests.test_utils - tests for passlib.util

CLASSES
    _Base64Test(passlib.tests.utils.TestCase)
        H64Big_Test
        H64_Test
    passlib.tests.utils.TestCase(passlib.tests.backports.TestCase)
        Base64EngineTest
        CodecTest
        MiscTest

    class Base64EngineTest(passlib.tests.utils.TestCase)
     |  Base64EngineTest(methodName='runTest')
     |
     |  test standalone parts of Base64Engine
     |
     |  Method resolution order:
     |      Base64EngineTest
     |      passlib.tests.utils.TestCase
     |      passlib.tests.backports.TestCase
     |      unittest.case.TestCase
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  test_ab64_decode(self)
     |      ab64_decode()
     |
     |  test_ab64_encode(self)
     |      ab64_encode()
     |
     |  test_b64s_decode(self)
     |      b64s_decode()
     |
     |  test_b64s_encode(self)
     |      b64s_encode()
     |
     |  test_constructor(self)
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from passlib.tests.utils.TestCase:
     |
     |  assertEquals(self, *a, **k)
     |      #---------------------------------------------------------------
     |      # forbid a bunch of deprecated aliases so I stop using them
     |      #---------------------------------------------------------------
     |
     |  assertNotEquals = assertEquals(self, *a, **k)
     |
     |  assertRaises(self, _exc_type, _callable=None, *args, **kwds)
     |      Fail unless an exception of class expected_exception is raised
     |      by the callable when invoked with specified positional and
     |      keyword arguments. If a different type of exception is
     |      raised, it will not be caught, and the test case will be
     |      deemed to have suffered an error, exactly as for an
     |      unexpected exception.
     |
     |      If called with the callable and arguments omitted, will return a
     |      context object used like this::
     |
     |           with self.assertRaises(SomeException):
     |               do_something()
     |
     |      An optional keyword argument 'msg' can be provided when assertRaises
     |      is used as a context object.
     |
     |      The context manager keeps a reference to the exception as
     |      the 'exception' attribute. This allows you to inspect the
     |      exception after the assertion::
     |
     |          with self.assertRaises(SomeException) as cm:
     |              do_something()
     |          the_exception = cm.exception
     |          self.assertEqual(the_exception.error_code, 3)
     |
     |  assertRegexMatches = assertEquals(self, *a, **k)
     |
     |  assertWarning(self, warning, message_re=None, message=None, category=None, filename_re=None, filename=None, lineno=None, msg=None)
     |      check if warning matches specified parameters.
     |      'warning' is the instance of Warning to match against;
     |      can also be instance of WarningMessage (as returned by catch_warnings).
     |
     |  assertWarningList(self, wlist=None, desc=None, msg=None)
     |      check that warning list (e.g. from catch_warnings) matches pattern
     |
     |  consumeWarningList(self, wlist, desc=None, *args, **kwds)
     |      [deprecated] assertWarningList() variant that clears list afterwards
     |
     |  getLogger(self)
     |      return logger named after current test.
     |
     |  getRandom(self, name='default', seed=None)
     |      Return a :class:`random.Random` object for current test method to use.
     |      Within an instance, multiple calls with the same name will return
     |      the same object.
     |
     |      When first created, each RNG will be seeded with value derived from
     |      a global seed, the test class module & name, the current test method name,
     |      and the **name** parameter.
     |
     |      The global seed taken from the $RANDOM_TEST_SEED env var,
     |      the $PYTHONHASHSEED env var, or a randomly generated the
     |      first time this method is called. In all cases, the value
     |      is logged for reproducibility.
     |
     |      :param name:
     |          name to uniquely identify separate RNGs w/in a test
     |          (e.g. for threaded tests).
     |
     |      :param seed:
     |          override global seed when initialzing rng.
     |
     |      :rtype: random.Random
     |
     |  mktemp(self, *args, **kwds)
     |      create temp file that's cleaned up at end of test
     |
     |  patchAttr(self, obj, attr, value, require_existing=True, wrap=False)
     |      monkeypatch object value, restoring original value on cleanup
     |
     |  require_TEST_MODE(self, level)
     |      skip test for all PASSLIB_TEST_MODE values below <level>
     |
     |  require_stringprep(self)
     |      helper to skip test if stringprep is missing
     |
     |  require_writeable_filesystem(self)
     |      skip test if writeable FS not available
     |
     |  setUp(self)
     |      Hook method for setting up the test fixture before exercising it.
     |
     |  setUpWarnings(self)
     |      helper to init warning filters before subclass setUp()
     |
     |  shortDescription(self)
     |      wrap shortDescription() method to prepend descriptionPrefix
     |
     |  subTest(self, *args, **kwds)
     |      wrapper/backport for .subTest() which also traps SkipTest errors.
     |      (see source for details)
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from passlib.tests.utils.TestCase:
     |
     |  __test__ = True
     |
     |  __unittest_skip__ = False
     |
     |  descriptionPrefix = None
     |
     |  has_real_subtest = True
     |
     |  longMessage = True
     |
     |  resetWarningState = True
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from unittest.case.TestCase:
     |
     |  __call__(self, *args, **kwds)
     |      Call self as a function.
     |
     |  __eq__(self, other)
     |      Return self==value.
     |
     |  __hash__(self)
     |      Return hash(self).
     |
     |  __init__(self, methodName='runTest')
     |      Create an instance of the class that will use the named test
     |      method when executed. Raises a ValueError if the instance does
     |      not have a method with the specified name.
     |
     |  __repr__(self)
     |      Return repr(self).
     |
     |  __str__(self)
     |      Return str(self).
     |
     |  addCleanup(self, function, /, *args, **kwargs)
     |      Add a function, with arguments, to be called when the test is
     |      completed. Functions added are called on a LIFO basis and are
     |      called after tearDown on test failure or success.
     |
     |      Cleanup items are called even if setUp fails (unlike tearDown).
     |
     |  addTypeEqualityFunc(self, typeobj, function)
     |      Add a type specific assertEqual style function to compare a type.
     |
     |      This method is for use by TestCase subclasses that need to register
     |      their own type equality functions to provide nicer error messages.
     |
     |      Args:
     |          typeobj: The data type to call this function on when both values
     |                  are of the same type in assertEqual().
     |          function: The callable taking two arguments and an optional
     |                  msg= argument that raises self.failureException with a
     |                  useful error message when the two arguments are not equal.
     |
     |  assertAlmostEqual(self, first, second, places=None, msg=None, delta=None)
     |      Fail if the two objects are unequal as determined by their
     |      difference rounded to the given number of decimal places
     |      (default 7) and comparing to zero, or by comparing that the
     |      difference between the two objects is more than the given
     |      delta.
     |
     |      Note that decimal places (from zero) are usually not the same
     |      as significant digits (measured from the most significant digit).
     |
     |      If the two objects compare equal then they will automatically
     |      compare almost equal.
     |
     |  assertCountEqual(self, first, second, msg=None)
     |      Asserts that two iterables have the same elements, the same number of
     |      times, without regard to order.
     |
     |          self.assertEqual(Counter(list(first)),
     |                           Counter(list(second)))
     |
     |       Example:
     |          - [0, 1, 1] and [1, 0, 1] compare equal.
     |          - [0, 0, 1] and [0, 1] compare unequal.
     |
     |  assertDictEqual(self, d1, d2, msg=None)
     |
     |  assertEqual(self, first, second, msg=None)
     |      Fail if the two objects are unequal as determined by the '=='
     |      operator.
     |
     |  assertFalse(self, expr, msg=None)
     |      Check that the expression is false.
     |
     |  assertGreater(self, a, b, msg=None)
     |      Just like self.assertTrue(a > b), but with a nicer default message.
     |
     |  assertGreaterEqual(self, a, b, msg=None)
     |      Just like self.assertTrue(a >= b), but with a nicer default message.
     |
     |  assertIn(self, member, container, msg=None)
     |      Just like self.assertTrue(a in b), but with a nicer default message.
     |
     |  assertIs(self, expr1, expr2, msg=None)
     |      Just like self.assertTrue(a is b), but with a nicer default message.
     |
     |  assertIsInstance(self, obj, cls, msg=None)
     |      Same as self.assertTrue(isinstance(obj, cls)), with a nicer
     |      default message.
     |
     |  assertIsNone(self, obj, msg=None)
     |      Same as self.assertTrue(obj is None), with a nicer default message.
     |
     |  assertIsNot(self, expr1, expr2, msg=None)
     |      Just like self.assertTrue(a is not b), but with a nicer default message.
     |
     |  assertIsNotNone(self, obj, msg=None)
     |      Included for symmetry with assertIsNone.
     |
     |  assertLess(self, a, b, msg=None)
     |      Just like self.assertTrue(a < b), but with a nicer default message.
     |
     |  assertLessEqual(self, a, b, msg=None)
     |      Just like self.assertTrue(a <= b), but with a nicer default message.
     |
     |  assertListEqual(self, list1, list2, msg=None)
     |      A list-specific equality assertion.
     |
     |      Args:
     |          list1: The first list to compare.
     |          list2: The second list to compare.
     |          msg: Optional message to use on failure instead of a list of
     |                  differences.
     |
     |  assertLogs(self, logger=None, level=None)
     |      Fail unless a log message of level *level* or higher is emitted
     |      on *logger_name* or its children.  If omitted, *level* defaults to
     |      INFO and *logger* defaults to the root logger.
     |
     |      This method must be used as a context manager, and will yield
     |      a recording object with two attributes: `output` and `records`.
     |      At the end of the context manager, the `output` attribute will
     |      be a list of the matching formatted log messages and the
     |      `records` attribute will be a list of the corresponding LogRecord
     |      objects.
     |
     |      Example::
     |
     |          with self.assertLogs('foo', level='INFO') as cm:
     |              logging.getLogger('foo').info('first message')
     |              logging.getLogger('foo.bar').error('second message')
     |          self.assertEqual(cm.output, ['INFO:foo:first message',
     |                                       'ERROR:foo.bar:second message'])
     |
     |  assertMultiLineEqual(self, first, second, msg=None)
     |      Assert that two multi-line strings are equal.
     |
     |  assertNoLogs(self, logger=None, level=None)
     |      Fail unless no log messages of level *level* or higher are emitted
     |      on *logger_name* or its children.
     |
     |      This method must be used as a context manager.
     |
     |  assertNotAlmostEqual(self, first, second, places=None, msg=None, delta=None)
     |      Fail if the two objects are equal as determined by their
     |      difference rounded to the given number of decimal places
     |      (default 7) and comparing to zero, or by comparing that the
     |      difference between the two objects is less than the given delta.
     |
     |      Note that decimal places (from zero) are usually not the same
     |      as significant digits (measured from the most significant digit).
     |
     |      Objects that are equal automatically fail.
     |
     |  assertNotEqual(self, first, second, msg=None)
     |      Fail if the two objects are equal as determined by the '!='
     |      operator.
     |
     |  assertNotIn(self, member, container, msg=None)
     |      Just like self.assertTrue(a not in b), but with a nicer default message.
     |
     |  assertNotIsInstance(self, obj, cls, msg=None)
     |      Included for symmetry with assertIsInstance.
     |
     |  assertNotRegex(self, text, unexpected_regex, msg=None)
     |      Fail the test if the text matches the regular expression.
     |
     |  assertRaisesRegex(self, expected_exception, expected_regex, *args, **kwargs)
     |      Asserts that the message in a raised exception matches a regex.
     |
     |      Args:
     |          expected_exception: Exception class expected to be raised.
     |          expected_regex: Regex (re.Pattern object or string) expected
     |                  to be found in error message.
     |          args: Function to be called and extra positional args.
     |          kwargs: Extra kwargs.
     |          msg: Optional message used in case of failure. Can only be used
     |                  when assertRaisesRegex is used as a context manager.
     |
     |  assertRegex(self, text, expected_regex, msg=None)
     |      Fail the test unless the text matches the regular expression.
     |
     |  assertSequenceEqual(self, seq1, seq2, msg=None, seq_type=None)
     |      An equality assertion for ordered sequences (like lists and tuples).
     |
     |      For the purposes of this function, a valid ordered sequence type is one
     |      which can be indexed, has a length, and has an equality operator.
     |
     |      Args:
     |          seq1: The first sequence to compare.
     |          seq2: The second sequence to compare.
     |          seq_type: The expected datatype of the sequences, or None if no
     |                  datatype should be enforced.
     |          msg: Optional message to use on failure instead of a list of
     |                  differences.
     |
     |  assertSetEqual(self, set1, set2, msg=None)
     |      A set-specific equality assertion.
     |
     |      Args:
     |          set1: The first set to compare.
     |          set2: The second set to compare.
     |          msg: Optional message to use on failure instead of a list of
     |                  differences.
     |
     |      assertSetEqual uses ducktyping to support different types of sets, and
     |      is optimized for sets specifically (parameters must support a
     |      difference method).
     |
     |  assertTrue(self, expr, msg=None)
     |      Check that the expression is true.
     |
     |  assertTupleEqual(self, tuple1, tuple2, msg=None)
     |      A tuple-specific equality assertion.
     |
     |      Args:
     |          tuple1: The first tuple to compare.
     |          tuple2: The second tuple to compare.
     |          msg: Optional message to use on failure instead of a list of
     |                  differences.
     |
     |  assertWarns(self, expected_warning, *args, **kwargs)
     |      Fail unless a warning of class warnClass is triggered
     |      by the callable when invoked with specified positional and
     |      keyword arguments.  If a different type of warning is
     |      triggered, it will not be handled: depending on the other
     |      warning filtering rules in effect, it might be silenced, printed
     |      out, or raised as an exception.
     |
     |      If called with the callable and arguments omitted, will return a
     |      context object used like this::
     |
     |           with self.assertWarns(SomeWarning):
     |               do_something()
     |
     |      An optional keyword argument 'msg' can be provided when assertWarns
     |      is used as a context object.
     |
     |      The context manager keeps a reference to the first matching
     |      warning as the 'warning' attribute; similarly, the 'filename'
     |      and 'lineno' attributes give you information about the line
     |      of Python code from which the warning was triggered.
     |      This allows you to inspect the warning after the assertion::
     |
     |          with self.assertWarns(SomeWarning) as cm:
     |              do_something()
     |          the_warning = cm.warning
     |          self.assertEqual(the_warning.some_attribute, 147)
     |
     |  assertWarnsRegex(self, expected_warning, expected_regex, *args, **kwargs)
     |      Asserts that the message in a triggered warning matches a regexp.
     |      Basic functioning is similar to assertWarns() with the addition
     |      that only warnings whose messages also match the regular expression
     |      are considered successful matches.
     |
     |      Args:
     |          expected_warning: Warning class expected to be triggered.
     |          expected_regex: Regex (re.Pattern object or string) expected
     |                  to be found in error message.
     |          args: Function to be called and extra positional args.
     |          kwargs: Extra kwargs.
     |          msg: Optional message used in case of failure. Can only be used
     |                  when assertWarnsRegex is used as a context manager.
     |
     |  countTestCases(self)
     |
     |  debug(self)
     |      Run the test without collecting errors in a TestResult
     |
     |  defaultTestResult(self)
     |
     |  doCleanups(self)
     |      Execute all cleanup functions. Normally called for you after
     |      tearDown.
     |
     |  enterContext(self, cm)
     |      Enters the supplied context manager.
     |
     |      If successful, also adds its __exit__ method as a cleanup
     |      function and returns the result of the __enter__ method.
     |
     |  fail(self, msg=None)
     |      Fail immediately, with the given message.
     |
     |  id(self)
     |
     |  run(self, result=None)
     |
     |  skipTest(self, reason)
     |      Skip this test.
     |
     |  tearDown(self)
     |      Hook method for deconstructing the test fixture after testing it.
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from unittest.case.TestCase:
     |
     |  __init_subclass__(*args, **kwargs)
     |      This method is called when a class is subclassed.
     |
     |      The default implementation does nothing. It may be
     |      overridden to extend subclasses.
     |
     |  addClassCleanup(function, /, *args, **kwargs)
     |      Same as addCleanup, except the cleanup items are called even if
     |      setUpClass fails (unlike tearDownClass).
     |
     |  doClassCleanups()
     |      Execute all class cleanup functions. Normally called for you after
     |      tearDownClass.
     |
     |  enterClassContext(cm)
     |      Same as enterContext, but class-wide.
     |
     |  setUpClass()
     |      Hook method for setting up class fixture before running tests in the class.
     |
     |  tearDownClass()
     |      Hook method for deconstructing the class fixture after running all tests in the class.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from unittest.case.TestCase:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from unittest.case.TestCase:
     |
     |  failureException = <class 'AssertionError'>
     |      Assertion failed.
     |
     |
     |  maxDiff = 640

    class CodecTest(passlib.tests.utils.TestCase)
     |  CodecTest(methodName='runTest')
     |
     |  tests bytes/unicode helpers in passlib.utils
     |
     |  Method resolution order:
     |      CodecTest
     |      passlib.tests.utils.TestCase
     |      passlib.tests.backports.TestCase
     |      unittest.case.TestCase
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  test_bytes(self)
     |      test b() helper, bytes and native str type
     |
     |  test_is_ascii_safe(self)
     |      test is_ascii_safe()
     |
     |  test_is_same_codec(self)
     |      test is_same_codec()
     |
     |  test_to_bytes(self)
     |      test to_bytes()
     |
     |  test_to_native_str(self)
     |      test to_native_str()
     |
     |  test_to_unicode(self)
     |      test to_unicode()
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from passlib.tests.utils.TestCase:
     |
     |  assertEquals(self, *a, **k)
     |      #---------------------------------------------------------------
     |      # forbid a bunch of deprecated aliases so I stop using them
     |      #---------------------------------------------------------------
     |
     |  assertNotEquals = assertEquals(self, *a, **k)
     |
     |  assertRaises(self, _exc_type, _callable=None, *args, **kwds)
     |      Fail unless an exception of class expected_exception is raised
     |      by the callable when invoked with specified positional and
     |      keyword arguments. If a different type of exception is
     |      raised, it will not be caught, and the test case will be
     |      deemed to have suffered an error, exactly as for an
     |      unexpected exception.
     |
     |      If called with the callable and arguments omitted, will return a
     |      context object used like this::
     |
     |           with self.assertRaises(SomeException):
     |               do_something()
     |
     |      An optional keyword argument 'msg' can be provided when assertRaises
     |      is used as a context object.
     |
     |      The context manager keeps a reference to the exception as
     |      the 'exception' attribute. This allows you to inspect the
     |      exception after the assertion::
     |
     |          with self.assertRaises(SomeException) as cm:
     |              do_something()
     |          the_exception = cm.exception
     |          self.assertEqual(the_exception.error_code, 3)
     |
     |  assertRegexMatches = assertEquals(self, *a, **k)
     |
     |  assertWarning(self, warning, message_re=None, message=None, category=None, filename_re=None, filename=None, lineno=None, msg=None)
     |      check if warning matches specified parameters.
     |      'warning' is the instance of Warning to match against;
     |      can also be instance of WarningMessage (as returned by catch_warnings).
     |
     |  assertWarningList(self, wlist=None, desc=None, msg=None)
     |      check that warning list (e.g. from catch_warnings) matches pattern
     |
     |  consumeWarningList(self, wlist, desc=None, *args, **kwds)
     |      [deprecated] assertWarningList() variant that clears list afterwards
     |
     |  getLogger(self)
     |      return logger named after current test.
     |
     |  getRandom(self, name='default', seed=None)
     |      Return a :class:`random.Random` object for current test method to use.
     |      Within an instance, multiple calls with the same name will return
     |      the same object.
     |
     |      When first created, each RNG will be seeded with value derived from
     |      a global seed, the test class module & name, the current test method name,
     |      and the **name** parameter.
     |
     |      The global seed taken from the $RANDOM_TEST_SEED env var,
     |      the $PYTHONHASHSEED env var, or a randomly generated the
     |      first time this method is called. In all cases, the value
     |      is logged for reproducibility.
     |
     |      :param name:
     |          name to uniquely identify separate RNGs w/in a test
     |          (e.g. for threaded tests).
     |
     |      :param seed:
     |          override global seed when initialzing rng.
     |
     |      :rtype: random.Random
     |
     |  mktemp(self, *args, **kwds)
     |      create temp file that's cleaned up at end of test
     |
     |  patchAttr(self, obj, attr, value, require_existing=True, wrap=False)
     |      monkeypatch object value, restoring original value on cleanup
     |
     |  require_TEST_MODE(self, level)
     |      skip test for all PASSLIB_TEST_MODE values below <level>
     |
     |  require_stringprep(self)
     |      helper to skip test if stringprep is missing
     |
     |  require_writeable_filesystem(self)
     |      skip test if writeable FS not available
     |
     |  setUp(self)
     |      Hook method for setting up the test fixture before exercising it.
     |
     |  setUpWarnings(self)
     |      helper to init warning filters before subclass setUp()
     |
     |  shortDescription(self)
     |      wrap shortDescription() method to prepend descriptionPrefix
     |
     |  subTest(self, *args, **kwds)
     |      wrapper/backport for .subTest() which also traps SkipTest errors.
     |      (see source for details)
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from passlib.tests.utils.TestCase:
     |
     |  __test__ = True
     |
     |  __unittest_skip__ = False
     |
     |  descriptionPrefix = None
     |
     |  has_real_subtest = True
     |
     |  longMessage = True
     |
     |  resetWarningState = True
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from unittest.case.TestCase:
     |
     |  __call__(self, *args, **kwds)
     |      Call self as a function.
     |
     |  __eq__(self, other)
     |      Return self==value.
     |
     |  __hash__(self)
     |      Return hash(self).
     |
     |  __init__(self, methodName='runTest')
     |      Create an instance of the class that will use the named test
     |      method when executed. Raises a ValueError if the instance does
     |      not have a method with the specified name.
     |
     |  __repr__(self)
     |      Return repr(self).
     |
     |  __str__(self)
     |      Return str(self).
     |
     |  addCleanup(self, function, /, *args, **kwargs)
     |      Add a function, with arguments, to be called when the test is
     |      completed. Functions added are called on a LIFO basis and are
     |      called after tearDown on test failure or success.
     |
     |      Cleanup items are called even if setUp fails (unlike tearDown).
     |
     |  addTypeEqualityFunc(self, typeobj, function)
     |      Add a type specific assertEqual style function to compare a type.
     |
     |      This method is for use by TestCase subclasses that need to register
     |      their own type equality functions to provide nicer error messages.
     |
     |      Args:
     |          typeobj: The data type to call this function on when both values
     |                  are of the same type in assertEqual().
     |          function: The callable taking two arguments and an optional
     |                  msg= argument that raises self.failureException with a
     |                  useful error message when the two arguments are not equal.
     |
     |  assertAlmostEqual(self, first, second, places=None, msg=None, delta=None)
     |      Fail if the two objects are unequal as determined by their
     |      difference rounded to the given number of decimal places
     |      (default 7) and comparing to zero, or by comparing that the
     |      difference between the two objects is more than the given
     |      delta.
     |
     |      Note that decimal places (from zero) are usually not the same
     |      as significant digits (measured from the most significant digit).
     |
     |      If the two objects compare equal then they will automatically
     |      compare almost equal.
     |
     |  assertCountEqual(self, first, second, msg=None)
     |      Asserts that two iterables have the same elements, the same number of
     |      times, without regard to order.
     |
     |          self.assertEqual(Counter(list(first)),
     |                           Counter(list(second)))
     |
     |       Example:
     |          - [0, 1, 1] and [1, 0, 1] compare equal.
     |          - [0, 0, 1] and [0, 1] compare unequal.
     |
     |  assertDictEqual(self, d1, d2, msg=None)
     |
     |  assertEqual(self, first, second, msg=None)
     |      Fail if the two objects are unequal as determined by the '=='
     |      operator.
     |
     |  assertFalse(self, expr, msg=None)
     |      Check that the expression is false.
     |
     |  assertGreater(self, a, b, msg=None)
     |      Just like self.assertTrue(a > b), but with a nicer default message.
     |
     |  assertGreaterEqual(self, a, b, msg=None)
     |      Just like self.assertTrue(a >= b), but with a nicer default message.
     |
     |  assertIn(self, member, container, msg=None)
     |      Just like self.assertTrue(a in b), but with a nicer default message.
     |
     |  assertIs(self, expr1, expr2, msg=None)
     |      Just like self.assertTrue(a is b), but with a nicer default message.
     |
     |  assertIsInstance(self, obj, cls, msg=None)
     |      Same as self.assertTrue(isinstance(obj, cls)), with a nicer
     |      default message.
     |
     |  assertIsNone(self, obj, msg=None)
     |      Same as self.assertTrue(obj is None), with a nicer default message.
     |
     |  assertIsNot(self, expr1, expr2, msg=None)
     |      Just like self.assertTrue(a is not b), but with a nicer default message.
     |
     |  assertIsNotNone(self, obj, msg=None)
     |      Included for symmetry with assertIsNone.
     |
     |  assertLess(self, a, b, msg=None)
     |      Just like self.assertTrue(a < b), but with a nicer default message.
     |
     |  assertLessEqual(self, a, b, msg=None)
     |      Just like self.assertTrue(a <= b), but with a nicer default message.
     |
     |  assertListEqual(self, list1, list2, msg=None)
     |      A list-specific equality assertion.
     |
     |      Args:
     |          list1: The first list to compare.
     |          list2: The second list to compare.
     |          msg: Optional message to use on failure instead of a list of
     |                  differences.
     |
     |  assertLogs(self, logger=None, level=None)
     |      Fail unless a log message of level *level* or higher is emitted
     |      on *logger_name* or its children.  If omitted, *level* defaults to
     |      INFO and *logger* defaults to the root logger.
     |
     |      This method must be used as a context manager, and will yield
     |      a recording object with two attributes: `output` and `records`.
     |      At the end of the context manager, the `output` attribute will
     |      be a list of the matching formatted log messages and the
     |      `records` attribute will be a list of the corresponding LogRecord
     |      objects.
     |
     |      Example::
     |
     |          with self.assertLogs('foo', level='INFO') as cm:
     |              logging.getLogger('foo').info('first message')
     |              logging.getLogger('foo.bar').error('second message')
     |          self.assertEqual(cm.output, ['INFO:foo:first message',
     |                                       'ERROR:foo.bar:second message'])
     |
     |  assertMultiLineEqual(self, first, second, msg=None)
     |      Assert that two multi-line strings are equal.
     |
     |  assertNoLogs(self, logger=None, level=None)
     |      Fail unless no log messages of level *level* or higher are emitted
     |      on *logger_name* or its children.
     |
     |      This method must be used as a context manager.
     |
     |  assertNotAlmostEqual(self, first, second, places=None, msg=None, delta=None)
     |      Fail if the two objects are equal as determined by their
     |      difference rounded to the given number of decimal places
     |      (default 7) and comparing to zero, or by comparing that the
     |      difference between the two objects is less than the given delta.
     |
     |      Note that decimal places (from zero) are usually not the same
     |      as significant digits (measured from the most significant digit).
     |
     |      Objects that are equal automatically fail.
     |
     |  assertNotEqual(self, first, second, msg=None)
     |      Fail if the two objects are equal as determined by the '!='
     |      operator.
     |
     |  assertNotIn(self, member, container, msg=None)
     |      Just like self.assertTrue(a not in b), but with a nicer default message.
     |
     |  assertNotIsInstance(self, obj, cls, msg=None)
     |      Included for symmetry with assertIsInstance.
     |
     |  assertNotRegex(self, text, unexpected_regex, msg=None)
     |      Fail the test if the text matches the regular expression.
     |
     |  assertRaisesRegex(self, expected_exception, expected_regex, *args, **kwargs)
     |      Asserts that the message in a raised exception matches a regex.
     |
     |      Args:
     |          expected_exception: Exception class expected to be raised.
     |          expected_regex: Regex (re.Pattern object or string) expected
     |                  to be found in error message.
     |          args: Function to be called and extra positional args.
     |          kwargs: Extra kwargs.
     |          msg: Optional message used in case of failure. Can only be used
     |                  when assertRaisesRegex is used as a context manager.
     |
     |  assertRegex(self, text, expected_regex, msg=None)
     |      Fail the test unless the text matches the regular expression.
     |
     |  assertSequenceEqual(self, seq1, seq2, msg=None, seq_type=None)
     |      An equality assertion for ordered sequences (like lists and tuples).
     |
     |      For the purposes of this function, a valid ordered sequence type is one
     |      which can be indexed, has a length, and has an equality operator.
     |
     |      Args:
     |          seq1: The first sequence to compare.
     |          seq2: The second sequence to compare.
     |          seq_type: The expected datatype of the sequences, or None if no
     |                  datatype should be enforced.
     |          msg: Optional message to use on failure instead of a list of
     |                  differences.
     |
     |  assertSetEqual(self, set1, set2, msg=None)
     |      A set-specific equality assertion.
     |
     |      Args:
     |          set1: The first set to compare.
     |          set2: The second set to compare.
     |          msg: Optional message to use on failure instead of a list of
     |                  differences.
     |
     |      assertSetEqual uses ducktyping to support different types of sets, and
     |      is optimized for sets specifically (parameters must support a
     |      difference method).
     |
     |  assertTrue(self, expr, msg=None)
     |      Check that the expression is true.
     |
     |  assertTupleEqual(self, tuple1, tuple2, msg=None)
     |      A tuple-specific equality assertion.
     |
     |      Args:
     |          tuple1: The first tuple to compare.
     |          tuple2: The second tuple to compare.
     |          msg: Optional message to use on failure instead of a list of
     |                  differences.
     |
     |  assertWarns(self, expected_warning, *args, **kwargs)
     |      Fail unless a warning of class warnClass is triggered
     |      by the callable when invoked with specified positional and
     |      keyword arguments.  If a different type of warning is
     |      triggered, it will not be handled: depending on the other
     |      warning filtering rules in effect, it might be silenced, printed
     |      out, or raised as an exception.
     |
     |      If called with the callable and arguments omitted, will return a
     |      context object used like this::
     |
     |           with self.assertWarns(SomeWarning):
     |               do_something()
     |
     |      An optional keyword argument 'msg' can be provided when assertWarns
     |      is used as a context object.
     |
     |      The context manager keeps a reference to the first matching
     |      warning as the 'warning' attribute; similarly, the 'filename'
     |      and 'lineno' attributes give you information about the line
     |      of Python code from which the warning was triggered.
     |      This allows you to inspect the warning after the assertion::
     |
     |          with self.assertWarns(SomeWarning) as cm:
     |              do_something()
     |          the_warning = cm.warning
     |          self.assertEqual(the_warning.some_attribute, 147)
     |
     |  assertWarnsRegex(self, expected_warning, expected_regex, *args, **kwargs)
     |      Asserts that the message in a triggered warning matches a regexp.
     |      Basic functioning is similar to assertWarns() with the addition
     |      that only warnings whose messages also match the regular expression
     |      are considered successful matches.
     |
     |      Args:
     |          expected_warning: Warning class expected to be triggered.
     |          expected_regex: Regex (re.Pattern object or string) expected
     |                  to be found in error message.
     |          args: Function to be called and extra positional args.
     |          kwargs: Extra kwargs.
     |          msg: Optional message used in case of failure. Can only be used
     |                  when assertWarnsRegex is used as a context manager.
     |
     |  countTestCases(self)
     |
     |  debug(self)
     |      Run the test without collecting errors in a TestResult
     |
     |  defaultTestResult(self)
     |
     |  doCleanups(self)
     |      Execute all cleanup functions. Normally called for you after
     |      tearDown.
     |
     |  enterContext(self, cm)
     |      Enters the supplied context manager.
     |
     |      If successful, also adds its __exit__ method as a cleanup
     |      function and returns the result of the __enter__ method.
     |
     |  fail(self, msg=None)
     |      Fail immediately, with the given message.
     |
     |  id(self)
     |
     |  run(self, result=None)
     |
     |  skipTest(self, reason)
     |      Skip this test.
     |
     |  tearDown(self)
     |      Hook method for deconstructing the test fixture after testing it.
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from unittest.case.TestCase:
     |
     |  __init_subclass__(*args, **kwargs)
     |      This method is called when a class is subclassed.
     |
     |      The default implementation does nothing. It may be
     |      overridden to extend subclasses.
     |
     |  addClassCleanup(function, /, *args, **kwargs)
     |      Same as addCleanup, except the cleanup items are called even if
     |      setUpClass fails (unlike tearDownClass).
     |
     |  doClassCleanups()
     |      Execute all class cleanup functions. Normally called for you after
     |      tearDownClass.
     |
     |  enterClassContext(cm)
     |      Same as enterContext, but class-wide.
     |
     |  setUpClass()
     |      Hook method for setting up class fixture before running tests in the class.
     |
     |  tearDownClass()
     |      Hook method for deconstructing the class fixture after running all tests in the class.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from unittest.case.TestCase:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from unittest.case.TestCase:
     |
     |  failureException = <class 'AssertionError'>
     |      Assertion failed.
     |
     |
     |  maxDiff = 640

    class H64Big_Test(_Base64Test)
     |  H64Big_Test(methodName='runTest')
     |
     |  test H64Big codec functions
     |
     |  Method resolution order:
     |      H64Big_Test
     |      _Base64Test
     |      passlib.tests.utils.TestCase
     |      passlib.tests.backports.TestCase
     |      unittest.case.TestCase
     |      builtins.object
     |
     |  Data and other attributes defined here:
     |
     |  descriptionPrefix = 'h64big codec'
     |
     |  encoded_data = [(b'', b''), (b'U', b'JE'), (b'U\xaa', b'JOc'), (b'U\xa...
     |
     |  encoded_ints = [(b'.z', 63, 12), (b'z.', 4032, 12)]
     |
     |  engine = <passlib.utils.binary.LazyBase64Engine object>
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from _Base64Test:
     |
     |  check_int_pair(self, bits, encoded_pairs)
     |      helper to check encode_intXX & decode_intXX functions
     |
     |  m(self, *offsets)
     |      generate byte string from offsets
     |
     |  test_codec(self)
     |      test encode_bytes/decode_bytes against random data
     |
     |  test_decode_bytes(self)
     |      test decode_bytes() against reference inputs
     |
     |  test_decode_bytes_bad(self)
     |      test decode_bytes() with bad input
     |
     |  test_decode_bytes_padding(self)
     |      test decode_bytes() ignores padding bits
     |
     |  test_decode_transposed_bytes(self)
     |      test decode_transposed_bytes()
     |
     |  test_decode_transposed_bytes_bad(self)
     |      test decode_transposed_bytes() fails if map is a one-way
     |
     |  test_encode_bytes(self)
     |      test encode_bytes() against reference inputs
     |
     |  test_encode_bytes_bad(self)
     |      test encode_bytes() with bad input
     |
     |  test_encode_transposed_bytes(self)
     |      test encode_transposed_bytes()
     |
     |  test_encoded_ints(self)
     |      test against reference integer encodings
     |
     |  test_int12(self)
     |
     |  test_int24(self)
     |
     |  test_int6(self)
     |
     |  test_int64(self)
     |
     |  test_repair_unused(self)
     |      test repair_unused()
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from _Base64Test:
     |
     |  bad_byte = b'?'
     |
     |  transposed = [(b'3"\x11', b'\x11"3', [2, 1, 0]), (b'"3\x11', b'\x11"3'...
     |
     |  transposed_dups = [(b'\x11\x11"', b'\x11"3', [0, 0, 1])]
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from passlib.tests.utils.TestCase:
     |
     |  assertEquals(self, *a, **k)
     |      #---------------------------------------------------------------
     |      # forbid a bunch of deprecated aliases so I stop using them
     |      #---------------------------------------------------------------
     |
     |  assertNotEquals = assertEquals(self, *a, **k)
     |
     |  assertRaises(self, _exc_type, _callable=None, *args, **kwds)
     |      Fail unless an exception of class expected_exception is raised
     |      by the callable when invoked with specified positional and
     |      keyword arguments. If a different type of exception is
     |      raised, it will not be caught, and the test case will be
     |      deemed to have suffered an error, exactly as for an
     |      unexpected exception.
     |
     |      If called with the callable and arguments omitted, will return a
     |      context object used like this::
     |
     |           with self.assertRaises(SomeException):
     |               do_something()
     |
     |      An optional keyword argument 'msg' can be provided when assertRaises
     |      is used as a context object.
     |
     |      The context manager keeps a reference to the exception as
     |      the 'exception' attribute. This allows you to inspect the
     |      exception after the assertion::
     |
     |          with self.assertRaises(SomeException) as cm:
     |              do_something()
     |          the_exception = cm.exception
     |          self.assertEqual(the_exception.error_code, 3)
     |
     |  assertRegexMatches = assertEquals(self, *a, **k)
     |
     |  assertWarning(self, warning, message_re=None, message=None, category=None, filename_re=None, filename=None, lineno=None, msg=None)
     |      check if warning matches specified parameters.
     |      'warning' is the instance of Warning to match against;
     |      can also be instance of WarningMessage (as returned by catch_warnings).
     |
     |  assertWarningList(self, wlist=None, desc=None, msg=None)
     |      check that warning list (e.g. from catch_warnings) matches pattern
     |
     |  consumeWarningList(self, wlist, desc=None, *args, **kwds)
     |      [deprecated] assertWarningList() variant that clears list afterwards
     |
     |  getLogger(self)
     |      return logger named after current test.
     |
     |  getRandom(self, name='default', seed=None)
     |      Return a :class:`random.Random` object for current test method to use.
     |      Within an instance, multiple calls with the same name will return
     |      the same object.
     |
     |      When first created, each RNG will be seeded with value derived from
     |      a global seed, the test class module & name, the current test method name,
     |      and the **name** parameter.
     |
     |      The global seed taken from the $RANDOM_TEST_SEED env var,
     |      the $PYTHONHASHSEED env var, or a randomly generated the
     |      first time this method is called. In all cases, the value
     |      is logged for reproducibility.
     |
     |      :param name:
     |          name to uniquely identify separate RNGs w/in a test
     |          (e.g. for threaded tests).
     |
     |      :param seed:
     |          override global seed when initialzing rng.
     |
     |      :rtype: random.Random
     |
     |  mktemp(self, *args, **kwds)
     |      create temp file that's cleaned up at end of test
     |
     |  patchAttr(self, obj, attr, value, require_existing=True, wrap=False)
     |      monkeypatch object value, restoring original value on cleanup
     |
     |  require_TEST_MODE(self, level)
     |      skip test for all PASSLIB_TEST_MODE values below <level>
     |
     |  require_stringprep(self)
     |      helper to skip test if stringprep is missing
     |
     |  require_writeable_filesystem(self)
     |      skip test if writeable FS not available
     |
     |  setUp(self)
     |      Hook method for setting up the test fixture before exercising it.
     |
     |  setUpWarnings(self)
     |      helper to init warning filters before subclass setUp()
     |
     |  shortDescription(self)
     |      wrap shortDescription() method to prepend descriptionPrefix
     |
     |  subTest(self, *args, **kwds)
     |      wrapper/backport for .subTest() which also traps SkipTest errors.
     |      (see source for details)
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from passlib.tests.utils.TestCase:
     |
     |  __test__ = True
     |
     |  __unittest_skip__ = False
     |
     |  has_real_subtest = True
     |
     |  longMessage = True
     |
     |  resetWarningState = True
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from unittest.case.TestCase:
     |
     |  __call__(self, *args, **kwds)
     |      Call self as a function.
     |
     |  __eq__(self, other)
     |      Return self==value.
     |
     |  __hash__(self)
     |      Return hash(self).
     |
     |  __init__(self, methodName='runTest')
     |      Create an instance of the class that will use the named test
     |      method when executed. Raises a ValueError if the instance does
     |      not have a method with the specified name.
     |
     |  __repr__(self)
     |      Return repr(self).
     |
     |  __str__(self)
     |      Return str(self).
     |
     |  addCleanup(self, function, /, *args, **kwargs)
     |      Add a function, with arguments, to be called when the test is
     |      completed. Functions added are called on a LIFO basis and are
     |      called after tearDown on test failure or success.
     |
     |      Cleanup items are called even if setUp fails (unlike tearDown).
     |
     |  addTypeEqualityFunc(self, typeobj, function)
     |      Add a type specific assertEqual style function to compare a type.
     |
     |      This method is for use by TestCase subclasses that need to register
     |      their own type equality functions to provide nicer error messages.
     |
     |      Args:
     |          typeobj: The data type to call this function on when both values
     |                  are of the same type in assertEqual().
     |          function: The callable taking two arguments and an optional
     |                  msg= argument that raises self.failureException with a
     |                  useful error message when the two arguments are not equal.
     |
     |  assertAlmostEqual(self, first, second, places=None, msg=None, delta=None)
     |      Fail if the two objects are unequal as determined by their
     |      difference rounded to the given number of decimal places
     |      (default 7) and comparing to zero, or by comparing that the
     |      difference between the two objects is more than the given
     |      delta.
     |
     |      Note that decimal places (from zero) are usually not the same
     |      as significant digits (measured from the most significant digit).
     |
     |      If the two objects compare equal then they will automatically
     |      compare almost equal.
     |
     |  assertCountEqual(self, first, second, msg=None)
     |      Asserts that two iterables have the same elements, the same number of
     |      times, without regard to order.
     |
     |          self.assertEqual(Counter(list(first)),
     |                           Counter(list(second)))
     |
     |       Example:
     |          - [0, 1, 1] and [1, 0, 1] compare equal.
     |          - [0, 0, 1] and [0, 1] compare unequal.
     |
     |  assertDictEqual(self, d1, d2, msg=None)
     |
     |  assertEqual(self, first, second, msg=None)
     |      Fail if the two objects are unequal as determined by the '=='
     |      operator.
     |
     |  assertFalse(self, expr, msg=None)
     |      Check that the expression is false.
     |
     |  assertGreater(self, a, b, msg=None)
     |      Just like self.assertTrue(a > b), but with a nicer default message.
     |
     |  assertGreaterEqual(self, a, b, msg=None)
     |      Just like self.assertTrue(a >= b), but with a nicer default message.
     |
     |  assertIn(self, member, container, msg=None)
     |      Just like self.assertTrue(a in b), but with a nicer default message.
     |
     |  assertIs(self, expr1, expr2, msg=None)
     |      Just like self.assertTrue(a is b), but with a nicer default message.
     |
     |  assertIsInstance(self, obj, cls, msg=None)
     |      Same as self.assertTrue(isinstance(obj, cls)), with a nicer
     |      default message.
     |
     |  assertIsNone(self, obj, msg=None)
     |      Same as self.assertTrue(obj is None), with a nicer default message.
     |
     |  assertIsNot(self, expr1, expr2, msg=None)
     |      Just like self.assertTrue(a is not b), but with a nicer default message.
     |
     |  assertIsNotNone(self, obj, msg=None)
     |      Included for symmetry with assertIsNone.
     |
     |  assertLess(self, a, b, msg=None)
     |      Just like self.assertTrue(a < b), but with a nicer default message.
     |
     |  assertLessEqual(self, a, b, msg=None)
     |      Just like self.assertTrue(a <= b), but with a nicer default message.
     |
     |  assertListEqual(self, list1, list2, msg=None)
     |      A list-specific equality assertion.
     |
     |      Args:
     |          list1: The first list to compare.
     |          list2: The second list to compare.
     |          msg: Optional message to use on failure instead of a list of
     |                  differences.
     |
     |  assertLogs(self, logger=None, level=None)
     |      Fail unless a log message of level *level* or higher is emitted
     |      on *logger_name* or its children.  If omitted, *level* defaults to
     |      INFO and *logger* defaults to the root logger.
     |
     |      This method must be used as a context manager, and will yield
     |      a recording object with two attributes: `output` and `records`.
     |      At the end of the context manager, the `output` attribute will
     |      be a list of the matching formatted log messages and the
     |      `records` attribute will be a list of the corresponding LogRecord
     |      objects.
     |
     |      Example::
     |
     |          with self.assertLogs('foo', level='INFO') as cm:
     |              logging.getLogger('foo').info('first message')
     |              logging.getLogger('foo.bar').error('second message')
     |          self.assertEqual(cm.output, ['INFO:foo:first message',
     |                                       'ERROR:foo.bar:second message'])
     |
     |  assertMultiLineEqual(self, first, second, msg=None)
     |      Assert that two multi-line strings are equal.
     |
     |  assertNoLogs(self, logger=None, level=None)
     |      Fail unless no log messages of level *level* or higher are emitted
     |      on *logger_name* or its children.
     |
     |      This method must be used as a context manager.
     |
     |  assertNotAlmostEqual(self, first, second, places=None, msg=None, delta=None)
     |      Fail if the two objects are equal as determined by their
     |      difference rounded to the given number of decimal places
     |      (default 7) and comparing to zero, or by comparing that the
     |      difference between the two objects is less than the given delta.
     |
     |      Note that decimal places (from zero) are usually not the same
     |      as significant digits (measured from the most significant digit).
     |
     |      Objects that are equal automatically fail.
     |
     |  assertNotEqual(self, first, second, msg=None)
     |      Fail if the two objects are equal as determined by the '!='
     |      operator.
     |
     |  assertNotIn(self, member, container, msg=None)
     |      Just like self.assertTrue(a not in b), but with a nicer default message.
     |
     |  assertNotIsInstance(self, obj, cls, msg=None)
     |      Included for symmetry with assertIsInstance.
     |
     |  assertNotRegex(self, text, unexpected_regex, msg=None)
     |      Fail the test if the text matches the regular expression.
     |
     |  assertRaisesRegex(self, expected_exception, expected_regex, *args, **kwargs)
     |      Asserts that the message in a raised exception matches a regex.
     |
     |      Args:
     |          expected_exception: Exception class expected to be raised.
     |          expected_regex: Regex (re.Pattern object or string) expected
     |                  to be found in error message.
     |          args: Function to be called and extra positional args.
     |          kwargs: Extra kwargs.
     |          msg: Optional message used in case of failure. Can only be used
     |                  when assertRaisesRegex is used as a context manager.
     |
     |  assertRegex(self, text, expected_regex, msg=None)
     |      Fail the test unless the text matches the regular expression.
     |
     |  assertSequenceEqual(self, seq1, seq2, msg=None, seq_type=None)
     |      An equality assertion for ordered sequences (like lists and tuples).
     |
     |      For the purposes of this function, a valid ordered sequence type is one
     |      which can be indexed, has a length, and has an equality operator.
     |
     |      Args:
     |          seq1: The first sequence to compare.
     |          seq2: The second sequence to compare.
     |          seq_type: The expected datatype of the sequences, or None if no
     |                  datatype should be enforced.
     |          msg: Optional message to use on failure instead of a list of
     |                  differences.
     |
     |  assertSetEqual(self, set1, set2, msg=None)
     |      A set-specific equality assertion.
     |
     |      Args:
     |          set1: The first set to compare.
     |          set2: The second set to compare.
     |          msg: Optional message to use on failure instead of a list of
     |                  differences.
     |
     |      assertSetEqual uses ducktyping to support different types of sets, and
     |      is optimized for sets specifically (parameters must support a
     |      difference method).
     |
     |  assertTrue(self, expr, msg=None)
     |      Check that the expression is true.
     |
     |  assertTupleEqual(self, tuple1, tuple2, msg=None)
     |      A tuple-specific equality assertion.
     |
     |      Args:
     |          tuple1: The first tuple to compare.
     |          tuple2: The second tuple to compare.
     |          msg: Optional message to use on failure instead of a list of
     |                  differences.
     |
     |  assertWarns(self, expected_warning, *args, **kwargs)
     |      Fail unless a warning of class warnClass is triggered
     |      by the callable when invoked with specified positional and
     |      keyword arguments.  If a different type of warning is
     |      triggered, it will not be handled: depending on the other
     |      warning filtering rules in effect, it might be silenced, printed
     |      out, or raised as an exception.
     |
     |      If called with the callable and arguments omitted, will return a
     |      context object used like this::
     |
     |           with self.assertWarns(SomeWarning):
     |               do_something()
     |
     |      An optional keyword argument 'msg' can be provided when assertWarns
     |      is used as a context object.
     |
     |      The context manager keeps a reference to the first matching
     |      warning as the 'warning' attribute; similarly, the 'filename'
     |      and 'lineno' attributes give you information about the line
     |      of Python code from which the warning was triggered.
     |      This allows you to inspect the warning after the assertion::
     |
     |          with self.assertWarns(SomeWarning) as cm:
     |              do_something()
     |          the_warning = cm.warning
     |          self.assertEqual(the_warning.some_attribute, 147)
     |
     |  assertWarnsRegex(self, expected_warning, expected_regex, *args, **kwargs)
     |      Asserts that the message in a triggered warning matches a regexp.
     |      Basic functioning is similar to assertWarns() with the addition
     |      that only warnings whose messages also match the regular expression
     |      are considered successful matches.
     |
     |      Args:
     |          expected_warning: Warning class expected to be triggered.
     |          expected_regex: Regex (re.Pattern object or string) expected
     |                  to be found in error message.
     |          args: Function to be called and extra positional args.
     |          kwargs: Extra kwargs.
     |          msg: Optional message used in case of failure. Can only be used
     |                  when assertWarnsRegex is used as a context manager.
     |
     |  countTestCases(self)
     |
     |  debug(self)
     |      Run the test without collecting errors in a TestResult
     |
     |  defaultTestResult(self)
     |
     |  doCleanups(self)
     |      Execute all cleanup functions. Normally called for you after
     |      tearDown.
     |
     |  enterContext(self, cm)
     |      Enters the supplied context manager.
     |
     |      If successful, also adds its __exit__ method as a cleanup
     |      function and returns the result of the __enter__ method.
     |
     |  fail(self, msg=None)
     |      Fail immediately, with the given message.
     |
     |  id(self)
     |
     |  run(self, result=None)
     |
     |  skipTest(self, reason)
     |      Skip this test.
     |
     |  tearDown(self)
     |      Hook method for deconstructing the test fixture after testing it.
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from unittest.case.TestCase:
     |
     |  __init_subclass__(*args, **kwargs)
     |      This method is called when a class is subclassed.
     |
     |      The default implementation does nothing. It may be
     |      overridden to extend subclasses.
     |
     |  addClassCleanup(function, /, *args, **kwargs)
     |      Same as addCleanup, except the cleanup items are called even if
     |      setUpClass fails (unlike tearDownClass).
     |
     |  doClassCleanups()
     |      Execute all class cleanup functions. Normally called for you after
     |      tearDownClass.
     |
     |  enterClassContext(cm)
     |      Same as enterContext, but class-wide.
     |
     |  setUpClass()
     |      Hook method for setting up class fixture before running tests in the class.
     |
     |  tearDownClass()
     |      Hook method for deconstructing the class fixture after running all tests in the class.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from unittest.case.TestCase:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from unittest.case.TestCase:
     |
     |  failureException = <class 'AssertionError'>
     |      Assertion failed.
     |
     |
     |  maxDiff = 640

    class H64_Test(_Base64Test)
     |  H64_Test(methodName='runTest')
     |
     |  test H64 codec functions
     |
     |  Method resolution order:
     |      H64_Test
     |      _Base64Test
     |      passlib.tests.utils.TestCase
     |      passlib.tests.backports.TestCase
     |      unittest.case.TestCase
     |      builtins.object
     |
     |  Data and other attributes defined here:
     |
     |  descriptionPrefix = 'h64 codec'
     |
     |  encoded_data = [(b'', b''), (b'U', b'J/'), (b'U\xaa', b'Jd8'), (b'U\xa...
     |
     |  encoded_ints = [(b'z.', 63, 12), (b'.z', 4032, 12)]
     |
     |  engine = <passlib.utils.binary.LazyBase64Engine object>
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from _Base64Test:
     |
     |  check_int_pair(self, bits, encoded_pairs)
     |      helper to check encode_intXX & decode_intXX functions
     |
     |  m(self, *offsets)
     |      generate byte string from offsets
     |
     |  test_codec(self)
     |      test encode_bytes/decode_bytes against random data
     |
     |  test_decode_bytes(self)
     |      test decode_bytes() against reference inputs
     |
     |  test_decode_bytes_bad(self)
     |      test decode_bytes() with bad input
     |
     |  test_decode_bytes_padding(self)
     |      test decode_bytes() ignores padding bits
     |
     |  test_decode_transposed_bytes(self)
     |      test decode_transposed_bytes()
     |
     |  test_decode_transposed_bytes_bad(self)
     |      test decode_transposed_bytes() fails if map is a one-way
     |
     |  test_encode_bytes(self)
     |      test encode_bytes() against reference inputs
     |
     |  test_encode_bytes_bad(self)
     |      test encode_bytes() with bad input
     |
     |  test_encode_transposed_bytes(self)
     |      test encode_transposed_bytes()
     |
     |  test_encoded_ints(self)
     |      test against reference integer encodings
     |
     |  test_int12(self)
     |
     |  test_int24(self)
     |
     |  test_int6(self)
     |
     |  test_int64(self)
     |
     |  test_repair_unused(self)
     |      test repair_unused()
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from _Base64Test:
     |
     |  bad_byte = b'?'
     |
     |  transposed = [(b'3"\x11', b'\x11"3', [2, 1, 0]), (b'"3\x11', b'\x11"3'...
     |
     |  transposed_dups = [(b'\x11\x11"', b'\x11"3', [0, 0, 1])]
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from passlib.tests.utils.TestCase:
     |
     |  assertEquals(self, *a, **k)
     |      #---------------------------------------------------------------
     |      # forbid a bunch of deprecated aliases so I stop using them
     |      #---------------------------------------------------------------
     |
     |  assertNotEquals = assertEquals(self, *a, **k)
     |
     |  assertRaises(self, _exc_type, _callable=None, *args, **kwds)
     |      Fail unless an exception of class expected_exception is raised
     |      by the callable when invoked with specified positional and
     |      keyword arguments. If a different type of exception is
     |      raised, it will not be caught, and the test case will be
     |      deemed to have suffered an error, exactly as for an
     |      unexpected exception.
     |
     |      If called with the callable and arguments omitted, will return a
     |      context object used like this::
     |
     |           with self.assertRaises(SomeException):
     |               do_something()
     |
     |      An optional keyword argument 'msg' can be provided when assertRaises
     |      is used as a context object.
     |
     |      The context manager keeps a reference to the exception as
     |      the 'exception' attribute. This allows you to inspect the
     |      exception after the assertion::
     |
     |          with self.assertRaises(SomeException) as cm:
     |              do_something()
     |          the_exception = cm.exception
     |          self.assertEqual(the_exception.error_code, 3)
     |
     |  assertRegexMatches = assertEquals(self, *a, **k)
     |
     |  assertWarning(self, warning, message_re=None, message=None, category=None, filename_re=None, filename=None, lineno=None, msg=None)
     |      check if warning matches specified parameters.
     |      'warning' is the instance of Warning to match against;
     |      can also be instance of WarningMessage (as returned by catch_warnings).
     |
     |  assertWarningList(self, wlist=None, desc=None, msg=None)
     |      check that warning list (e.g. from catch_warnings) matches pattern
     |
     |  consumeWarningList(self, wlist, desc=None, *args, **kwds)
     |      [deprecated] assertWarningList() variant that clears list afterwards
     |
     |  getLogger(self)
     |      return logger named after current test.
     |
     |  getRandom(self, name='default', seed=None)
     |      Return a :class:`random.Random` object for current test method to use.
     |      Within an instance, multiple calls with the same name will return
     |      the same object.
     |
     |      When first created, each RNG will be seeded with value derived from
     |      a global seed, the test class module & name, the current test method name,
     |      and the **name** parameter.
     |
     |      The global seed taken from the $RANDOM_TEST_SEED env var,
     |      the $PYTHONHASHSEED env var, or a randomly generated the
     |      first time this method is called. In all cases, the value
     |      is logged for reproducibility.
     |
     |      :param name:
     |          name to uniquely identify separate RNGs w/in a test
     |          (e.g. for threaded tests).
     |
     |      :param seed:
     |          override global seed when initialzing rng.
     |
     |      :rtype: random.Random
     |
     |  mktemp(self, *args, **kwds)
     |      create temp file that's cleaned up at end of test
     |
     |  patchAttr(self, obj, attr, value, require_existing=True, wrap=False)
     |      monkeypatch object value, restoring original value on cleanup
     |
     |  require_TEST_MODE(self, level)
     |      skip test for all PASSLIB_TEST_MODE values below <level>
     |
     |  require_stringprep(self)
     |      helper to skip test if stringprep is missing
     |
     |  require_writeable_filesystem(self)
     |      skip test if writeable FS not available
     |
     |  setUp(self)
     |      Hook method for setting up the test fixture before exercising it.
     |
     |  setUpWarnings(self)
     |      helper to init warning filters before subclass setUp()
     |
     |  shortDescription(self)
     |      wrap shortDescription() method to prepend descriptionPrefix
     |
     |  subTest(self, *args, **kwds)
     |      wrapper/backport for .subTest() which also traps SkipTest errors.
     |      (see source for details)
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from passlib.tests.utils.TestCase:
     |
     |  __test__ = True
     |
     |  __unittest_skip__ = False
     |
     |  has_real_subtest = True
     |
     |  longMessage = True
     |
     |  resetWarningState = True
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from unittest.case.TestCase:
     |
     |  __call__(self, *args, **kwds)
     |      Call self as a function.
     |
     |  __eq__(self, other)
     |      Return self==value.
     |
     |  __hash__(self)
     |      Return hash(self).
     |
     |  __init__(self, methodName='runTest')
     |      Create an instance of the class that will use the named test
     |      method when executed. Raises a ValueError if the instance does
     |      not have a method with the specified name.
     |
     |  __repr__(self)
     |      Return repr(self).
     |
     |  __str__(self)
     |      Return str(self).
     |
     |  addCleanup(self, function, /, *args, **kwargs)
     |      Add a function, with arguments, to be called when the test is
     |      completed. Functions added are called on a LIFO basis and are
     |      called after tearDown on test failure or success.
     |
     |      Cleanup items are called even if setUp fails (unlike tearDown).
     |
     |  addTypeEqualityFunc(self, typeobj, function)
     |      Add a type specific assertEqual style function to compare a type.
     |
     |      This method is for use by TestCase subclasses that need to register
     |      their own type equality functions to provide nicer error messages.
     |
     |      Args:
     |          typeobj: The data type to call this function on when both values
     |                  are of the same type in assertEqual().
     |          function: The callable taking two arguments and an optional
     |                  msg= argument that raises self.failureException with a
     |                  useful error message when the two arguments are not equal.
     |
     |  assertAlmostEqual(self, first, second, places=None, msg=None, delta=None)
     |      Fail if the two objects are unequal as determined by their
     |      difference rounded to the given number of decimal places
     |      (default 7) and comparing to zero, or by comparing that the
     |      difference between the two objects is more than the given
     |      delta.
     |
     |      Note that decimal places (from zero) are usually not the same
     |      as significant digits (measured from the most significant digit).
     |
     |      If the two objects compare equal then they will automatically
     |      compare almost equal.
     |
     |  assertCountEqual(self, first, second, msg=None)
     |      Asserts that two iterables have the same elements, the same number of
     |      times, without regard to order.
     |
     |          self.assertEqual(Counter(list(first)),
     |                           Counter(list(second)))
     |
     |       Example:
     |          - [0, 1, 1] and [1, 0, 1] compare equal.
     |          - [0, 0, 1] and [0, 1] compare unequal.
     |
     |  assertDictEqual(self, d1, d2, msg=None)
     |
     |  assertEqual(self, first, second, msg=None)
     |      Fail if the two objects are unequal as determined by the '=='
     |      operator.
     |
     |  assertFalse(self, expr, msg=None)
     |      Check that the expression is false.
     |
     |  assertGreater(self, a, b, msg=None)
     |      Just like self.assertTrue(a > b), but with a nicer default message.
     |
     |  assertGreaterEqual(self, a, b, msg=None)
     |      Just like self.assertTrue(a >= b), but with a nicer default message.
     |
     |  assertIn(self, member, container, msg=None)
     |      Just like self.assertTrue(a in b), but with a nicer default message.
     |
     |  assertIs(self, expr1, expr2, msg=None)
     |      Just like self.assertTrue(a is b), but with a nicer default message.
     |
     |  assertIsInstance(self, obj, cls, msg=None)
     |      Same as self.assertTrue(isinstance(obj, cls)), with a nicer
     |      default message.
     |
     |  assertIsNone(self, obj, msg=None)
     |      Same as self.assertTrue(obj is None), with a nicer default message.
     |
     |  assertIsNot(self, expr1, expr2, msg=None)
     |      Just like self.assertTrue(a is not b), but with a nicer default message.
     |
     |  assertIsNotNone(self, obj, msg=None)
     |      Included for symmetry with assertIsNone.
     |
     |  assertLess(self, a, b, msg=None)
     |      Just like self.assertTrue(a < b), but with a nicer default message.
     |
     |  assertLessEqual(self, a, b, msg=None)
     |      Just like self.assertTrue(a <= b), but with a nicer default message.
     |
     |  assertListEqual(self, list1, list2, msg=None)
     |      A list-specific equality assertion.
     |
     |      Args:
     |          list1: The first list to compare.
     |          list2: The second list to compare.
     |          msg: Optional message to use on failure instead of a list of
     |                  differences.
     |
     |  assertLogs(self, logger=None, level=None)
     |      Fail unless a log message of level *level* or higher is emitted
     |      on *logger_name* or its children.  If omitted, *level* defaults to
     |      INFO and *logger* defaults to the root logger.
     |
     |      This method must be used as a context manager, and will yield
     |      a recording object with two attributes: `output` and `records`.
     |      At the end of the context manager, the `output` attribute will
     |      be a list of the matching formatted log messages and the
     |      `records` attribute will be a list of the corresponding LogRecord
     |      objects.
     |
     |      Example::
     |
     |          with self.assertLogs('foo', level='INFO') as cm:
     |              logging.getLogger('foo').info('first message')
     |              logging.getLogger('foo.bar').error('second message')
     |          self.assertEqual(cm.output, ['INFO:foo:first message',
     |                                       'ERROR:foo.bar:second message'])
     |
     |  assertMultiLineEqual(self, first, second, msg=None)
     |      Assert that two multi-line strings are equal.
     |
     |  assertNoLogs(self, logger=None, level=None)
     |      Fail unless no log messages of level *level* or higher are emitted
     |      on *logger_name* or its children.
     |
     |      This method must be used as a context manager.
     |
     |  assertNotAlmostEqual(self, first, second, places=None, msg=None, delta=None)
     |      Fail if the two objects are equal as determined by their
     |      difference rounded to the given number of decimal places
     |      (default 7) and comparing to zero, or by comparing that the
     |      difference between the two objects is less than the given delta.
     |
     |      Note that decimal places (from zero) are usually not the same
     |      as significant digits (measured from the most significant digit).
     |
     |      Objects that are equal automatically fail.
     |
     |  assertNotEqual(self, first, second, msg=None)
     |      Fail if the two objects are equal as determined by the '!='
     |      operator.
     |
     |  assertNotIn(self, member, container, msg=None)
     |      Just like self.assertTrue(a not in b), but with a nicer default message.
     |
     |  assertNotIsInstance(self, obj, cls, msg=None)
     |      Included for symmetry with assertIsInstance.
     |
     |  assertNotRegex(self, text, unexpected_regex, msg=None)
     |      Fail the test if the text matches the regular expression.
     |
     |  assertRaisesRegex(self, expected_exception, expected_regex, *args, **kwargs)
     |      Asserts that the message in a raised exception matches a regex.
     |
     |      Args:
     |          expected_exception: Exception class expected to be raised.
     |          expected_regex: Regex (re.Pattern object or string) expected
     |                  to be found in error message.
     |          args: Function to be called and extra positional args.
     |          kwargs: Extra kwargs.
     |          msg: Optional message used in case of failure. Can only be used
     |                  when assertRaisesRegex is used as a context manager.
     |
     |  assertRegex(self, text, expected_regex, msg=None)
     |      Fail the test unless the text matches the regular expression.
     |
     |  assertSequenceEqual(self, seq1, seq2, msg=None, seq_type=None)
     |      An equality assertion for ordered sequences (like lists and tuples).
     |
     |      For the purposes of this function, a valid ordered sequence type is one
     |      which can be indexed, has a length, and has an equality operator.
     |
     |      Args:
     |          seq1: The first sequence to compare.
     |          seq2: The second sequence to compare.
     |          seq_type: The expected datatype of the sequences, or None if no
     |                  datatype should be enforced.
     |          msg: Optional message to use on failure instead of a list of
     |                  differences.
     |
     |  assertSetEqual(self, set1, set2, msg=None)
     |      A set-specific equality assertion.
     |
     |      Args:
     |          set1: The first set to compare.
     |          set2: The second set to compare.
     |          msg: Optional message to use on failure instead of a list of
     |                  differences.
     |
     |      assertSetEqual uses ducktyping to support different types of sets, and
     |      is optimized for sets specifically (parameters must support a
     |      difference method).
     |
     |  assertTrue(self, expr, msg=None)
     |      Check that the expression is true.
     |
     |  assertTupleEqual(self, tuple1, tuple2, msg=None)
     |      A tuple-specific equality assertion.
     |
     |      Args:
     |          tuple1: The first tuple to compare.
     |          tuple2: The second tuple to compare.
     |          msg: Optional message to use on failure instead of a list of
     |                  differences.
     |
     |  assertWarns(self, expected_warning, *args, **kwargs)
     |      Fail unless a warning of class warnClass is triggered
     |      by the callable when invoked with specified positional and
     |      keyword arguments.  If a different type of warning is
     |      triggered, it will not be handled: depending on the other
     |      warning filtering rules in effect, it might be silenced, printed
     |      out, or raised as an exception.
     |
     |      If called with the callable and arguments omitted, will return a
     |      context object used like this::
     |
     |           with self.assertWarns(SomeWarning):
     |               do_something()
     |
     |      An optional keyword argument 'msg' can be provided when assertWarns
     |      is used as a context object.
     |
     |      The context manager keeps a reference to the first matching
     |      warning as the 'warning' attribute; similarly, the 'filename'
     |      and 'lineno' attributes give you information about the line
     |      of Python code from which the warning was triggered.
     |      This allows you to inspect the warning after the assertion::
     |
     |          with self.assertWarns(SomeWarning) as cm:
     |              do_something()
     |          the_warning = cm.warning
     |          self.assertEqual(the_warning.some_attribute, 147)
     |
     |  assertWarnsRegex(self, expected_warning, expected_regex, *args, **kwargs)
     |      Asserts that the message in a triggered warning matches a regexp.
     |      Basic functioning is similar to assertWarns() with the addition
     |      that only warnings whose messages also match the regular expression
     |      are considered successful matches.
     |
     |      Args:
     |          expected_warning: Warning class expected to be triggered.
     |          expected_regex: Regex (re.Pattern object or string) expected
     |                  to be found in error message.
     |          args: Function to be called and extra positional args.
     |          kwargs: Extra kwargs.
     |          msg: Optional message used in case of failure. Can only be used
     |                  when assertWarnsRegex is used as a context manager.
     |
     |  countTestCases(self)
     |
     |  debug(self)
     |      Run the test without collecting errors in a TestResult
     |
     |  defaultTestResult(self)
     |
     |  doCleanups(self)
     |      Execute all cleanup functions. Normally called for you after
     |      tearDown.
     |
     |  enterContext(self, cm)
     |      Enters the supplied context manager.
     |
     |      If successful, also adds its __exit__ method as a cleanup
     |      function and returns the result of the __enter__ method.
     |
     |  fail(self, msg=None)
     |      Fail immediately, with the given message.
     |
     |  id(self)
     |
     |  run(self, result=None)
     |
     |  skipTest(self, reason)
     |      Skip this test.
     |
     |  tearDown(self)
     |      Hook method for deconstructing the test fixture after testing it.
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from unittest.case.TestCase:
     |
     |  __init_subclass__(*args, **kwargs)
     |      This method is called when a class is subclassed.
     |
     |      The default implementation does nothing. It may be
     |      overridden to extend subclasses.
     |
     |  addClassCleanup(function, /, *args, **kwargs)
     |      Same as addCleanup, except the cleanup items are called even if
     |      setUpClass fails (unlike tearDownClass).
     |
     |  doClassCleanups()
     |      Execute all class cleanup functions. Normally called for you after
     |      tearDownClass.
     |
     |  enterClassContext(cm)
     |      Same as enterContext, but class-wide.
     |
     |  setUpClass()
     |      Hook method for setting up class fixture before running tests in the class.
     |
     |  tearDownClass()
     |      Hook method for deconstructing the class fixture after running all tests in the class.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from unittest.case.TestCase:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from unittest.case.TestCase:
     |
     |  failureException = <class 'AssertionError'>
     |      Assertion failed.
     |
     |
     |  maxDiff = 640

    class MiscTest(passlib.tests.utils.TestCase)
     |  MiscTest(methodName='runTest')
     |
     |  tests various parts of utils module
     |
     |  Method resolution order:
     |      MiscTest
     |      passlib.tests.utils.TestCase
     |      passlib.tests.backports.TestCase
     |      unittest.case.TestCase
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  test_classproperty(self)
     |
     |  test_compat(self)
     |      test compat's lazymodule
     |
     |  test_consteq(self)
     |      test consteq()
     |
     |  test_crypt(self)
     |      test crypt.crypt() wrappers
     |
     |  test_deprecated_function(self)
     |
     |  test_generate_password(self)
     |      generate_password()
     |
     |  test_genseed(self)
     |      test genseed()
     |
     |  test_getrandbytes(self)
     |      getrandbytes()
     |
     |  test_getrandstr(self, seed)
     |      getrandstr()
     |
     |  test_is_crypt_context(self)
     |      test is_crypt_context()
     |
     |  test_memoized_property(self)
     |
     |  test_saslprep(self)
     |      test saslprep() unicode normalizer
     |
     |  test_splitcomma(self)
     |
     |  test_utf8_truncate(self)
     |      utf8_truncate()
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from passlib.tests.utils.TestCase:
     |
     |  assertEquals(self, *a, **k)
     |      #---------------------------------------------------------------
     |      # forbid a bunch of deprecated aliases so I stop using them
     |      #---------------------------------------------------------------
     |
     |  assertNotEquals = assertEquals(self, *a, **k)
     |
     |  assertRaises(self, _exc_type, _callable=None, *args, **kwds)
     |      Fail unless an exception of class expected_exception is raised
     |      by the callable when invoked with specified positional and
     |      keyword arguments. If a different type of exception is
     |      raised, it will not be caught, and the test case will be
     |      deemed to have suffered an error, exactly as for an
     |      unexpected exception.
     |
     |      If called with the callable and arguments omitted, will return a
     |      context object used like this::
     |
     |           with self.assertRaises(SomeException):
     |               do_something()
     |
     |      An optional keyword argument 'msg' can be provided when assertRaises
     |      is used as a context object.
     |
     |      The context manager keeps a reference to the exception as
     |      the 'exception' attribute. This allows you to inspect the
     |      exception after the assertion::
     |
     |          with self.assertRaises(SomeException) as cm:
     |              do_something()
     |          the_exception = cm.exception
     |          self.assertEqual(the_exception.error_code, 3)
     |
     |  assertRegexMatches = assertEquals(self, *a, **k)
     |
     |  assertWarning(self, warning, message_re=None, message=None, category=None, filename_re=None, filename=None, lineno=None, msg=None)
     |      check if warning matches specified parameters.
     |      'warning' is the instance of Warning to match against;
     |      can also be instance of WarningMessage (as returned by catch_warnings).
     |
     |  assertWarningList(self, wlist=None, desc=None, msg=None)
     |      check that warning list (e.g. from catch_warnings) matches pattern
     |
     |  consumeWarningList(self, wlist, desc=None, *args, **kwds)
     |      [deprecated] assertWarningList() variant that clears list afterwards
     |
     |  getLogger(self)
     |      return logger named after current test.
     |
     |  getRandom(self, name='default', seed=None)
     |      Return a :class:`random.Random` object for current test method to use.
     |      Within an instance, multiple calls with the same name will return
     |      the same object.
     |
     |      When first created, each RNG will be seeded with value derived from
     |      a global seed, the test class module & name, the current test method name,
     |      and the **name** parameter.
     |
     |      The global seed taken from the $RANDOM_TEST_SEED env var,
     |      the $PYTHONHASHSEED env var, or a randomly generated the
     |      first time this method is called. In all cases, the value
     |      is logged for reproducibility.
     |
     |      :param name:
     |          name to uniquely identify separate RNGs w/in a test
     |          (e.g. for threaded tests).
     |
     |      :param seed:
     |          override global seed when initialzing rng.
     |
     |      :rtype: random.Random
     |
     |  mktemp(self, *args, **kwds)
     |      create temp file that's cleaned up at end of test
     |
     |  patchAttr(self, obj, attr, value, require_existing=True, wrap=False)
     |      monkeypatch object value, restoring original value on cleanup
     |
     |  require_TEST_MODE(self, level)
     |      skip test for all PASSLIB_TEST_MODE values below <level>
     |
     |  require_stringprep(self)
     |      helper to skip test if stringprep is missing
     |
     |  require_writeable_filesystem(self)
     |      skip test if writeable FS not available
     |
     |  setUp(self)
     |      Hook method for setting up the test fixture before exercising it.
     |
     |  setUpWarnings(self)
     |      helper to init warning filters before subclass setUp()
     |
     |  shortDescription(self)
     |      wrap shortDescription() method to prepend descriptionPrefix
     |
     |  subTest(self, *args, **kwds)
     |      wrapper/backport for .subTest() which also traps SkipTest errors.
     |      (see source for details)
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from passlib.tests.utils.TestCase:
     |
     |  __test__ = True
     |
     |  __unittest_skip__ = False
     |
     |  descriptionPrefix = None
     |
     |  has_real_subtest = True
     |
     |  longMessage = True
     |
     |  resetWarningState = True
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from unittest.case.TestCase:
     |
     |  __call__(self, *args, **kwds)
     |      Call self as a function.
     |
     |  __eq__(self, other)
     |      Return self==value.
     |
     |  __hash__(self)
     |      Return hash(self).
     |
     |  __init__(self, methodName='runTest')
     |      Create an instance of the class that will use the named test
     |      method when executed. Raises a ValueError if the instance does
     |      not have a method with the specified name.
     |
     |  __repr__(self)
     |      Return repr(self).
     |
     |  __str__(self)
     |      Return str(self).
     |
     |  addCleanup(self, function, /, *args, **kwargs)
     |      Add a function, with arguments, to be called when the test is
     |      completed. Functions added are called on a LIFO basis and are
     |      called after tearDown on test failure or success.
     |
     |      Cleanup items are called even if setUp fails (unlike tearDown).
     |
     |  addTypeEqualityFunc(self, typeobj, function)
     |      Add a type specific assertEqual style function to compare a type.
     |
     |      This method is for use by TestCase subclasses that need to register
     |      their own type equality functions to provide nicer error messages.
     |
     |      Args:
     |          typeobj: The data type to call this function on when both values
     |                  are of the same type in assertEqual().
     |          function: The callable taking two arguments and an optional
     |                  msg= argument that raises self.failureException with a
     |                  useful error message when the two arguments are not equal.
     |
     |  assertAlmostEqual(self, first, second, places=None, msg=None, delta=None)
     |      Fail if the two objects are unequal as determined by their
     |      difference rounded to the given number of decimal places
     |      (default 7) and comparing to zero, or by comparing that the
     |      difference between the two objects is more than the given
     |      delta.
     |
     |      Note that decimal places (from zero) are usually not the same
     |      as significant digits (measured from the most significant digit).
     |
     |      If the two objects compare equal then they will automatically
     |      compare almost equal.
     |
     |  assertCountEqual(self, first, second, msg=None)
     |      Asserts that two iterables have the same elements, the same number of
     |      times, without regard to order.
     |
     |          self.assertEqual(Counter(list(first)),
     |                           Counter(list(second)))
     |
     |       Example:
     |          - [0, 1, 1] and [1, 0, 1] compare equal.
     |          - [0, 0, 1] and [0, 1] compare unequal.
     |
     |  assertDictEqual(self, d1, d2, msg=None)
     |
     |  assertEqual(self, first, second, msg=None)
     |      Fail if the two objects are unequal as determined by the '=='
     |      operator.
     |
     |  assertFalse(self, expr, msg=None)
     |      Check that the expression is false.
     |
     |  assertGreater(self, a, b, msg=None)
     |      Just like self.assertTrue(a > b), but with a nicer default message.
     |
     |  assertGreaterEqual(self, a, b, msg=None)
     |      Just like self.assertTrue(a >= b), but with a nicer default message.
     |
     |  assertIn(self, member, container, msg=None)
     |      Just like self.assertTrue(a in b), but with a nicer default message.
     |
     |  assertIs(self, expr1, expr2, msg=None)
     |      Just like self.assertTrue(a is b), but with a nicer default message.
     |
     |  assertIsInstance(self, obj, cls, msg=None)
     |      Same as self.assertTrue(isinstance(obj, cls)), with a nicer
     |      default message.
     |
     |  assertIsNone(self, obj, msg=None)
     |      Same as self.assertTrue(obj is None), with a nicer default message.
     |
     |  assertIsNot(self, expr1, expr2, msg=None)
     |      Just like self.assertTrue(a is not b), but with a nicer default message.
     |
     |  assertIsNotNone(self, obj, msg=None)
     |      Included for symmetry with assertIsNone.
     |
     |  assertLess(self, a, b, msg=None)
     |      Just like self.assertTrue(a < b), but with a nicer default message.
     |
     |  assertLessEqual(self, a, b, msg=None)
     |      Just like self.assertTrue(a <= b), but with a nicer default message.
     |
     |  assertListEqual(self, list1, list2, msg=None)
     |      A list-specific equality assertion.
     |
     |      Args:
     |          list1: The first list to compare.
     |          list2: The second list to compare.
     |          msg: Optional message to use on failure instead of a list of
     |                  differences.
     |
     |  assertLogs(self, logger=None, level=None)
     |      Fail unless a log message of level *level* or higher is emitted
     |      on *logger_name* or its children.  If omitted, *level* defaults to
     |      INFO and *logger* defaults to the root logger.
     |
     |      This method must be used as a context manager, and will yield
     |      a recording object with two attributes: `output` and `records`.
     |      At the end of the context manager, the `output` attribute will
     |      be a list of the matching formatted log messages and the
     |      `records` attribute will be a list of the corresponding LogRecord
     |      objects.
     |
     |      Example::
     |
     |          with self.assertLogs('foo', level='INFO') as cm:
     |              logging.getLogger('foo').info('first message')
     |              logging.getLogger('foo.bar').error('second message')
     |          self.assertEqual(cm.output, ['INFO:foo:first message',
     |                                       'ERROR:foo.bar:second message'])
     |
     |  assertMultiLineEqual(self, first, second, msg=None)
     |      Assert that two multi-line strings are equal.
     |
     |  assertNoLogs(self, logger=None, level=None)
     |      Fail unless no log messages of level *level* or higher are emitted
     |      on *logger_name* or its children.
     |
     |      This method must be used as a context manager.
     |
     |  assertNotAlmostEqual(self, first, second, places=None, msg=None, delta=None)
     |      Fail if the two objects are equal as determined by their
     |      difference rounded to the given number of decimal places
     |      (default 7) and comparing to zero, or by comparing that the
     |      difference between the two objects is less than the given delta.
     |
     |      Note that decimal places (from zero) are usually not the same
     |      as significant digits (measured from the most significant digit).
     |
     |      Objects that are equal automatically fail.
     |
     |  assertNotEqual(self, first, second, msg=None)
     |      Fail if the two objects are equal as determined by the '!='
     |      operator.
     |
     |  assertNotIn(self, member, container, msg=None)
     |      Just like self.assertTrue(a not in b), but with a nicer default message.
     |
     |  assertNotIsInstance(self, obj, cls, msg=None)
     |      Included for symmetry with assertIsInstance.
     |
     |  assertNotRegex(self, text, unexpected_regex, msg=None)
     |      Fail the test if the text matches the regular expression.
     |
     |  assertRaisesRegex(self, expected_exception, expected_regex, *args, **kwargs)
     |      Asserts that the message in a raised exception matches a regex.
     |
     |      Args:
     |          expected_exception: Exception class expected to be raised.
     |          expected_regex: Regex (re.Pattern object or string) expected
     |                  to be found in error message.
     |          args: Function to be called and extra positional args.
     |          kwargs: Extra kwargs.
     |          msg: Optional message used in case of failure. Can only be used
     |                  when assertRaisesRegex is used as a context manager.
     |
     |  assertRegex(self, text, expected_regex, msg=None)
     |      Fail the test unless the text matches the regular expression.
     |
     |  assertSequenceEqual(self, seq1, seq2, msg=None, seq_type=None)
     |      An equality assertion for ordered sequences (like lists and tuples).
     |
     |      For the purposes of this function, a valid ordered sequence type is one
     |      which can be indexed, has a length, and has an equality operator.
     |
     |      Args:
     |          seq1: The first sequence to compare.
     |          seq2: The second sequence to compare.
     |          seq_type: The expected datatype of the sequences, or None if no
     |                  datatype should be enforced.
     |          msg: Optional message to use on failure instead of a list of
     |                  differences.
     |
     |  assertSetEqual(self, set1, set2, msg=None)
     |      A set-specific equality assertion.
     |
     |      Args:
     |          set1: The first set to compare.
     |          set2: The second set to compare.
     |          msg: Optional message to use on failure instead of a list of
     |                  differences.
     |
     |      assertSetEqual uses ducktyping to support different types of sets, and
     |      is optimized for sets specifically (parameters must support a
     |      difference method).
     |
     |  assertTrue(self, expr, msg=None)
     |      Check that the expression is true.
     |
     |  assertTupleEqual(self, tuple1, tuple2, msg=None)
     |      A tuple-specific equality assertion.
     |
     |      Args:
     |          tuple1: The first tuple to compare.
     |          tuple2: The second tuple to compare.
     |          msg: Optional message to use on failure instead of a list of
     |                  differences.
     |
     |  assertWarns(self, expected_warning, *args, **kwargs)
     |      Fail unless a warning of class warnClass is triggered
     |      by the callable when invoked with specified positional and
     |      keyword arguments.  If a different type of warning is
     |      triggered, it will not be handled: depending on the other
     |      warning filtering rules in effect, it might be silenced, printed
     |      out, or raised as an exception.
     |
     |      If called with the callable and arguments omitted, will return a
     |      context object used like this::
     |
     |           with self.assertWarns(SomeWarning):
     |               do_something()
     |
     |      An optional keyword argument 'msg' can be provided when assertWarns
     |      is used as a context object.
     |
     |      The context manager keeps a reference to the first matching
     |      warning as the 'warning' attribute; similarly, the 'filename'
     |      and 'lineno' attributes give you information about the line
     |      of Python code from which the warning was triggered.
     |      This allows you to inspect the warning after the assertion::
     |
     |          with self.assertWarns(SomeWarning) as cm:
     |              do_something()
     |          the_warning = cm.warning
     |          self.assertEqual(the_warning.some_attribute, 147)
     |
     |  assertWarnsRegex(self, expected_warning, expected_regex, *args, **kwargs)
     |      Asserts that the message in a triggered warning matches a regexp.
     |      Basic functioning is similar to assertWarns() with the addition
     |      that only warnings whose messages also match the regular expression
     |      are considered successful matches.
     |
     |      Args:
     |          expected_warning: Warning class expected to be triggered.
     |          expected_regex: Regex (re.Pattern object or string) expected
     |                  to be found in error message.
     |          args: Function to be called and extra positional args.
     |          kwargs: Extra kwargs.
     |          msg: Optional message used in case of failure. Can only be used
     |                  when assertWarnsRegex is used as a context manager.
     |
     |  countTestCases(self)
     |
     |  debug(self)
     |      Run the test without collecting errors in a TestResult
     |
     |  defaultTestResult(self)
     |
     |  doCleanups(self)
     |      Execute all cleanup functions. Normally called for you after
     |      tearDown.
     |
     |  enterContext(self, cm)
     |      Enters the supplied context manager.
     |
     |      If successful, also adds its __exit__ method as a cleanup
     |      function and returns the result of the __enter__ method.
     |
     |  fail(self, msg=None)
     |      Fail immediately, with the given message.
     |
     |  id(self)
     |
     |  run(self, result=None)
     |
     |  skipTest(self, reason)
     |      Skip this test.
     |
     |  tearDown(self)
     |      Hook method for deconstructing the test fixture after testing it.
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from unittest.case.TestCase:
     |
     |  __init_subclass__(*args, **kwargs)
     |      This method is called when a class is subclassed.
     |
     |      The default implementation does nothing. It may be
     |      overridden to extend subclasses.
     |
     |  addClassCleanup(function, /, *args, **kwargs)
     |      Same as addCleanup, except the cleanup items are called even if
     |      setUpClass fails (unlike tearDownClass).
     |
     |  doClassCleanups()
     |      Execute all class cleanup functions. Normally called for you after
     |      tearDownClass.
     |
     |  enterClassContext(cm)
     |      Same as enterContext, but class-wide.
     |
     |  setUpClass()
     |      Hook method for setting up class fixture before running tests in the class.
     |
     |  tearDownClass()
     |      Hook method for deconstructing the class fixture after running all tests in the class.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from unittest.case.TestCase:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from unittest.case.TestCase:
     |
     |  failureException = <class 'AssertionError'>
     |      Assertion failed.
     |
     |
     |  maxDiff = 640

FUNCTIONS
    join_bytes = join(iterable_of_bytes, /) method of builtins.bytes instance
        Concatenate any number of bytes objects.

        The bytes whose method is called is inserted in between each pair.

        The result is returned as a new bytes object.

        Example: b'.'.join([b'ab', b'pq', b'rs']) -> b'ab.pq.rs'.

DATA
    PY2 = False
    PY3 = True
    PYPY = False
    h64 = <passlib.utils.binary.LazyBase64Engine object>
    h64big = <passlib.utils.binary.LazyBase64Engine object>

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\backend\lib\site-packages\passlib\tests\test_utils.py



================================================================================
Help on module backend.Lib.site-packages.passlib.tests.utils in backend.Lib.site-packages.passlib.tests:

NAME
    backend.Lib.site-packages.passlib.tests.utils - helpers for passlib unittests

CLASSES
    passlib.tests.backports.TestCase(unittest.case.TestCase)
        TestCase
            HandlerCase

    class HandlerCase(TestCase)
     |  HandlerCase(methodName='runTest')
     |
     |  base class for testing password hash handlers (esp passlib.utils.handlers subclasses)
     |
     |  In order to use this to test a handler,
     |  create a subclass will all the appropriate attributes
     |  filled as listed in the example below,
     |  and run the subclass via unittest.
     |
     |  .. todo::
     |
     |      Document all of the options HandlerCase offers.
     |
     |  .. note::
     |
     |      This is subclass of :class:`unittest.TestCase`
     |      (or :class:`unittest2.TestCase` if available).
     |
     |  Method resolution order:
     |      HandlerCase
     |      TestCase
     |      passlib.tests.backports.TestCase
     |      unittest.case.TestCase
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  assert_is_masked(self, value)
     |      check value properly masked by :func:`passlib.utils.mask_value`
     |
     |  check_returned_native_str(self, result, func_name)
     |
     |  check_verify(self, secret, hash, msg=None, negate=False)
     |      helper to check verify() outcome, honoring is_disabled_handler
     |
     |  do_encrypt(self, secret, use_encrypt=False, handler=None, context=None, **settings)
     |      call handler's hash() method with specified options
     |
     |  do_genconfig(self, **kwds)
     |      call handler's genconfig method with specified options
     |
     |  do_genhash(self, secret, config, **kwds)
     |      call handler's genhash method with specified options
     |
     |  do_identify(self, hash)
     |      call handler's identify method
     |
     |  do_stub_encrypt(self, handler=None, context=None, **settings)
     |      return sample hash for handler, w/o caring if digest is valid
     |      (uses some monkeypatching to minimize digest calculation cost)
     |
     |  do_verify(self, secret, hash, handler=None, **kwds)
     |      call handler's verify method
     |
     |  expect_os_crypt_failure(self, secret)
     |      check if we're expecting potential verify failure due to crypt.crypt() encoding limitation
     |
     |  forbidden_characters = None
     |  fuzz_verifier_default(self)
     |
     |  get_fuzz_verifiers(self, threaded=False)
     |      return list of password verifiers (including external libs)
     |
     |      used by fuzz testing.
     |      verifiers should be callable with signature
     |      ``func(password: unicode, hash: ascii str) -> ok: bool``.
     |
     |  get_sample_hash(self)
     |      test random sample secret/hash pair
     |
     |  is_secret_8bit(self, secret)
     |      #===================================================================
     |      # check identify(), verify(), genhash() against test vectors
     |      #===================================================================
     |
     |  populate_context(self, secret, kwds)
     |      subclassable method allowing 'secret' to be encode context kwds
     |
     |  populate_settings(self, kwds)
     |      subclassable method to populate default settings
     |
     |  prepare_salt(self, salt)
     |      prepare generated salt
     |
     |  require_many_idents(self)
     |      #===================================================================
     |      # idents
     |      #===================================================================
     |
     |  require_parsehash(self)
     |
     |  require_rounds_info(self)
     |      #===================================================================
     |      # rounds
     |      #===================================================================
     |
     |  require_salt(self)
     |      #===================================================================
     |      # salts
     |      #===================================================================
     |
     |  require_salt_info(self)
     |
     |  setUp(self)
     |      Hook method for setting up the test fixture before exercising it.
     |
     |  test_01_required_attributes(self)
     |      validate required attributes
     |
     |  test_02_config_workflow(self)
     |      test basic config-string workflow
     |
     |      this tests that genconfig() returns the expected types,
     |      and that identify() and genhash() handle the result correctly.
     |
     |  test_02_using_workflow(self)
     |      test basic using() workflow
     |
     |  test_03_hash_workflow(self, use_16_legacy=False)
     |      test basic hash-string workflow.
     |
     |      this tests that hash()'s hashes are accepted
     |      by verify() and identify(), and regenerated correctly by genhash().
     |      the test is run against a couple of different stock passwords.
     |
     |  test_03_legacy_hash_workflow(self)
     |      test hash-string workflow with legacy .encrypt() & .genhash() methods
     |
     |  test_04_hash_types(self)
     |      test hashes can be unicode or bytes
     |
     |  test_05_backends(self)
     |      test multi-backend support
     |
     |  test_10_optional_salt_attributes(self)
     |      validate optional salt attributes
     |
     |  test_11_unique_salt(self)
     |      test hash() / genconfig() creates new salt each time
     |
     |  test_12_min_salt_size(self)
     |      test hash() / genconfig() honors min_salt_size
     |
     |  test_13_max_salt_size(self)
     |      test hash() / genconfig() honors max_salt_size
     |
     |  test_14_salt_chars(self)
     |      test hash() honors salt_chars
     |
     |  test_15_salt_type(self)
     |      test non-string salt values
     |
     |  test_20_optional_rounds_attributes(self)
     |      validate optional rounds attributes
     |
     |  test_21_min_rounds(self)
     |      test hash() / genconfig() honors min_rounds
     |
     |  test_21b_max_rounds(self)
     |      test hash() / genconfig() honors max_rounds
     |
     |  test_30_HasManyIdents(self)
     |      validate HasManyIdents configuration
     |
     |  test_61_secret_case_sensitive(self)
     |      test password case sensitivity
     |
     |  test_62_secret_border(self)
     |      test non-string passwords are rejected
     |
     |  test_63_large_secret(self)
     |      test MAX_PASSWORD_SIZE is enforced
     |
     |  test_64_forbidden_chars(self)
     |      test forbidden characters not allowed in password
     |
     |  test_70_hashes(self)
     |      test known hashes
     |
     |  test_70_parsehash(self)
     |      parsehash()
     |
     |  test_71_alternates(self)
     |      test known alternate hashes
     |
     |  test_71_parsehash_results(self)
     |      parsehash() -- known outputs
     |
     |  test_72_configs(self)
     |      test known config strings
     |
     |  test_73_unidentified(self)
     |      test known unidentifiably-mangled strings
     |
     |  test_74_malformed(self)
     |      test known identifiable-but-malformed strings
     |
     |  test_75_foreign(self)
     |      test known foreign hashes
     |
     |  test_76_hash_border(self)
     |      test non-string hashes are rejected
     |
     |  test_77_fuzz_input(self, threaded=False)
     |      fuzz testing -- random passwords and options
     |
     |      This test attempts to perform some basic fuzz testing of the hash,
     |      based on whatever information can be found about it.
     |      It does as much as it can within a fixed amount of time
     |      (defaults to 1 second, but can be overridden via $PASSLIB_TEST_FUZZ_TIME).
     |      It tests the following:
     |
     |      * randomly generated passwords including extended unicode chars
     |      * randomly selected rounds values (if rounds supported)
     |      * randomly selected salt sizes (if salts supported)
     |      * randomly selected identifiers (if multiple found)
     |      * runs output of selected backend against other available backends
     |        (if any) to detect errors occurring between different backends.
     |      * runs output against other "external" verifiers such as OS crypt()
     |
     |      :param report_thread_state:
     |          if true, writes state of loop to current_thread().passlib_fuzz_state.
     |          used to help debug multi-threaded fuzz test issues (below)
     |
     |  test_78_fuzz_threading(self)
     |      multithreaded fuzz testing -- random password & options using multiple threads
     |
     |      run test_77 simultaneously in multiple threads
     |      in an attempt to detect any concurrency issues
     |      (e.g. the bug fixed by pybcrypt 0.3)
     |
     |  test_disable_and_enable(self)
     |      .disable() / .enable() methods
     |
     |  test_has_many_idents_using(self)
     |      HasManyIdents.using() -- 'default_ident' and 'ident' keywords
     |
     |  test_has_rounds_replace_w_max_rounds(self)
     |      HasRounds.using() -- max_rounds / max_desired_rounds
     |
     |  test_has_rounds_using_and_needs_update(self)
     |      HasRounds.using() -- desired_rounds + needs_update()
     |
     |  test_has_rounds_using_harness(self)
     |      HasRounds.using() -- sanity check test harness
     |
     |  test_has_rounds_using_w_default_rounds(self)
     |      HasRounds.using() -- default_rounds
     |
     |  test_has_rounds_using_w_min_rounds(self)
     |      HasRounds.using() -- min_rounds / min_desired_rounds
     |
     |  test_has_rounds_using_w_rounds(self)
     |      HasRounds.using() -- rounds
     |
     |  test_has_rounds_using_w_vary_rounds_generation(self)
     |      HasRounds.using() -- vary_rounds generation
     |
     |  test_has_rounds_using_w_vary_rounds_parsing(self)
     |      HasRounds.using() -- vary_rounds parsing
     |
     |  test_secret_w_truncate_size(self)
     |      test password size limits raise truncate_error (if appropriate)
     |
     |  test_secret_wo_truncate_size(self)
     |      test no password size limits enforced (if truncate_size=None)
     |
     |  test_truncate_error_setting(self)
     |      validate 'truncate_error' setting & related attributes
     |
     |  test_using_salt_size(self)
     |      Handler.using() -- default_salt_size
     |
     |  ----------------------------------------------------------------------
     |  Class methods defined here:
     |
     |  create_backend_case(backend)
     |
     |  iter_known_hashes()
     |      iterate through known (secret, hash) pairs
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties defined here:
     |
     |  descriptionPrefix
     |
     |  fuzz_thread_count
     |      number of threads for threaded fuzz testing
     |
     |  max_fuzz_time
     |      amount of time to spend on fuzz testing
     |
     |  salt_bits
     |      calculate number of salt bits in hash
     |
     |  salt_type
     |      hack to determine salt keyword's datatype
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  FuzzHashGenerator = <class 'backend.Lib.site-packages.passlib.tests.ut...
     |      helper which takes care of generating random
     |      passwords & configuration options to test hash with.
     |      separate from test class so we can create one per thread.
     |
     |
     |  accepts_all_hashes = False
     |
     |  backend = None
     |
     |  disabled_contains_salt = False
     |
     |  filter_config_warnings = False
     |
     |  fuzz_salts_need_bcrypt_repair = False
     |
     |  fuzz_verifiers = ('fuzz_verifier_default',)
     |
     |  handler = None
     |
     |  known_alternate_hashes = []
     |
     |  known_correct_configs = []
     |
     |  known_correct_hashes = []
     |
     |  known_malformed_hashes = []
     |
     |  known_other_hashes = [('des_crypt', '6f8c114b58f2c'), ('md5_crypt', '$...
     |
     |  known_parsehash_results = []
     |
     |  known_unidentified_hashes = []
     |
     |  secret_case_insensitive = False
     |
     |  stock_passwords = ['test', '¥$', b'\xe2\x82\xac\xc2\xa5$']
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from TestCase:
     |
     |  assertEquals(self, *a, **k)
     |      #---------------------------------------------------------------
     |      # forbid a bunch of deprecated aliases so I stop using them
     |      #---------------------------------------------------------------
     |
     |  assertNotEquals = assertEquals(self, *a, **k)
     |
     |  assertRaises(self, _exc_type, _callable=None, *args, **kwds)
     |      Fail unless an exception of class expected_exception is raised
     |      by the callable when invoked with specified positional and
     |      keyword arguments. If a different type of exception is
     |      raised, it will not be caught, and the test case will be
     |      deemed to have suffered an error, exactly as for an
     |      unexpected exception.
     |
     |      If called with the callable and arguments omitted, will return a
     |      context object used like this::
     |
     |           with self.assertRaises(SomeException):
     |               do_something()
     |
     |      An optional keyword argument 'msg' can be provided when assertRaises
     |      is used as a context object.
     |
     |      The context manager keeps a reference to the exception as
     |      the 'exception' attribute. This allows you to inspect the
     |      exception after the assertion::
     |
     |          with self.assertRaises(SomeException) as cm:
     |              do_something()
     |          the_exception = cm.exception
     |          self.assertEqual(the_exception.error_code, 3)
     |
     |  assertRegexMatches = assertEquals(self, *a, **k)
     |
     |  assertWarning(self, warning, message_re=None, message=None, category=None, filename_re=None, filename=None, lineno=None, msg=None)
     |      check if warning matches specified parameters.
     |      'warning' is the instance of Warning to match against;
     |      can also be instance of WarningMessage (as returned by catch_warnings).
     |
     |  assertWarningList(self, wlist=None, desc=None, msg=None)
     |      check that warning list (e.g. from catch_warnings) matches pattern
     |
     |  consumeWarningList(self, wlist, desc=None, *args, **kwds)
     |      [deprecated] assertWarningList() variant that clears list afterwards
     |
     |  getLogger(self)
     |      return logger named after current test.
     |
     |  getRandom(self, name='default', seed=None)
     |      Return a :class:`random.Random` object for current test method to use.
     |      Within an instance, multiple calls with the same name will return
     |      the same object.
     |
     |      When first created, each RNG will be seeded with value derived from
     |      a global seed, the test class module & name, the current test method name,
     |      and the **name** parameter.
     |
     |      The global seed taken from the $RANDOM_TEST_SEED env var,
     |      the $PYTHONHASHSEED env var, or a randomly generated the
     |      first time this method is called. In all cases, the value
     |      is logged for reproducibility.
     |
     |      :param name:
     |          name to uniquely identify separate RNGs w/in a test
     |          (e.g. for threaded tests).
     |
     |      :param seed:
     |          override global seed when initialzing rng.
     |
     |      :rtype: random.Random
     |
     |  mktemp(self, *args, **kwds)
     |      create temp file that's cleaned up at end of test
     |
     |  patchAttr(self, obj, attr, value, require_existing=True, wrap=False)
     |      monkeypatch object value, restoring original value on cleanup
     |
     |  require_TEST_MODE(self, level)
     |      skip test for all PASSLIB_TEST_MODE values below <level>
     |
     |  require_stringprep(self)
     |      helper to skip test if stringprep is missing
     |
     |  require_writeable_filesystem(self)
     |      skip test if writeable FS not available
     |
     |  setUpWarnings(self)
     |      helper to init warning filters before subclass setUp()
     |
     |  shortDescription(self)
     |      wrap shortDescription() method to prepend descriptionPrefix
     |
     |  subTest(self, *args, **kwds)
     |      wrapper/backport for .subTest() which also traps SkipTest errors.
     |      (see source for details)
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from TestCase:
     |
     |  __test__ = False
     |
     |  __unittest_skip__ = True
     |
     |  has_real_subtest = True
     |
     |  longMessage = True
     |
     |  resetWarningState = True
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from unittest.case.TestCase:
     |
     |  __call__(self, *args, **kwds)
     |      Call self as a function.
     |
     |  __eq__(self, other)
     |      Return self==value.
     |
     |  __hash__(self)
     |      Return hash(self).
     |
     |  __init__(self, methodName='runTest')
     |      Create an instance of the class that will use the named test
     |      method when executed. Raises a ValueError if the instance does
     |      not have a method with the specified name.
     |
     |  __repr__(self)
     |      Return repr(self).
     |
     |  __str__(self)
     |      Return str(self).
     |
     |  addCleanup(self, function, /, *args, **kwargs)
     |      Add a function, with arguments, to be called when the test is
     |      completed. Functions added are called on a LIFO basis and are
     |      called after tearDown on test failure or success.
     |
     |      Cleanup items are called even if setUp fails (unlike tearDown).
     |
     |  addTypeEqualityFunc(self, typeobj, function)
     |      Add a type specific assertEqual style function to compare a type.
     |
     |      This method is for use by TestCase subclasses that need to register
     |      their own type equality functions to provide nicer error messages.
     |
     |      Args:
     |          typeobj: The data type to call this function on when both values
     |                  are of the same type in assertEqual().
     |          function: The callable taking two arguments and an optional
     |                  msg= argument that raises self.failureException with a
     |                  useful error message when the two arguments are not equal.
     |
     |  assertAlmostEqual(self, first, second, places=None, msg=None, delta=None)
     |      Fail if the two objects are unequal as determined by their
     |      difference rounded to the given number of decimal places
     |      (default 7) and comparing to zero, or by comparing that the
     |      difference between the two objects is more than the given
     |      delta.
     |
     |      Note that decimal places (from zero) are usually not the same
     |      as significant digits (measured from the most significant digit).
     |
     |      If the two objects compare equal then they will automatically
     |      compare almost equal.
     |
     |  assertCountEqual(self, first, second, msg=None)
     |      Asserts that two iterables have the same elements, the same number of
     |      times, without regard to order.
     |
     |          self.assertEqual(Counter(list(first)),
     |                           Counter(list(second)))
     |
     |       Example:
     |          - [0, 1, 1] and [1, 0, 1] compare equal.
     |          - [0, 0, 1] and [0, 1] compare unequal.
     |
     |  assertDictEqual(self, d1, d2, msg=None)
     |
     |  assertEqual(self, first, second, msg=None)
     |      Fail if the two objects are unequal as determined by the '=='
     |      operator.
     |
     |  assertFalse(self, expr, msg=None)
     |      Check that the expression is false.
     |
     |  assertGreater(self, a, b, msg=None)
     |      Just like self.assertTrue(a > b), but with a nicer default message.
     |
     |  assertGreaterEqual(self, a, b, msg=None)
     |      Just like self.assertTrue(a >= b), but with a nicer default message.
     |
     |  assertIn(self, member, container, msg=None)
     |      Just like self.assertTrue(a in b), but with a nicer default message.
     |
     |  assertIs(self, expr1, expr2, msg=None)
     |      Just like self.assertTrue(a is b), but with a nicer default message.
     |
     |  assertIsInstance(self, obj, cls, msg=None)
     |      Same as self.assertTrue(isinstance(obj, cls)), with a nicer
     |      default message.
     |
     |  assertIsNone(self, obj, msg=None)
     |      Same as self.assertTrue(obj is None), with a nicer default message.
     |
     |  assertIsNot(self, expr1, expr2, msg=None)
     |      Just like self.assertTrue(a is not b), but with a nicer default message.
     |
     |  assertIsNotNone(self, obj, msg=None)
     |      Included for symmetry with assertIsNone.
     |
     |  assertLess(self, a, b, msg=None)
     |      Just like self.assertTrue(a < b), but with a nicer default message.
     |
     |  assertLessEqual(self, a, b, msg=None)
     |      Just like self.assertTrue(a <= b), but with a nicer default message.
     |
     |  assertListEqual(self, list1, list2, msg=None)
     |      A list-specific equality assertion.
     |
     |      Args:
     |          list1: The first list to compare.
     |          list2: The second list to compare.
     |          msg: Optional message to use on failure instead of a list of
     |                  differences.
     |
     |  assertLogs(self, logger=None, level=None)
     |      Fail unless a log message of level *level* or higher is emitted
     |      on *logger_name* or its children.  If omitted, *level* defaults to
     |      INFO and *logger* defaults to the root logger.
     |
     |      This method must be used as a context manager, and will yield
     |      a recording object with two attributes: `output` and `records`.
     |      At the end of the context manager, the `output` attribute will
     |      be a list of the matching formatted log messages and the
     |      `records` attribute will be a list of the corresponding LogRecord
     |      objects.
     |
     |      Example::
     |
     |          with self.assertLogs('foo', level='INFO') as cm:
     |              logging.getLogger('foo').info('first message')
     |              logging.getLogger('foo.bar').error('second message')
     |          self.assertEqual(cm.output, ['INFO:foo:first message',
     |                                       'ERROR:foo.bar:second message'])
     |
     |  assertMultiLineEqual(self, first, second, msg=None)
     |      Assert that two multi-line strings are equal.
     |
     |  assertNoLogs(self, logger=None, level=None)
     |      Fail unless no log messages of level *level* or higher are emitted
     |      on *logger_name* or its children.
     |
     |      This method must be used as a context manager.
     |
     |  assertNotAlmostEqual(self, first, second, places=None, msg=None, delta=None)
     |      Fail if the two objects are equal as determined by their
     |      difference rounded to the given number of decimal places
     |      (default 7) and comparing to zero, or by comparing that the
     |      difference between the two objects is less than the given delta.
     |
     |      Note that decimal places (from zero) are usually not the same
     |      as significant digits (measured from the most significant digit).
     |
     |      Objects that are equal automatically fail.
     |
     |  assertNotEqual(self, first, second, msg=None)
     |      Fail if the two objects are equal as determined by the '!='
     |      operator.
     |
     |  assertNotIn(self, member, container, msg=None)
     |      Just like self.assertTrue(a not in b), but with a nicer default message.
     |
     |  assertNotIsInstance(self, obj, cls, msg=None)
     |      Included for symmetry with assertIsInstance.
     |
     |  assertNotRegex(self, text, unexpected_regex, msg=None)
     |      Fail the test if the text matches the regular expression.
     |
     |  assertRaisesRegex(self, expected_exception, expected_regex, *args, **kwargs)
     |      Asserts that the message in a raised exception matches a regex.
     |
     |      Args:
     |          expected_exception: Exception class expected to be raised.
     |          expected_regex: Regex (re.Pattern object or string) expected
     |                  to be found in error message.
     |          args: Function to be called and extra positional args.
     |          kwargs: Extra kwargs.
     |          msg: Optional message used in case of failure. Can only be used
     |                  when assertRaisesRegex is used as a context manager.
     |
     |  assertRegex(self, text, expected_regex, msg=None)
     |      Fail the test unless the text matches the regular expression.
     |
     |  assertSequenceEqual(self, seq1, seq2, msg=None, seq_type=None)
     |      An equality assertion for ordered sequences (like lists and tuples).
     |
     |      For the purposes of this function, a valid ordered sequence type is one
     |      which can be indexed, has a length, and has an equality operator.
     |
     |      Args:
     |          seq1: The first sequence to compare.
     |          seq2: The second sequence to compare.
     |          seq_type: The expected datatype of the sequences, or None if no
     |                  datatype should be enforced.
     |          msg: Optional message to use on failure instead of a list of
     |                  differences.
     |
     |  assertSetEqual(self, set1, set2, msg=None)
     |      A set-specific equality assertion.
     |
     |      Args:
     |          set1: The first set to compare.
     |          set2: The second set to compare.
     |          msg: Optional message to use on failure instead of a list of
     |                  differences.
     |
     |      assertSetEqual uses ducktyping to support different types of sets, and
     |      is optimized for sets specifically (parameters must support a
     |      difference method).
     |
     |  assertTrue(self, expr, msg=None)
     |      Check that the expression is true.
     |
     |  assertTupleEqual(self, tuple1, tuple2, msg=None)
     |      A tuple-specific equality assertion.
     |
     |      Args:
     |          tuple1: The first tuple to compare.
     |          tuple2: The second tuple to compare.
     |          msg: Optional message to use on failure instead of a list of
     |                  differences.
     |
     |  assertWarns(self, expected_warning, *args, **kwargs)
     |      Fail unless a warning of class warnClass is triggered
     |      by the callable when invoked with specified positional and
     |      keyword arguments.  If a different type of warning is
     |      triggered, it will not be handled: depending on the other
     |      warning filtering rules in effect, it might be silenced, printed
     |      out, or raised as an exception.
     |
     |      If called with the callable and arguments omitted, will return a
     |      context object used like this::
     |
     |           with self.assertWarns(SomeWarning):
     |               do_something()
     |
     |      An optional keyword argument 'msg' can be provided when assertWarns
     |      is used as a context object.
     |
     |      The context manager keeps a reference to the first matching
     |      warning as the 'warning' attribute; similarly, the 'filename'
     |      and 'lineno' attributes give you information about the line
     |      of Python code from which the warning was triggered.
     |      This allows you to inspect the warning after the assertion::
     |
     |          with self.assertWarns(SomeWarning) as cm:
     |              do_something()
     |          the_warning = cm.warning
     |          self.assertEqual(the_warning.some_attribute, 147)
     |
     |  assertWarnsRegex(self, expected_warning, expected_regex, *args, **kwargs)
     |      Asserts that the message in a triggered warning matches a regexp.
     |      Basic functioning is similar to assertWarns() with the addition
     |      that only warnings whose messages also match the regular expression
     |      are considered successful matches.
     |
     |      Args:
     |          expected_warning: Warning class expected to be triggered.
     |          expected_regex: Regex (re.Pattern object or string) expected
     |                  to be found in error message.
     |          args: Function to be called and extra positional args.
     |          kwargs: Extra kwargs.
     |          msg: Optional message used in case of failure. Can only be used
     |                  when assertWarnsRegex is used as a context manager.
     |
     |  countTestCases(self)
     |
     |  debug(self)
     |      Run the test without collecting errors in a TestResult
     |
     |  defaultTestResult(self)
     |
     |  doCleanups(self)
     |      Execute all cleanup functions. Normally called for you after
     |      tearDown.
     |
     |  enterContext(self, cm)
     |      Enters the supplied context manager.
     |
     |      If successful, also adds its __exit__ method as a cleanup
     |      function and returns the result of the __enter__ method.
     |
     |  fail(self, msg=None)
     |      Fail immediately, with the given message.
     |
     |  id(self)
     |
     |  run(self, result=None)
     |
     |  skipTest(self, reason)
     |      Skip this test.
     |
     |  tearDown(self)
     |      Hook method for deconstructing the test fixture after testing it.
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from unittest.case.TestCase:
     |
     |  __init_subclass__(*args, **kwargs)
     |      This method is called when a class is subclassed.
     |
     |      The default implementation does nothing. It may be
     |      overridden to extend subclasses.
     |
     |  addClassCleanup(function, /, *args, **kwargs)
     |      Same as addCleanup, except the cleanup items are called even if
     |      setUpClass fails (unlike tearDownClass).
     |
     |  doClassCleanups()
     |      Execute all class cleanup functions. Normally called for you after
     |      tearDownClass.
     |
     |  enterClassContext(cm)
     |      Same as enterContext, but class-wide.
     |
     |  setUpClass()
     |      Hook method for setting up class fixture before running tests in the class.
     |
     |  tearDownClass()
     |      Hook method for deconstructing the class fixture after running all tests in the class.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from unittest.case.TestCase:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from unittest.case.TestCase:
     |
     |  failureException = <class 'AssertionError'>
     |      Assertion failed.
     |
     |
     |  maxDiff = 640

    class TestCase(passlib.tests.backports.TestCase)
     |  TestCase(methodName='runTest')
     |
     |  passlib-specific test case class
     |
     |  this class adds a number of features to the standard TestCase...
     |  * common prefix for all test descriptions
     |  * resets warnings filter & registry for every test
     |  * tweaks to message formatting
     |  * __msg__ kwd added to assertRaises()
     |  * suite of methods for matching against warnings
     |
     |  Method resolution order:
     |      TestCase
     |      passlib.tests.backports.TestCase
     |      unittest.case.TestCase
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  assertEquals(self, *a, **k)
     |      #---------------------------------------------------------------
     |      # forbid a bunch of deprecated aliases so I stop using them
     |      #---------------------------------------------------------------
     |
     |  assertNotEquals = assertEquals(self, *a, **k)
     |
     |  assertRaises(self, _exc_type, _callable=None, *args, **kwds)
     |      Fail unless an exception of class expected_exception is raised
     |      by the callable when invoked with specified positional and
     |      keyword arguments. If a different type of exception is
     |      raised, it will not be caught, and the test case will be
     |      deemed to have suffered an error, exactly as for an
     |      unexpected exception.
     |
     |      If called with the callable and arguments omitted, will return a
     |      context object used like this::
     |
     |           with self.assertRaises(SomeException):
     |               do_something()
     |
     |      An optional keyword argument 'msg' can be provided when assertRaises
     |      is used as a context object.
     |
     |      The context manager keeps a reference to the exception as
     |      the 'exception' attribute. This allows you to inspect the
     |      exception after the assertion::
     |
     |          with self.assertRaises(SomeException) as cm:
     |              do_something()
     |          the_exception = cm.exception
     |          self.assertEqual(the_exception.error_code, 3)
     |
     |  assertRegexMatches = assertEquals(self, *a, **k)
     |
     |  assertWarning(self, warning, message_re=None, message=None, category=None, filename_re=None, filename=None, lineno=None, msg=None)
     |      check if warning matches specified parameters.
     |      'warning' is the instance of Warning to match against;
     |      can also be instance of WarningMessage (as returned by catch_warnings).
     |
     |  assertWarningList(self, wlist=None, desc=None, msg=None)
     |      check that warning list (e.g. from catch_warnings) matches pattern
     |
     |  consumeWarningList(self, wlist, desc=None, *args, **kwds)
     |      [deprecated] assertWarningList() variant that clears list afterwards
     |
     |  getLogger(self)
     |      return logger named after current test.
     |
     |  getRandom(self, name='default', seed=None)
     |      Return a :class:`random.Random` object for current test method to use.
     |      Within an instance, multiple calls with the same name will return
     |      the same object.
     |
     |      When first created, each RNG will be seeded with value derived from
     |      a global seed, the test class module & name, the current test method name,
     |      and the **name** parameter.
     |
     |      The global seed taken from the $RANDOM_TEST_SEED env var,
     |      the $PYTHONHASHSEED env var, or a randomly generated the
     |      first time this method is called. In all cases, the value
     |      is logged for reproducibility.
     |
     |      :param name:
     |          name to uniquely identify separate RNGs w/in a test
     |          (e.g. for threaded tests).
     |
     |      :param seed:
     |          override global seed when initialzing rng.
     |
     |      :rtype: random.Random
     |
     |  mktemp(self, *args, **kwds)
     |      create temp file that's cleaned up at end of test
     |
     |  patchAttr(self, obj, attr, value, require_existing=True, wrap=False)
     |      monkeypatch object value, restoring original value on cleanup
     |
     |  require_TEST_MODE(self, level)
     |      skip test for all PASSLIB_TEST_MODE values below <level>
     |
     |  require_stringprep(self)
     |      helper to skip test if stringprep is missing
     |
     |  require_writeable_filesystem(self)
     |      skip test if writeable FS not available
     |
     |  setUp(self)
     |      Hook method for setting up the test fixture before exercising it.
     |
     |  setUpWarnings(self)
     |      helper to init warning filters before subclass setUp()
     |
     |  shortDescription(self)
     |      wrap shortDescription() method to prepend descriptionPrefix
     |
     |  subTest(self, *args, **kwds)
     |      wrapper/backport for .subTest() which also traps SkipTest errors.
     |      (see source for details)
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  __test__ = False
     |
     |  __unittest_skip__ = True
     |
     |  descriptionPrefix = None
     |
     |  has_real_subtest = True
     |
     |  longMessage = True
     |
     |  resetWarningState = True
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from unittest.case.TestCase:
     |
     |  __call__(self, *args, **kwds)
     |      Call self as a function.
     |
     |  __eq__(self, other)
     |      Return self==value.
     |
     |  __hash__(self)
     |      Return hash(self).
     |
     |  __init__(self, methodName='runTest')
     |      Create an instance of the class that will use the named test
     |      method when executed. Raises a ValueError if the instance does
     |      not have a method with the specified name.
     |
     |  __repr__(self)
     |      Return repr(self).
     |
     |  __str__(self)
     |      Return str(self).
     |
     |  addCleanup(self, function, /, *args, **kwargs)
     |      Add a function, with arguments, to be called when the test is
     |      completed. Functions added are called on a LIFO basis and are
     |      called after tearDown on test failure or success.
     |
     |      Cleanup items are called even if setUp fails (unlike tearDown).
     |
     |  addTypeEqualityFunc(self, typeobj, function)
     |      Add a type specific assertEqual style function to compare a type.
     |
     |      This method is for use by TestCase subclasses that need to register
     |      their own type equality functions to provide nicer error messages.
     |
     |      Args:
     |          typeobj: The data type to call this function on when both values
     |                  are of the same type in assertEqual().
     |          function: The callable taking two arguments and an optional
     |                  msg= argument that raises self.failureException with a
     |                  useful error message when the two arguments are not equal.
     |
     |  assertAlmostEqual(self, first, second, places=None, msg=None, delta=None)
     |      Fail if the two objects are unequal as determined by their
     |      difference rounded to the given number of decimal places
     |      (default 7) and comparing to zero, or by comparing that the
     |      difference between the two objects is more than the given
     |      delta.
     |
     |      Note that decimal places (from zero) are usually not the same
     |      as significant digits (measured from the most significant digit).
     |
     |      If the two objects compare equal then they will automatically
     |      compare almost equal.
     |
     |  assertCountEqual(self, first, second, msg=None)
     |      Asserts that two iterables have the same elements, the same number of
     |      times, without regard to order.
     |
     |          self.assertEqual(Counter(list(first)),
     |                           Counter(list(second)))
     |
     |       Example:
     |          - [0, 1, 1] and [1, 0, 1] compare equal.
     |          - [0, 0, 1] and [0, 1] compare unequal.
     |
     |  assertDictEqual(self, d1, d2, msg=None)
     |
     |  assertEqual(self, first, second, msg=None)
     |      Fail if the two objects are unequal as determined by the '=='
     |      operator.
     |
     |  assertFalse(self, expr, msg=None)
     |      Check that the expression is false.
     |
     |  assertGreater(self, a, b, msg=None)
     |      Just like self.assertTrue(a > b), but with a nicer default message.
     |
     |  assertGreaterEqual(self, a, b, msg=None)
     |      Just like self.assertTrue(a >= b), but with a nicer default message.
     |
     |  assertIn(self, member, container, msg=None)
     |      Just like self.assertTrue(a in b), but with a nicer default message.
     |
     |  assertIs(self, expr1, expr2, msg=None)
     |      Just like self.assertTrue(a is b), but with a nicer default message.
     |
     |  assertIsInstance(self, obj, cls, msg=None)
     |      Same as self.assertTrue(isinstance(obj, cls)), with a nicer
     |      default message.
     |
     |  assertIsNone(self, obj, msg=None)
     |      Same as self.assertTrue(obj is None), with a nicer default message.
     |
     |  assertIsNot(self, expr1, expr2, msg=None)
     |      Just like self.assertTrue(a is not b), but with a nicer default message.
     |
     |  assertIsNotNone(self, obj, msg=None)
     |      Included for symmetry with assertIsNone.
     |
     |  assertLess(self, a, b, msg=None)
     |      Just like self.assertTrue(a < b), but with a nicer default message.
     |
     |  assertLessEqual(self, a, b, msg=None)
     |      Just like self.assertTrue(a <= b), but with a nicer default message.
     |
     |  assertListEqual(self, list1, list2, msg=None)
     |      A list-specific equality assertion.
     |
     |      Args:
     |          list1: The first list to compare.
     |          list2: The second list to compare.
     |          msg: Optional message to use on failure instead of a list of
     |                  differences.
     |
     |  assertLogs(self, logger=None, level=None)
     |      Fail unless a log message of level *level* or higher is emitted
     |      on *logger_name* or its children.  If omitted, *level* defaults to
     |      INFO and *logger* defaults to the root logger.
     |
     |      This method must be used as a context manager, and will yield
     |      a recording object with two attributes: `output` and `records`.
     |      At the end of the context manager, the `output` attribute will
     |      be a list of the matching formatted log messages and the
     |      `records` attribute will be a list of the corresponding LogRecord
     |      objects.
     |
     |      Example::
     |
     |          with self.assertLogs('foo', level='INFO') as cm:
     |              logging.getLogger('foo').info('first message')
     |              logging.getLogger('foo.bar').error('second message')
     |          self.assertEqual(cm.output, ['INFO:foo:first message',
     |                                       'ERROR:foo.bar:second message'])
     |
     |  assertMultiLineEqual(self, first, second, msg=None)
     |      Assert that two multi-line strings are equal.
     |
     |  assertNoLogs(self, logger=None, level=None)
     |      Fail unless no log messages of level *level* or higher are emitted
     |      on *logger_name* or its children.
     |
     |      This method must be used as a context manager.
     |
     |  assertNotAlmostEqual(self, first, second, places=None, msg=None, delta=None)
     |      Fail if the two objects are equal as determined by their
     |      difference rounded to the given number of decimal places
     |      (default 7) and comparing to zero, or by comparing that the
     |      difference between the two objects is less than the given delta.
     |
     |      Note that decimal places (from zero) are usually not the same
     |      as significant digits (measured from the most significant digit).
     |
     |      Objects that are equal automatically fail.
     |
     |  assertNotEqual(self, first, second, msg=None)
     |      Fail if the two objects are equal as determined by the '!='
     |      operator.
     |
     |  assertNotIn(self, member, container, msg=None)
     |      Just like self.assertTrue(a not in b), but with a nicer default message.
     |
     |  assertNotIsInstance(self, obj, cls, msg=None)
     |      Included for symmetry with assertIsInstance.
     |
     |  assertNotRegex(self, text, unexpected_regex, msg=None)
     |      Fail the test if the text matches the regular expression.
     |
     |  assertRaisesRegex(self, expected_exception, expected_regex, *args, **kwargs)
     |      Asserts that the message in a raised exception matches a regex.
     |
     |      Args:
     |          expected_exception: Exception class expected to be raised.
     |          expected_regex: Regex (re.Pattern object or string) expected
     |                  to be found in error message.
     |          args: Function to be called and extra positional args.
     |          kwargs: Extra kwargs.
     |          msg: Optional message used in case of failure. Can only be used
     |                  when assertRaisesRegex is used as a context manager.
     |
     |  assertRegex(self, text, expected_regex, msg=None)
     |      Fail the test unless the text matches the regular expression.
     |
     |  assertSequenceEqual(self, seq1, seq2, msg=None, seq_type=None)
     |      An equality assertion for ordered sequences (like lists and tuples).
     |
     |      For the purposes of this function, a valid ordered sequence type is one
     |      which can be indexed, has a length, and has an equality operator.
     |
     |      Args:
     |          seq1: The first sequence to compare.
     |          seq2: The second sequence to compare.
     |          seq_type: The expected datatype of the sequences, or None if no
     |                  datatype should be enforced.
     |          msg: Optional message to use on failure instead of a list of
     |                  differences.
     |
     |  assertSetEqual(self, set1, set2, msg=None)
     |      A set-specific equality assertion.
     |
     |      Args:
     |          set1: The first set to compare.
     |          set2: The second set to compare.
     |          msg: Optional message to use on failure instead of a list of
     |                  differences.
     |
     |      assertSetEqual uses ducktyping to support different types of sets, and
     |      is optimized for sets specifically (parameters must support a
     |      difference method).
     |
     |  assertTrue(self, expr, msg=None)
     |      Check that the expression is true.
     |
     |  assertTupleEqual(self, tuple1, tuple2, msg=None)
     |      A tuple-specific equality assertion.
     |
     |      Args:
     |          tuple1: The first tuple to compare.
     |          tuple2: The second tuple to compare.
     |          msg: Optional message to use on failure instead of a list of
     |                  differences.
     |
     |  assertWarns(self, expected_warning, *args, **kwargs)
     |      Fail unless a warning of class warnClass is triggered
     |      by the callable when invoked with specified positional and
     |      keyword arguments.  If a different type of warning is
     |      triggered, it will not be handled: depending on the other
     |      warning filtering rules in effect, it might be silenced, printed
     |      out, or raised as an exception.
     |
     |      If called with the callable and arguments omitted, will return a
     |      context object used like this::
     |
     |           with self.assertWarns(SomeWarning):
     |               do_something()
     |
     |      An optional keyword argument 'msg' can be provided when assertWarns
     |      is used as a context object.
     |
     |      The context manager keeps a reference to the first matching
     |      warning as the 'warning' attribute; similarly, the 'filename'
     |      and 'lineno' attributes give you information about the line
     |      of Python code from which the warning was triggered.
     |      This allows you to inspect the warning after the assertion::
     |
     |          with self.assertWarns(SomeWarning) as cm:
     |              do_something()
     |          the_warning = cm.warning
     |          self.assertEqual(the_warning.some_attribute, 147)
     |
     |  assertWarnsRegex(self, expected_warning, expected_regex, *args, **kwargs)
     |      Asserts that the message in a triggered warning matches a regexp.
     |      Basic functioning is similar to assertWarns() with the addition
     |      that only warnings whose messages also match the regular expression
     |      are considered successful matches.
     |
     |      Args:
     |          expected_warning: Warning class expected to be triggered.
     |          expected_regex: Regex (re.Pattern object or string) expected
     |                  to be found in error message.
     |          args: Function to be called and extra positional args.
     |          kwargs: Extra kwargs.
     |          msg: Optional message used in case of failure. Can only be used
     |                  when assertWarnsRegex is used as a context manager.
     |
     |  countTestCases(self)
     |
     |  debug(self)
     |      Run the test without collecting errors in a TestResult
     |
     |  defaultTestResult(self)
     |
     |  doCleanups(self)
     |      Execute all cleanup functions. Normally called for you after
     |      tearDown.
     |
     |  enterContext(self, cm)
     |      Enters the supplied context manager.
     |
     |      If successful, also adds its __exit__ method as a cleanup
     |      function and returns the result of the __enter__ method.
     |
     |  fail(self, msg=None)
     |      Fail immediately, with the given message.
     |
     |  id(self)
     |
     |  run(self, result=None)
     |
     |  skipTest(self, reason)
     |      Skip this test.
     |
     |  tearDown(self)
     |      Hook method for deconstructing the test fixture after testing it.
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from unittest.case.TestCase:
     |
     |  __init_subclass__(*args, **kwargs)
     |      This method is called when a class is subclassed.
     |
     |      The default implementation does nothing. It may be
     |      overridden to extend subclasses.
     |
     |  addClassCleanup(function, /, *args, **kwargs)
     |      Same as addCleanup, except the cleanup items are called even if
     |      setUpClass fails (unlike tearDownClass).
     |
     |  doClassCleanups()
     |      Execute all class cleanup functions. Normally called for you after
     |      tearDownClass.
     |
     |  enterClassContext(cm)
     |      Same as enterContext, but class-wide.
     |
     |  setUpClass()
     |      Hook method for setting up class fixture before running tests in the class.
     |
     |  tearDownClass()
     |      Hook method for deconstructing the class fixture after running all tests in the class.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from unittest.case.TestCase:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from unittest.case.TestCase:
     |
     |  failureException = <class 'AssertionError'>
     |      Assertion failed.
     |
     |
     |  maxDiff = 640

FUNCTIONS
    TEST_MODE(min=None, max=None)
        check if test for specified mode should be enabled.

        ``"quick"``
            run the bare minimum tests to ensure functionality.
            variable-cost hashes are tested at their lowest setting.
            hash algorithms are only tested against the backend that will
            be used on the current host. no fuzz testing is done.

        ``"default"``
            same as ``"quick"``, except: hash algorithms are tested
            at default levels, and a brief round of fuzz testing is done
            for each hash.

        ``"full"``
            extra regression and internal tests are enabled, hash algorithms are tested
            against all available backends, unavailable ones are mocked whre possible,
            additional time is devoted to fuzz testing.

    get_file(path)
        read file as bytes

    set_file(path, content)
        set file to specified bytes

DATA
    __all__ = ['TEST_MODE', 'set_file', 'get_file', 'TestCase', 'HandlerCa...

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\backend\lib\site-packages\passlib\tests\utils.py



================================================================================
Help on module backend.Lib.site-packages.pip._internal.main in backend.Lib.site-packages.pip._internal:

NAME
    backend.Lib.site-packages.pip._internal.main

FUNCTIONS
    main(args: Optional[List[str]] = None) -> int
        This is preserved for old console scripts that may still be referencing
        it.

        For additional details, see https://github.com/pypa/pip/issues/7498.

DATA
    List = typing.List
        A generic version of list.

    Optional = typing.Optional
        Optional[X] is equivalent to Union[X, None].

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\backend\lib\site-packages\pip\_internal\main.py



================================================================================
Help on module backend.Lib.site-packages.pip._internal.cli.main in backend.Lib.site-packages.pip._internal.cli:

NAME
    backend.Lib.site-packages.pip._internal.cli.main - Primary application entrypoint.

FUNCTIONS
    main(args: Optional[List[str]] = None) -> int

DATA
    List = typing.List
        A generic version of list.

    Optional = typing.Optional
        Optional[X] is equivalent to Union[X, None].

    logger = <VerboseLogger backend.Lib.site-packages.pip._internal.cli.ma...

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\backend\lib\site-packages\pip\_internal\cli\main.py



================================================================================
Help on module backend.Lib.site-packages.pip._internal.network.auth in backend.Lib.site-packages.pip._internal.network:

NAME
    backend.Lib.site-packages.pip._internal.network.auth - Network Authentication Helpers

DESCRIPTION
    Contains interface (MultiDomainBasicAuth) and associated glue code for
    providing credentials in the context of network requests.

CLASSES
    abc.ABC(builtins.object)
        KeyRingBaseProvider
            KeyRingCliProvider
            KeyRingNullProvider
            KeyRingPythonProvider
    builtins.tuple(builtins.object)
        Credentials
    pip._vendor.requests.auth.AuthBase(builtins.object)
        MultiDomainBasicAuth

    class Credentials(builtins.tuple)
     |  Credentials(url: str, username: str, password: str)
     |
     |  Credentials(url, username, password)
     |
     |  Method resolution order:
     |      Credentials
     |      builtins.tuple
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __getnewargs__(self) from collections.Credentials
     |      Return self as a plain tuple.  Used by copy and pickle.
     |
     |  __repr__(self) from collections.Credentials
     |      Return a nicely formatted representation string
     |
     |  _asdict(self) from collections.Credentials
     |      Return a new dict which maps field names to their values.
     |
     |  _replace(self, /, **kwds) from collections.Credentials
     |      Return a new Credentials object replacing specified fields with new values
     |
     |  ----------------------------------------------------------------------
     |  Class methods defined here:
     |
     |  _make(iterable) from collections.Credentials
     |      Make a new Credentials object from a sequence or iterable
     |
     |  ----------------------------------------------------------------------
     |  Static methods defined here:
     |
     |  __new__(_cls, url: str, username: str, password: str) from namedtuple_Credentials.Credentials
     |      Create new instance of Credentials(url, username, password)
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  url
     |      Alias for field number 0
     |
     |  username
     |      Alias for field number 1
     |
     |  password
     |      Alias for field number 2
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  __annotations__ = {'password': <class 'str'>, 'url': <class 'str'>, 'u...
     |
     |  __match_args__ = ('url', 'username', 'password')
     |
     |  __orig_bases__ = (<function NamedTuple>,)
     |
     |  _field_defaults = {}
     |
     |  _fields = ('url', 'username', 'password')
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.tuple:
     |
     |  __add__(self, value, /)
     |      Return self+value.
     |
     |  __contains__(self, key, /)
     |      Return bool(key in self).
     |
     |  __eq__(self, value, /)
     |      Return self==value.
     |
     |  __ge__(self, value, /)
     |      Return self>=value.
     |
     |  __getattribute__(self, name, /)
     |      Return getattr(self, name).
     |
     |  __getitem__(self, key, /)
     |      Return self[key].
     |
     |  __gt__(self, value, /)
     |      Return self>value.
     |
     |  __hash__(self, /)
     |      Return hash(self).
     |
     |  __iter__(self, /)
     |      Implement iter(self).
     |
     |  __le__(self, value, /)
     |      Return self<=value.
     |
     |  __len__(self, /)
     |      Return len(self).
     |
     |  __lt__(self, value, /)
     |      Return self<value.
     |
     |  __mul__(self, value, /)
     |      Return self*value.
     |
     |  __ne__(self, value, /)
     |      Return self!=value.
     |
     |  __rmul__(self, value, /)
     |      Return value*self.
     |
     |  count(self, value, /)
     |      Return number of occurrences of value.
     |
     |  index(self, value, start=0, stop=9223372036854775807, /)
     |      Return first index of value.
     |
     |      Raises ValueError if the value is not present.
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from builtins.tuple:
     |
     |  __class_getitem__(...)
     |      See PEP 585

    class KeyRingBaseProvider(abc.ABC)
     |  Keyring base provider interface
     |
     |  Method resolution order:
     |      KeyRingBaseProvider
     |      abc.ABC
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  get_auth_info(self, url: str, username: Optional[str]) -> Optional[Tuple[Optional[str], Optional[str]]]
     |
     |  save_auth_info(self, url: str, username: str, password: str) -> None
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  __abstractmethods__ = frozenset({'get_auth_info', 'save_auth_info'})
     |
     |  __annotations__ = {'has_keyring': <class 'bool'>}

    class KeyRingCliProvider(KeyRingBaseProvider)
     |  KeyRingCliProvider(cmd: str) -> None
     |
     |  Provider which uses `keyring` cli
     |
     |  Instead of calling the keyring package installed alongside pip
     |  we call keyring on the command line which will enable pip to
     |  use which ever installation of keyring is available first in
     |  PATH.
     |
     |  Method resolution order:
     |      KeyRingCliProvider
     |      KeyRingBaseProvider
     |      abc.ABC
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, cmd: str) -> None
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  get_auth_info(self, url: str, username: Optional[str]) -> Optional[Tuple[Optional[str], Optional[str]]]
     |
     |  save_auth_info(self, url: str, username: str, password: str) -> None
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  __abstractmethods__ = frozenset()
     |
     |  __annotations__ = {}
     |
     |  has_keyring = True
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from KeyRingBaseProvider:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

    class KeyRingNullProvider(KeyRingBaseProvider)
     |  Keyring null provider
     |
     |  Method resolution order:
     |      KeyRingNullProvider
     |      KeyRingBaseProvider
     |      abc.ABC
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  get_auth_info(self, url: str, username: Optional[str]) -> Optional[Tuple[Optional[str], Optional[str]]]
     |
     |  save_auth_info(self, url: str, username: str, password: str) -> None
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  __abstractmethods__ = frozenset()
     |
     |  __annotations__ = {}
     |
     |  has_keyring = False
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from KeyRingBaseProvider:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

    class KeyRingPythonProvider(KeyRingBaseProvider)
     |  KeyRingPythonProvider() -> None
     |
     |  Keyring interface which uses locally imported `keyring`
     |
     |  Method resolution order:
     |      KeyRingPythonProvider
     |      KeyRingBaseProvider
     |      abc.ABC
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self) -> None
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  get_auth_info(self, url: str, username: Optional[str]) -> Optional[Tuple[Optional[str], Optional[str]]]
     |
     |  save_auth_info(self, url: str, username: str, password: str) -> None
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  __abstractmethods__ = frozenset()
     |
     |  __annotations__ = {}
     |
     |  has_keyring = True
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from KeyRingBaseProvider:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

    class MultiDomainBasicAuth(pip._vendor.requests.auth.AuthBase)
     |  MultiDomainBasicAuth(prompting: bool = True, index_urls: Optional[List[str]] = None, keyring_provider: str = 'auto') -> None
     |
     |  Method resolution order:
     |      MultiDomainBasicAuth
     |      pip._vendor.requests.auth.AuthBase
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __call__(self, req: pip._vendor.requests.models.Request) -> pip._vendor.requests.models.Request
     |      Call self as a function.
     |
     |  __init__(self, prompting: bool = True, index_urls: Optional[List[str]] = None, keyring_provider: str = 'auto') -> None
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  handle_401(self, resp: pip._vendor.requests.models.Response, **kwargs: Any) -> pip._vendor.requests.models.Response
     |
     |  save_credentials(self, resp: pip._vendor.requests.models.Response, **kwargs: Any) -> None
     |      Response callback to save credentials on success.
     |
     |  warn_on_401(self, resp: pip._vendor.requests.models.Response, **kwargs: Any) -> None
     |      Response callback to warn about incorrect credentials.
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties defined here:
     |
     |  use_keyring
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  keyring_provider
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from pip._vendor.requests.auth.AuthBase:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

FUNCTIONS
    get_keyring_provider(provider: str) -> backend.Lib.site-packages.pip._internal.network.auth.KeyRingBaseProvider

DATA
    AuthInfo = typing.Tuple[typing.Optional[str], typing.Optional[str]]
    Dict = typing.Dict
        A generic version of dict.

    KEYRING_DISABLED = False
    List = typing.List
        A generic version of list.

    Optional = typing.Optional
        Optional[X] is equivalent to Union[X, None].

    Tuple = typing.Tuple
        Deprecated alias to builtins.tuple.

        Tuple[X, Y] is the cross-product type of X and Y.

        Example: Tuple[T1, T2] is a tuple of two elements corresponding
        to type variables T1 and T2.  Tuple[int, float, str] is a tuple
        of an int, a float and a string.

        To specify a variable-length tuple of homogeneous type, use Tuple[T, ...].

    logger = <VerboseLogger backend.Lib.site-packages.pip._internal.networ...

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\backend\lib\site-packages\pip\_internal\network\auth.py



================================================================================
Help on module backend.Lib.site-packages.pip._internal.network.utils in backend.Lib.site-packages.pip._internal.network:

NAME
    backend.Lib.site-packages.pip._internal.network.utils

FUNCTIONS
    raise_for_status(resp: pip._vendor.requests.models.Response) -> None

    response_chunks(response: pip._vendor.requests.models.Response, chunk_size: int = 10240) -> Generator[bytes, NoneType, NoneType]
        Given a requests Response, provide the data chunks.

DATA
    CONTENT_CHUNK_SIZE = 10240
    Dict = typing.Dict
        A generic version of dict.

    Generator = typing.Generator
        A generic version of collections.abc.Generator.

    HEADERS = {'Accept-Encoding': 'identity'}
    __annotations__ = {'HEADERS': typing.Dict[str, str]}

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\backend\lib\site-packages\pip\_internal\network\utils.py



================================================================================
Help on module backend.Lib.site-packages.pip._internal.utils.models in backend.Lib.site-packages.pip._internal.utils:

NAME
    backend.Lib.site-packages.pip._internal.utils.models - Utilities for defining models

CLASSES
    builtins.object
        KeyBasedCompareMixin

    class KeyBasedCompareMixin(builtins.object)
     |  KeyBasedCompareMixin(key: Any, defining_class: Type[ForwardRef('KeyBasedCompareMixin')]) -> None
     |
     |  Provides comparison capabilities that is based on a key
     |
     |  Methods defined here:
     |
     |  __eq__(self, other: Any) -> bool
     |      Return self==value.
     |
     |  __ge__(self, other: Any) -> bool
     |      Return self>=value.
     |
     |  __gt__(self, other: Any) -> bool
     |      Return self>value.
     |
     |  __hash__(self) -> int
     |      Return hash(self).
     |
     |  __init__(self, key: Any, defining_class: Type[ForwardRef('KeyBasedCompareMixin')]) -> None
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  __le__(self, other: Any) -> bool
     |      Return self<=value.
     |
     |  __lt__(self, other: Any) -> bool
     |      Return self<value.

DATA
    Callable = typing.Callable
        Deprecated alias to collections.abc.Callable.

        Callable[[int], str] signifies a function that takes a single
        parameter of type int and returns a str.

        The subscription syntax must always be used with exactly two
        values: the argument list and the return type.
        The argument list must be a list of types, a ParamSpec,
        Concatenate or ellipsis. The return type must be a single type.

        There is no syntax to indicate optional or keyword arguments;
        such function types are rarely used as callback types.

    Type = typing.Type
        Deprecated alias to builtins.type.

        builtins.type or typing.Type can be used to annotate class objects.
        For example, suppose we have the following classes::

            class User: ...  # Abstract base for User classes
            class BasicUser(User): ...
            class ProUser(User): ...
            class TeamUser(User): ...

        And a function that takes a class argument that's a subclass of
        User and returns an instance of the corresponding class::

            def new_user[U](user_class: Type[U]) -> U:
                user = user_class()
                # (Here we could write the user object to a database)
                return user

            joe = new_user(BasicUser)

        At this point the type checker knows that joe has type BasicUser.

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\backend\lib\site-packages\pip\_internal\utils\models.py



================================================================================
Help on module backend.Lib.site-packages.pip._vendor.colorama.tests.utils in backend.Lib.site-packages.pip._vendor.colorama.tests:

NAME
    backend.Lib.site-packages.pip._vendor.colorama.tests.utils - # Copyright Jonathan Hartley 2013. BSD 3-Clause license, see LICENSE file.

CLASSES
    _io.StringIO(_io._TextIOBase)
        StreamNonTTY
        StreamTTY

    class StreamNonTTY(_io.StringIO)
     |  StreamNonTTY(initial_value='', newline='\n')
     |
     |  Method resolution order:
     |      StreamNonTTY
     |      _io.StringIO
     |      _io._TextIOBase
     |      _io._IOBase
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  isatty(self)
     |      Return whether this is an 'interactive' stream.
     |
     |      Return False if it can't be determined.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from _io.StringIO:
     |
     |  __getstate__(...)
     |      Helper for pickle.
     |
     |  __init__(self, /, *args, **kwargs)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  __next__(self, /)
     |      Implement next(self).
     |
     |  __setstate__(...)
     |
     |  close(self, /)
     |      Close the IO object.
     |
     |      Attempting any further operation after the object is closed
     |      will raise a ValueError.
     |
     |      This method has no effect if the file is already closed.
     |
     |  getvalue(self, /)
     |      Retrieve the entire contents of the object.
     |
     |  read(self, size=-1, /)
     |      Read at most size characters, returned as a string.
     |
     |      If the argument is negative or omitted, read until EOF
     |      is reached. Return an empty string at EOF.
     |
     |  readable(self, /)
     |      Returns True if the IO object can be read.
     |
     |  readline(self, size=-1, /)
     |      Read until newline or EOF.
     |
     |      Returns an empty string if EOF is hit immediately.
     |
     |  seek(self, pos, whence=0, /)
     |      Change stream position.
     |
     |      Seek to character offset pos relative to position indicated by whence:
     |          0  Start of stream (the default).  pos should be >= 0;
     |          1  Current position - pos must be 0;
     |          2  End of stream - pos must be 0.
     |      Returns the new absolute position.
     |
     |  seekable(self, /)
     |      Returns True if the IO object can be seeked.
     |
     |  tell(self, /)
     |      Tell the current file position.
     |
     |  truncate(self, pos=None, /)
     |      Truncate size to pos.
     |
     |      The pos argument defaults to the current file position, as
     |      returned by tell().  The current file position is unchanged.
     |      Returns the new absolute position.
     |
     |  writable(self, /)
     |      Returns True if the IO object can be written.
     |
     |  write(self, s, /)
     |      Write string to file.
     |
     |      Returns the number of characters written, which is always equal to
     |      the length of the string.
     |
     |  ----------------------------------------------------------------------
     |  Static methods inherited from _io.StringIO:
     |
     |  __new__(*args, **kwargs) class method of _io.StringIO
     |      Create and return a new object.  See help(type) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from _io.StringIO:
     |
     |  closed
     |
     |  line_buffering
     |
     |  newlines
     |      Line endings translated so far.
     |
     |      Only line endings translated during reading are considered.
     |
     |      Subclasses should override.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from _io._TextIOBase:
     |
     |  detach(self, /)
     |      Separate the underlying buffer from the TextIOBase and return it.
     |
     |      After the underlying buffer has been detached, the TextIO is in an unusable state.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from _io._TextIOBase:
     |
     |  encoding
     |      Encoding of the text stream.
     |
     |      Subclasses should override.
     |
     |  errors
     |      The error setting of the decoder or encoder.
     |
     |      Subclasses should override.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from _io._IOBase:
     |
     |  __del__(...)
     |
     |  __enter__(...)
     |
     |  __exit__(...)
     |
     |  __iter__(self, /)
     |      Implement iter(self).
     |
     |  fileno(self, /)
     |      Return underlying file descriptor if one exists.
     |
     |      Raise OSError if the IO object does not use a file descriptor.
     |
     |  flush(self, /)
     |      Flush write buffers, if applicable.
     |
     |      This is not implemented for read-only and non-blocking streams.
     |
     |  readlines(self, hint=-1, /)
     |      Return a list of lines from the stream.
     |
     |      hint can be specified to control the number of lines read: no more
     |      lines will be read if the total size (in bytes/characters) of all
     |      lines so far exceeds hint.
     |
     |  writelines(self, lines, /)
     |      Write a list of lines to stream.
     |
     |      Line separators are not added, so it is usual for each of the
     |      lines provided to have a line separator at the end.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from _io._IOBase:
     |
     |  __dict__

    class StreamTTY(_io.StringIO)
     |  StreamTTY(initial_value='', newline='\n')
     |
     |  Method resolution order:
     |      StreamTTY
     |      _io.StringIO
     |      _io._TextIOBase
     |      _io._IOBase
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  isatty(self)
     |      Return whether this is an 'interactive' stream.
     |
     |      Return False if it can't be determined.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from _io.StringIO:
     |
     |  __getstate__(...)
     |      Helper for pickle.
     |
     |  __init__(self, /, *args, **kwargs)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  __next__(self, /)
     |      Implement next(self).
     |
     |  __setstate__(...)
     |
     |  close(self, /)
     |      Close the IO object.
     |
     |      Attempting any further operation after the object is closed
     |      will raise a ValueError.
     |
     |      This method has no effect if the file is already closed.
     |
     |  getvalue(self, /)
     |      Retrieve the entire contents of the object.
     |
     |  read(self, size=-1, /)
     |      Read at most size characters, returned as a string.
     |
     |      If the argument is negative or omitted, read until EOF
     |      is reached. Return an empty string at EOF.
     |
     |  readable(self, /)
     |      Returns True if the IO object can be read.
     |
     |  readline(self, size=-1, /)
     |      Read until newline or EOF.
     |
     |      Returns an empty string if EOF is hit immediately.
     |
     |  seek(self, pos, whence=0, /)
     |      Change stream position.
     |
     |      Seek to character offset pos relative to position indicated by whence:
     |          0  Start of stream (the default).  pos should be >= 0;
     |          1  Current position - pos must be 0;
     |          2  End of stream - pos must be 0.
     |      Returns the new absolute position.
     |
     |  seekable(self, /)
     |      Returns True if the IO object can be seeked.
     |
     |  tell(self, /)
     |      Tell the current file position.
     |
     |  truncate(self, pos=None, /)
     |      Truncate size to pos.
     |
     |      The pos argument defaults to the current file position, as
     |      returned by tell().  The current file position is unchanged.
     |      Returns the new absolute position.
     |
     |  writable(self, /)
     |      Returns True if the IO object can be written.
     |
     |  write(self, s, /)
     |      Write string to file.
     |
     |      Returns the number of characters written, which is always equal to
     |      the length of the string.
     |
     |  ----------------------------------------------------------------------
     |  Static methods inherited from _io.StringIO:
     |
     |  __new__(*args, **kwargs) class method of _io.StringIO
     |      Create and return a new object.  See help(type) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from _io.StringIO:
     |
     |  closed
     |
     |  line_buffering
     |
     |  newlines
     |      Line endings translated so far.
     |
     |      Only line endings translated during reading are considered.
     |
     |      Subclasses should override.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from _io._TextIOBase:
     |
     |  detach(self, /)
     |      Separate the underlying buffer from the TextIOBase and return it.
     |
     |      After the underlying buffer has been detached, the TextIO is in an unusable state.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from _io._TextIOBase:
     |
     |  encoding
     |      Encoding of the text stream.
     |
     |      Subclasses should override.
     |
     |  errors
     |      The error setting of the decoder or encoder.
     |
     |      Subclasses should override.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from _io._IOBase:
     |
     |  __del__(...)
     |
     |  __enter__(...)
     |
     |  __exit__(...)
     |
     |  __iter__(self, /)
     |      Implement iter(self).
     |
     |  fileno(self, /)
     |      Return underlying file descriptor if one exists.
     |
     |      Raise OSError if the IO object does not use a file descriptor.
     |
     |  flush(self, /)
     |      Flush write buffers, if applicable.
     |
     |      This is not implemented for read-only and non-blocking streams.
     |
     |  readlines(self, hint=-1, /)
     |      Return a list of lines from the stream.
     |
     |      hint can be specified to control the number of lines read: no more
     |      lines will be read if the total size (in bytes/characters) of all
     |      lines so far exceeds hint.
     |
     |  writelines(self, lines, /)
     |      Write a list of lines to stream.
     |
     |      Line separators are not added, so it is usual for each of the
     |      lines provided to have a line separator at the end.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from _io._IOBase:
     |
     |  __dict__

FUNCTIONS
    osname(name)

    pycharm()

    replace_by(stream)

    replace_original_by(stream)

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\backend\lib\site-packages\pip\_vendor\colorama\tests\utils.py



================================================================================
Help on module backend.Lib.site-packages.pip._vendor.packaging.utils in backend.Lib.site-packages.pip._vendor.packaging:

NAME
    backend.Lib.site-packages.pip._vendor.packaging.utils

DESCRIPTION
    # This file is dual licensed under the terms of the Apache License, Version
    # 2.0, and the BSD License. See the LICENSE file in the root of this repository
    # for complete details.

CLASSES
    builtins.ValueError(builtins.Exception)
        InvalidSdistFilename
        InvalidWheelFilename

    class InvalidSdistFilename(builtins.ValueError)
     |  An invalid sdist filename was found, users should refer to the packaging user guide.
     |
     |  Method resolution order:
     |      InvalidSdistFilename
     |      builtins.ValueError
     |      builtins.Exception
     |      builtins.BaseException
     |      builtins.object
     |
     |  Data descriptors defined here:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.ValueError:
     |
     |  __init__(self, /, *args, **kwargs)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Static methods inherited from builtins.ValueError:
     |
     |  __new__(*args, **kwargs) class method of builtins.ValueError
     |      Create and return a new object.  See help(type) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.BaseException:
     |
     |  __delattr__(self, name, /)
     |      Implement delattr(self, name).
     |
     |  __getattribute__(self, name, /)
     |      Return getattr(self, name).
     |
     |  __reduce__(...)
     |      Helper for pickle.
     |
     |  __repr__(self, /)
     |      Return repr(self).
     |
     |  __setattr__(self, name, value, /)
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(...)
     |
     |  __str__(self, /)
     |      Return str(self).
     |
     |  add_note(...)
     |      Exception.add_note(note) --
     |      add a note to the exception
     |
     |  with_traceback(...)
     |      Exception.with_traceback(tb) --
     |      set self.__traceback__ to tb and return self.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from builtins.BaseException:
     |
     |  __cause__
     |      exception cause
     |
     |  __context__
     |      exception context
     |
     |  __dict__
     |
     |  __suppress_context__
     |
     |  __traceback__
     |
     |  args

    class InvalidWheelFilename(builtins.ValueError)
     |  An invalid wheel filename was found, users should refer to PEP 427.
     |
     |  Method resolution order:
     |      InvalidWheelFilename
     |      builtins.ValueError
     |      builtins.Exception
     |      builtins.BaseException
     |      builtins.object
     |
     |  Data descriptors defined here:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.ValueError:
     |
     |  __init__(self, /, *args, **kwargs)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Static methods inherited from builtins.ValueError:
     |
     |  __new__(*args, **kwargs) class method of builtins.ValueError
     |      Create and return a new object.  See help(type) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.BaseException:
     |
     |  __delattr__(self, name, /)
     |      Implement delattr(self, name).
     |
     |  __getattribute__(self, name, /)
     |      Return getattr(self, name).
     |
     |  __reduce__(...)
     |      Helper for pickle.
     |
     |  __repr__(self, /)
     |      Return repr(self).
     |
     |  __setattr__(self, name, value, /)
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(...)
     |
     |  __str__(self, /)
     |      Return str(self).
     |
     |  add_note(...)
     |      Exception.add_note(note) --
     |      add a note to the exception
     |
     |  with_traceback(...)
     |      Exception.with_traceback(tb) --
     |      set self.__traceback__ to tb and return self.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from builtins.BaseException:
     |
     |  __cause__
     |      exception cause
     |
     |  __context__
     |      exception context
     |
     |  __dict__
     |
     |  __suppress_context__
     |
     |  __traceback__
     |
     |  args

FUNCTIONS
    canonicalize_name(name: str) -> backend.Lib.site-packages.pip._vendor.packaging.utils.NormalizedName

    canonicalize_version(version: Union[backend.Lib.site-packages.pip._vendor.packaging.version.Version, str]) -> str
        This is very similar to Version.__str__, but has one subtle difference
        with the way it handles the release segment.

    parse_sdist_filename(filename: str) -> Tuple[backend.Lib.site-packages.pip._vendor.packaging.utils.NormalizedName, backend.Lib.site-packages.pip._vendor.packaging.version.Version]

    parse_wheel_filename(filename: str) -> Tuple[backend.Lib.site-packages.pip._vendor.packaging.utils.NormalizedName, backend.Lib.site-packages.pip._vendor.packaging.version.Version, Union[Tuple[()], Tuple[int, str]], FrozenSet[backend.Lib.site-packages.pip._vendor.packaging.tags.Tag]]

DATA
    BuildTag = typing.Union[typing.Tuple[()], typing.Tuple[int, str]]
    FrozenSet = typing.FrozenSet
        A generic version of frozenset.

    NormalizedName = backend.Lib.site-packages.pip._vendor.packaging.utils...
    Tuple = typing.Tuple
        Deprecated alias to builtins.tuple.

        Tuple[X, Y] is the cross-product type of X and Y.

        Example: Tuple[T1, T2] is a tuple of two elements corresponding
        to type variables T1 and T2.  Tuple[int, float, str] is a tuple
        of an int, a float and a string.

        To specify a variable-length tuple of homogeneous type, use Tuple[T, ...].

    Union = typing.Union
        Union type; Union[X, Y] means either X or Y.

        On Python 3.10 and higher, the | operator
        can also be used to denote unions;
        X | Y means the same thing to the type checker as Union[X, Y].

        To define a union, use e.g. Union[int, str]. Details:
        - The arguments must be types and there must be at least one.
        - None as an argument is a special case and is replaced by
          type(None).
        - Unions of unions are flattened, e.g.::

            assert Union[Union[int, str], float] == Union[int, str, float]

        - Unions of a single argument vanish, e.g.::

            assert Union[int] == int  # The constructor actually returns int

        - Redundant arguments are skipped, e.g.::

            assert Union[int, str, int] == Union[int, str]

        - When comparing unions, the argument order is ignored, e.g.::

            assert Union[int, str] == Union[str, int]

        - You cannot subclass or instantiate a union.
        - You can use Optional[X] as a shorthand for Union[X, None].

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\backend\lib\site-packages\pip\_vendor\packaging\utils.py



================================================================================
Help on module backend.Lib.site-packages.pip._vendor.rich.status in backend.Lib.site-packages.pip._vendor.rich:

NAME
    backend.Lib.site-packages.pip._vendor.rich.status

CLASSES
    backend.Lib.site-packages.pip._vendor.rich.jupyter.JupyterMixin(builtins.object)
        Status

    class Status(backend.Lib.site-packages.pip._vendor.rich.jupyter.JupyterMixin)
     |  Status(status: Union[backend.Lib.site-packages.pip._vendor.rich.console.ConsoleRenderable, backend.Lib.site-packages.pip._vendor.rich.console.RichCast, str], *, console: Optional[backend.Lib.site-packages.pip._vendor.rich.console.Console] = None, spinner: str = 'dots', spinner_style: Union[str, ForwardRef('Style')] = 'status.spinner', speed: float = 1.0, refresh_per_second: float = 12.5)
     |
     |  Displays a status indicator with a 'spinner' animation.
     |
     |  Args:
     |      status (RenderableType): A status renderable (str or Text typically).
     |      console (Console, optional): Console instance to use, or None for global console. Defaults to None.
     |      spinner (str, optional): Name of spinner animation (see python -m rich.spinner). Defaults to "dots".
     |      spinner_style (StyleType, optional): Style of spinner. Defaults to "status.spinner".
     |      speed (float, optional): Speed factor for spinner animation. Defaults to 1.0.
     |      refresh_per_second (float, optional): Number of refreshes per second. Defaults to 12.5.
     |
     |  Method resolution order:
     |      Status
     |      backend.Lib.site-packages.pip._vendor.rich.jupyter.JupyterMixin
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __enter__(self) -> 'Status'
     |
     |  __exit__(self, exc_type: Optional[Type[BaseException]], exc_val: Optional[BaseException], exc_tb: Optional[traceback]) -> None
     |
     |  __init__(self, status: Union[backend.Lib.site-packages.pip._vendor.rich.console.ConsoleRenderable, backend.Lib.site-packages.pip._vendor.rich.console.RichCast, str], *, console: Optional[backend.Lib.site-packages.pip._vendor.rich.console.Console] = None, spinner: str = 'dots', spinner_style: Union[str, ForwardRef('Style')] = 'status.spinner', speed: float = 1.0, refresh_per_second: float = 12.5)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  __rich__(self) -> Union[backend.Lib.site-packages.pip._vendor.rich.console.ConsoleRenderable, backend.Lib.site-packages.pip._vendor.rich.console.RichCast, str]
     |
     |  start(self) -> None
     |      Start the status animation.
     |
     |  stop(self) -> None
     |      Stop the spinner animation.
     |
     |  update(self, status: Union[backend.Lib.site-packages.pip._vendor.rich.console.ConsoleRenderable, backend.Lib.site-packages.pip._vendor.rich.console.RichCast, str, NoneType] = None, *, spinner: Optional[str] = None, spinner_style: Union[str, ForwardRef('Style'), NoneType] = None, speed: Optional[float] = None) -> None
     |      Update status.
     |
     |      Args:
     |          status (Optional[RenderableType], optional): New status renderable or None for no change. Defaults to None.
     |          spinner (Optional[str], optional): New spinner or None for no change. Defaults to None.
     |          spinner_style (Optional[StyleType], optional): New spinner style or None for no change. Defaults to None.
     |          speed (Optional[float], optional): Speed factor for spinner animation or None for no change. Defaults to None.
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties defined here:
     |
     |  console
     |      Get the Console used by the Status objects.
     |
     |  renderable
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

DATA
    Optional = typing.Optional
        Optional[X] is equivalent to Union[X, None].

    RenderableType = typing.Union[backend.Lib.site-packages.pip._vend...-p...
    StyleType = typing.Union[str, ForwardRef('Style')]
    Type = typing.Type
        Deprecated alias to builtins.type.

        builtins.type or typing.Type can be used to annotate class objects.
        For example, suppose we have the following classes::

            class User: ...  # Abstract base for User classes
            class BasicUser(User): ...
            class ProUser(User): ...
            class TeamUser(User): ...

        And a function that takes a class argument that's a subclass of
        User and returns an instance of the corresponding class::

            def new_user[U](user_class: Type[U]) -> U:
                user = user_class()
                # (Here we could write the user object to a database)
                return user

            joe = new_user(BasicUser)

        At this point the type checker knows that joe has type BasicUser.

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\backend\lib\site-packages\pip\_vendor\rich\status.py



================================================================================
Help on module backend.Lib.site-packages.pip._vendor.urllib3.response in backend.Lib.site-packages.pip._vendor.urllib3:

NAME
    backend.Lib.site-packages.pip._vendor.urllib3.response

CLASSES
    builtins.object
        DeflateDecoder
        GzipDecoder
        GzipDecoderState
        MultiDecoder
    io.IOBase(_io._IOBase)
        HTTPResponse

    class DeflateDecoder(builtins.object)
     |  Methods defined here:
     |
     |  __getattr__(self, name)
     |
     |  __init__(self)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  decompress(self, data)
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

    class GzipDecoder(builtins.object)
     |  Methods defined here:
     |
     |  __getattr__(self, name)
     |
     |  __init__(self)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  decompress(self, data)
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

    class GzipDecoderState(builtins.object)
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  FIRST_MEMBER = 0
     |
     |  OTHER_MEMBERS = 1
     |
     |  SWALLOW_DATA = 2

    class HTTPResponse(io.IOBase)
     |  HTTPResponse(body='', headers=None, status=0, version=0, reason=None, strict=0, preload_content=True, decode_content=True, original_response=None, pool=None, connection=None, msg=None, retries=None, enforce_content_length=False, request_method=None, request_url=None, auto_close=True)
     |
     |  HTTP Response container.
     |
     |  Backwards-compatible with :class:`http.client.HTTPResponse` but the response ``body`` is
     |  loaded and decoded on-demand when the ``data`` property is accessed.  This
     |  class is also compatible with the Python standard library's :mod:`io`
     |  module, and can hence be treated as a readable object in the context of that
     |  framework.
     |
     |  Extra parameters for behaviour not present in :class:`http.client.HTTPResponse`:
     |
     |  :param preload_content:
     |      If True, the response's body will be preloaded during construction.
     |
     |  :param decode_content:
     |      If True, will attempt to decode the body based on the
     |      'content-encoding' header.
     |
     |  :param original_response:
     |      When this HTTPResponse wrapper is generated from an :class:`http.client.HTTPResponse`
     |      object, it's convenient to include the original for debug purposes. It's
     |      otherwise unused.
     |
     |  :param retries:
     |      The retries contains the last :class:`~urllib3.util.retry.Retry` that
     |      was used during the request.
     |
     |  :param enforce_content_length:
     |      Enforce content length checking. Body returned by server must match
     |      value of Content-Length header, if present. Otherwise, raise error.
     |
     |  Method resolution order:
     |      HTTPResponse
     |      io.IOBase
     |      _io._IOBase
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, body='', headers=None, status=0, version=0, reason=None, strict=0, preload_content=True, decode_content=True, original_response=None, pool=None, connection=None, msg=None, retries=None, enforce_content_length=False, request_method=None, request_url=None, auto_close=True)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  __iter__(self)
     |      Implement iter(self).
     |
     |  close(self)
     |      Flush and close the IO object.
     |
     |      This method has no effect if the file is already closed.
     |
     |  drain_conn(self)
     |      Read and discard any remaining HTTP response data in the response connection.
     |
     |      Unread data in the HTTPResponse connection blocks the connection from being released back to the pool.
     |
     |  fileno(self)
     |      Return underlying file descriptor if one exists.
     |
     |      Raise OSError if the IO object does not use a file descriptor.
     |
     |  flush(self)
     |      Flush write buffers, if applicable.
     |
     |      This is not implemented for read-only and non-blocking streams.
     |
     |  get_redirect_location(self)
     |      Should we redirect and where to?
     |
     |      :returns: Truthy redirect location string if we got a redirect status
     |          code and valid location. ``None`` if redirect status and no
     |          location. ``False`` if not a redirect status code.
     |
     |  getheader(self, name, default=None)
     |
     |  getheaders(self)
     |      # Backwards-compatibility methods for http.client.HTTPResponse
     |
     |  geturl(self)
     |      Returns the URL that was the source of this response.
     |      If the request that generated this response redirected, this method
     |      will return the final redirect location.
     |
     |  info(self)
     |      # Backwards compatibility for http.cookiejar
     |
     |  isclosed(self)
     |
     |  read(self, amt=None, decode_content=None, cache_content=False)
     |      Similar to :meth:`http.client.HTTPResponse.read`, but with two additional
     |      parameters: ``decode_content`` and ``cache_content``.
     |
     |      :param amt:
     |          How much of the content to read. If specified, caching is skipped
     |          because it doesn't make sense to cache partial content as the full
     |          response.
     |
     |      :param decode_content:
     |          If True, will attempt to decode the body based on the
     |          'content-encoding' header.
     |
     |      :param cache_content:
     |          If True, will save the returned data such that the same result is
     |          returned despite of the state of the underlying file object. This
     |          is useful if you want the ``.data`` property to continue working
     |          after having ``.read()`` the file object. (Overridden if ``amt`` is
     |          set.)
     |
     |  read_chunked(self, amt=None, decode_content=None)
     |      Similar to :meth:`HTTPResponse.read`, but with an additional
     |      parameter: ``decode_content``.
     |
     |      :param amt:
     |          How much of the content to read. If specified, caching is skipped
     |          because it doesn't make sense to cache partial content as the full
     |          response.
     |
     |      :param decode_content:
     |          If True, will attempt to decode the body based on the
     |          'content-encoding' header.
     |
     |  readable(self)
     |      Return whether object was opened for reading.
     |
     |      If False, read() will raise OSError.
     |
     |  readinto(self, b)
     |
     |  release_conn(self)
     |
     |  stream(self, amt=65536, decode_content=None)
     |      A generator wrapper for the read() method. A call will block until
     |      ``amt`` bytes have been read from the connection or until the
     |      connection is closed.
     |
     |      :param amt:
     |          How much of the content to read. The generator will return up to
     |          much data per iteration, but may return less. This is particularly
     |          likely when using compressed data. However, the empty string will
     |          never be returned.
     |
     |      :param decode_content:
     |          If True, will attempt to decode the body based on the
     |          'content-encoding' header.
     |
     |  supports_chunked_reads(self)
     |      Checks if the underlying file-like object looks like a
     |      :class:`http.client.HTTPResponse` object. We do this by testing for
     |      the fp attribute. If it is present we assume it returns raw chunks as
     |      processed by read_chunked().
     |
     |  tell(self)
     |      Obtain the number of bytes pulled over the wire so far. May differ from
     |      the amount of content returned by :meth:``urllib3.response.HTTPResponse.read``
     |      if bytes are encoded on the wire (e.g, compressed).
     |
     |  ----------------------------------------------------------------------
     |  Class methods defined here:
     |
     |  from_httplib(r, **response_kw)
     |      Given an :class:`http.client.HTTPResponse` instance ``r``, return a
     |      corresponding :class:`urllib3.response.HTTPResponse` object.
     |
     |      Remaining parameters are passed to the HTTPResponse constructor, along
     |      with ``original_response=r``.
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties defined here:
     |
     |  closed
     |
     |  connection
     |
     |  data
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  CONTENT_DECODERS = ['gzip', 'deflate']
     |
     |  DECODER_ERROR_CLASSES = (<class 'OSError'>, <class 'zlib.error'>)
     |
     |  REDIRECT_STATUSES = [301, 302, 303, 307, 308]
     |
     |  __abstractmethods__ = frozenset()
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from _io._IOBase:
     |
     |  __del__(...)
     |
     |  __enter__(...)
     |
     |  __exit__(...)
     |
     |  __next__(self, /)
     |      Implement next(self).
     |
     |  isatty(self, /)
     |      Return whether this is an 'interactive' stream.
     |
     |      Return False if it can't be determined.
     |
     |  readline(self, size=-1, /)
     |      Read and return a line from the stream.
     |
     |      If size is specified, at most size bytes will be read.
     |
     |      The line terminator is always b'\n' for binary files; for text
     |      files, the newlines argument to open can be used to select the line
     |      terminator(s) recognized.
     |
     |  readlines(self, hint=-1, /)
     |      Return a list of lines from the stream.
     |
     |      hint can be specified to control the number of lines read: no more
     |      lines will be read if the total size (in bytes/characters) of all
     |      lines so far exceeds hint.
     |
     |  seek(self, offset, whence=0, /)
     |      Change the stream position to the given byte offset.
     |
     |        offset
     |          The stream position, relative to 'whence'.
     |        whence
     |          The relative position to seek from.
     |
     |      The offset is interpreted relative to the position indicated by whence.
     |      Values for whence are:
     |
     |      * os.SEEK_SET or 0 -- start of stream (the default); offset should be zero or positive
     |      * os.SEEK_CUR or 1 -- current stream position; offset may be negative
     |      * os.SEEK_END or 2 -- end of stream; offset is usually negative
     |
     |      Return the new absolute position.
     |
     |  seekable(self, /)
     |      Return whether object supports random access.
     |
     |      If False, seek(), tell() and truncate() will raise OSError.
     |      This method may need to do a test seek().
     |
     |  truncate(self, size=None, /)
     |      Truncate file to size bytes.
     |
     |      File pointer is left unchanged. Size defaults to the current IO position
     |      as reported by tell(). Return the new size.
     |
     |  writable(self, /)
     |      Return whether object was opened for writing.
     |
     |      If False, write() will raise OSError.
     |
     |  writelines(self, lines, /)
     |      Write a list of lines to stream.
     |
     |      Line separators are not added, so it is usual for each of the
     |      lines provided to have a line separator at the end.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from _io._IOBase:
     |
     |  __dict__

    class MultiDecoder(builtins.object)
     |  MultiDecoder(modes)
     |
     |  From RFC7231:
     |      If one or more encodings have been applied to a representation, the
     |      sender that applied the encodings MUST generate a Content-Encoding
     |      header field that lists the content codings in the order in which
     |      they were applied.
     |
     |  Methods defined here:
     |
     |  __init__(self, modes)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  decompress(self, data)
     |
     |  flush(self)
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

DATA
    brotli = None
    log = <Logger backend.Lib.site-packages.pip._vendor.urllib3.response (...

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\backend\lib\site-packages\pip\_vendor\urllib3\response.py



================================================================================
Help on module backend.Lib.site-packages.pip._vendor.urllib3.util.response in backend.Lib.site-packages.pip._vendor.urllib3.util:

NAME
    backend.Lib.site-packages.pip._vendor.urllib3.util.response

FUNCTIONS
    assert_header_parsing(headers)
        Asserts whether all headers have been successfully parsed.
        Extracts encountered errors from the result of parsing headers.

        Only works on Python 3.

        :param http.client.HTTPMessage headers: Headers to verify.

        :raises urllib3.exceptions.HeaderParsingError:
            If parsing errors are found.

    is_fp_closed(obj)
        Checks whether a given file-like object is closed.

        :param obj:
            The file-like object to check.

    is_response_to_head(response)
        Checks whether the request of a response has been a HEAD-request.
        Handles the quirks of AppEngine.

        :param http.client.HTTPResponse response:
            Response to check if the originating request
            used 'HEAD' as a method.

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\backend\lib\site-packages\pip\_vendor\urllib3\util\response.py



================================================================================
Help on module backend.Lib.site-packages.proto.utils in backend.Lib.site-packages.proto:

NAME
    backend.Lib.site-packages.proto.utils

DESCRIPTION
    # Copyright 2018 Google LLC
    #
    # Licensed under the Apache License, Version 2.0 (the "License");
    # you may not use this file except in compliance with the License.
    # You may obtain a copy of the License at
    #
    #     https://www.apache.org/licenses/LICENSE-2.0
    #
    # Unless required by applicable law or agreed to in writing, software
    # distributed under the License is distributed on an "AS IS" BASIS,
    # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    # See the License for the specific language governing permissions and
    # limitations under the License.

FUNCTIONS
    cached_property(fx)
        Make the callable into a cached property.

        Similar to @property, but the function will only be called once per
        object.

        Args:
            fx (Callable[]): The property function.

        Returns:
            Callable[]: The wrapped function.

DATA
    __all__ = ('cached_property',)

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\backend\lib\site-packages\proto\utils.py



================================================================================
Help on module backend.Lib.site-packages.requests.auth in backend.Lib.site-packages.requests:

NAME
    backend.Lib.site-packages.requests.auth

DESCRIPTION
    requests.auth
    ~~~~~~~~~~~~~

    This module contains the authentication handlers for Requests.

CLASSES
    builtins.object
        AuthBase
            HTTPBasicAuth
                HTTPProxyAuth
            HTTPDigestAuth

    class AuthBase(builtins.object)
     |  Base class that all auth implementations derive from
     |
     |  Methods defined here:
     |
     |  __call__(self, r)
     |      Call self as a function.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

    class HTTPBasicAuth(AuthBase)
     |  HTTPBasicAuth(username, password)
     |
     |  Attaches HTTP Basic Authentication to the given Request object.
     |
     |  Method resolution order:
     |      HTTPBasicAuth
     |      AuthBase
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __call__(self, r)
     |      Call self as a function.
     |
     |  __eq__(self, other)
     |      Return self==value.
     |
     |  __init__(self, username, password)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  __ne__(self, other)
     |      Return self!=value.
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  __hash__ = None
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from AuthBase:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

    class HTTPDigestAuth(AuthBase)
     |  HTTPDigestAuth(username, password)
     |
     |  Attaches HTTP Digest Authentication to the given Request object.
     |
     |  Method resolution order:
     |      HTTPDigestAuth
     |      AuthBase
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __call__(self, r)
     |      Call self as a function.
     |
     |  __eq__(self, other)
     |      Return self==value.
     |
     |  __init__(self, username, password)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  __ne__(self, other)
     |      Return self!=value.
     |
     |  build_digest_header(self, method, url)
     |      :rtype: str
     |
     |  handle_401(self, r, **kwargs)
     |      Takes the given response and tries digest-auth, if needed.
     |
     |      :rtype: requests.Response
     |
     |  handle_redirect(self, r, **kwargs)
     |      Reset num_401_calls counter on redirects.
     |
     |  init_per_thread_state(self)
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  __hash__ = None
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from AuthBase:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

    class HTTPProxyAuth(HTTPBasicAuth)
     |  HTTPProxyAuth(username, password)
     |
     |  Attaches HTTP Proxy Authentication to a given Request object.
     |
     |  Method resolution order:
     |      HTTPProxyAuth
     |      HTTPBasicAuth
     |      AuthBase
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __call__(self, r)
     |      Call self as a function.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from HTTPBasicAuth:
     |
     |  __eq__(self, other)
     |      Return self==value.
     |
     |  __init__(self, username, password)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  __ne__(self, other)
     |      Return self!=value.
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from HTTPBasicAuth:
     |
     |  __hash__ = None
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from AuthBase:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

DATA
    CONTENT_TYPE_FORM_URLENCODED = 'application/x-www-form-urlencoded'
    CONTENT_TYPE_MULTI_PART = 'multipart/form-data'
    basestring = (<class 'str'>, <class 'bytes'>)

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\backend\lib\site-packages\requests\auth.py



================================================================================
Help on module backend.Lib.site-packages.requests.models in backend.Lib.site-packages.requests:

NAME
    backend.Lib.site-packages.requests.models

DESCRIPTION
    requests.models
    ~~~~~~~~~~~~~~~

    This module contains the primary objects that power Requests.

CLASSES
    builtins.object
        RequestEncodingMixin
            PreparedRequest(RequestEncodingMixin, RequestHooksMixin)
        RequestHooksMixin
            Request
        Response

    class PreparedRequest(RequestEncodingMixin, RequestHooksMixin)
     |  The fully mutable :class:`PreparedRequest <PreparedRequest>` object,
     |  containing the exact bytes that will be sent to the server.
     |
     |  Instances are generated from a :class:`Request <Request>` object, and
     |  should not be instantiated manually; doing so may produce undesirable
     |  effects.
     |
     |  Usage::
     |
     |    >>> import requests
     |    >>> req = requests.Request('GET', 'https://httpbin.org/get')
     |    >>> r = req.prepare()
     |    >>> r
     |    <PreparedRequest [GET]>
     |
     |    >>> s = requests.Session()
     |    >>> s.send(r)
     |    <Response [200]>
     |
     |  Method resolution order:
     |      PreparedRequest
     |      RequestEncodingMixin
     |      RequestHooksMixin
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  __repr__(self)
     |      Return repr(self).
     |
     |  copy(self)
     |
     |  prepare(self, method=None, url=None, headers=None, files=None, data=None, params=None, auth=None, cookies=None, hooks=None, json=None)
     |      Prepares the entire request with the given parameters.
     |
     |  prepare_auth(self, auth, url='')
     |      Prepares the given HTTP auth data.
     |
     |  prepare_body(self, data, files, json=None)
     |      Prepares the given HTTP body data.
     |
     |  prepare_content_length(self, body)
     |      Prepare Content-Length header based on request method and body
     |
     |  prepare_cookies(self, cookies)
     |      Prepares the given HTTP cookie data.
     |
     |      This function eventually generates a ``Cookie`` header from the
     |      given cookies using cookielib. Due to cookielib's design, the header
     |      will not be regenerated if it already exists, meaning this function
     |      can only be called once for the life of the
     |      :class:`PreparedRequest <PreparedRequest>` object. Any subsequent calls
     |      to ``prepare_cookies`` will have no actual effect, unless the "Cookie"
     |      header is removed beforehand.
     |
     |  prepare_headers(self, headers)
     |      Prepares the given HTTP headers.
     |
     |  prepare_hooks(self, hooks)
     |      Prepares the given hooks.
     |
     |  prepare_method(self, method)
     |      Prepares the given HTTP method.
     |
     |  prepare_url(self, url, params)
     |      Prepares the given HTTP URL.
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from RequestEncodingMixin:
     |
     |  path_url
     |      Build the path URL to use.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from RequestEncodingMixin:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from RequestHooksMixin:
     |
     |  deregister_hook(self, event, hook)
     |      Deregister a previously registered hook.
     |      Returns True if the hook existed, False if not.
     |
     |  register_hook(self, event, hook)
     |      Properly register a hook.

    class Request(RequestHooksMixin)
     |  Request(method=None, url=None, headers=None, files=None, data=None, params=None, auth=None, cookies=None, hooks=None, json=None)
     |
     |  A user-created :class:`Request <Request>` object.
     |
     |  Used to prepare a :class:`PreparedRequest <PreparedRequest>`, which is sent to the server.
     |
     |  :param method: HTTP method to use.
     |  :param url: URL to send.
     |  :param headers: dictionary of headers to send.
     |  :param files: dictionary of {filename: fileobject} files to multipart upload.
     |  :param data: the body to attach to the request. If a dictionary or
     |      list of tuples ``[(key, value)]`` is provided, form-encoding will
     |      take place.
     |  :param json: json for the body to attach to the request (if files or data is not specified).
     |  :param params: URL parameters to append to the URL. If a dictionary or
     |      list of tuples ``[(key, value)]`` is provided, form-encoding will
     |      take place.
     |  :param auth: Auth handler or (user, pass) tuple.
     |  :param cookies: dictionary or CookieJar of cookies to attach to this request.
     |  :param hooks: dictionary of callback hooks, for internal usage.
     |
     |  Usage::
     |
     |    >>> import requests
     |    >>> req = requests.Request('GET', 'https://httpbin.org/get')
     |    >>> req.prepare()
     |    <PreparedRequest [GET]>
     |
     |  Method resolution order:
     |      Request
     |      RequestHooksMixin
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, method=None, url=None, headers=None, files=None, data=None, params=None, auth=None, cookies=None, hooks=None, json=None)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  __repr__(self)
     |      Return repr(self).
     |
     |  prepare(self)
     |      Constructs a :class:`PreparedRequest <PreparedRequest>` for transmission and returns it.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from RequestHooksMixin:
     |
     |  deregister_hook(self, event, hook)
     |      Deregister a previously registered hook.
     |      Returns True if the hook existed, False if not.
     |
     |  register_hook(self, event, hook)
     |      Properly register a hook.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from RequestHooksMixin:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

    class RequestEncodingMixin(builtins.object)
     |  Readonly properties defined here:
     |
     |  path_url
     |      Build the path URL to use.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

    class RequestHooksMixin(builtins.object)
     |  Methods defined here:
     |
     |  deregister_hook(self, event, hook)
     |      Deregister a previously registered hook.
     |      Returns True if the hook existed, False if not.
     |
     |  register_hook(self, event, hook)
     |      Properly register a hook.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

    class Response(builtins.object)
     |  The :class:`Response <Response>` object, which contains a
     |  server's response to an HTTP request.
     |
     |  Methods defined here:
     |
     |  __bool__(self)
     |      Returns True if :attr:`status_code` is less than 400.
     |
     |      This attribute checks if the status code of the response is between
     |      400 and 600 to see if there was a client error or a server error. If
     |      the status code, is between 200 and 400, this will return True. This
     |      is **not** a check to see if the response code is ``200 OK``.
     |
     |  __enter__(self)
     |
     |  __exit__(self, *args)
     |
     |  __getstate__(self)
     |      Helper for pickle.
     |
     |  __init__(self)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  __iter__(self)
     |      Allows you to use a response as an iterator.
     |
     |  __nonzero__(self)
     |      Returns True if :attr:`status_code` is less than 400.
     |
     |      This attribute checks if the status code of the response is between
     |      400 and 600 to see if there was a client error or a server error. If
     |      the status code, is between 200 and 400, this will return True. This
     |      is **not** a check to see if the response code is ``200 OK``.
     |
     |  __repr__(self)
     |      Return repr(self).
     |
     |  __setstate__(self, state)
     |
     |  close(self)
     |      Releases the connection back to the pool. Once this method has been
     |      called the underlying ``raw`` object must not be accessed again.
     |
     |      *Note: Should not normally need to be called explicitly.*
     |
     |  iter_content(self, chunk_size=1, decode_unicode=False)
     |      Iterates over the response data.  When stream=True is set on the
     |      request, this avoids reading the content at once into memory for
     |      large responses.  The chunk size is the number of bytes it should
     |      read into memory.  This is not necessarily the length of each item
     |      returned as decoding can take place.
     |
     |      chunk_size must be of type int or None. A value of None will
     |      function differently depending on the value of `stream`.
     |      stream=True will read data as it arrives in whatever size the
     |      chunks are received. If stream=False, data is returned as
     |      a single chunk.
     |
     |      If decode_unicode is True, content will be decoded using the best
     |      available encoding based on the response.
     |
     |  iter_lines(self, chunk_size=512, decode_unicode=False, delimiter=None)
     |      Iterates over the response data, one line at a time.  When
     |      stream=True is set on the request, this avoids reading the
     |      content at once into memory for large responses.
     |
     |      .. note:: This method is not reentrant safe.
     |
     |  json(self, **kwargs)
     |      Returns the json-encoded content of a response, if any.
     |
     |      :param \*\*kwargs: Optional arguments that ``json.loads`` takes.
     |      :raises requests.exceptions.JSONDecodeError: If the response body does not
     |          contain valid json.
     |
     |  raise_for_status(self)
     |      Raises :class:`HTTPError`, if one occurred.
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties defined here:
     |
     |  apparent_encoding
     |      The apparent encoding, provided by the charset_normalizer or chardet libraries.
     |
     |  content
     |      Content of the response, in bytes.
     |
     |  is_permanent_redirect
     |      True if this Response one of the permanent versions of redirect.
     |
     |  is_redirect
     |      True if this Response is a well-formed HTTP redirect that could have
     |      been processed automatically (by :meth:`Session.resolve_redirects`).
     |
     |  links
     |      Returns the parsed header links of the response, if any.
     |
     |  next
     |      Returns a PreparedRequest for the next request in a redirect chain, if there is one.
     |
     |  ok
     |      Returns True if :attr:`status_code` is less than 400, False if not.
     |
     |      This attribute checks if the status code of the response is between
     |      400 and 600 to see if there was a client error or a server error. If
     |      the status code is between 200 and 400, this will return True. This
     |      is **not** a check to see if the response code is ``200 OK``.
     |
     |  text
     |      Content of the response, in unicode.
     |
     |      If Response.encoding is None, encoding will be guessed using
     |      ``charset_normalizer`` or ``chardet``.
     |
     |      The encoding of the response content is determined based solely on HTTP
     |      headers, following RFC 2616 to the letter. If you can take advantage of
     |      non-HTTP knowledge to make a better guess at the encoding, you should
     |      set ``r.encoding`` appropriately before accessing this property.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  __attrs__ = ['_content', 'status_code', 'headers', 'url', 'history', '...

DATA
    CONTENT_CHUNK_SIZE = 10240
    DEFAULT_REDIRECT_LIMIT = 30
    ITER_CHUNK_SIZE = 512
    REDIRECT_STATI = (301, 302, 303, 307, 308)
    basestring = (<class 'str'>, <class 'bytes'>)
    codes = <lookup 'status_codes'>

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\backend\lib\site-packages\requests\models.py



================================================================================
Help on module backend.Lib.site-packages.requests.utils in backend.Lib.site-packages.requests:

NAME
    backend.Lib.site-packages.requests.utils

DESCRIPTION
    requests.utils
    ~~~~~~~~~~~~~~

    This module provides utility functions that are used within Requests
    that are also useful for external consumption.

FUNCTIONS
    add_dict_to_cookiejar(cj, cookie_dict)
        Returns a CookieJar from a key/value dictionary.

        :param cj: CookieJar to insert cookies into.
        :param cookie_dict: Dict of key/values to insert into CookieJar.
        :rtype: CookieJar

    address_in_network(ip, net)
        This function allows you to check if an IP belongs to a network subnet

        Example: returns True if ip = 192.168.1.1 and net = 192.168.1.0/24
                 returns False if ip = 192.168.1.1 and net = 192.168.100.0/24

        :rtype: bool

    atomic_open(filename)
        Write a file to the disk in an atomic fashion

    check_header_validity(header)
        Verifies that header parts don't contain leading whitespace
        reserved characters, or return characters.

        :param header: tuple, in the format (name, value).

    default_headers()
        :rtype: requests.structures.CaseInsensitiveDict

    default_user_agent(name='python-requests')
        Return a string representing the default user agent.

        :rtype: str

    dict_from_cookiejar(cj)
        Returns a key/value dictionary from a CookieJar.

        :param cj: CookieJar object to extract cookies from.
        :rtype: dict

    dict_to_sequence(d)
        Returns an internal sequence dictionary update.

    dotted_netmask(mask)
        Converts mask from /xx format to xxx.xxx.xxx.xxx

        Example: if mask is 24 function returns 255.255.255.0

        :rtype: str

    extract_zipped_paths(path)
        Replace nonexistent paths that look like they refer to a member of a zip
        archive with the location of an extracted copy of the target, or else
        just return the provided path unchanged.

    from_key_val_list(value)
        Take an object and test to see if it can be represented as a
        dictionary. Unless it can not be represented as such, return an
        OrderedDict, e.g.,

        ::

            >>> from_key_val_list([('key', 'val')])
            OrderedDict([('key', 'val')])
            >>> from_key_val_list('string')
            Traceback (most recent call last):
            ...
            ValueError: cannot encode objects that are not 2-tuples
            >>> from_key_val_list({'key': 'val'})
            OrderedDict([('key', 'val')])

        :rtype: OrderedDict

    get_auth_from_url(url)
        Given a url with authentication components, extract them into a tuple of
        username,password.

        :rtype: (str,str)

    get_encoding_from_headers(headers)
        Returns encodings from given HTTP Header Dict.

        :param headers: dictionary to extract encoding from.
        :rtype: str

    get_encodings_from_content(content)
        Returns encodings from given content string.

        :param content: bytestring to extract encodings from.

    get_environ_proxies(url, no_proxy=None)
        Return a dict of environment proxies.

        :rtype: dict

    get_netrc_auth(url, raise_errors=False)
        Returns the Requests tuple auth for a given url from netrc.

    get_unicode_from_response(r)
        Returns the requested content back in unicode.

        :param r: Response object to get unicode content from.

        Tried:

        1. charset from content-type
        2. fall back and replace all unicode characters

        :rtype: str

    guess_filename(obj)
        Tries to guess the filename of the given object.

    guess_json_utf(data)
        :rtype: str

    is_ipv4_address(string_ip)
        :rtype: bool

    is_valid_cidr(string_network)
        Very simple check of the cidr format in no_proxy variable.

        :rtype: bool

    iter_slices(string, slice_length)
        Iterate over slices of a string.

    parse_dict_header(value)
        Parse lists of key, value pairs as described by RFC 2068 Section 2 and
        convert them into a python dict:

        >>> d = parse_dict_header('foo="is a fish", bar="as well"')
        >>> type(d) is dict
        True
        >>> sorted(d.items())
        [('bar', 'as well'), ('foo', 'is a fish')]

        If there is no value for a key it will be `None`:

        >>> parse_dict_header('key_without_value')
        {'key_without_value': None}

        To create a header from the :class:`dict` again, use the
        :func:`dump_header` function.

        :param value: a string with a dict header.
        :return: :class:`dict`
        :rtype: dict

    parse_header_links(value)
        Return a list of parsed link headers proxies.

        i.e. Link: <http:/.../front.jpeg>; rel=front; type="image/jpeg",<http://.../back.jpeg>; rel=back;type="image/jpeg"

        :rtype: list

    parse_list_header(value)
        Parse lists as described by RFC 2068 Section 2.

        In particular, parse comma-separated lists where the elements of
        the list may include quoted-strings.  A quoted-string could
        contain a comma.  A non-quoted string could have quotes in the
        middle.  Quotes are removed automatically after parsing.

        It basically works like :func:`parse_set_header` just that items
        may appear multiple times and case sensitivity is preserved.

        The return value is a standard :class:`list`:

        >>> parse_list_header('token, "quoted value"')
        ['token', 'quoted value']

        To create a header from the :class:`list` again, use the
        :func:`dump_header` function.

        :param value: a string with a list header.
        :return: :class:`list`
        :rtype: list

    prepend_scheme_if_needed(url, new_scheme)
        Given a URL that may or may not have a scheme, prepend the given scheme.
        Does not replace a present scheme with the one provided as an argument.

        :rtype: str

    proxy_bypass(host)
        Return True, if the host should be bypassed.

        Checks proxy settings gathered from the environment, if specified,
        or the registry.

    proxy_bypass_registry(host)

    requote_uri(uri)
        Re-quote the given URI.

        This function passes the given URI through an unquote/quote cycle to
        ensure that it is fully and consistently quoted.

        :rtype: str

    resolve_proxies(request, proxies, trust_env=True)
        This method takes proxy information from a request and configuration
        input to resolve a mapping of target proxies. This will consider settings
        such as NO_PROXY to strip proxy configurations.

        :param request: Request or PreparedRequest
        :param proxies: A dictionary of schemes or schemes and hosts to proxy URLs
        :param trust_env: Boolean declaring whether to trust environment configs

        :rtype: dict

    rewind_body(prepared_request)
        Move file pointer back to its recorded starting position
        so it can be read again on redirect.

    select_proxy(url, proxies)
        Select a proxy for the url, if applicable.

        :param url: The url being for the request
        :param proxies: A dictionary of schemes or schemes and hosts to proxy URLs

    set_environ(env_name, value)
        Set the environment variable 'env_name' to 'value'

        Save previous value, yield, and then restore the previous value stored in
        the environment variable 'env_name'.

        If 'value' is None, do nothing

    should_bypass_proxies(url, no_proxy)
        Returns whether we should bypass proxies or not.

        :rtype: bool

    stream_decode_response_unicode(iterator, r)
        Stream decodes an iterator.

    super_len(o)

    to_key_val_list(value)
        Take an object and test to see if it can be represented as a
        dictionary. If it can be, return a list of tuples, e.g.,

        ::

            >>> to_key_val_list([('key', 'val')])
            [('key', 'val')]
            >>> to_key_val_list({'key': 'val'})
            [('key', 'val')]
            >>> to_key_val_list('string')
            Traceback (most recent call last):
            ...
            ValueError: cannot encode objects that are not 2-tuples

        :rtype: list

    unquote_header_value(value, is_filename=False)
        Unquotes a header value.  (Reversal of :func:`quote_header_value`).
        This does not use the real unquoting but what browsers are actually
        using for quoting.

        :param value: the header value to unquote.
        :rtype: str

    unquote_unreserved(uri)
        Un-escape any percent-escape sequences in a URI that are unreserved
        characters. This leaves all reserved, illegal and non-ASCII bytes encoded.

        :rtype: str

    urldefragauth(url)
        Given a url remove the fragment and the authentication part.

        :rtype: str

DATA
    DEFAULT_ACCEPT_ENCODING = 'gzip, deflate'
    DEFAULT_CA_BUNDLE_PATH = r'C:\Python312\Lib\site-packages\certifi\cace...
    DEFAULT_PORTS = {'http': 80, 'https': 443}
    HEADER_VALIDATORS = {<class 'bytes'>: (re.compile(b'^[^:\\s][^:\\r\\n]...
    NETRC_FILES = ('.netrc', '_netrc')
    UNRESERVED_SET = frozenset({'-', '.', '0', '1', '2', '3', ...})
    basestring = (<class 'str'>, <class 'bytes'>)
    integer_types = (<class 'int'>,)

VERSION
    2.32.3

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\backend\lib\site-packages\requests\utils.py



================================================================================
Help on module backend.Lib.site-packages.requests._internal_utils in backend.Lib.site-packages.requests:

NAME
    backend.Lib.site-packages.requests._internal_utils

DESCRIPTION
    requests._internal_utils
    ~~~~~~~~~~~~~~

    Provides utility functions that are consumed internally by Requests
    which depend on extremely few external helpers (such as compat)

FUNCTIONS
    to_native_string(string, encoding='ascii')
        Given a string object, regardless of type, returns a representation of
        that string in the native string type, encoding and decoding where
        necessary. This assumes ASCII unless told otherwise.

    unicode_is_ascii(u_string)
        Determine if unicode string only contains ASCII characters.

        :param str u_string: unicode string to check. Must be unicode
            and not Python 2 `str`.
        :rtype: bool

DATA
    HEADER_VALIDATORS = {<class 'bytes'>: (re.compile(b'^[^:\\s][^:\\r\\n]...

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\backend\lib\site-packages\requests\_internal_utils.py



================================================================================
Help on module backend.Lib.site-packages.requests_oauthlib.oauth1_auth in backend.Lib.site-packages.requests_oauthlib:

NAME
    backend.Lib.site-packages.requests_oauthlib.oauth1_auth - # -*- coding: utf-8 -*-

CLASSES
    requests.auth.AuthBase(builtins.object)
        OAuth1

    class OAuth1(requests.auth.AuthBase)
     |  OAuth1(client_key, client_secret=None, resource_owner_key=None, resource_owner_secret=None, callback_uri=None, signature_method='HMAC-SHA1', signature_type='AUTH_HEADER', rsa_key=None, verifier=None, decoding='utf-8', client_class=None, force_include_body=False, **kwargs)
     |
     |  Signs the request using OAuth 1 (RFC5849)
     |
     |  Method resolution order:
     |      OAuth1
     |      requests.auth.AuthBase
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __call__(self, r)
     |      Add OAuth parameters to the request.
     |
     |      Parameters may be included from the body if the content-type is
     |      urlencoded, if no content type is set a guess is made.
     |
     |  __init__(self, client_key, client_secret=None, resource_owner_key=None, resource_owner_secret=None, callback_uri=None, signature_method='HMAC-SHA1', signature_type='AUTH_HEADER', rsa_key=None, verifier=None, decoding='utf-8', client_class=None, force_include_body=False, **kwargs)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  client_class = <class 'oauthlib.oauth1.rfc5849.Client'>
     |      A client used to sign OAuth 1.0 RFC 5849 requests.
     |
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from requests.auth.AuthBase:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

DATA
    CONTENT_TYPE_FORM_URLENCODED = 'application/x-www-form-urlencoded'
    CONTENT_TYPE_MULTI_PART = 'multipart/form-data'
    SIGNATURE_HMAC = 'HMAC-SHA1'
    SIGNATURE_TYPE_AUTH_HEADER = 'AUTH_HEADER'
    SIGNATURE_TYPE_BODY = 'BODY'
    log = <Logger backend.Lib.site-packages.requests_oauthlib.oauth1_auth ...

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\backend\lib\site-packages\requests_oauthlib\oauth1_auth.py



================================================================================
Help on module backend.Lib.site-packages.requests_oauthlib.oauth2_auth in backend.Lib.site-packages.requests_oauthlib:

NAME
    backend.Lib.site-packages.requests_oauthlib.oauth2_auth

CLASSES
    requests.auth.AuthBase(builtins.object)
        OAuth2

    class OAuth2(requests.auth.AuthBase)
     |  OAuth2(client_id=None, client=None, token=None)
     |
     |  Adds proof of authorization (OAuth2 token) to the request.
     |
     |  Method resolution order:
     |      OAuth2
     |      requests.auth.AuthBase
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __call__(self, r)
     |      Append an OAuth 2 token to the request.
     |
     |      Note that currently HTTPS is required for all requests. There may be
     |      a token type that allows for plain HTTP in the future and then this
     |      should be updated to allow plain HTTP on a white list basis.
     |
     |  __init__(self, client_id=None, client=None, token=None)
     |      Construct a new OAuth 2 authorization object.
     |
     |      :param client_id: Client id obtained during registration
     |      :param client: :class:`oauthlib.oauth2.Client` to be used. Default is
     |                     WebApplicationClient which is useful for any
     |                     hosted application but not mobile or desktop.
     |      :param token: Token dictionary, must include access_token
     |                    and token_type.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from requests.auth.AuthBase:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\backend\lib\site-packages\requests_oauthlib\oauth2_auth.py



================================================================================
Help on module backend.Lib.site-packages.starlette.status in backend.Lib.site-packages.starlette:

NAME
    backend.Lib.site-packages.starlette.status

DESCRIPTION
    HTTP codes
    See HTTP Status Code Registry:
    https://www.iana.org/assignments/http-status-codes/http-status-codes.xhtml

    And RFC 2324 - https://tools.ietf.org/html/rfc2324

DATA
    HTTP_100_CONTINUE = 100
    HTTP_101_SWITCHING_PROTOCOLS = 101
    HTTP_102_PROCESSING = 102
    HTTP_103_EARLY_HINTS = 103
    HTTP_200_OK = 200
    HTTP_201_CREATED = 201
    HTTP_202_ACCEPTED = 202
    HTTP_203_NON_AUTHORITATIVE_INFORMATION = 203
    HTTP_204_NO_CONTENT = 204
    HTTP_205_RESET_CONTENT = 205
    HTTP_206_PARTIAL_CONTENT = 206
    HTTP_207_MULTI_STATUS = 207
    HTTP_208_ALREADY_REPORTED = 208
    HTTP_226_IM_USED = 226
    HTTP_300_MULTIPLE_CHOICES = 300
    HTTP_301_MOVED_PERMANENTLY = 301
    HTTP_302_FOUND = 302
    HTTP_303_SEE_OTHER = 303
    HTTP_304_NOT_MODIFIED = 304
    HTTP_305_USE_PROXY = 305
    HTTP_306_RESERVED = 306
    HTTP_307_TEMPORARY_REDIRECT = 307
    HTTP_308_PERMANENT_REDIRECT = 308
    HTTP_400_BAD_REQUEST = 400
    HTTP_401_UNAUTHORIZED = 401
    HTTP_402_PAYMENT_REQUIRED = 402
    HTTP_403_FORBIDDEN = 403
    HTTP_404_NOT_FOUND = 404
    HTTP_405_METHOD_NOT_ALLOWED = 405
    HTTP_406_NOT_ACCEPTABLE = 406
    HTTP_407_PROXY_AUTHENTICATION_REQUIRED = 407
    HTTP_408_REQUEST_TIMEOUT = 408
    HTTP_409_CONFLICT = 409
    HTTP_410_GONE = 410
    HTTP_411_LENGTH_REQUIRED = 411
    HTTP_412_PRECONDITION_FAILED = 412
    HTTP_413_REQUEST_ENTITY_TOO_LARGE = 413
    HTTP_414_REQUEST_URI_TOO_LONG = 414
    HTTP_415_UNSUPPORTED_MEDIA_TYPE = 415
    HTTP_416_REQUESTED_RANGE_NOT_SATISFIABLE = 416
    HTTP_417_EXPECTATION_FAILED = 417
    HTTP_418_IM_A_TEAPOT = 418
    HTTP_421_MISDIRECTED_REQUEST = 421
    HTTP_422_UNPROCESSABLE_ENTITY = 422
    HTTP_423_LOCKED = 423
    HTTP_424_FAILED_DEPENDENCY = 424
    HTTP_425_TOO_EARLY = 425
    HTTP_426_UPGRADE_REQUIRED = 426
    HTTP_428_PRECONDITION_REQUIRED = 428
    HTTP_429_TOO_MANY_REQUESTS = 429
    HTTP_431_REQUEST_HEADER_FIELDS_TOO_LARGE = 431
    HTTP_451_UNAVAILABLE_FOR_LEGAL_REASONS = 451
    HTTP_500_INTERNAL_SERVER_ERROR = 500
    HTTP_501_NOT_IMPLEMENTED = 501
    HTTP_502_BAD_GATEWAY = 502
    HTTP_503_SERVICE_UNAVAILABLE = 503
    HTTP_504_GATEWAY_TIMEOUT = 504
    HTTP_505_HTTP_VERSION_NOT_SUPPORTED = 505
    HTTP_506_VARIANT_ALSO_NEGOTIATES = 506
    HTTP_507_INSUFFICIENT_STORAGE = 507
    HTTP_508_LOOP_DETECTED = 508
    HTTP_510_NOT_EXTENDED = 510
    HTTP_511_NETWORK_AUTHENTICATION_REQUIRED = 511
    WS_1000_NORMAL_CLOSURE = 1000
    WS_1001_GOING_AWAY = 1001
    WS_1002_PROTOCOL_ERROR = 1002
    WS_1003_UNSUPPORTED_DATA = 1003
    WS_1005_NO_STATUS_RCVD = 1005
    WS_1006_ABNORMAL_CLOSURE = 1006
    WS_1007_INVALID_FRAME_PAYLOAD_DATA = 1007
    WS_1008_POLICY_VIOLATION = 1008
    WS_1009_MESSAGE_TOO_BIG = 1009
    WS_1010_MANDATORY_EXT = 1010
    WS_1011_INTERNAL_ERROR = 1011
    WS_1012_SERVICE_RESTART = 1012
    WS_1013_TRY_AGAIN_LATER = 1013
    WS_1014_BAD_GATEWAY = 1014
    WS_1015_TLS_HANDSHAKE = 1015

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\backend\lib\site-packages\starlette\status.py



================================================================================
Help on module backend.Lib.site-packages.starlette._utils in backend.Lib.site-packages.starlette:

NAME
    backend.Lib.site-packages.starlette._utils

CLASSES
    collections.abc.Awaitable(builtins.object)
        AwaitableOrContextManager(collections.abc.Awaitable, contextlib.AbstractAsyncContextManager, typing.Protocol)
    contextlib.AbstractAsyncContextManager(abc.ABC)
        AwaitableOrContextManager(collections.abc.Awaitable, contextlib.AbstractAsyncContextManager, typing.Protocol)
    typing.Generic(builtins.object)
        AwaitableOrContextManagerWrapper
    typing.Protocol(typing.Generic)
        AwaitableOrContextManager(collections.abc.Awaitable, contextlib.AbstractAsyncContextManager, typing.Protocol)
        SupportsAsyncClose

    class AwaitableOrContextManager(collections.abc.Awaitable, contextlib.AbstractAsyncContextManager, typing.Protocol)
     |  AwaitableOrContextManager(*args, **kwargs)
     |
     |  Method resolution order:
     |      AwaitableOrContextManager
     |      collections.abc.Awaitable
     |      contextlib.AbstractAsyncContextManager
     |      abc.ABC
     |      typing.Protocol
     |      typing.Generic
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__ = _no_init_or_replace_init(self, *args, **kwargs) from typing
     |
     |  ----------------------------------------------------------------------
     |  Class methods defined here:
     |
     |  __subclasshook__ = _proto_hook(other) from typing
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  __abstractmethods__ = frozenset({'__aexit__', '__await__'})
     |
     |  __annotations__ = {}
     |
     |  __orig_bases__ = (typing.Awaitable[+T_co], typing.AsyncContextManager[...
     |
     |  __parameters__ = (+T_co,)
     |
     |  __protocol_attrs__ = {'__aenter__', '__aexit__', '__await__'}
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from collections.abc.Awaitable:
     |
     |  __await__(self)
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from collections.abc.Awaitable:
     |
     |  __class_getitem__ = GenericAlias(...)
     |      Represent a PEP 585 generic type
     |
     |      E.g. for t = list[int], t.__origin__ is list and t.__args__ is (int,).
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from contextlib.AbstractAsyncContextManager:
     |
     |  async __aenter__(self)
     |      Return `self` upon entering the runtime context.
     |
     |  async __aexit__(self, exc_type, exc_value, traceback)
     |      Raise any exception triggered within the runtime context.
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from typing.Protocol:
     |
     |  __init_subclass__(*args, **kwargs)
     |      This method is called when a class is subclassed.
     |
     |      The default implementation does nothing. It may be
     |      overridden to extend subclasses.

    class AwaitableOrContextManagerWrapper(typing.Generic)
     |  AwaitableOrContextManagerWrapper(aw: 'typing.Awaitable[SupportsAsyncCloseType]') -> 'None'
     |
     |  Method resolution order:
     |      AwaitableOrContextManagerWrapper
     |      typing.Generic
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  async __aenter__(self) -> 'SupportsAsyncCloseType'
     |
     |  async __aexit__(self, *args: 'typing.Any') -> 'None | bool'
     |
     |  __await__(self) -> 'typing.Generator[typing.Any, None, SupportsAsyncCloseType]'
     |
     |  __init__(self, aw: 'typing.Awaitable[SupportsAsyncCloseType]') -> 'None'
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  aw
     |
     |  entered
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  __annotations__ = {}
     |
     |  __orig_bases__ = (typing.Generic[~SupportsAsyncCloseType],)
     |
     |  __parameters__ = (~SupportsAsyncCloseType,)
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from typing.Generic:
     |
     |  __class_getitem__(...)
     |      Parameterizes a generic class.
     |
     |      At least, parameterizing a generic class is the *main* thing this
     |      method does. For example, for some generic class `Foo`, this is called
     |      when we do `Foo[int]` - there, with `cls=Foo` and `params=int`.
     |
     |      However, note that this method is also called when defining generic
     |      classes in the first place with `class Foo[T]: ...`.
     |
     |  __init_subclass__(...)
     |      Function to initialize subclasses.

    class SupportsAsyncClose(typing.Protocol)
     |  SupportsAsyncClose(*args, **kwargs)
     |
     |  Method resolution order:
     |      SupportsAsyncClose
     |      typing.Protocol
     |      typing.Generic
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__ = _no_init_or_replace_init(self, *args, **kwargs) from typing
     |
     |  async close(self) -> 'None'
     |
     |  ----------------------------------------------------------------------
     |  Class methods defined here:
     |
     |  __subclasshook__ = _proto_hook(other) from typing
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  __abstractmethods__ = frozenset()
     |
     |  __annotations__ = {}
     |
     |  __parameters__ = ()
     |
     |  __protocol_attrs__ = {'close'}
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from typing.Protocol:
     |
     |  __init_subclass__(*args, **kwargs)
     |      Function to initialize subclasses.
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from typing.Generic:
     |
     |  __class_getitem__(...)
     |      Parameterizes a generic class.
     |
     |      At least, parameterizing a generic class is the *main* thing this
     |      method does. For example, for some generic class `Foo`, this is called
     |      when we do `Foo[int]` - there, with `cls=Foo` and `params=int`.
     |
     |      However, note that this method is also called when defining generic
     |      classes in the first place with `class Foo[T]: ...`.

FUNCTIONS
    collapse_excgroups() -> 'typing.Generator[None, None, None]'

    get_route_path(scope: 'Scope') -> 'str'

    is_async_callable(obj: 'typing.Any') -> 'typing.Any'

DATA
    AwaitableCallable = typing.Callable[..., typing.Awaitable[~T]]
    Scope = typing.MutableMapping[str, typing.Any]
    SupportsAsyncCloseType = ~SupportsAsyncCloseType
    T = ~T
    T_co = +T_co
    TypeGuard = typing.TypeGuard
        Special typing construct for marking user-defined type guard functions.

        ``TypeGuard`` can be used to annotate the return type of a user-defined
        type guard function.  ``TypeGuard`` only accepts a single type argument.
        At runtime, functions marked this way should return a boolean.

        ``TypeGuard`` aims to benefit *type narrowing* -- a technique used by static
        type checkers to determine a more precise type of an expression within a
        program's code flow.  Usually type narrowing is done by analyzing
        conditional code flow and applying the narrowing to a block of code.  The
        conditional expression here is sometimes referred to as a "type guard".

        Sometimes it would be convenient to use a user-defined boolean function
        as a type guard.  Such a function should use ``TypeGuard[...]`` as its
        return type to alert static type checkers to this intention.

        Using  ``-> TypeGuard`` tells the static type checker that for a given
        function:

        1. The return value is a boolean.
        2. If the return value is ``True``, the type of its argument
           is the type inside ``TypeGuard``.

        For example::

             def is_str_list(val: list[object]) -> TypeGuard[list[str]]:
                 '''Determines whether all objects in the list are strings'''
                 return all(isinstance(x, str) for x in val)

             def func1(val: list[object]):
                 if is_str_list(val):
                     # Type of ``val`` is narrowed to ``list[str]``.
                     print(" ".join(val))
                 else:
                     # Type of ``val`` remains as ``list[object]``.
                     print("Not a list of strings!")

        Strict type narrowing is not enforced -- ``TypeB`` need not be a narrower
        form of ``TypeA`` (it can even be a wider form) and this may lead to
        type-unsafe results.  The main reason is to allow for things like
        narrowing ``list[object]`` to ``list[str]`` even though the latter is not
        a subtype of the former, since ``list`` is invariant.  The responsibility of
        writing type-safe type guards is left to the user.

        ``TypeGuard`` also works with type variables.  For more information, see
        PEP 647 (User-Defined Type Guards).

    has_exceptiongroups = True

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\backend\lib\site-packages\starlette\_utils.py



================================================================================
Help on module backend.Lib.site-packages.urllib3.response in backend.Lib.site-packages.urllib3:

NAME
    backend.Lib.site-packages.urllib3.response

CLASSES
    builtins.object
        BytesQueueBuffer
        ContentDecoder
            DeflateDecoder
            GzipDecoder
            MultiDecoder
        GzipDecoderState
    io.IOBase(_io._IOBase)
        BaseHTTPResponse
            HTTPResponse

    class BaseHTTPResponse(io.IOBase)
     |  BaseHTTPResponse(*, headers: 'typing.Mapping[str, str] | typing.Mapping[bytes, bytes] | None' = None, status: 'int', version: 'int', version_string: 'str', reason: 'str | None', decode_content: 'bool', request_url: 'str | None', retries: 'Retry | None' = None) -> 'None'
     |
     |  Method resolution order:
     |      BaseHTTPResponse
     |      io.IOBase
     |      _io._IOBase
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, *, headers: 'typing.Mapping[str, str] | typing.Mapping[bytes, bytes] | None' = None, status: 'int', version: 'int', version_string: 'str', reason: 'str | None', decode_content: 'bool', request_url: 'str | None', retries: 'Retry | None' = None) -> 'None'
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  close(self) -> 'None'
     |      Flush and close the IO object.
     |
     |      This method has no effect if the file is already closed.
     |
     |  drain_conn(self) -> 'None'
     |
     |  get_redirect_location(self) -> 'str | None | typing.Literal[False]'
     |      Should we redirect and where to?
     |
     |      :returns: Truthy redirect location string if we got a redirect status
     |          code and valid location. ``None`` if redirect status and no
     |          location. ``False`` if not a redirect status code.
     |
     |  getheader(self, name: 'str', default: 'str | None' = None) -> 'str | None'
     |
     |  getheaders(self) -> 'HTTPHeaderDict'
     |      # Compatibility methods for http.client.HTTPResponse
     |
     |  geturl(self) -> 'str | None'
     |
     |  info(self) -> 'HTTPHeaderDict'
     |      # Compatibility method for http.cookiejar
     |
     |  json(self) -> 'typing.Any'
     |      Deserializes the body of the HTTP response as a Python object.
     |
     |      The body of the HTTP response must be encoded using UTF-8, as per
     |      `RFC 8529 Section 8.1 <https://www.rfc-editor.org/rfc/rfc8259#section-8.1>`_.
     |
     |      To use a custom JSON decoder pass the result of :attr:`HTTPResponse.data` to
     |      your custom decoder instead.
     |
     |      If the body of the HTTP response is not decodable to UTF-8, a
     |      `UnicodeDecodeError` will be raised. If the body of the HTTP response is not a
     |      valid JSON document, a `json.JSONDecodeError` will be raised.
     |
     |      Read more :ref:`here <json_content>`.
     |
     |      :returns: The body of the HTTP response as a Python object.
     |
     |  read(self, amt: 'int | None' = None, decode_content: 'bool | None' = None, cache_content: 'bool' = False) -> 'bytes'
     |
     |  read1(self, amt: 'int | None' = None, decode_content: 'bool | None' = None) -> 'bytes'
     |
     |  read_chunked(self, amt: 'int | None' = None, decode_content: 'bool | None' = None) -> 'typing.Iterator[bytes]'
     |
     |  readinto(self, b: 'bytearray') -> 'int'
     |      # Compatibility methods for `io` module
     |
     |  release_conn(self) -> 'None'
     |
     |  stream(self, amt: 'int | None' = 65536, decode_content: 'bool | None' = None) -> 'typing.Iterator[bytes]'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties defined here:
     |
     |  connection
     |
     |  data
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  retries
     |
     |  url
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  CONTENT_DECODERS = ['gzip', 'x-gzip', 'deflate']
     |
     |  DECODER_ERROR_CLASSES = (<class 'OSError'>, <class 'zlib.error'>)
     |
     |  REDIRECT_STATUSES = [301, 302, 303, 307, 308]
     |
     |  __abstractmethods__ = frozenset()
     |
     |  __annotations__ = {'DECODER_ERROR_CLASSES': 'tuple[type[Exception], .....
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from _io._IOBase:
     |
     |  __del__(...)
     |
     |  __enter__(...)
     |
     |  __exit__(...)
     |
     |  __iter__(self, /)
     |      Implement iter(self).
     |
     |  __next__(self, /)
     |      Implement next(self).
     |
     |  fileno(self, /)
     |      Return underlying file descriptor if one exists.
     |
     |      Raise OSError if the IO object does not use a file descriptor.
     |
     |  flush(self, /)
     |      Flush write buffers, if applicable.
     |
     |      This is not implemented for read-only and non-blocking streams.
     |
     |  isatty(self, /)
     |      Return whether this is an 'interactive' stream.
     |
     |      Return False if it can't be determined.
     |
     |  readable(self, /)
     |      Return whether object was opened for reading.
     |
     |      If False, read() will raise OSError.
     |
     |  readline(self, size=-1, /)
     |      Read and return a line from the stream.
     |
     |      If size is specified, at most size bytes will be read.
     |
     |      The line terminator is always b'\n' for binary files; for text
     |      files, the newlines argument to open can be used to select the line
     |      terminator(s) recognized.
     |
     |  readlines(self, hint=-1, /)
     |      Return a list of lines from the stream.
     |
     |      hint can be specified to control the number of lines read: no more
     |      lines will be read if the total size (in bytes/characters) of all
     |      lines so far exceeds hint.
     |
     |  seek(self, offset, whence=0, /)
     |      Change the stream position to the given byte offset.
     |
     |        offset
     |          The stream position, relative to 'whence'.
     |        whence
     |          The relative position to seek from.
     |
     |      The offset is interpreted relative to the position indicated by whence.
     |      Values for whence are:
     |
     |      * os.SEEK_SET or 0 -- start of stream (the default); offset should be zero or positive
     |      * os.SEEK_CUR or 1 -- current stream position; offset may be negative
     |      * os.SEEK_END or 2 -- end of stream; offset is usually negative
     |
     |      Return the new absolute position.
     |
     |  seekable(self, /)
     |      Return whether object supports random access.
     |
     |      If False, seek(), tell() and truncate() will raise OSError.
     |      This method may need to do a test seek().
     |
     |  tell(self, /)
     |      Return current stream position.
     |
     |  truncate(self, size=None, /)
     |      Truncate file to size bytes.
     |
     |      File pointer is left unchanged. Size defaults to the current IO position
     |      as reported by tell(). Return the new size.
     |
     |  writable(self, /)
     |      Return whether object was opened for writing.
     |
     |      If False, write() will raise OSError.
     |
     |  writelines(self, lines, /)
     |      Write a list of lines to stream.
     |
     |      Line separators are not added, so it is usual for each of the
     |      lines provided to have a line separator at the end.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from _io._IOBase:
     |
     |  __dict__
     |
     |  closed

    class BytesQueueBuffer(builtins.object)
     |  BytesQueueBuffer() -> 'None'
     |
     |  Memory-efficient bytes buffer
     |
     |  To return decoded data in read() and still follow the BufferedIOBase API, we need a
     |  buffer to always return the correct amount of bytes.
     |
     |  This buffer should be filled using calls to put()
     |
     |  Our maximum memory usage is determined by the sum of the size of:
     |
     |   * self.buffer, which contains the full data
     |   * the largest chunk that we will copy in get()
     |
     |  The worst case scenario is a single chunk, in which case we'll make a full copy of
     |  the data inside get().
     |
     |  Methods defined here:
     |
     |  __init__(self) -> 'None'
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  __len__(self) -> 'int'
     |
     |  get(self, n: 'int') -> 'bytes'
     |
     |  get_all(self) -> 'bytes'
     |
     |  put(self, data: 'bytes') -> 'None'
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

    class ContentDecoder(builtins.object)
     |  Methods defined here:
     |
     |  decompress(self, data: 'bytes') -> 'bytes'
     |
     |  flush(self) -> 'bytes'
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

    class DeflateDecoder(ContentDecoder)
     |  DeflateDecoder() -> 'None'
     |
     |  Method resolution order:
     |      DeflateDecoder
     |      ContentDecoder
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self) -> 'None'
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  decompress(self, data: 'bytes') -> 'bytes'
     |
     |  flush(self) -> 'bytes'
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from ContentDecoder:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

    class GzipDecoder(ContentDecoder)
     |  GzipDecoder() -> 'None'
     |
     |  Method resolution order:
     |      GzipDecoder
     |      ContentDecoder
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self) -> 'None'
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  decompress(self, data: 'bytes') -> 'bytes'
     |
     |  flush(self) -> 'bytes'
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from ContentDecoder:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

    class GzipDecoderState(builtins.object)
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  FIRST_MEMBER = 0
     |
     |  OTHER_MEMBERS = 1
     |
     |  SWALLOW_DATA = 2

    class HTTPResponse(BaseHTTPResponse)
     |  HTTPResponse(body: '_TYPE_BODY' = '', headers: 'typing.Mapping[str, str] | typing.Mapping[bytes, bytes] | None' = None, status: 'int' = 0, version: 'int' = 0, version_string: 'str' = 'HTTP/?', reason: 'str | None' = None, preload_content: 'bool' = True, decode_content: 'bool' = True, original_response: '_HttplibHTTPResponse | None' = None, pool: 'HTTPConnectionPool | None' = None, connection: 'HTTPConnection | None' = None, msg: '_HttplibHTTPMessage | None' = None, retries: 'Retry | None' = None, enforce_content_length: 'bool' = True, request_method: 'str | None' = None, request_url: 'str | None' = None, auto_close: 'bool' = True) -> 'None'
     |
     |  HTTP Response container.
     |
     |  Backwards-compatible with :class:`http.client.HTTPResponse` but the response ``body`` is
     |  loaded and decoded on-demand when the ``data`` property is accessed.  This
     |  class is also compatible with the Python standard library's :mod:`io`
     |  module, and can hence be treated as a readable object in the context of that
     |  framework.
     |
     |  Extra parameters for behaviour not present in :class:`http.client.HTTPResponse`:
     |
     |  :param preload_content:
     |      If True, the response's body will be preloaded during construction.
     |
     |  :param decode_content:
     |      If True, will attempt to decode the body based on the
     |      'content-encoding' header.
     |
     |  :param original_response:
     |      When this HTTPResponse wrapper is generated from an :class:`http.client.HTTPResponse`
     |      object, it's convenient to include the original for debug purposes. It's
     |      otherwise unused.
     |
     |  :param retries:
     |      The retries contains the last :class:`~urllib3.util.retry.Retry` that
     |      was used during the request.
     |
     |  :param enforce_content_length:
     |      Enforce content length checking. Body returned by server must match
     |      value of Content-Length header, if present. Otherwise, raise error.
     |
     |  Method resolution order:
     |      HTTPResponse
     |      BaseHTTPResponse
     |      io.IOBase
     |      _io._IOBase
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, body: '_TYPE_BODY' = '', headers: 'typing.Mapping[str, str] | typing.Mapping[bytes, bytes] | None' = None, status: 'int' = 0, version: 'int' = 0, version_string: 'str' = 'HTTP/?', reason: 'str | None' = None, preload_content: 'bool' = True, decode_content: 'bool' = True, original_response: '_HttplibHTTPResponse | None' = None, pool: 'HTTPConnectionPool | None' = None, connection: 'HTTPConnection | None' = None, msg: '_HttplibHTTPMessage | None' = None, retries: 'Retry | None' = None, enforce_content_length: 'bool' = True, request_method: 'str | None' = None, request_url: 'str | None' = None, auto_close: 'bool' = True) -> 'None'
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  __iter__(self) -> 'typing.Iterator[bytes]'
     |      Implement iter(self).
     |
     |  close(self) -> 'None'
     |      Flush and close the IO object.
     |
     |      This method has no effect if the file is already closed.
     |
     |  drain_conn(self) -> 'None'
     |      Read and discard any remaining HTTP response data in the response connection.
     |
     |      Unread data in the HTTPResponse connection blocks the connection from being released back to the pool.
     |
     |  fileno(self) -> 'int'
     |      Return underlying file descriptor if one exists.
     |
     |      Raise OSError if the IO object does not use a file descriptor.
     |
     |  flush(self) -> 'None'
     |      Flush write buffers, if applicable.
     |
     |      This is not implemented for read-only and non-blocking streams.
     |
     |  isclosed(self) -> 'bool'
     |
     |  read(self, amt: 'int | None' = None, decode_content: 'bool | None' = None, cache_content: 'bool' = False) -> 'bytes'
     |      Similar to :meth:`http.client.HTTPResponse.read`, but with two additional
     |      parameters: ``decode_content`` and ``cache_content``.
     |
     |      :param amt:
     |          How much of the content to read. If specified, caching is skipped
     |          because it doesn't make sense to cache partial content as the full
     |          response.
     |
     |      :param decode_content:
     |          If True, will attempt to decode the body based on the
     |          'content-encoding' header.
     |
     |      :param cache_content:
     |          If True, will save the returned data such that the same result is
     |          returned despite of the state of the underlying file object. This
     |          is useful if you want the ``.data`` property to continue working
     |          after having ``.read()`` the file object. (Overridden if ``amt`` is
     |          set.)
     |
     |  read1(self, amt: 'int | None' = None, decode_content: 'bool | None' = None) -> 'bytes'
     |      Similar to ``http.client.HTTPResponse.read1`` and documented
     |      in :meth:`io.BufferedReader.read1`, but with an additional parameter:
     |      ``decode_content``.
     |
     |      :param amt:
     |          How much of the content to read.
     |
     |      :param decode_content:
     |          If True, will attempt to decode the body based on the
     |          'content-encoding' header.
     |
     |  read_chunked(self, amt: 'int | None' = None, decode_content: 'bool | None' = None) -> 'typing.Generator[bytes, None, None]'
     |      Similar to :meth:`HTTPResponse.read`, but with an additional
     |      parameter: ``decode_content``.
     |
     |      :param amt:
     |          How much of the content to read. If specified, caching is skipped
     |          because it doesn't make sense to cache partial content as the full
     |          response.
     |
     |      :param decode_content:
     |          If True, will attempt to decode the body based on the
     |          'content-encoding' header.
     |
     |  readable(self) -> 'bool'
     |      Return whether object was opened for reading.
     |
     |      If False, read() will raise OSError.
     |
     |  release_conn(self) -> 'None'
     |
     |  stream(self, amt: 'int | None' = 65536, decode_content: 'bool | None' = None) -> 'typing.Generator[bytes, None, None]'
     |      A generator wrapper for the read() method. A call will block until
     |      ``amt`` bytes have been read from the connection or until the
     |      connection is closed.
     |
     |      :param amt:
     |          How much of the content to read. The generator will return up to
     |          much data per iteration, but may return less. This is particularly
     |          likely when using compressed data. However, the empty string will
     |          never be returned.
     |
     |      :param decode_content:
     |          If True, will attempt to decode the body based on the
     |          'content-encoding' header.
     |
     |  supports_chunked_reads(self) -> 'bool'
     |      Checks if the underlying file-like object looks like a
     |      :class:`http.client.HTTPResponse` object. We do this by testing for
     |      the fp attribute. If it is present we assume it returns raw chunks as
     |      processed by read_chunked().
     |
     |  tell(self) -> 'int'
     |      Obtain the number of bytes pulled over the wire so far. May differ from
     |      the amount of content returned by :meth:``urllib3.response.HTTPResponse.read``
     |      if bytes are encoded on the wire (e.g, compressed).
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties defined here:
     |
     |  closed
     |
     |  connection
     |
     |  data
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  url
     |      Returns the URL that was the source of this response.
     |      If the request that generated this response redirected, this method
     |      will return the final redirect location.
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  __abstractmethods__ = frozenset()
     |
     |  __annotations__ = {}
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from BaseHTTPResponse:
     |
     |  get_redirect_location(self) -> 'str | None | typing.Literal[False]'
     |      Should we redirect and where to?
     |
     |      :returns: Truthy redirect location string if we got a redirect status
     |          code and valid location. ``None`` if redirect status and no
     |          location. ``False`` if not a redirect status code.
     |
     |  getheader(self, name: 'str', default: 'str | None' = None) -> 'str | None'
     |
     |  getheaders(self) -> 'HTTPHeaderDict'
     |      # Compatibility methods for http.client.HTTPResponse
     |
     |  geturl(self) -> 'str | None'
     |
     |  info(self) -> 'HTTPHeaderDict'
     |      # Compatibility method for http.cookiejar
     |
     |  json(self) -> 'typing.Any'
     |      Deserializes the body of the HTTP response as a Python object.
     |
     |      The body of the HTTP response must be encoded using UTF-8, as per
     |      `RFC 8529 Section 8.1 <https://www.rfc-editor.org/rfc/rfc8259#section-8.1>`_.
     |
     |      To use a custom JSON decoder pass the result of :attr:`HTTPResponse.data` to
     |      your custom decoder instead.
     |
     |      If the body of the HTTP response is not decodable to UTF-8, a
     |      `UnicodeDecodeError` will be raised. If the body of the HTTP response is not a
     |      valid JSON document, a `json.JSONDecodeError` will be raised.
     |
     |      Read more :ref:`here <json_content>`.
     |
     |      :returns: The body of the HTTP response as a Python object.
     |
     |  readinto(self, b: 'bytearray') -> 'int'
     |      # Compatibility methods for `io` module
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from BaseHTTPResponse:
     |
     |  retries
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from BaseHTTPResponse:
     |
     |  CONTENT_DECODERS = ['gzip', 'x-gzip', 'deflate']
     |
     |  DECODER_ERROR_CLASSES = (<class 'OSError'>, <class 'zlib.error'>)
     |
     |  REDIRECT_STATUSES = [301, 302, 303, 307, 308]
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from _io._IOBase:
     |
     |  __del__(...)
     |
     |  __enter__(...)
     |
     |  __exit__(...)
     |
     |  __next__(self, /)
     |      Implement next(self).
     |
     |  isatty(self, /)
     |      Return whether this is an 'interactive' stream.
     |
     |      Return False if it can't be determined.
     |
     |  readline(self, size=-1, /)
     |      Read and return a line from the stream.
     |
     |      If size is specified, at most size bytes will be read.
     |
     |      The line terminator is always b'\n' for binary files; for text
     |      files, the newlines argument to open can be used to select the line
     |      terminator(s) recognized.
     |
     |  readlines(self, hint=-1, /)
     |      Return a list of lines from the stream.
     |
     |      hint can be specified to control the number of lines read: no more
     |      lines will be read if the total size (in bytes/characters) of all
     |      lines so far exceeds hint.
     |
     |  seek(self, offset, whence=0, /)
     |      Change the stream position to the given byte offset.
     |
     |        offset
     |          The stream position, relative to 'whence'.
     |        whence
     |          The relative position to seek from.
     |
     |      The offset is interpreted relative to the position indicated by whence.
     |      Values for whence are:
     |
     |      * os.SEEK_SET or 0 -- start of stream (the default); offset should be zero or positive
     |      * os.SEEK_CUR or 1 -- current stream position; offset may be negative
     |      * os.SEEK_END or 2 -- end of stream; offset is usually negative
     |
     |      Return the new absolute position.
     |
     |  seekable(self, /)
     |      Return whether object supports random access.
     |
     |      If False, seek(), tell() and truncate() will raise OSError.
     |      This method may need to do a test seek().
     |
     |  truncate(self, size=None, /)
     |      Truncate file to size bytes.
     |
     |      File pointer is left unchanged. Size defaults to the current IO position
     |      as reported by tell(). Return the new size.
     |
     |  writable(self, /)
     |      Return whether object was opened for writing.
     |
     |      If False, write() will raise OSError.
     |
     |  writelines(self, lines, /)
     |      Write a list of lines to stream.
     |
     |      Line separators are not added, so it is usual for each of the
     |      lines provided to have a line separator at the end.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from _io._IOBase:
     |
     |  __dict__

    class MultiDecoder(ContentDecoder)
     |  MultiDecoder(modes: 'str') -> 'None'
     |
     |  From RFC7231:
     |      If one or more encodings have been applied to a representation, the
     |      sender that applied the encodings MUST generate a Content-Encoding
     |      header field that lists the content codings in the order in which
     |      they were applied.
     |
     |  Method resolution order:
     |      MultiDecoder
     |      ContentDecoder
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, modes: 'str') -> 'None'
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  decompress(self, data: 'bytes') -> 'bytes'
     |
     |  flush(self) -> 'bytes'
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from ContentDecoder:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

DATA
    HAS_ZSTD = False
    brotli = None
    log = <Logger backend.Lib.site-packages.urllib3.response (WARNING)>

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\backend\lib\site-packages\urllib3\response.py



================================================================================
Help on module backend.Lib.site-packages.urllib3.util.response in backend.Lib.site-packages.urllib3.util:

NAME
    backend.Lib.site-packages.urllib3.util.response

FUNCTIONS
    assert_header_parsing(headers: 'httplib.HTTPMessage') -> 'None'
        Asserts whether all headers have been successfully parsed.
        Extracts encountered errors from the result of parsing headers.

        Only works on Python 3.

        :param http.client.HTTPMessage headers: Headers to verify.

        :raises urllib3.exceptions.HeaderParsingError:
            If parsing errors are found.

    is_fp_closed(obj: 'object') -> 'bool'
        Checks whether a given file-like object is closed.

        :param obj:
            The file-like object to check.

    is_response_to_head(response: 'httplib.HTTPResponse') -> 'bool'
        Checks whether the request of a response has been a HEAD-request.

        :param http.client.HTTPResponse response:
            Response to check if the originating request
            used 'HEAD' as a method.

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\backend\lib\site-packages\urllib3\util\response.py



================================================================================
Help on module backend.Lib.site-packages.uvicorn.main in backend.Lib.site-packages.uvicorn:

NAME
    backend.Lib.site-packages.uvicorn.main

FUNCTIONS
    print_version(ctx: 'click.Context', param: 'click.Parameter', value: 'bool') -> 'None'

    run(app: 'ASGIApplication | Callable[..., Any] | str', *, host: 'str' = '127.0.0.1', port: 'int' = 8000, uds: 'str | None' = None, fd: 'int | None' = None, loop: 'LoopSetupType' = 'auto', http: 'type[asyncio.Protocol] | HTTPProtocolType' = 'auto', ws: 'type[asyncio.Protocol] | WSProtocolType' = 'auto', ws_max_size: 'int' = 16777216, ws_max_queue: 'int' = 32, ws_ping_interval: 'float | None' = 20.0, ws_ping_timeout: 'float | None' = 20.0, ws_per_message_deflate: 'bool' = True, lifespan: 'LifespanType' = 'auto', interface: 'InterfaceType' = 'auto', reload: 'bool' = False, reload_dirs: 'list[str] | str | None' = None, reload_includes: 'list[str] | str | None' = None, reload_excludes: 'list[str] | str | None' = None, reload_delay: 'float' = 0.25, workers: 'int | None' = None, env_file: 'str | os.PathLike[str] | None' = None, log_config: 'dict[str, Any] | str | RawConfigParser | IO[Any] | None' = {'version': 1, 'disable_existing_loggers': False, 'formatters': {'default': {'()': 'uvicorn.logging.DefaultFormatter', 'fmt': '%(levelprefix)s %(message)s', 'use_colors': None}, 'access': {'()': 'uvicorn.logging.AccessFormatter', 'fmt': '%(levelprefix)s %(client_addr)s - "%(request_line)s" %(status_code)s'}}, 'handlers': {'default': {'formatter': 'default', 'class': 'logging.StreamHandler', 'stream': 'ext://sys.stderr'}, 'access': {'formatter': 'access', 'class': 'logging.StreamHandler', 'stream': 'ext://sys.stdout'}}, 'loggers': {'uvicorn': {'handlers': ['default'], 'level': 'INFO', 'propagate': False}, 'uvicorn.error': {'level': 'INFO'}, 'uvicorn.access': {'handlers': ['access'], 'level': 'INFO', 'propagate': False}}}, log_level: 'str | int | None' = None, access_log: 'bool' = True, proxy_headers: 'bool' = True, server_header: 'bool' = True, date_header: 'bool' = True, forwarded_allow_ips: 'list[str] | str | None' = None, root_path: 'str' = '', limit_concurrency: 'int | None' = None, backlog: 'int' = 2048, limit_max_requests: 'int | None' = None, timeout_keep_alive: 'int' = 5, timeout_graceful_shutdown: 'int | None' = None, ssl_keyfile: 'str | None' = None, ssl_certfile: 'str | os.PathLike[str] | None' = None, ssl_keyfile_password: 'str | None' = None, ssl_version: 'int' = <_SSLMethod.PROTOCOL_TLS_SERVER: 17>, ssl_cert_reqs: 'int' = <VerifyMode.CERT_NONE: 0>, ssl_ca_certs: 'str | None' = None, ssl_ciphers: 'str' = 'TLSv1', headers: 'list[tuple[str, str]] | None' = None, use_colors: 'bool | None' = None, app_dir: 'str | None' = None, factory: 'bool' = False, h11_max_incomplete_event_size: 'int | None' = None) -> 'None'

DATA
    ASGIApplication = typing.Union[typing.Type[uvicorn._types.ASGI2Pro...a...
    Callable = typing.Callable
        Deprecated alias to collections.abc.Callable.

        Callable[[int], str] signifies a function that takes a single
        parameter of type int and returns a str.

        The subscription syntax must always be used with exactly two
        values: the argument list and the return type.
        The argument list must be a list of types, a ParamSpec,
        Concatenate or ellipsis. The return type must be a single type.

        There is no syntax to indicate optional or keyword arguments;
        such function types are rarely used as callback types.

    HTTPProtocolType = typing.Literal['auto', 'h11', 'httptools']
    HTTP_CHOICES = Choice(['auto', 'h11', 'httptools'])
    HTTP_PROTOCOLS = {'auto': 'uvicorn.protocols.http.auto:AutoHTTPProtoco...
    INTERFACES = ['auto', 'asgi3', 'asgi2', 'wsgi']
    INTERFACE_CHOICES = Choice(['auto', 'asgi3', 'asgi2', 'wsgi'])
    InterfaceType = typing.Literal['auto', 'asgi3', 'asgi2', 'wsgi']
    LEVEL_CHOICES = Choice(['critical', 'error', 'warning', 'info', 'debug...
    LIFESPAN = {'auto': 'uvicorn.lifespan.on:LifespanOn', 'off': 'uvicorn....
    LIFESPAN_CHOICES = Choice(['auto', 'on', 'off'])
    LOGGING_CONFIG = {'disable_existing_loggers': False, 'formatters': {'a...
    LOG_LEVELS = {'critical': 50, 'debug': 10, 'error': 40, 'info': 20, 't...
    LOOP_CHOICES = Choice(['auto', 'asyncio', 'uvloop'])
    LOOP_SETUPS = {'asyncio': 'uvicorn.loops.asyncio:asyncio_setup', 'auto...
    LifespanType = typing.Literal['auto', 'on', 'off']
    LoopSetupType = typing.Literal['none', 'auto', 'asyncio', 'uvloop']
    SSL_PROTOCOL_VERSION = <_SSLMethod.PROTOCOL_TLS_SERVER: 17>
    STARTUP_FAILURE = 3
    WSProtocolType = typing.Literal['auto', 'none', 'websockets', 'wsproto...
    WS_CHOICES = Choice(['auto', 'none', 'websockets', 'wsproto'])
    WS_PROTOCOLS = {'auto': 'uvicorn.protocols.websockets.auto:AutoWebSock...
    logger = <Logger uvicorn.error (WARNING)>
    main = <Command main>

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\backend\lib\site-packages\uvicorn\main.py



================================================================================
Help on module backend.Lib.site-packages.uvicorn.protocols.utils in backend.Lib.site-packages.uvicorn.protocols:

NAME
    backend.Lib.site-packages.uvicorn.protocols.utils

CLASSES
    builtins.OSError(builtins.Exception)
        ClientDisconnected

    class ClientDisconnected(builtins.OSError)
     |  Method resolution order:
     |      ClientDisconnected
     |      builtins.OSError
     |      builtins.Exception
     |      builtins.BaseException
     |      builtins.object
     |
     |  Data descriptors defined here:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.OSError:
     |
     |  __init__(self, /, *args, **kwargs)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  __reduce__(...)
     |      Helper for pickle.
     |
     |  __str__(self, /)
     |      Return str(self).
     |
     |  ----------------------------------------------------------------------
     |  Static methods inherited from builtins.OSError:
     |
     |  __new__(*args, **kwargs) class method of builtins.OSError
     |      Create and return a new object.  See help(type) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from builtins.OSError:
     |
     |  characters_written
     |
     |  errno
     |      POSIX exception code
     |
     |  filename
     |      exception filename
     |
     |  filename2
     |      second exception filename
     |
     |  strerror
     |      exception strerror
     |
     |  winerror
     |      Win32 exception code
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.BaseException:
     |
     |  __delattr__(self, name, /)
     |      Implement delattr(self, name).
     |
     |  __getattribute__(self, name, /)
     |      Return getattr(self, name).
     |
     |  __repr__(self, /)
     |      Return repr(self).
     |
     |  __setattr__(self, name, value, /)
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(...)
     |
     |  add_note(...)
     |      Exception.add_note(note) --
     |      add a note to the exception
     |
     |  with_traceback(...)
     |      Exception.with_traceback(tb) --
     |      set self.__traceback__ to tb and return self.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from builtins.BaseException:
     |
     |  __cause__
     |      exception cause
     |
     |  __context__
     |      exception context
     |
     |  __dict__
     |
     |  __suppress_context__
     |
     |  __traceback__
     |
     |  args

FUNCTIONS
    get_client_addr(scope: 'WWWScope') -> 'str'

    get_local_addr(transport: 'asyncio.Transport') -> 'tuple[str, int] | None'

    get_path_with_query_string(scope: 'WWWScope') -> 'str'

    get_remote_addr(transport: 'asyncio.Transport') -> 'tuple[str, int] | None'

    is_ssl(transport: 'asyncio.Transport') -> 'bool'

DATA
    WWWScope = typing.Union[uvicorn._types.HTTPScope, uvicorn._types.WebSo...

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\backend\lib\site-packages\uvicorn\protocols\utils.py



================================================================================
Help on module backend.Lib.site-packages._pytest.main in backend.Lib.site-packages._pytest:

NAME
    backend.Lib.site-packages._pytest.main - Core implementation of the testing process: init, session, runtest loop.

CLASSES
    _pytest.nodes.Collector(_pytest.nodes.Node, abc.ABC)
        Session
    _pytest.nodes.Directory(_pytest.nodes.FSCollector, abc.ABC)
        Dir
    builtins.Exception(builtins.BaseException)
        Failed
    builtins.UserWarning(builtins.Warning)
        pytest.PytestWarning
    builtins.object
        CollectionArgument
        FSHookProxy

    class CollectionArgument(builtins.object)
     |  CollectionArgument(path: 'Path', parts: 'Sequence[str]', module_name: 'str | None') -> None
     |
     |  A resolved collection argument.
     |
     |  Methods defined here:
     |
     |  __delattr__(self, name)
     |      Implement delattr(self, name).
     |
     |  __eq__(self, other)
     |      Return self==value.
     |
     |  __hash__(self)
     |      Return hash(self).
     |
     |  __init__(self, path: 'Path', parts: 'Sequence[str]', module_name: 'str | None') -> None
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  __repr__(self)
     |      Return repr(self).
     |
     |  __setattr__(self, name, value)
     |      Implement setattr(self, name, value).
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  __annotations__ = {'module_name': 'str | None', 'parts': 'Sequence[str...
     |
     |  __dataclass_fields__ = {'module_name': Field(name='module_name',type='...
     |
     |  __dataclass_params__ = _DataclassParams(init=True,repr=True,eq=True,or...
     |
     |  __match_args__ = ('path', 'parts', 'module_name')

    class Dir(_pytest.nodes.Directory)
     |  Dir(*k, **kw) -> 'NoReturn'
     |
     |  Collector of files in a file system directory.
     |
     |  .. versionadded:: 8.0
     |
     |  .. note::
     |
     |      Python directories with an `__init__.py` file are instead collected by
     |      :class:`~pytest.Package` by default. Both are :class:`~pytest.Directory`
     |      collectors.
     |
     |  Method resolution order:
     |      Dir
     |      _pytest.nodes.Directory
     |      _pytest.nodes.FSCollector
     |      _pytest.nodes.Collector
     |      _pytest.nodes.Node
     |      abc.ABC
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  collect(self) -> 'Iterable[nodes.Item | nodes.Collector]'
     |      Collect children (items and collectors) for this collector.
     |
     |  ----------------------------------------------------------------------
     |  Class methods defined here:
     |
     |  from_parent(parent: 'nodes.Collector', *, path: 'Path') -> 'Self'
     |      The public constructor.
     |
     |      :param parent: The parent collector of this Dir.
     |      :param path: The directory's path.
     |      :type path: pathlib.Path
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  __abstractmethods__ = frozenset()
     |
     |  __annotations__ = {}
     |
     |  __final__ = True
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from _pytest.nodes.FSCollector:
     |
     |  __init__(self, fspath: 'LEGACY_PATH | None' = None, path_or_parent: 'Path | Node | None' = None, path: 'Path | None' = None, name: 'str | None' = None, parent: 'Node | None' = None, config: 'Config | None' = None, session: 'Session | None' = None, nodeid: 'str | None' = None) -> 'None'
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from _pytest.nodes.Collector:
     |
     |  repr_failure(self, excinfo: 'ExceptionInfo[BaseException]') -> 'str | TerminalRepr'
     |      Return a representation of a collection failure.
     |
     |      :param excinfo: Exception information for the failure.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from _pytest.nodes.Collector:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from _pytest.nodes.Collector:
     |
     |  CollectError = <class '_pytest.nodes.Collector.CollectError'>
     |      An error during collection, contains a custom message.
     |
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from _pytest.nodes.Node:
     |
     |  __hash__(self) -> 'int'
     |      Return hash(self).
     |
     |  __repr__(self) -> 'str'
     |      Return repr(self).
     |
     |  add_marker(self, marker: 'str | MarkDecorator', append: 'bool' = True) -> 'None'
     |      Dynamically add a marker object to the node.
     |
     |      :param marker:
     |          The marker.
     |      :param append:
     |          Whether to append the marker, or prepend it.
     |
     |  addfinalizer(self, fin: 'Callable[[], object]') -> 'None'
     |      Register a function to be called without arguments when this node is
     |      finalized.
     |
     |      This method can only be called when this node is active
     |      in a setup chain, for example during self.setup().
     |
     |  get_closest_marker(self, name: 'str', default: 'Mark | None' = None) -> 'Mark | None'
     |      Return the first marker matching the name, from closest (for
     |      example function) to farther level (for example module level).
     |
     |      :param default: Fallback return value if no marker was found.
     |      :param name: Name to filter by.
     |
     |  getparent(self, cls: 'type[_NodeType]') -> '_NodeType | None'
     |      Get the closest parent node (including self) which is an instance of
     |      the given class.
     |
     |      :param cls: The node class to search for.
     |      :returns: The node, if found.
     |
     |  iter_markers(self, name: 'str | None' = None) -> 'Iterator[Mark]'
     |      Iterate over all markers of the node.
     |
     |      :param name: If given, filter the results by the name attribute.
     |      :returns: An iterator of the markers of the node.
     |
     |  iter_markers_with_node(self, name: 'str | None' = None) -> 'Iterator[tuple[Node, Mark]]'
     |      Iterate over all markers of the node.
     |
     |      :param name: If given, filter the results by the name attribute.
     |      :returns: An iterator of (node, mark) tuples.
     |
     |  iter_parents(self) -> 'Iterator[Node]'
     |      Iterate over all parent collectors starting from and including self
     |      up to the root of the collection tree.
     |
     |      .. versionadded:: 8.1
     |
     |  listchain(self) -> 'list[Node]'
     |      Return a list of all parent collectors starting from the root of the
     |      collection tree down to and including self.
     |
     |  listextrakeywords(self) -> 'set[str]'
     |      Return a set of all extra keywords in self and any parents.
     |
     |  listnames(self) -> 'list[str]'
     |
     |  setup(self) -> 'None'
     |
     |  teardown(self) -> 'None'
     |
     |  warn(self, warning: 'Warning') -> 'None'
     |      Issue a warning for this Node.
     |
     |      Warnings will be displayed after the test session, unless explicitly suppressed.
     |
     |      :param Warning warning:
     |          The warning instance to issue.
     |
     |      :raises ValueError: If ``warning`` instance is not a subclass of Warning.
     |
     |      Example usage:
     |
     |      .. code-block:: python
     |
     |          node.warn(PytestWarning("some message"))
     |          node.warn(UserWarning("some message"))
     |
     |      .. versionchanged:: 6.2
     |          Any subclass of :class:`Warning` is now accepted, rather than only
     |          :class:`PytestWarning <pytest.PytestWarning>` subclasses.
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from _pytest.nodes.Node:
     |
     |  ihook
     |      fspath-sensitive hook proxy used to call pytest hooks.
     |
     |  nodeid
     |      A ::-separated string denoting its collection tree address.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from _pytest.nodes.Node:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  config
     |
     |  name
     |
     |  parent
     |
     |  path
     |
     |  session

    class FSHookProxy(builtins.object)
     |  FSHookProxy(pm: 'PytestPluginManager', remove_mods: 'AbstractSet[object]') -> 'None'
     |
     |  Methods defined here:
     |
     |  __getattr__(self, name: 'str') -> 'pluggy.HookCaller'
     |
     |  __init__(self, pm: 'PytestPluginManager', remove_mods: 'AbstractSet[object]') -> 'None'
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object

    class Failed(builtins.Exception)
     |  Signals a stop as failed test run.
     |
     |  Method resolution order:
     |      Failed
     |      builtins.Exception
     |      builtins.BaseException
     |      builtins.object
     |
     |  Data descriptors defined here:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.Exception:
     |
     |  __init__(self, /, *args, **kwargs)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Static methods inherited from builtins.Exception:
     |
     |  __new__(*args, **kwargs) class method of builtins.Exception
     |      Create and return a new object.  See help(type) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.BaseException:
     |
     |  __delattr__(self, name, /)
     |      Implement delattr(self, name).
     |
     |  __getattribute__(self, name, /)
     |      Return getattr(self, name).
     |
     |  __reduce__(...)
     |      Helper for pickle.
     |
     |  __repr__(self, /)
     |      Return repr(self).
     |
     |  __setattr__(self, name, value, /)
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(...)
     |
     |  __str__(self, /)
     |      Return str(self).
     |
     |  add_note(...)
     |      Exception.add_note(note) --
     |      add a note to the exception
     |
     |  with_traceback(...)
     |      Exception.with_traceback(tb) --
     |      set self.__traceback__ to tb and return self.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from builtins.BaseException:
     |
     |  __cause__
     |      exception cause
     |
     |  __context__
     |      exception context
     |
     |  __dict__
     |
     |  __suppress_context__
     |
     |  __traceback__
     |
     |  args

    class PytestWarning(builtins.UserWarning)
     |  Base class for all warnings emitted by pytest.
     |
     |  Method resolution order:
     |      PytestWarning
     |      builtins.UserWarning
     |      builtins.Warning
     |      builtins.Exception
     |      builtins.BaseException
     |      builtins.object
     |
     |  Data descriptors defined here:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.UserWarning:
     |
     |  __init__(self, /, *args, **kwargs)
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Static methods inherited from builtins.UserWarning:
     |
     |  __new__(*args, **kwargs) class method of builtins.UserWarning
     |      Create and return a new object.  See help(type) for accurate signature.
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from builtins.BaseException:
     |
     |  __delattr__(self, name, /)
     |      Implement delattr(self, name).
     |
     |  __getattribute__(self, name, /)
     |      Return getattr(self, name).
     |
     |  __reduce__(...)
     |      Helper for pickle.
     |
     |  __repr__(self, /)
     |      Return repr(self).
     |
     |  __setattr__(self, name, value, /)
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(...)
     |
     |  __str__(self, /)
     |      Return str(self).
     |
     |  add_note(...)
     |      Exception.add_note(note) --
     |      add a note to the exception
     |
     |  with_traceback(...)
     |      Exception.with_traceback(tb) --
     |      set self.__traceback__ to tb and return self.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from builtins.BaseException:
     |
     |  __cause__
     |      exception cause
     |
     |  __context__
     |      exception context
     |
     |  __dict__
     |
     |  __suppress_context__
     |
     |  __traceback__
     |
     |  args

    class Session(_pytest.nodes.Collector)
     |  Session(*k, **kw) -> 'NoReturn'
     |
     |  The root of the collection tree.
     |
     |  ``Session`` collects the initial paths given as arguments to pytest.
     |
     |  Method resolution order:
     |      Session
     |      _pytest.nodes.Collector
     |      _pytest.nodes.Node
     |      abc.ABC
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, config: 'Config') -> 'None'
     |      Initialize self.  See help(type(self)) for accurate signature.
     |
     |  __repr__(self) -> 'str'
     |      Return repr(self).
     |
     |  collect(self) -> 'Iterator[nodes.Item | nodes.Collector]'
     |      Collect children (items and collectors) for this collector.
     |
     |  genitems(self, node: 'nodes.Item | nodes.Collector') -> 'Iterator[nodes.Item]'
     |
     |  gethookproxy(self, fspath: 'os.PathLike[str]') -> 'pluggy.HookRelay'
     |
     |  isinitpath(self, path: 'str | os.PathLike[str]', *, with_parents: 'bool' = False) -> 'bool'
     |      Is path an initial path?
     |
     |      An initial path is a path explicitly given to pytest on the command
     |      line.
     |
     |      :param with_parents:
     |          If set, also return True if the path is a parent of an initial path.
     |
     |      .. versionchanged:: 8.0
     |          Added the ``with_parents`` parameter.
     |
     |  perform_collect(self, args: 'Sequence[str] | None' = None, genitems: 'bool' = True) -> 'Sequence[nodes.Item | nodes.Collector]'
     |      Perform the collection phase for this session.
     |
     |      This is called by the default :hook:`pytest_collection` hook
     |      implementation; see the documentation of this hook for more details.
     |      For testing purposes, it may also be called directly on a fresh
     |      ``Session``.
     |
     |      This function normally recursively expands any collectors collected
     |      from the session to their items, and only items are returned. For
     |      testing purposes, this may be suppressed by passing ``genitems=False``,
     |      in which case the return value contains these collectors unexpanded,
     |      and ``session.items`` is empty.
     |
     |  pytest_collectreport = pytest_runtest_logreport(self, report: 'TestReport | CollectReport') -> 'None'
     |
     |  pytest_collectstart(self) -> 'None'
     |
     |  pytest_runtest_logreport(self, report: 'TestReport | CollectReport') -> 'None'
     |
     |  ----------------------------------------------------------------------
     |  Class methods defined here:
     |
     |  from_config(config: 'Config') -> 'Session'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties defined here:
     |
     |  startpath
     |      The path from which pytest was invoked.
     |
     |      .. versionadded:: 7.0.0
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  shouldfail
     |
     |  shouldstop
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  Failed = <class 'backend.Lib.site-packages._pytest.main.Failed'>
     |      Signals a stop as failed test run.
     |
     |
     |  Interrupted = <class 'Interrupted'>
     |      Signals that the test run was interrupted.
     |
     |
     |  __abstractmethods__ = frozenset()
     |
     |  __annotations__ = {'_fixturemanager': 'FixtureManager', '_setupstate':...
     |
     |  __final__ = True
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from _pytest.nodes.Collector:
     |
     |  repr_failure(self, excinfo: 'ExceptionInfo[BaseException]') -> 'str | TerminalRepr'
     |      Return a representation of a collection failure.
     |
     |      :param excinfo: Exception information for the failure.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from _pytest.nodes.Collector:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from _pytest.nodes.Collector:
     |
     |  CollectError = <class '_pytest.nodes.Collector.CollectError'>
     |      An error during collection, contains a custom message.
     |
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from _pytest.nodes.Node:
     |
     |  __hash__(self) -> 'int'
     |      Return hash(self).
     |
     |  add_marker(self, marker: 'str | MarkDecorator', append: 'bool' = True) -> 'None'
     |      Dynamically add a marker object to the node.
     |
     |      :param marker:
     |          The marker.
     |      :param append:
     |          Whether to append the marker, or prepend it.
     |
     |  addfinalizer(self, fin: 'Callable[[], object]') -> 'None'
     |      Register a function to be called without arguments when this node is
     |      finalized.
     |
     |      This method can only be called when this node is active
     |      in a setup chain, for example during self.setup().
     |
     |  get_closest_marker(self, name: 'str', default: 'Mark | None' = None) -> 'Mark | None'
     |      Return the first marker matching the name, from closest (for
     |      example function) to farther level (for example module level).
     |
     |      :param default: Fallback return value if no marker was found.
     |      :param name: Name to filter by.
     |
     |  getparent(self, cls: 'type[_NodeType]') -> '_NodeType | None'
     |      Get the closest parent node (including self) which is an instance of
     |      the given class.
     |
     |      :param cls: The node class to search for.
     |      :returns: The node, if found.
     |
     |  iter_markers(self, name: 'str | None' = None) -> 'Iterator[Mark]'
     |      Iterate over all markers of the node.
     |
     |      :param name: If given, filter the results by the name attribute.
     |      :returns: An iterator of the markers of the node.
     |
     |  iter_markers_with_node(self, name: 'str | None' = None) -> 'Iterator[tuple[Node, Mark]]'
     |      Iterate over all markers of the node.
     |
     |      :param name: If given, filter the results by the name attribute.
     |      :returns: An iterator of (node, mark) tuples.
     |
     |  iter_parents(self) -> 'Iterator[Node]'
     |      Iterate over all parent collectors starting from and including self
     |      up to the root of the collection tree.
     |
     |      .. versionadded:: 8.1
     |
     |  listchain(self) -> 'list[Node]'
     |      Return a list of all parent collectors starting from the root of the
     |      collection tree down to and including self.
     |
     |  listextrakeywords(self) -> 'set[str]'
     |      Return a set of all extra keywords in self and any parents.
     |
     |  listnames(self) -> 'list[str]'
     |
     |  setup(self) -> 'None'
     |
     |  teardown(self) -> 'None'
     |
     |  warn(self, warning: 'Warning') -> 'None'
     |      Issue a warning for this Node.
     |
     |      Warnings will be displayed after the test session, unless explicitly suppressed.
     |
     |      :param Warning warning:
     |          The warning instance to issue.
     |
     |      :raises ValueError: If ``warning`` instance is not a subclass of Warning.
     |
     |      Example usage:
     |
     |      .. code-block:: python
     |
     |          node.warn(PytestWarning("some message"))
     |          node.warn(UserWarning("some message"))
     |
     |      .. versionchanged:: 6.2
     |          Any subclass of :class:`Warning` is now accepted, rather than only
     |          :class:`PytestWarning <pytest.PytestWarning>` subclasses.
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from _pytest.nodes.Node:
     |
     |  from_parent(parent: 'Node', **kw) -> 'Self'
     |      Public constructor for Nodes.
     |
     |      This indirection got introduced in order to enable removing
     |      the fragile logic from the node constructors.
     |
     |      Subclasses can use ``super().from_parent(...)`` when overriding the
     |      construction.
     |
     |      :param parent: The parent node of this Node.
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from _pytest.nodes.Node:
     |
     |  ihook
     |      fspath-sensitive hook proxy used to call pytest hooks.
     |
     |  nodeid
     |      A ::-separated string denoting its collection tree address.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from _pytest.nodes.Node:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  config
     |
     |  name
     |
     |  parent
     |
     |  path
     |
     |  session

FUNCTIONS
    pytest_addoption(parser: 'Parser') -> 'None'

    pytest_cmdline_main(config: 'Config') -> 'int | ExitCode'

    pytest_collect_directory(path: 'Path', parent: 'nodes.Collector') -> 'nodes.Collector | None'

    pytest_collection(session: 'Session') -> 'None'

    pytest_collection_modifyitems(items: 'list[nodes.Item]', config: 'Config') -> 'None'

    pytest_ignore_collect(collection_path: 'Path', config: 'Config') -> 'bool | None'

    pytest_runtestloop(session: 'Session') -> 'bool'

    resolve_collection_argument(invocation_path: 'Path', arg: 'str', *, as_pypath: 'bool' = False) -> 'CollectionArgument'
        Parse path arguments optionally containing selection parts and return (fspath, names).

        Command-line arguments can point to files and/or directories, and optionally contain
        parts for specific tests selection, for example:

            "pkg/tests/test_foo.py::TestClass::test_foo"

        This function ensures the path exists, and returns a resolved `CollectionArgument`:

            CollectionArgument(
                path=Path("/full/path/to/pkg/tests/test_foo.py"),
                parts=["TestClass", "test_foo"],
                module_name=None,
            )

        When as_pypath is True, expects that the command-line argument actually contains
        module paths instead of file-system paths:

            "pkg.tests.test_foo::TestClass::test_foo"

        In which case we search sys.path for a matching module, and then return the *path* to the
        found module, which may look like this:

            CollectionArgument(
                path=Path("/home/u/myvenv/lib/site-packages/pkg/tests/test_foo.py"),
                parts=["TestClass", "test_foo"],
                module_name="pkg.tests.test_foo",
            )

        If the path doesn't exist, raise UsageError.
        If the path is a directory and selection parts are present, raise UsageError.

    search_pypath(module_name: 'str') -> 'str | None'
        Search sys.path for the given a dotted module name, and return its file
        system path if found.

    validate_basetemp(path: 'str') -> 'str'

    wrap_session(config: 'Config', doit: 'Callable[[Config, Session], int | ExitCode | None]') -> 'int | ExitCode'
        Skeleton command line program.

DATA
    AbstractSet = typing.AbstractSet
        A generic version of collections.abc.Set.

    Callable = typing.Callable
        Deprecated alias to collections.abc.Callable.

        Callable[[int], str] signifies a function that takes a single
        parameter of type int and returns a str.

        The subscription syntax must always be used with exactly two
        values: the argument list and the return type.
        The argument list must be a list of types, a ParamSpec,
        Concatenate or ellipsis. The return type must be a single type.

        There is no syntax to indicate optional or keyword arguments;
        such function types are rarely used as callback types.

    Dict = typing.Dict
        A generic version of dict.

    Iterable = typing.Iterable
        A generic version of collections.abc.Iterable.

    Iterator = typing.Iterator
        A generic version of collections.abc.Iterator.

    Literal = typing.Literal
        Special typing form to define literal types (a.k.a. value types).

        This form can be used to indicate to type checkers that the corresponding
        variable or function parameter has a value equivalent to the provided
        literal (or one of several literals)::

            def validate_simple(data: Any) -> Literal[True]:  # always returns True
                ...

            MODE = Literal['r', 'rb', 'w', 'wb']
            def open_helper(file: str, mode: MODE) -> str:
                ...

            open_helper('/some/path', 'r')  # Passes type check
            open_helper('/other/path', 'typo')  # Error in type checker

        Literal[...] cannot be subclassed. At runtime, an arbitrary value
        is allowed as type argument to Literal[...], but type checkers may
        impose restrictions.

    Sequence = typing.Sequence
        A generic version of collections.abc.Sequence.

    TYPE_CHECKING = False
    hookimpl = <pluggy._hooks.HookimplMarker object>

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\backend\lib\site-packages\_pytest\main.py



================================================================================
INFO:endpoints.auth:Aplicación iniciada
postgresql://coffeetech:Coffeetech.12@localhost:5432/CoffeeTech
Conexión exitosa a la base de datos
Help on module endpoints.auth in endpoints:

NAME
    endpoints.auth

CLASSES
    pydantic.main.BaseModel(builtins.object)
        LoginRequest
        LogoutRequest
        PasswordChange
        PasswordReset
        PasswordResetRequest
        UpdateProfile
        UserCreate
        VerifyTokenRequest

    class LoginRequest(pydantic.main.BaseModel)
     |  LoginRequest(*, email: pydantic.networks.EmailStr, password: str, fcm_token: str) -> None
     |
     |  Method resolution order:
     |      LoginRequest
     |      pydantic.main.BaseModel
     |      builtins.object
     |
     |  Data descriptors defined here:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  __abstractmethods__ = frozenset()
     |
     |  __annotations__ = {'email': <class 'pydantic.networks.EmailStr'>, 'fcm...
     |
     |  __class_vars__ = set()
     |
     |  __private_attributes__ = {}
     |
     |  __pydantic_complete__ = True
     |
     |  __pydantic_core_schema__ = {'cls': <class 'endpoints.auth.LoginRequest...
     |
     |  __pydantic_custom_init__ = False
     |
     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...
     |
     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...
     |
     |  __pydantic_parent_namespace__ = {'APIRouter': <pydantic._internal._mod...
     |
     |  __pydantic_post_init__ = None
     |
     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(
     |      Model...
     |
     |  __pydantic_validator__ = SchemaValidator(title="LoginRequest", validat...
     |
     |  __signature__ = <Signature (*, email: pydantic.networks.EmailStr, pass...
     |
     |  model_computed_fields = {}
     |
     |  model_config = {}
     |
     |  model_fields = {'email': FieldInfo(annotation=EmailStr, required=True)...
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from pydantic.main.BaseModel:
     |
     |  __copy__(self) -> 'Self'
     |      Returns a shallow copy of the model.
     |
     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'
     |      Returns a deep copy of the model.
     |
     |  __delattr__(self, item: 'str') -> 'Any'
     |      Implement delattr(self, name).
     |
     |  __eq__(self, other: 'Any') -> 'bool'
     |      Return self==value.
     |
     |  __getattr__(self, item: 'str') -> 'Any'
     |
     |  __getstate__(self) -> 'dict[Any, Any]'
     |      Helper for pickle.
     |
     |  __init__(self, /, **data: 'Any') -> 'None'
     |      Create a new model by parsing and validating input data from keyword arguments.
     |
     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be
     |      validated to form a valid model.
     |
     |      `self` is explicitly positional-only to allow `self` as a field name.
     |
     |  __iter__(self) -> 'TupleGenerator'
     |      So `dict(model)` works.
     |
     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation
     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.
     |
     |  __repr__(self) -> 'str'
     |      Return repr(self).
     |
     |  __repr_args__(self) -> '_repr.ReprArgs'
     |
     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation
     |      Name of the instance's class, used in __repr__.
     |
     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation
     |
     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation
     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.
     |
     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'
     |
     |  __str__(self) -> 'str'
     |      Return str(self).
     |
     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Returns a copy of the model.
     |
     |      !!! warning "Deprecated"
     |          This method is now deprecated; use `model_copy` instead.
     |
     |      If you need `include` or `exclude`, use:
     |
     |      ```py
     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)
     |      data = {**data, **(update or {})}
     |      copied = self.model_validate(data)
     |      ```
     |
     |      Args:
     |          include: Optional set or mapping specifying which fields to include in the copied model.
     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.
     |          update: Optional dictionary of field-value pairs to override field values in the copied model.
     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.
     |
     |      Returns:
     |          A copy of the model with included, excluded and updated fields as specified.
     |
     |  dict(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'
     |
     |  json(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'
     |
     |  model_copy(self, *, update: 'dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#model_copy
     |
     |      Returns a copy of the model.
     |
     |      Args:
     |          update: Values to change/add in the new model. Note: the data is not validated
     |              before creating the new model. You should trust this data.
     |          deep: Set to `True` to make a deep copy of the model.
     |
     |      Returns:
     |          New model instance.
     |
     |  model_dump(self, *, mode: "Literal['json', 'python'] | str" = 'python', include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump
     |
     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.
     |
     |      Args:
     |          mode: The mode in which `to_python` should run.
     |              If mode is 'json', the output will only contain JSON serializable types.
     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.
     |          include: A set of fields to include in the output.
     |          exclude: A set of fields to exclude from the output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to use the field's alias in the dictionary key if defined.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A dictionary representation of the model.
     |
     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'str'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump_json
     |
     |      Generates a JSON representation of the model using Pydantic's `to_json` method.
     |
     |      Args:
     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.
     |          include: Field(s) to include in the JSON output.
     |          exclude: Field(s) to exclude from the JSON output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to serialize using field aliases.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A JSON string representation of the model.
     |
     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'
     |      Override this method to perform additional initialization after `__init__` and `model_construct`.
     |      This is useful if you want to do some validation that requires the entire model to be initialized.
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from pydantic.main.BaseModel:
     |
     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'
     |
     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'
     |      Hook into generating the model's CoreSchema.
     |
     |      Args:
     |          source: The class we are generating a schema for.
     |              This will generally be the same as the `cls` argument if this is a classmethod.
     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.
     |
     |      Returns:
     |          A `pydantic-core` `CoreSchema`.
     |
     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'
     |      Hook into generating the model's JSON schema.
     |
     |      Args:
     |          core_schema: A `pydantic-core` CoreSchema.
     |              You can ignore this argument and call the handler with a new CoreSchema,
     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),
     |              or just call the handler with the original schema.
     |          handler: Call into Pydantic's internal JSON schema generation.
     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema
     |              generation fails.
     |              Since this gets called by `BaseModel.model_json_schema` you can override the
     |              `schema_generator` argument to that function to change JSON schema generation globally
     |              for a type.
     |
     |      Returns:
     |          A JSON schema, as a Python object.
     |
     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'
     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`
     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will
     |      be present when this is called.
     |
     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,
     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that
     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.
     |
     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,
     |      any kwargs passed to the class definition that aren't used internally by pydantic.
     |
     |      Args:
     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally
     |              by pydantic.
     |
     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |
     |  from_orm(obj: 'Any') -> 'Self'
     |
     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |      Creates a new instance of the `Model` class with validated data.
     |
     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.
     |      Default values are respected, but no other validation is performed.
     |
     |      !!! note
     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.
     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`
     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.
     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in
     |          an error if extra values are passed, but they will be ignored.
     |
     |      Args:
     |          _fields_set: The set of field names accepted for the Model instance.
     |          values: Trusted or pre-validated data dictionary.
     |
     |      Returns:
     |          A new instance of the `Model` class with validated data.
     |
     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'
     |      Generates a JSON schema for a model class.
     |
     |      Args:
     |          by_alias: Whether to use attribute aliases or not.
     |          ref_template: The reference template.
     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of
     |              `GenerateJsonSchema` with your desired modifications
     |          mode: The mode in which to generate the schema.
     |
     |      Returns:
     |          The JSON schema for the given model class.
     |
     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'
     |      Compute the class name for parametrizations of generic classes.
     |
     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.
     |
     |      Args:
     |          params: Tuple of types of the class. Given a generic class
     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,
     |              the value `(str, int)` would be passed to `params`.
     |
     |      Returns:
     |          String representing the new class where `params` are passed to `cls` as type variables.
     |
     |      Raises:
     |          TypeError: Raised when trying to generate concrete names for non-generic models.
     |
     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'dict[str, Any] | None' = None) -> 'bool | None'
     |      Try to rebuild the pydantic-core schema for the model.
     |
     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during
     |      the initial attempt to build the schema, and automatic rebuilding fails.
     |
     |      Args:
     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.
     |          raise_errors: Whether to raise errors, defaults to `True`.
     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.
     |          _types_namespace: The types namespace, defaults to `None`.
     |
     |      Returns:
     |          Returns `None` if the schema is already "complete" and rebuilding was not required.
     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.
     |
     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate a pydantic model instance.
     |
     |      Args:
     |          obj: The object to validate.
     |          strict: Whether to enforce types strictly.
     |          from_attributes: Whether to extract data from object attributes.
     |          context: Additional context to pass to the validator.
     |
     |      Raises:
     |          ValidationError: If the object could not be validated.
     |
     |      Returns:
     |          The validated model instance.
     |
     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/json/#json-parsing
     |
     |      Validate the given JSON data against the Pydantic model.
     |
     |      Args:
     |          json_data: The JSON data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |      Raises:
     |          ValueError: If `json_data` is not a JSON string.
     |
     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate the given object with string data against the Pydantic model.
     |
     |      Args:
     |          obj: The object containing string data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  parse_obj(obj: 'Any') -> 'Self'
     |
     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'
     |
     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'
     |
     |  update_forward_refs(**localns: 'Any') -> 'None'
     |
     |  validate(value: 'Any') -> 'Self'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from pydantic.main.BaseModel:
     |
     |  __fields_set__
     |
     |  model_extra
     |      Get extra fields set during validation.
     |
     |      Returns:
     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `"allow"`.
     |
     |  model_fields_set
     |      Returns the set of fields that have been explicitly set on this model instance.
     |
     |      Returns:
     |          A set of strings representing the fields that have been set,
     |              i.e. that were not filled from defaults.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from pydantic.main.BaseModel:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __pydantic_extra__
     |
     |  __pydantic_fields_set__
     |
     |  __pydantic_private__
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from pydantic.main.BaseModel:
     |
     |  __hash__ = None
     |
     |  __pydantic_root_model__ = False

    class LogoutRequest(pydantic.main.BaseModel)
     |  LogoutRequest(*, session_token: str) -> None
     |
     |  Method resolution order:
     |      LogoutRequest
     |      pydantic.main.BaseModel
     |      builtins.object
     |
     |  Data descriptors defined here:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  __abstractmethods__ = frozenset()
     |
     |  __annotations__ = {'session_token': <class 'str'>}
     |
     |  __class_vars__ = set()
     |
     |  __private_attributes__ = {}
     |
     |  __pydantic_complete__ = True
     |
     |  __pydantic_core_schema__ = {'cls': <class 'endpoints.auth.LogoutReques...
     |
     |  __pydantic_custom_init__ = False
     |
     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...
     |
     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...
     |
     |  __pydantic_parent_namespace__ = {'APIRouter': <pydantic._internal._mod...
     |
     |  __pydantic_post_init__ = None
     |
     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(
     |      Model...
     |
     |  __pydantic_validator__ = SchemaValidator(title="LogoutRequest", valida...
     |
     |  __signature__ = <Signature (*, session_token: str) -> None>
     |
     |  model_computed_fields = {}
     |
     |  model_config = {}
     |
     |  model_fields = {'session_token': FieldInfo(annotation=str, required=Tr...
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from pydantic.main.BaseModel:
     |
     |  __copy__(self) -> 'Self'
     |      Returns a shallow copy of the model.
     |
     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'
     |      Returns a deep copy of the model.
     |
     |  __delattr__(self, item: 'str') -> 'Any'
     |      Implement delattr(self, name).
     |
     |  __eq__(self, other: 'Any') -> 'bool'
     |      Return self==value.
     |
     |  __getattr__(self, item: 'str') -> 'Any'
     |
     |  __getstate__(self) -> 'dict[Any, Any]'
     |      Helper for pickle.
     |
     |  __init__(self, /, **data: 'Any') -> 'None'
     |      Create a new model by parsing and validating input data from keyword arguments.
     |
     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be
     |      validated to form a valid model.
     |
     |      `self` is explicitly positional-only to allow `self` as a field name.
     |
     |  __iter__(self) -> 'TupleGenerator'
     |      So `dict(model)` works.
     |
     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation
     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.
     |
     |  __repr__(self) -> 'str'
     |      Return repr(self).
     |
     |  __repr_args__(self) -> '_repr.ReprArgs'
     |
     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation
     |      Name of the instance's class, used in __repr__.
     |
     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation
     |
     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation
     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.
     |
     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'
     |
     |  __str__(self) -> 'str'
     |      Return str(self).
     |
     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Returns a copy of the model.
     |
     |      !!! warning "Deprecated"
     |          This method is now deprecated; use `model_copy` instead.
     |
     |      If you need `include` or `exclude`, use:
     |
     |      ```py
     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)
     |      data = {**data, **(update or {})}
     |      copied = self.model_validate(data)
     |      ```
     |
     |      Args:
     |          include: Optional set or mapping specifying which fields to include in the copied model.
     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.
     |          update: Optional dictionary of field-value pairs to override field values in the copied model.
     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.
     |
     |      Returns:
     |          A copy of the model with included, excluded and updated fields as specified.
     |
     |  dict(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'
     |
     |  json(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'
     |
     |  model_copy(self, *, update: 'dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#model_copy
     |
     |      Returns a copy of the model.
     |
     |      Args:
     |          update: Values to change/add in the new model. Note: the data is not validated
     |              before creating the new model. You should trust this data.
     |          deep: Set to `True` to make a deep copy of the model.
     |
     |      Returns:
     |          New model instance.
     |
     |  model_dump(self, *, mode: "Literal['json', 'python'] | str" = 'python', include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump
     |
     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.
     |
     |      Args:
     |          mode: The mode in which `to_python` should run.
     |              If mode is 'json', the output will only contain JSON serializable types.
     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.
     |          include: A set of fields to include in the output.
     |          exclude: A set of fields to exclude from the output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to use the field's alias in the dictionary key if defined.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A dictionary representation of the model.
     |
     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'str'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump_json
     |
     |      Generates a JSON representation of the model using Pydantic's `to_json` method.
     |
     |      Args:
     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.
     |          include: Field(s) to include in the JSON output.
     |          exclude: Field(s) to exclude from the JSON output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to serialize using field aliases.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A JSON string representation of the model.
     |
     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'
     |      Override this method to perform additional initialization after `__init__` and `model_construct`.
     |      This is useful if you want to do some validation that requires the entire model to be initialized.
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from pydantic.main.BaseModel:
     |
     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'
     |
     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'
     |      Hook into generating the model's CoreSchema.
     |
     |      Args:
     |          source: The class we are generating a schema for.
     |              This will generally be the same as the `cls` argument if this is a classmethod.
     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.
     |
     |      Returns:
     |          A `pydantic-core` `CoreSchema`.
     |
     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'
     |      Hook into generating the model's JSON schema.
     |
     |      Args:
     |          core_schema: A `pydantic-core` CoreSchema.
     |              You can ignore this argument and call the handler with a new CoreSchema,
     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),
     |              or just call the handler with the original schema.
     |          handler: Call into Pydantic's internal JSON schema generation.
     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema
     |              generation fails.
     |              Since this gets called by `BaseModel.model_json_schema` you can override the
     |              `schema_generator` argument to that function to change JSON schema generation globally
     |              for a type.
     |
     |      Returns:
     |          A JSON schema, as a Python object.
     |
     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'
     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`
     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will
     |      be present when this is called.
     |
     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,
     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that
     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.
     |
     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,
     |      any kwargs passed to the class definition that aren't used internally by pydantic.
     |
     |      Args:
     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally
     |              by pydantic.
     |
     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |
     |  from_orm(obj: 'Any') -> 'Self'
     |
     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |      Creates a new instance of the `Model` class with validated data.
     |
     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.
     |      Default values are respected, but no other validation is performed.
     |
     |      !!! note
     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.
     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`
     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.
     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in
     |          an error if extra values are passed, but they will be ignored.
     |
     |      Args:
     |          _fields_set: The set of field names accepted for the Model instance.
     |          values: Trusted or pre-validated data dictionary.
     |
     |      Returns:
     |          A new instance of the `Model` class with validated data.
     |
     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'
     |      Generates a JSON schema for a model class.
     |
     |      Args:
     |          by_alias: Whether to use attribute aliases or not.
     |          ref_template: The reference template.
     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of
     |              `GenerateJsonSchema` with your desired modifications
     |          mode: The mode in which to generate the schema.
     |
     |      Returns:
     |          The JSON schema for the given model class.
     |
     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'
     |      Compute the class name for parametrizations of generic classes.
     |
     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.
     |
     |      Args:
     |          params: Tuple of types of the class. Given a generic class
     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,
     |              the value `(str, int)` would be passed to `params`.
     |
     |      Returns:
     |          String representing the new class where `params` are passed to `cls` as type variables.
     |
     |      Raises:
     |          TypeError: Raised when trying to generate concrete names for non-generic models.
     |
     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'dict[str, Any] | None' = None) -> 'bool | None'
     |      Try to rebuild the pydantic-core schema for the model.
     |
     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during
     |      the initial attempt to build the schema, and automatic rebuilding fails.
     |
     |      Args:
     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.
     |          raise_errors: Whether to raise errors, defaults to `True`.
     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.
     |          _types_namespace: The types namespace, defaults to `None`.
     |
     |      Returns:
     |          Returns `None` if the schema is already "complete" and rebuilding was not required.
     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.
     |
     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate a pydantic model instance.
     |
     |      Args:
     |          obj: The object to validate.
     |          strict: Whether to enforce types strictly.
     |          from_attributes: Whether to extract data from object attributes.
     |          context: Additional context to pass to the validator.
     |
     |      Raises:
     |          ValidationError: If the object could not be validated.
     |
     |      Returns:
     |          The validated model instance.
     |
     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/json/#json-parsing
     |
     |      Validate the given JSON data against the Pydantic model.
     |
     |      Args:
     |          json_data: The JSON data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |      Raises:
     |          ValueError: If `json_data` is not a JSON string.
     |
     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate the given object with string data against the Pydantic model.
     |
     |      Args:
     |          obj: The object containing string data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  parse_obj(obj: 'Any') -> 'Self'
     |
     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'
     |
     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'
     |
     |  update_forward_refs(**localns: 'Any') -> 'None'
     |
     |  validate(value: 'Any') -> 'Self'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from pydantic.main.BaseModel:
     |
     |  __fields_set__
     |
     |  model_extra
     |      Get extra fields set during validation.
     |
     |      Returns:
     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `"allow"`.
     |
     |  model_fields_set
     |      Returns the set of fields that have been explicitly set on this model instance.
     |
     |      Returns:
     |          A set of strings representing the fields that have been set,
     |              i.e. that were not filled from defaults.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from pydantic.main.BaseModel:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __pydantic_extra__
     |
     |  __pydantic_fields_set__
     |
     |  __pydantic_private__
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from pydantic.main.BaseModel:
     |
     |  __hash__ = None
     |
     |  __pydantic_root_model__ = False

    class PasswordChange(pydantic.main.BaseModel)
     |  PasswordChange(*, current_password: str, new_password: str) -> None
     |
     |  Method resolution order:
     |      PasswordChange
     |      pydantic.main.BaseModel
     |      builtins.object
     |
     |  Data descriptors defined here:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  __abstractmethods__ = frozenset()
     |
     |  __annotations__ = {'current_password': <class 'str'>, 'new_password': ...
     |
     |  __class_vars__ = set()
     |
     |  __private_attributes__ = {}
     |
     |  __pydantic_complete__ = True
     |
     |  __pydantic_core_schema__ = {'cls': <class 'endpoints.auth.PasswordChan...
     |
     |  __pydantic_custom_init__ = False
     |
     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...
     |
     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...
     |
     |  __pydantic_parent_namespace__ = {'APIRouter': <pydantic._internal._mod...
     |
     |  __pydantic_post_init__ = None
     |
     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(
     |      Model...
     |
     |  __pydantic_validator__ = SchemaValidator(title="PasswordChange", valid...
     |
     |  __signature__ = <Signature (*, current_password: str, new_password: st...
     |
     |  model_computed_fields = {}
     |
     |  model_config = {}
     |
     |  model_fields = {'current_password': FieldInfo(annotation=str, required...
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from pydantic.main.BaseModel:
     |
     |  __copy__(self) -> 'Self'
     |      Returns a shallow copy of the model.
     |
     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'
     |      Returns a deep copy of the model.
     |
     |  __delattr__(self, item: 'str') -> 'Any'
     |      Implement delattr(self, name).
     |
     |  __eq__(self, other: 'Any') -> 'bool'
     |      Return self==value.
     |
     |  __getattr__(self, item: 'str') -> 'Any'
     |
     |  __getstate__(self) -> 'dict[Any, Any]'
     |      Helper for pickle.
     |
     |  __init__(self, /, **data: 'Any') -> 'None'
     |      Create a new model by parsing and validating input data from keyword arguments.
     |
     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be
     |      validated to form a valid model.
     |
     |      `self` is explicitly positional-only to allow `self` as a field name.
     |
     |  __iter__(self) -> 'TupleGenerator'
     |      So `dict(model)` works.
     |
     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation
     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.
     |
     |  __repr__(self) -> 'str'
     |      Return repr(self).
     |
     |  __repr_args__(self) -> '_repr.ReprArgs'
     |
     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation
     |      Name of the instance's class, used in __repr__.
     |
     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation
     |
     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation
     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.
     |
     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'
     |
     |  __str__(self) -> 'str'
     |      Return str(self).
     |
     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Returns a copy of the model.
     |
     |      !!! warning "Deprecated"
     |          This method is now deprecated; use `model_copy` instead.
     |
     |      If you need `include` or `exclude`, use:
     |
     |      ```py
     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)
     |      data = {**data, **(update or {})}
     |      copied = self.model_validate(data)
     |      ```
     |
     |      Args:
     |          include: Optional set or mapping specifying which fields to include in the copied model.
     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.
     |          update: Optional dictionary of field-value pairs to override field values in the copied model.
     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.
     |
     |      Returns:
     |          A copy of the model with included, excluded and updated fields as specified.
     |
     |  dict(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'
     |
     |  json(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'
     |
     |  model_copy(self, *, update: 'dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#model_copy
     |
     |      Returns a copy of the model.
     |
     |      Args:
     |          update: Values to change/add in the new model. Note: the data is not validated
     |              before creating the new model. You should trust this data.
     |          deep: Set to `True` to make a deep copy of the model.
     |
     |      Returns:
     |          New model instance.
     |
     |  model_dump(self, *, mode: "Literal['json', 'python'] | str" = 'python', include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump
     |
     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.
     |
     |      Args:
     |          mode: The mode in which `to_python` should run.
     |              If mode is 'json', the output will only contain JSON serializable types.
     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.
     |          include: A set of fields to include in the output.
     |          exclude: A set of fields to exclude from the output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to use the field's alias in the dictionary key if defined.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A dictionary representation of the model.
     |
     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'str'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump_json
     |
     |      Generates a JSON representation of the model using Pydantic's `to_json` method.
     |
     |      Args:
     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.
     |          include: Field(s) to include in the JSON output.
     |          exclude: Field(s) to exclude from the JSON output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to serialize using field aliases.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A JSON string representation of the model.
     |
     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'
     |      Override this method to perform additional initialization after `__init__` and `model_construct`.
     |      This is useful if you want to do some validation that requires the entire model to be initialized.
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from pydantic.main.BaseModel:
     |
     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'
     |
     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'
     |      Hook into generating the model's CoreSchema.
     |
     |      Args:
     |          source: The class we are generating a schema for.
     |              This will generally be the same as the `cls` argument if this is a classmethod.
     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.
     |
     |      Returns:
     |          A `pydantic-core` `CoreSchema`.
     |
     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'
     |      Hook into generating the model's JSON schema.
     |
     |      Args:
     |          core_schema: A `pydantic-core` CoreSchema.
     |              You can ignore this argument and call the handler with a new CoreSchema,
     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),
     |              or just call the handler with the original schema.
     |          handler: Call into Pydantic's internal JSON schema generation.
     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema
     |              generation fails.
     |              Since this gets called by `BaseModel.model_json_schema` you can override the
     |              `schema_generator` argument to that function to change JSON schema generation globally
     |              for a type.
     |
     |      Returns:
     |          A JSON schema, as a Python object.
     |
     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'
     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`
     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will
     |      be present when this is called.
     |
     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,
     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that
     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.
     |
     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,
     |      any kwargs passed to the class definition that aren't used internally by pydantic.
     |
     |      Args:
     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally
     |              by pydantic.
     |
     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |
     |  from_orm(obj: 'Any') -> 'Self'
     |
     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |      Creates a new instance of the `Model` class with validated data.
     |
     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.
     |      Default values are respected, but no other validation is performed.
     |
     |      !!! note
     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.
     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`
     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.
     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in
     |          an error if extra values are passed, but they will be ignored.
     |
     |      Args:
     |          _fields_set: The set of field names accepted for the Model instance.
     |          values: Trusted or pre-validated data dictionary.
     |
     |      Returns:
     |          A new instance of the `Model` class with validated data.
     |
     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'
     |      Generates a JSON schema for a model class.
     |
     |      Args:
     |          by_alias: Whether to use attribute aliases or not.
     |          ref_template: The reference template.
     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of
     |              `GenerateJsonSchema` with your desired modifications
     |          mode: The mode in which to generate the schema.
     |
     |      Returns:
     |          The JSON schema for the given model class.
     |
     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'
     |      Compute the class name for parametrizations of generic classes.
     |
     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.
     |
     |      Args:
     |          params: Tuple of types of the class. Given a generic class
     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,
     |              the value `(str, int)` would be passed to `params`.
     |
     |      Returns:
     |          String representing the new class where `params` are passed to `cls` as type variables.
     |
     |      Raises:
     |          TypeError: Raised when trying to generate concrete names for non-generic models.
     |
     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'dict[str, Any] | None' = None) -> 'bool | None'
     |      Try to rebuild the pydantic-core schema for the model.
     |
     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during
     |      the initial attempt to build the schema, and automatic rebuilding fails.
     |
     |      Args:
     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.
     |          raise_errors: Whether to raise errors, defaults to `True`.
     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.
     |          _types_namespace: The types namespace, defaults to `None`.
     |
     |      Returns:
     |          Returns `None` if the schema is already "complete" and rebuilding was not required.
     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.
     |
     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate a pydantic model instance.
     |
     |      Args:
     |          obj: The object to validate.
     |          strict: Whether to enforce types strictly.
     |          from_attributes: Whether to extract data from object attributes.
     |          context: Additional context to pass to the validator.
     |
     |      Raises:
     |          ValidationError: If the object could not be validated.
     |
     |      Returns:
     |          The validated model instance.
     |
     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/json/#json-parsing
     |
     |      Validate the given JSON data against the Pydantic model.
     |
     |      Args:
     |          json_data: The JSON data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |      Raises:
     |          ValueError: If `json_data` is not a JSON string.
     |
     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate the given object with string data against the Pydantic model.
     |
     |      Args:
     |          obj: The object containing string data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  parse_obj(obj: 'Any') -> 'Self'
     |
     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'
     |
     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'
     |
     |  update_forward_refs(**localns: 'Any') -> 'None'
     |
     |  validate(value: 'Any') -> 'Self'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from pydantic.main.BaseModel:
     |
     |  __fields_set__
     |
     |  model_extra
     |      Get extra fields set during validation.
     |
     |      Returns:
     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `"allow"`.
     |
     |  model_fields_set
     |      Returns the set of fields that have been explicitly set on this model instance.
     |
     |      Returns:
     |          A set of strings representing the fields that have been set,
     |              i.e. that were not filled from defaults.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from pydantic.main.BaseModel:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __pydantic_extra__
     |
     |  __pydantic_fields_set__
     |
     |  __pydantic_private__
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from pydantic.main.BaseModel:
     |
     |  __hash__ = None
     |
     |  __pydantic_root_model__ = False

    class PasswordReset(pydantic.main.BaseModel)
     |  PasswordReset(*, token: str, new_password: str, confirm_password: str) -> None
     |
     |  Method resolution order:
     |      PasswordReset
     |      pydantic.main.BaseModel
     |      builtins.object
     |
     |  Data descriptors defined here:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  __abstractmethods__ = frozenset()
     |
     |  __annotations__ = {'confirm_password': <class 'str'>, 'new_password': ...
     |
     |  __class_vars__ = set()
     |
     |  __private_attributes__ = {}
     |
     |  __pydantic_complete__ = True
     |
     |  __pydantic_core_schema__ = {'cls': <class 'endpoints.auth.PasswordRese...
     |
     |  __pydantic_custom_init__ = False
     |
     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...
     |
     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...
     |
     |  __pydantic_parent_namespace__ = {'APIRouter': <pydantic._internal._mod...
     |
     |  __pydantic_post_init__ = None
     |
     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(
     |      Model...
     |
     |  __pydantic_validator__ = SchemaValidator(title="PasswordReset", valida...
     |
     |  __signature__ = <Signature (*, token: str, new_password: str, confirm_...
     |
     |  model_computed_fields = {}
     |
     |  model_config = {}
     |
     |  model_fields = {'confirm_password': FieldInfo(annotation=str, required...
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from pydantic.main.BaseModel:
     |
     |  __copy__(self) -> 'Self'
     |      Returns a shallow copy of the model.
     |
     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'
     |      Returns a deep copy of the model.
     |
     |  __delattr__(self, item: 'str') -> 'Any'
     |      Implement delattr(self, name).
     |
     |  __eq__(self, other: 'Any') -> 'bool'
     |      Return self==value.
     |
     |  __getattr__(self, item: 'str') -> 'Any'
     |
     |  __getstate__(self) -> 'dict[Any, Any]'
     |      Helper for pickle.
     |
     |  __init__(self, /, **data: 'Any') -> 'None'
     |      Create a new model by parsing and validating input data from keyword arguments.
     |
     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be
     |      validated to form a valid model.
     |
     |      `self` is explicitly positional-only to allow `self` as a field name.
     |
     |  __iter__(self) -> 'TupleGenerator'
     |      So `dict(model)` works.
     |
     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation
     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.
     |
     |  __repr__(self) -> 'str'
     |      Return repr(self).
     |
     |  __repr_args__(self) -> '_repr.ReprArgs'
     |
     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation
     |      Name of the instance's class, used in __repr__.
     |
     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation
     |
     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation
     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.
     |
     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'
     |
     |  __str__(self) -> 'str'
     |      Return str(self).
     |
     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Returns a copy of the model.
     |
     |      !!! warning "Deprecated"
     |          This method is now deprecated; use `model_copy` instead.
     |
     |      If you need `include` or `exclude`, use:
     |
     |      ```py
     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)
     |      data = {**data, **(update or {})}
     |      copied = self.model_validate(data)
     |      ```
     |
     |      Args:
     |          include: Optional set or mapping specifying which fields to include in the copied model.
     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.
     |          update: Optional dictionary of field-value pairs to override field values in the copied model.
     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.
     |
     |      Returns:
     |          A copy of the model with included, excluded and updated fields as specified.
     |
     |  dict(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'
     |
     |  json(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'
     |
     |  model_copy(self, *, update: 'dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#model_copy
     |
     |      Returns a copy of the model.
     |
     |      Args:
     |          update: Values to change/add in the new model. Note: the data is not validated
     |              before creating the new model. You should trust this data.
     |          deep: Set to `True` to make a deep copy of the model.
     |
     |      Returns:
     |          New model instance.
     |
     |  model_dump(self, *, mode: "Literal['json', 'python'] | str" = 'python', include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump
     |
     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.
     |
     |      Args:
     |          mode: The mode in which `to_python` should run.
     |              If mode is 'json', the output will only contain JSON serializable types.
     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.
     |          include: A set of fields to include in the output.
     |          exclude: A set of fields to exclude from the output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to use the field's alias in the dictionary key if defined.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A dictionary representation of the model.
     |
     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'str'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump_json
     |
     |      Generates a JSON representation of the model using Pydantic's `to_json` method.
     |
     |      Args:
     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.
     |          include: Field(s) to include in the JSON output.
     |          exclude: Field(s) to exclude from the JSON output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to serialize using field aliases.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A JSON string representation of the model.
     |
     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'
     |      Override this method to perform additional initialization after `__init__` and `model_construct`.
     |      This is useful if you want to do some validation that requires the entire model to be initialized.
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from pydantic.main.BaseModel:
     |
     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'
     |
     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'
     |      Hook into generating the model's CoreSchema.
     |
     |      Args:
     |          source: The class we are generating a schema for.
     |              This will generally be the same as the `cls` argument if this is a classmethod.
     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.
     |
     |      Returns:
     |          A `pydantic-core` `CoreSchema`.
     |
     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'
     |      Hook into generating the model's JSON schema.
     |
     |      Args:
     |          core_schema: A `pydantic-core` CoreSchema.
     |              You can ignore this argument and call the handler with a new CoreSchema,
     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),
     |              or just call the handler with the original schema.
     |          handler: Call into Pydantic's internal JSON schema generation.
     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema
     |              generation fails.
     |              Since this gets called by `BaseModel.model_json_schema` you can override the
     |              `schema_generator` argument to that function to change JSON schema generation globally
     |              for a type.
     |
     |      Returns:
     |          A JSON schema, as a Python object.
     |
     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'
     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`
     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will
     |      be present when this is called.
     |
     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,
     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that
     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.
     |
     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,
     |      any kwargs passed to the class definition that aren't used internally by pydantic.
     |
     |      Args:
     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally
     |              by pydantic.
     |
     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |
     |  from_orm(obj: 'Any') -> 'Self'
     |
     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |      Creates a new instance of the `Model` class with validated data.
     |
     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.
     |      Default values are respected, but no other validation is performed.
     |
     |      !!! note
     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.
     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`
     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.
     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in
     |          an error if extra values are passed, but they will be ignored.
     |
     |      Args:
     |          _fields_set: The set of field names accepted for the Model instance.
     |          values: Trusted or pre-validated data dictionary.
     |
     |      Returns:
     |          A new instance of the `Model` class with validated data.
     |
     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'
     |      Generates a JSON schema for a model class.
     |
     |      Args:
     |          by_alias: Whether to use attribute aliases or not.
     |          ref_template: The reference template.
     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of
     |              `GenerateJsonSchema` with your desired modifications
     |          mode: The mode in which to generate the schema.
     |
     |      Returns:
     |          The JSON schema for the given model class.
     |
     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'
     |      Compute the class name for parametrizations of generic classes.
     |
     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.
     |
     |      Args:
     |          params: Tuple of types of the class. Given a generic class
     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,
     |              the value `(str, int)` would be passed to `params`.
     |
     |      Returns:
     |          String representing the new class where `params` are passed to `cls` as type variables.
     |
     |      Raises:
     |          TypeError: Raised when trying to generate concrete names for non-generic models.
     |
     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'dict[str, Any] | None' = None) -> 'bool | None'
     |      Try to rebuild the pydantic-core schema for the model.
     |
     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during
     |      the initial attempt to build the schema, and automatic rebuilding fails.
     |
     |      Args:
     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.
     |          raise_errors: Whether to raise errors, defaults to `True`.
     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.
     |          _types_namespace: The types namespace, defaults to `None`.
     |
     |      Returns:
     |          Returns `None` if the schema is already "complete" and rebuilding was not required.
     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.
     |
     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate a pydantic model instance.
     |
     |      Args:
     |          obj: The object to validate.
     |          strict: Whether to enforce types strictly.
     |          from_attributes: Whether to extract data from object attributes.
     |          context: Additional context to pass to the validator.
     |
     |      Raises:
     |          ValidationError: If the object could not be validated.
     |
     |      Returns:
     |          The validated model instance.
     |
     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/json/#json-parsing
     |
     |      Validate the given JSON data against the Pydantic model.
     |
     |      Args:
     |          json_data: The JSON data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |      Raises:
     |          ValueError: If `json_data` is not a JSON string.
     |
     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate the given object with string data against the Pydantic model.
     |
     |      Args:
     |          obj: The object containing string data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  parse_obj(obj: 'Any') -> 'Self'
     |
     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'
     |
     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'
     |
     |  update_forward_refs(**localns: 'Any') -> 'None'
     |
     |  validate(value: 'Any') -> 'Self'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from pydantic.main.BaseModel:
     |
     |  __fields_set__
     |
     |  model_extra
     |      Get extra fields set during validation.
     |
     |      Returns:
     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `"allow"`.
     |
     |  model_fields_set
     |      Returns the set of fields that have been explicitly set on this model instance.
     |
     |      Returns:
     |          A set of strings representing the fields that have been set,
     |              i.e. that were not filled from defaults.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from pydantic.main.BaseModel:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __pydantic_extra__
     |
     |  __pydantic_fields_set__
     |
     |  __pydantic_private__
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from pydantic.main.BaseModel:
     |
     |  __hash__ = None
     |
     |  __pydantic_root_model__ = False

    class PasswordResetRequest(pydantic.main.BaseModel)
     |  PasswordResetRequest(*, email: pydantic.networks.EmailStr) -> None
     |
     |  Method resolution order:
     |      PasswordResetRequest
     |      pydantic.main.BaseModel
     |      builtins.object
     |
     |  Data descriptors defined here:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  __abstractmethods__ = frozenset()
     |
     |  __annotations__ = {'email': <class 'pydantic.networks.EmailStr'>}
     |
     |  __class_vars__ = set()
     |
     |  __private_attributes__ = {}
     |
     |  __pydantic_complete__ = True
     |
     |  __pydantic_core_schema__ = {'cls': <class 'endpoints.auth.PasswordRese...
     |
     |  __pydantic_custom_init__ = False
     |
     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...
     |
     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...
     |
     |  __pydantic_parent_namespace__ = {'APIRouter': <pydantic._internal._mod...
     |
     |  __pydantic_post_init__ = None
     |
     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(
     |      Model...
     |
     |  __pydantic_validator__ = SchemaValidator(title="PasswordResetRequest",...
     |
     |  __signature__ = <Signature (*, email: pydantic.networks.EmailStr) -> N...
     |
     |  model_computed_fields = {}
     |
     |  model_config = {}
     |
     |  model_fields = {'email': FieldInfo(annotation=EmailStr, required=True)...
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from pydantic.main.BaseModel:
     |
     |  __copy__(self) -> 'Self'
     |      Returns a shallow copy of the model.
     |
     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'
     |      Returns a deep copy of the model.
     |
     |  __delattr__(self, item: 'str') -> 'Any'
     |      Implement delattr(self, name).
     |
     |  __eq__(self, other: 'Any') -> 'bool'
     |      Return self==value.
     |
     |  __getattr__(self, item: 'str') -> 'Any'
     |
     |  __getstate__(self) -> 'dict[Any, Any]'
     |      Helper for pickle.
     |
     |  __init__(self, /, **data: 'Any') -> 'None'
     |      Create a new model by parsing and validating input data from keyword arguments.
     |
     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be
     |      validated to form a valid model.
     |
     |      `self` is explicitly positional-only to allow `self` as a field name.
     |
     |  __iter__(self) -> 'TupleGenerator'
     |      So `dict(model)` works.
     |
     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation
     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.
     |
     |  __repr__(self) -> 'str'
     |      Return repr(self).
     |
     |  __repr_args__(self) -> '_repr.ReprArgs'
     |
     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation
     |      Name of the instance's class, used in __repr__.
     |
     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation
     |
     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation
     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.
     |
     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'
     |
     |  __str__(self) -> 'str'
     |      Return str(self).
     |
     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Returns a copy of the model.
     |
     |      !!! warning "Deprecated"
     |          This method is now deprecated; use `model_copy` instead.
     |
     |      If you need `include` or `exclude`, use:
     |
     |      ```py
     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)
     |      data = {**data, **(update or {})}
     |      copied = self.model_validate(data)
     |      ```
     |
     |      Args:
     |          include: Optional set or mapping specifying which fields to include in the copied model.
     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.
     |          update: Optional dictionary of field-value pairs to override field values in the copied model.
     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.
     |
     |      Returns:
     |          A copy of the model with included, excluded and updated fields as specified.
     |
     |  dict(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'
     |
     |  json(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'
     |
     |  model_copy(self, *, update: 'dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#model_copy
     |
     |      Returns a copy of the model.
     |
     |      Args:
     |          update: Values to change/add in the new model. Note: the data is not validated
     |              before creating the new model. You should trust this data.
     |          deep: Set to `True` to make a deep copy of the model.
     |
     |      Returns:
     |          New model instance.
     |
     |  model_dump(self, *, mode: "Literal['json', 'python'] | str" = 'python', include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump
     |
     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.
     |
     |      Args:
     |          mode: The mode in which `to_python` should run.
     |              If mode is 'json', the output will only contain JSON serializable types.
     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.
     |          include: A set of fields to include in the output.
     |          exclude: A set of fields to exclude from the output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to use the field's alias in the dictionary key if defined.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A dictionary representation of the model.
     |
     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'str'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump_json
     |
     |      Generates a JSON representation of the model using Pydantic's `to_json` method.
     |
     |      Args:
     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.
     |          include: Field(s) to include in the JSON output.
     |          exclude: Field(s) to exclude from the JSON output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to serialize using field aliases.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A JSON string representation of the model.
     |
     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'
     |      Override this method to perform additional initialization after `__init__` and `model_construct`.
     |      This is useful if you want to do some validation that requires the entire model to be initialized.
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from pydantic.main.BaseModel:
     |
     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'
     |
     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'
     |      Hook into generating the model's CoreSchema.
     |
     |      Args:
     |          source: The class we are generating a schema for.
     |              This will generally be the same as the `cls` argument if this is a classmethod.
     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.
     |
     |      Returns:
     |          A `pydantic-core` `CoreSchema`.
     |
     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'
     |      Hook into generating the model's JSON schema.
     |
     |      Args:
     |          core_schema: A `pydantic-core` CoreSchema.
     |              You can ignore this argument and call the handler with a new CoreSchema,
     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),
     |              or just call the handler with the original schema.
     |          handler: Call into Pydantic's internal JSON schema generation.
     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema
     |              generation fails.
     |              Since this gets called by `BaseModel.model_json_schema` you can override the
     |              `schema_generator` argument to that function to change JSON schema generation globally
     |              for a type.
     |
     |      Returns:
     |          A JSON schema, as a Python object.
     |
     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'
     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`
     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will
     |      be present when this is called.
     |
     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,
     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that
     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.
     |
     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,
     |      any kwargs passed to the class definition that aren't used internally by pydantic.
     |
     |      Args:
     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally
     |              by pydantic.
     |
     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |
     |  from_orm(obj: 'Any') -> 'Self'
     |
     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |      Creates a new instance of the `Model` class with validated data.
     |
     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.
     |      Default values are respected, but no other validation is performed.
     |
     |      !!! note
     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.
     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`
     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.
     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in
     |          an error if extra values are passed, but they will be ignored.
     |
     |      Args:
     |          _fields_set: The set of field names accepted for the Model instance.
     |          values: Trusted or pre-validated data dictionary.
     |
     |      Returns:
     |          A new instance of the `Model` class with validated data.
     |
     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'
     |      Generates a JSON schema for a model class.
     |
     |      Args:
     |          by_alias: Whether to use attribute aliases or not.
     |          ref_template: The reference template.
     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of
     |              `GenerateJsonSchema` with your desired modifications
     |          mode: The mode in which to generate the schema.
     |
     |      Returns:
     |          The JSON schema for the given model class.
     |
     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'
     |      Compute the class name for parametrizations of generic classes.
     |
     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.
     |
     |      Args:
     |          params: Tuple of types of the class. Given a generic class
     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,
     |              the value `(str, int)` would be passed to `params`.
     |
     |      Returns:
     |          String representing the new class where `params` are passed to `cls` as type variables.
     |
     |      Raises:
     |          TypeError: Raised when trying to generate concrete names for non-generic models.
     |
     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'dict[str, Any] | None' = None) -> 'bool | None'
     |      Try to rebuild the pydantic-core schema for the model.
     |
     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during
     |      the initial attempt to build the schema, and automatic rebuilding fails.
     |
     |      Args:
     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.
     |          raise_errors: Whether to raise errors, defaults to `True`.
     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.
     |          _types_namespace: The types namespace, defaults to `None`.
     |
     |      Returns:
     |          Returns `None` if the schema is already "complete" and rebuilding was not required.
     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.
     |
     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate a pydantic model instance.
     |
     |      Args:
     |          obj: The object to validate.
     |          strict: Whether to enforce types strictly.
     |          from_attributes: Whether to extract data from object attributes.
     |          context: Additional context to pass to the validator.
     |
     |      Raises:
     |          ValidationError: If the object could not be validated.
     |
     |      Returns:
     |          The validated model instance.
     |
     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/json/#json-parsing
     |
     |      Validate the given JSON data against the Pydantic model.
     |
     |      Args:
     |          json_data: The JSON data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |      Raises:
     |          ValueError: If `json_data` is not a JSON string.
     |
     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate the given object with string data against the Pydantic model.
     |
     |      Args:
     |          obj: The object containing string data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  parse_obj(obj: 'Any') -> 'Self'
     |
     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'
     |
     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'
     |
     |  update_forward_refs(**localns: 'Any') -> 'None'
     |
     |  validate(value: 'Any') -> 'Self'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from pydantic.main.BaseModel:
     |
     |  __fields_set__
     |
     |  model_extra
     |      Get extra fields set during validation.
     |
     |      Returns:
     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `"allow"`.
     |
     |  model_fields_set
     |      Returns the set of fields that have been explicitly set on this model instance.
     |
     |      Returns:
     |          A set of strings representing the fields that have been set,
     |              i.e. that were not filled from defaults.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from pydantic.main.BaseModel:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __pydantic_extra__
     |
     |  __pydantic_fields_set__
     |
     |  __pydantic_private__
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from pydantic.main.BaseModel:
     |
     |  __hash__ = None
     |
     |  __pydantic_root_model__ = False

    class UpdateProfile(pydantic.main.BaseModel)
     |  UpdateProfile(*, new_name: str) -> None
     |
     |  Method resolution order:
     |      UpdateProfile
     |      pydantic.main.BaseModel
     |      builtins.object
     |
     |  Data descriptors defined here:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  __abstractmethods__ = frozenset()
     |
     |  __annotations__ = {'new_name': <class 'str'>}
     |
     |  __class_vars__ = set()
     |
     |  __private_attributes__ = {}
     |
     |  __pydantic_complete__ = True
     |
     |  __pydantic_core_schema__ = {'cls': <class 'endpoints.auth.UpdateProfil...
     |
     |  __pydantic_custom_init__ = False
     |
     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...
     |
     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...
     |
     |  __pydantic_parent_namespace__ = {'APIRouter': <pydantic._internal._mod...
     |
     |  __pydantic_post_init__ = None
     |
     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(
     |      Model...
     |
     |  __pydantic_validator__ = SchemaValidator(title="UpdateProfile", valida...
     |
     |  __signature__ = <Signature (*, new_name: str) -> None>
     |
     |  model_computed_fields = {}
     |
     |  model_config = {}
     |
     |  model_fields = {'new_name': FieldInfo(annotation=str, required=True)}
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from pydantic.main.BaseModel:
     |
     |  __copy__(self) -> 'Self'
     |      Returns a shallow copy of the model.
     |
     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'
     |      Returns a deep copy of the model.
     |
     |  __delattr__(self, item: 'str') -> 'Any'
     |      Implement delattr(self, name).
     |
     |  __eq__(self, other: 'Any') -> 'bool'
     |      Return self==value.
     |
     |  __getattr__(self, item: 'str') -> 'Any'
     |
     |  __getstate__(self) -> 'dict[Any, Any]'
     |      Helper for pickle.
     |
     |  __init__(self, /, **data: 'Any') -> 'None'
     |      Create a new model by parsing and validating input data from keyword arguments.
     |
     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be
     |      validated to form a valid model.
     |
     |      `self` is explicitly positional-only to allow `self` as a field name.
     |
     |  __iter__(self) -> 'TupleGenerator'
     |      So `dict(model)` works.
     |
     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation
     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.
     |
     |  __repr__(self) -> 'str'
     |      Return repr(self).
     |
     |  __repr_args__(self) -> '_repr.ReprArgs'
     |
     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation
     |      Name of the instance's class, used in __repr__.
     |
     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation
     |
     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation
     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.
     |
     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'
     |
     |  __str__(self) -> 'str'
     |      Return str(self).
     |
     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Returns a copy of the model.
     |
     |      !!! warning "Deprecated"
     |          This method is now deprecated; use `model_copy` instead.
     |
     |      If you need `include` or `exclude`, use:
     |
     |      ```py
     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)
     |      data = {**data, **(update or {})}
     |      copied = self.model_validate(data)
     |      ```
     |
     |      Args:
     |          include: Optional set or mapping specifying which fields to include in the copied model.
     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.
     |          update: Optional dictionary of field-value pairs to override field values in the copied model.
     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.
     |
     |      Returns:
     |          A copy of the model with included, excluded and updated fields as specified.
     |
     |  dict(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'
     |
     |  json(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'
     |
     |  model_copy(self, *, update: 'dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#model_copy
     |
     |      Returns a copy of the model.
     |
     |      Args:
     |          update: Values to change/add in the new model. Note: the data is not validated
     |              before creating the new model. You should trust this data.
     |          deep: Set to `True` to make a deep copy of the model.
     |
     |      Returns:
     |          New model instance.
     |
     |  model_dump(self, *, mode: "Literal['json', 'python'] | str" = 'python', include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump
     |
     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.
     |
     |      Args:
     |          mode: The mode in which `to_python` should run.
     |              If mode is 'json', the output will only contain JSON serializable types.
     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.
     |          include: A set of fields to include in the output.
     |          exclude: A set of fields to exclude from the output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to use the field's alias in the dictionary key if defined.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A dictionary representation of the model.
     |
     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'str'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump_json
     |
     |      Generates a JSON representation of the model using Pydantic's `to_json` method.
     |
     |      Args:
     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.
     |          include: Field(s) to include in the JSON output.
     |          exclude: Field(s) to exclude from the JSON output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to serialize using field aliases.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A JSON string representation of the model.
     |
     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'
     |      Override this method to perform additional initialization after `__init__` and `model_construct`.
     |      This is useful if you want to do some validation that requires the entire model to be initialized.
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from pydantic.main.BaseModel:
     |
     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'
     |
     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'
     |      Hook into generating the model's CoreSchema.
     |
     |      Args:
     |          source: The class we are generating a schema for.
     |              This will generally be the same as the `cls` argument if this is a classmethod.
     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.
     |
     |      Returns:
     |          A `pydantic-core` `CoreSchema`.
     |
     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'
     |      Hook into generating the model's JSON schema.
     |
     |      Args:
     |          core_schema: A `pydantic-core` CoreSchema.
     |              You can ignore this argument and call the handler with a new CoreSchema,
     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),
     |              or just call the handler with the original schema.
     |          handler: Call into Pydantic's internal JSON schema generation.
     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema
     |              generation fails.
     |              Since this gets called by `BaseModel.model_json_schema` you can override the
     |              `schema_generator` argument to that function to change JSON schema generation globally
     |              for a type.
     |
     |      Returns:
     |          A JSON schema, as a Python object.
     |
     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'
     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`
     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will
     |      be present when this is called.
     |
     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,
     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that
     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.
     |
     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,
     |      any kwargs passed to the class definition that aren't used internally by pydantic.
     |
     |      Args:
     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally
     |              by pydantic.
     |
     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |
     |  from_orm(obj: 'Any') -> 'Self'
     |
     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |      Creates a new instance of the `Model` class with validated data.
     |
     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.
     |      Default values are respected, but no other validation is performed.
     |
     |      !!! note
     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.
     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`
     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.
     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in
     |          an error if extra values are passed, but they will be ignored.
     |
     |      Args:
     |          _fields_set: The set of field names accepted for the Model instance.
     |          values: Trusted or pre-validated data dictionary.
     |
     |      Returns:
     |          A new instance of the `Model` class with validated data.
     |
     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'
     |      Generates a JSON schema for a model class.
     |
     |      Args:
     |          by_alias: Whether to use attribute aliases or not.
     |          ref_template: The reference template.
     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of
     |              `GenerateJsonSchema` with your desired modifications
     |          mode: The mode in which to generate the schema.
     |
     |      Returns:
     |          The JSON schema for the given model class.
     |
     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'
     |      Compute the class name for parametrizations of generic classes.
     |
     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.
     |
     |      Args:
     |          params: Tuple of types of the class. Given a generic class
     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,
     |              the value `(str, int)` would be passed to `params`.
     |
     |      Returns:
     |          String representing the new class where `params` are passed to `cls` as type variables.
     |
     |      Raises:
     |          TypeError: Raised when trying to generate concrete names for non-generic models.
     |
     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'dict[str, Any] | None' = None) -> 'bool | None'
     |      Try to rebuild the pydantic-core schema for the model.
     |
     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during
     |      the initial attempt to build the schema, and automatic rebuilding fails.
     |
     |      Args:
     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.
     |          raise_errors: Whether to raise errors, defaults to `True`.
     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.
     |          _types_namespace: The types namespace, defaults to `None`.
     |
     |      Returns:
     |          Returns `None` if the schema is already "complete" and rebuilding was not required.
     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.
     |
     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate a pydantic model instance.
     |
     |      Args:
     |          obj: The object to validate.
     |          strict: Whether to enforce types strictly.
     |          from_attributes: Whether to extract data from object attributes.
     |          context: Additional context to pass to the validator.
     |
     |      Raises:
     |          ValidationError: If the object could not be validated.
     |
     |      Returns:
     |          The validated model instance.
     |
     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/json/#json-parsing
     |
     |      Validate the given JSON data against the Pydantic model.
     |
     |      Args:
     |          json_data: The JSON data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |      Raises:
     |          ValueError: If `json_data` is not a JSON string.
     |
     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate the given object with string data against the Pydantic model.
     |
     |      Args:
     |          obj: The object containing string data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  parse_obj(obj: 'Any') -> 'Self'
     |
     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'
     |
     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'
     |
     |  update_forward_refs(**localns: 'Any') -> 'None'
     |
     |  validate(value: 'Any') -> 'Self'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from pydantic.main.BaseModel:
     |
     |  __fields_set__
     |
     |  model_extra
     |      Get extra fields set during validation.
     |
     |      Returns:
     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `"allow"`.
     |
     |  model_fields_set
     |      Returns the set of fields that have been explicitly set on this model instance.
     |
     |      Returns:
     |          A set of strings representing the fields that have been set,
     |              i.e. that were not filled from defaults.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from pydantic.main.BaseModel:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __pydantic_extra__
     |
     |  __pydantic_fields_set__
     |
     |  __pydantic_private__
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from pydantic.main.BaseModel:
     |
     |  __hash__ = None
     |
     |  __pydantic_root_model__ = False

    class UserCreate(pydantic.main.BaseModel)
     |  UserCreate(*, name: str, email: pydantic.networks.EmailStr, password: str, passwordConfirmation: str) -> None
     |
     |  Method resolution order:
     |      UserCreate
     |      pydantic.main.BaseModel
     |      builtins.object
     |
     |  Data descriptors defined here:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  __abstractmethods__ = frozenset()
     |
     |  __annotations__ = {'email': <class 'pydantic.networks.EmailStr'>, 'nam...
     |
     |  __class_vars__ = set()
     |
     |  __private_attributes__ = {}
     |
     |  __pydantic_complete__ = True
     |
     |  __pydantic_core_schema__ = {'cls': <class 'endpoints.auth.UserCreate'>...
     |
     |  __pydantic_custom_init__ = False
     |
     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...
     |
     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...
     |
     |  __pydantic_parent_namespace__ = {'APIRouter': <pydantic._internal._mod...
     |
     |  __pydantic_post_init__ = None
     |
     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(
     |      Model...
     |
     |  __pydantic_validator__ = SchemaValidator(title="UserCreate", validator...
     |
     |  __signature__ = <Signature (*, name: str, email: pydantic.networ...ass...
     |
     |  model_computed_fields = {}
     |
     |  model_config = {}
     |
     |  model_fields = {'email': FieldInfo(annotation=EmailStr, required=True)...
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from pydantic.main.BaseModel:
     |
     |  __copy__(self) -> 'Self'
     |      Returns a shallow copy of the model.
     |
     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'
     |      Returns a deep copy of the model.
     |
     |  __delattr__(self, item: 'str') -> 'Any'
     |      Implement delattr(self, name).
     |
     |  __eq__(self, other: 'Any') -> 'bool'
     |      Return self==value.
     |
     |  __getattr__(self, item: 'str') -> 'Any'
     |
     |  __getstate__(self) -> 'dict[Any, Any]'
     |      Helper for pickle.
     |
     |  __init__(self, /, **data: 'Any') -> 'None'
     |      Create a new model by parsing and validating input data from keyword arguments.
     |
     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be
     |      validated to form a valid model.
     |
     |      `self` is explicitly positional-only to allow `self` as a field name.
     |
     |  __iter__(self) -> 'TupleGenerator'
     |      So `dict(model)` works.
     |
     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation
     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.
     |
     |  __repr__(self) -> 'str'
     |      Return repr(self).
     |
     |  __repr_args__(self) -> '_repr.ReprArgs'
     |
     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation
     |      Name of the instance's class, used in __repr__.
     |
     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation
     |
     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation
     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.
     |
     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'
     |
     |  __str__(self) -> 'str'
     |      Return str(self).
     |
     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Returns a copy of the model.
     |
     |      !!! warning "Deprecated"
     |          This method is now deprecated; use `model_copy` instead.
     |
     |      If you need `include` or `exclude`, use:
     |
     |      ```py
     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)
     |      data = {**data, **(update or {})}
     |      copied = self.model_validate(data)
     |      ```
     |
     |      Args:
     |          include: Optional set or mapping specifying which fields to include in the copied model.
     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.
     |          update: Optional dictionary of field-value pairs to override field values in the copied model.
     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.
     |
     |      Returns:
     |          A copy of the model with included, excluded and updated fields as specified.
     |
     |  dict(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'
     |
     |  json(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'
     |
     |  model_copy(self, *, update: 'dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#model_copy
     |
     |      Returns a copy of the model.
     |
     |      Args:
     |          update: Values to change/add in the new model. Note: the data is not validated
     |              before creating the new model. You should trust this data.
     |          deep: Set to `True` to make a deep copy of the model.
     |
     |      Returns:
     |          New model instance.
     |
     |  model_dump(self, *, mode: "Literal['json', 'python'] | str" = 'python', include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump
     |
     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.
     |
     |      Args:
     |          mode: The mode in which `to_python` should run.
     |              If mode is 'json', the output will only contain JSON serializable types.
     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.
     |          include: A set of fields to include in the output.
     |          exclude: A set of fields to exclude from the output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to use the field's alias in the dictionary key if defined.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A dictionary representation of the model.
     |
     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'str'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump_json
     |
     |      Generates a JSON representation of the model using Pydantic's `to_json` method.
     |
     |      Args:
     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.
     |          include: Field(s) to include in the JSON output.
     |          exclude: Field(s) to exclude from the JSON output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to serialize using field aliases.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A JSON string representation of the model.
     |
     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'
     |      Override this method to perform additional initialization after `__init__` and `model_construct`.
     |      This is useful if you want to do some validation that requires the entire model to be initialized.
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from pydantic.main.BaseModel:
     |
     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'
     |
     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'
     |      Hook into generating the model's CoreSchema.
     |
     |      Args:
     |          source: The class we are generating a schema for.
     |              This will generally be the same as the `cls` argument if this is a classmethod.
     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.
     |
     |      Returns:
     |          A `pydantic-core` `CoreSchema`.
     |
     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'
     |      Hook into generating the model's JSON schema.
     |
     |      Args:
     |          core_schema: A `pydantic-core` CoreSchema.
     |              You can ignore this argument and call the handler with a new CoreSchema,
     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),
     |              or just call the handler with the original schema.
     |          handler: Call into Pydantic's internal JSON schema generation.
     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema
     |              generation fails.
     |              Since this gets called by `BaseModel.model_json_schema` you can override the
     |              `schema_generator` argument to that function to change JSON schema generation globally
     |              for a type.
     |
     |      Returns:
     |          A JSON schema, as a Python object.
     |
     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'
     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`
     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will
     |      be present when this is called.
     |
     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,
     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that
     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.
     |
     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,
     |      any kwargs passed to the class definition that aren't used internally by pydantic.
     |
     |      Args:
     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally
     |              by pydantic.
     |
     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |
     |  from_orm(obj: 'Any') -> 'Self'
     |
     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |      Creates a new instance of the `Model` class with validated data.
     |
     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.
     |      Default values are respected, but no other validation is performed.
     |
     |      !!! note
     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.
     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`
     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.
     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in
     |          an error if extra values are passed, but they will be ignored.
     |
     |      Args:
     |          _fields_set: The set of field names accepted for the Model instance.
     |          values: Trusted or pre-validated data dictionary.
     |
     |      Returns:
     |          A new instance of the `Model` class with validated data.
     |
     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'
     |      Generates a JSON schema for a model class.
     |
     |      Args:
     |          by_alias: Whether to use attribute aliases or not.
     |          ref_template: The reference template.
     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of
     |              `GenerateJsonSchema` with your desired modifications
     |          mode: The mode in which to generate the schema.
     |
     |      Returns:
     |          The JSON schema for the given model class.
     |
     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'
     |      Compute the class name for parametrizations of generic classes.
     |
     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.
     |
     |      Args:
     |          params: Tuple of types of the class. Given a generic class
     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,
     |              the value `(str, int)` would be passed to `params`.
     |
     |      Returns:
     |          String representing the new class where `params` are passed to `cls` as type variables.
     |
     |      Raises:
     |          TypeError: Raised when trying to generate concrete names for non-generic models.
     |
     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'dict[str, Any] | None' = None) -> 'bool | None'
     |      Try to rebuild the pydantic-core schema for the model.
     |
     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during
     |      the initial attempt to build the schema, and automatic rebuilding fails.
     |
     |      Args:
     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.
     |          raise_errors: Whether to raise errors, defaults to `True`.
     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.
     |          _types_namespace: The types namespace, defaults to `None`.
     |
     |      Returns:
     |          Returns `None` if the schema is already "complete" and rebuilding was not required.
     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.
     |
     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate a pydantic model instance.
     |
     |      Args:
     |          obj: The object to validate.
     |          strict: Whether to enforce types strictly.
     |          from_attributes: Whether to extract data from object attributes.
     |          context: Additional context to pass to the validator.
     |
     |      Raises:
     |          ValidationError: If the object could not be validated.
     |
     |      Returns:
     |          The validated model instance.
     |
     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/json/#json-parsing
     |
     |      Validate the given JSON data against the Pydantic model.
     |
     |      Args:
     |          json_data: The JSON data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |      Raises:
     |          ValueError: If `json_data` is not a JSON string.
     |
     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate the given object with string data against the Pydantic model.
     |
     |      Args:
     |          obj: The object containing string data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  parse_obj(obj: 'Any') -> 'Self'
     |
     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'
     |
     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'
     |
     |  update_forward_refs(**localns: 'Any') -> 'None'
     |
     |  validate(value: 'Any') -> 'Self'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from pydantic.main.BaseModel:
     |
     |  __fields_set__
     |
     |  model_extra
     |      Get extra fields set during validation.
     |
     |      Returns:
     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `"allow"`.
     |
     |  model_fields_set
     |      Returns the set of fields that have been explicitly set on this model instance.
     |
     |      Returns:
     |          A set of strings representing the fields that have been set,
     |              i.e. that were not filled from defaults.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from pydantic.main.BaseModel:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __pydantic_extra__
     |
     |  __pydantic_fields_set__
     |
     |  __pydantic_private__
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from pydantic.main.BaseModel:
     |
     |  __hash__ = None
     |
     |  __pydantic_root_model__ = False

    class VerifyTokenRequest(pydantic.main.BaseModel)
     |  VerifyTokenRequest(*, token: str) -> None
     |
     |  Method resolution order:
     |      VerifyTokenRequest
     |      pydantic.main.BaseModel
     |      builtins.object
     |
     |  Data descriptors defined here:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  __abstractmethods__ = frozenset()
     |
     |  __annotations__ = {'token': <class 'str'>}
     |
     |  __class_vars__ = set()
     |
     |  __private_attributes__ = {}
     |
     |  __pydantic_complete__ = True
     |
     |  __pydantic_core_schema__ = {'cls': <class 'endpoints.auth.VerifyTokenR...
     |
     |  __pydantic_custom_init__ = False
     |
     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...
     |
     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...
     |
     |  __pydantic_parent_namespace__ = {'APIRouter': <pydantic._internal._mod...
     |
     |  __pydantic_post_init__ = None
     |
     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(
     |      Model...
     |
     |  __pydantic_validator__ = SchemaValidator(title="VerifyTokenRequest", v...
     |
     |  __signature__ = <Signature (*, token: str) -> None>
     |
     |  model_computed_fields = {}
     |
     |  model_config = {}
     |
     |  model_fields = {'token': FieldInfo(annotation=str, required=True)}
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from pydantic.main.BaseModel:
     |
     |  __copy__(self) -> 'Self'
     |      Returns a shallow copy of the model.
     |
     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'
     |      Returns a deep copy of the model.
     |
     |  __delattr__(self, item: 'str') -> 'Any'
     |      Implement delattr(self, name).
     |
     |  __eq__(self, other: 'Any') -> 'bool'
     |      Return self==value.
     |
     |  __getattr__(self, item: 'str') -> 'Any'
     |
     |  __getstate__(self) -> 'dict[Any, Any]'
     |      Helper for pickle.
     |
     |  __init__(self, /, **data: 'Any') -> 'None'
     |      Create a new model by parsing and validating input data from keyword arguments.
     |
     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be
     |      validated to form a valid model.
     |
     |      `self` is explicitly positional-only to allow `self` as a field name.
     |
     |  __iter__(self) -> 'TupleGenerator'
     |      So `dict(model)` works.
     |
     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation
     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.
     |
     |  __repr__(self) -> 'str'
     |      Return repr(self).
     |
     |  __repr_args__(self) -> '_repr.ReprArgs'
     |
     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation
     |      Name of the instance's class, used in __repr__.
     |
     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation
     |
     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation
     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.
     |
     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'
     |
     |  __str__(self) -> 'str'
     |      Return str(self).
     |
     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Returns a copy of the model.
     |
     |      !!! warning "Deprecated"
     |          This method is now deprecated; use `model_copy` instead.
     |
     |      If you need `include` or `exclude`, use:
     |
     |      ```py
     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)
     |      data = {**data, **(update or {})}
     |      copied = self.model_validate(data)
     |      ```
     |
     |      Args:
     |          include: Optional set or mapping specifying which fields to include in the copied model.
     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.
     |          update: Optional dictionary of field-value pairs to override field values in the copied model.
     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.
     |
     |      Returns:
     |          A copy of the model with included, excluded and updated fields as specified.
     |
     |  dict(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'
     |
     |  json(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'
     |
     |  model_copy(self, *, update: 'dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#model_copy
     |
     |      Returns a copy of the model.
     |
     |      Args:
     |          update: Values to change/add in the new model. Note: the data is not validated
     |              before creating the new model. You should trust this data.
     |          deep: Set to `True` to make a deep copy of the model.
     |
     |      Returns:
     |          New model instance.
     |
     |  model_dump(self, *, mode: "Literal['json', 'python'] | str" = 'python', include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump
     |
     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.
     |
     |      Args:
     |          mode: The mode in which `to_python` should run.
     |              If mode is 'json', the output will only contain JSON serializable types.
     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.
     |          include: A set of fields to include in the output.
     |          exclude: A set of fields to exclude from the output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to use the field's alias in the dictionary key if defined.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A dictionary representation of the model.
     |
     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'str'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump_json
     |
     |      Generates a JSON representation of the model using Pydantic's `to_json` method.
     |
     |      Args:
     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.
     |          include: Field(s) to include in the JSON output.
     |          exclude: Field(s) to exclude from the JSON output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to serialize using field aliases.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A JSON string representation of the model.
     |
     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'
     |      Override this method to perform additional initialization after `__init__` and `model_construct`.
     |      This is useful if you want to do some validation that requires the entire model to be initialized.
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from pydantic.main.BaseModel:
     |
     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'
     |
     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'
     |      Hook into generating the model's CoreSchema.
     |
     |      Args:
     |          source: The class we are generating a schema for.
     |              This will generally be the same as the `cls` argument if this is a classmethod.
     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.
     |
     |      Returns:
     |          A `pydantic-core` `CoreSchema`.
     |
     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'
     |      Hook into generating the model's JSON schema.
     |
     |      Args:
     |          core_schema: A `pydantic-core` CoreSchema.
     |              You can ignore this argument and call the handler with a new CoreSchema,
     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),
     |              or just call the handler with the original schema.
     |          handler: Call into Pydantic's internal JSON schema generation.
     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema
     |              generation fails.
     |              Since this gets called by `BaseModel.model_json_schema` you can override the
     |              `schema_generator` argument to that function to change JSON schema generation globally
     |              for a type.
     |
     |      Returns:
     |          A JSON schema, as a Python object.
     |
     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'
     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`
     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will
     |      be present when this is called.
     |
     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,
     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that
     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.
     |
     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,
     |      any kwargs passed to the class definition that aren't used internally by pydantic.
     |
     |      Args:
     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally
     |              by pydantic.
     |
     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |
     |  from_orm(obj: 'Any') -> 'Self'
     |
     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |      Creates a new instance of the `Model` class with validated data.
     |
     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.
     |      Default values are respected, but no other validation is performed.
     |
     |      !!! note
     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.
     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`
     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.
     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in
     |          an error if extra values are passed, but they will be ignored.
     |
     |      Args:
     |          _fields_set: The set of field names accepted for the Model instance.
     |          values: Trusted or pre-validated data dictionary.
     |
     |      Returns:
     |          A new instance of the `Model` class with validated data.
     |
     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'
     |      Generates a JSON schema for a model class.
     |
     |      Args:
     |          by_alias: Whether to use attribute aliases or not.
     |          ref_template: The reference template.
     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of
     |              `GenerateJsonSchema` with your desired modifications
     |          mode: The mode in which to generate the schema.
     |
     |      Returns:
     |          The JSON schema for the given model class.
     |
     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'
     |      Compute the class name for parametrizations of generic classes.
     |
     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.
     |
     |      Args:
     |          params: Tuple of types of the class. Given a generic class
     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,
     |              the value `(str, int)` would be passed to `params`.
     |
     |      Returns:
     |          String representing the new class where `params` are passed to `cls` as type variables.
     |
     |      Raises:
     |          TypeError: Raised when trying to generate concrete names for non-generic models.
     |
     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'dict[str, Any] | None' = None) -> 'bool | None'
     |      Try to rebuild the pydantic-core schema for the model.
     |
     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during
     |      the initial attempt to build the schema, and automatic rebuilding fails.
     |
     |      Args:
     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.
     |          raise_errors: Whether to raise errors, defaults to `True`.
     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.
     |          _types_namespace: The types namespace, defaults to `None`.
     |
     |      Returns:
     |          Returns `None` if the schema is already "complete" and rebuilding was not required.
     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.
     |
     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate a pydantic model instance.
     |
     |      Args:
     |          obj: The object to validate.
     |          strict: Whether to enforce types strictly.
     |          from_attributes: Whether to extract data from object attributes.
     |          context: Additional context to pass to the validator.
     |
     |      Raises:
     |          ValidationError: If the object could not be validated.
     |
     |      Returns:
     |          The validated model instance.
     |
     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/json/#json-parsing
     |
     |      Validate the given JSON data against the Pydantic model.
     |
     |      Args:
     |          json_data: The JSON data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |      Raises:
     |          ValueError: If `json_data` is not a JSON string.
     |
     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate the given object with string data against the Pydantic model.
     |
     |      Args:
     |          obj: The object containing string data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  parse_obj(obj: 'Any') -> 'Self'
     |
     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'
     |
     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'
     |
     |  update_forward_refs(**localns: 'Any') -> 'None'
     |
     |  validate(value: 'Any') -> 'Self'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from pydantic.main.BaseModel:
     |
     |  __fields_set__
     |
     |  model_extra
     |      Get extra fields set during validation.
     |
     |      Returns:
     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `"allow"`.
     |
     |  model_fields_set
     |      Returns the set of fields that have been explicitly set on this model instance.
     |
     |      Returns:
     |          A set of strings representing the fields that have been set,
     |              i.e. that were not filled from defaults.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from pydantic.main.BaseModel:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __pydantic_extra__
     |
     |  __pydantic_fields_set__
     |
     |  __pydantic_private__
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from pydantic.main.BaseModel:
     |
     |  __hash__ = None
     |
     |  __pydantic_root_model__ = False

FUNCTIONS
    change_password(change: endpoints.auth.PasswordChange, session_token: str, db: sqlalchemy.orm.session.Session = Depends(get_db_session))
        Cambio de Contraseña

        Este endpoint permite a los usuarios cambiar su contraseña siempre que proporcionen la contraseña actual correctamente.

        - **URL**: `/change-password`
        - **Método**: `PUT`
        - **Cuerpo de la solicitud**:
          - `current_password` (string): La contraseña actual.
          - `new_password` (string): La nueva contraseña.
          - `confirm_password` (string): Confirmación de la nueva contraseña.

        - **Respuestas**:
          - **200 OK**: El cambio de contraseña fue exitoso.
            ```json
            {
                "status": "success",
                "message": "Cambio de contraseña exitoso"
            }
            ```
          - **400 Bad Request**: Las contraseñas no coinciden, no cumplen con los requisitos de seguridad, o la contraseña actual es incorrecta.
            ```json
            {
                "status": "error",
                "message": "Credenciales incorrectas" / "Las contraseñas no coinciden"
            }
            ```

        - **Ejemplo de solicitud**:
            ```bash
            curl -X PUT "https://tu-api.com/change-password"     -H "Content-Type: application/json"     -d '{"current_password": "OldPassword123!", "new_password": "NewPassword123!", "confirm_password": "NewPassword123!"}'
            ```

        - **Logs**: Se registran logs para errores de validación de contraseñas, así como cualquier error al confirmar cambios en la base de datos.

    delete_account(session_token: str, db: sqlalchemy.orm.session.Session = Depends(get_db_session))
        Elimina la cuenta de un usuario en función de su token de sesión.

        - **session_token**: El token de sesión del usuario.
        - **db**: Sesión de base de datos inyectada con `Depends(get_db_session)`.

        **Retornos**:
        - Respuesta de éxito si la cuenta fue eliminada correctamente.
        - Respuesta de error si el token de sesión es inválido o si ocurre algún error durante la eliminación de la cuenta.

    forgot_password(request: endpoints.auth.PasswordResetRequest, db: sqlalchemy.orm.session.Session = Depends(get_db_session))
        Inicia el proceso de restablecimiento de contraseña.

        - **email**: El correo electrónico del usuario que solicita el restablecimiento.

    login(request: endpoints.auth.LoginRequest, db: sqlalchemy.orm.session.Session = Depends(get_db_session))
        Inicio de Sesión

        Este endpoint permite a los usuarios autenticarse mediante correo electrónico y contraseña. Si el correo no está verificado, se enviará un nuevo token de verificación.

        - **URL**: `/login`
        - **Método**: `POST`
        - **Cuerpo de la solicitud**:
          - `email` (string): Correo electrónico del usuario.
          - `password` (string): Contraseña del usuario.
          - `fcm_token` (string): Token FCM para notificaciones push.

        - **Respuestas**:
          - **200 OK**: El inicio de sesión fue exitoso.
            ```json
            {
                "status": "success",
                "message": "Inicio de sesión exitoso",
                "data": {
                    "session_token": "abcd1234",
                    "name": "Usuario Ejemplo"
                }
            }
            ```
          - **400 Bad Request**: Credenciales incorrectas o el correo no ha sido verificado.
            ```json
            {
                "status": "error",
                "message": "Credenciales incorrectas" / "Debes verificar tu correo antes de iniciar sesión"
            }
            ```

        - **Ejemplo de solicitud**:
            ```bash
            curl -X POST "https://tu-api.com/login"     -H "Content-Type: application/json"     -d '{"email": "user@example.com", "password": "MySecurePassword", "fcm_token": "fcmToken123"}'
            ```

        - **Logs**: Se registran logs para errores de autenticación, generación de tokens de sesión y cualquier error durante el inicio de sesión.

    logout(request: endpoints.auth.LogoutRequest, db: sqlalchemy.orm.session.Session = Depends(get_db_session))
        Cierra la sesión de un usuario eliminando su session_token y fcm_token.

        - **request**: Objeto `LogoutRequest` que contiene el `session_token`.
        - **db**: Sesión de base de datos inyectada con `Depends(get_db_session)`.

        **Retornos**:
        - Respuesta de éxito si el cierre de sesión fue exitoso.
        - Respuesta de error si el token de sesión es inválido o si ocurre algún error durante el proceso de cierre de sesión.

    register_user(user: endpoints.auth.UserCreate, db: sqlalchemy.orm.session.Session = Depends(get_db_session))
        Registra un nuevo usuario.

        - **name**: El nombre completo del usuario.
        - **email**: El correo electrónico del usuario.
        - **password**: La contraseña del usuario.
        - **passwordConfirmation**: Confirmación de la contraseña.

    reset_password(reset: endpoints.auth.PasswordReset, db: sqlalchemy.orm.session.Session = Depends(get_db_session))
        Restablecimiento de Contraseña

        Este endpoint permite restablecer la contraseña de un usuario, siempre que el token sea válido y no haya expirado.

        - **URL**: `/reset-password`
        - **Método**: `POST`
        - **Cuerpo de la solicitud**:
          - `token` (string): El token de verificación.
          - `new_password` (string): La nueva contraseña.
          - `confirm_password` (string): Confirmación de la nueva contraseña.

        - **Respuestas**:
          - **200 OK**: La contraseña fue restablecida exitosamente.
            ```json
            {
                "status": "success",
                "message": "Contraseña restablecida exitosamente"
            }
            ```
          - **400 Bad Request**: Las contraseñas no coinciden, no cumplen con los requisitos, o el token es inválido o ha expirado.
            ```json
            {
                "status": "error",
                "message": "Las contraseñas no coinciden" / "Token ha expirado" / "Token inválido o expirado"
            }
            ```

        - **Ejemplo de solicitud**:
            ```bash
            curl -X POST "https://tu-api.com/reset-password"     -H "Content-Type: application/json"     -d '{"token": "abcd1234", "new_password": "NewPassword123!", "confirm_password": "NewPassword123!"}'
            ```

        - **Logs**: Se generan logs detallados para cada paso, incluidos errores al actualizar la contraseña o si el token ha expirado.

    update_profile(profile: endpoints.auth.UpdateProfile, session_token: str, db: sqlalchemy.orm.session.Session = Depends(get_db_session))
        Actualiza el perfil del usuario (actualmente solo el nombre) usando su token de sesión.

        - **profile**: Objeto `UpdateProfile` que contiene el nuevo nombre del usuario.
        - **session_token**: El token de sesión del usuario.
        - **db**: Sesión de base de datos inyectada con `Depends(get_db_session)`.

        **Retornos**:
        - Respuesta de éxito si el perfil se actualizó correctamente.
        - Respuesta de error si el token de sesión es inválido, el nombre está vacío, o si ocurre algún error durante la actualización del perfil.

    validate_password_strength(password: str) -> bool
        # Función auxiliar para validar la contraseña

    verify_email(request: endpoints.auth.VerifyTokenRequest, db: sqlalchemy.orm.session.Session = Depends(get_db_session))
        Verifica el correo electrónico de un usuario.

        - **token**: El token enviado al correo electrónico del usuario.

    verify_session_token(session_token: str, db: sqlalchemy.orm.session.Session) -> models.models.User
        # Función auxiliar para verificar tokens de sesión

    verify_token(request: endpoints.auth.VerifyTokenRequest, db: sqlalchemy.orm.session.Session = Depends(get_db_session))
        Verificación de Token de Restablecimiento de Contraseña

        Este endpoint permite verificar si un token de restablecimiento de contraseña es válido y no ha expirado.

        - **URL**: `/verify-token`
        - **Método**: `POST`
        - **Cuerpo de la solicitud**:
          - `token` (string): El token de verificación que debe ser validado.

        - **Respuestas**:
          - **200 OK**: El token es válido y se puede proceder con el restablecimiento de contraseña.
            ```json
            {
                "status": "success",
                "message": "Token válido. Puede proceder a restablecer la contraseña."
            }
            ```
          - **400 Bad Request**: El token es inválido o ha expirado.
            ```json
            {
                "status": "error",
                "message": "Token ha expirado" / "Token inválido o expirado"
            }
            ```

        - **Ejemplo de solicitud**:
            ```bash
            curl -X POST "https://tu-api.com/verify-token"     -H "Content-Type: application/json"     -d '{"token": "abcd1234"}'
            ```

        - **Logs**: El endpoint genera logs para el inicio y la finalización del proceso de verificación del token, así como cualquier token expirado o inválido.

    verify_user_token(token: str, db: sqlalchemy.orm.session.Session) -> models.models.User
        # Función auxiliar para verificar tokens

DATA
    Dict = typing.Dict
        A generic version of dict.

    logger = <Logger endpoints.auth (INFO)>
    reset_tokens = {}
    router = <fastapi.routing.APIRouter object>

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\endpoints\auth.py



================================================================================
postgresql://coffeetech:Coffeetech.12@localhost:5432/CoffeeTech
Conexión exitosa a la base de datos
Help on module endpoints.collaborators in endpoints:

NAME
    endpoints.collaborators

CLASSES
    pydantic.main.BaseModel(builtins.object)
        Collaborator
        DeleteCollaboratorRequest
        EditCollaboratorRoleRequest

    class Collaborator(pydantic.main.BaseModel)
     |  Collaborator(*, user_id: int, name: str, email: pydantic.networks.EmailStr, role: str) -> None
     |
     |  Modelo Pydantic para representar un colaborador.
     |
     |  Attributes:
     |      user_id (int): ID del usuario del colaborador.
     |      name (str): Nombre del colaborador.
     |      email (EmailStr): Correo electrónico del colaborador.
     |      role (str): Rol del colaborador.
     |
     |  Method resolution order:
     |      Collaborator
     |      pydantic.main.BaseModel
     |      builtins.object
     |
     |  Data descriptors defined here:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  Config = <class 'endpoints.collaborators.Collaborator.Config'>
     |
     |  __abstractmethods__ = frozenset()
     |
     |  __annotations__ = {'email': <class 'pydantic.networks.EmailStr'>, 'nam...
     |
     |  __class_vars__ = set()
     |
     |  __private_attributes__ = {}
     |
     |  __pydantic_complete__ = True
     |
     |  __pydantic_core_schema__ = {'cls': <class 'endpoints.collaborators.Col...
     |
     |  __pydantic_custom_init__ = False
     |
     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...
     |
     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...
     |
     |  __pydantic_parent_namespace__ = {'APIRouter': <pydantic._internal._mod...
     |
     |  __pydantic_post_init__ = None
     |
     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(
     |      Model...
     |
     |  __pydantic_validator__ = SchemaValidator(title="Collaborator", validat...
     |
     |  __signature__ = <Signature (*, user_id: int, name: str, email: pydanti...
     |
     |  model_computed_fields = {}
     |
     |  model_config = {'from_attributes': True}
     |
     |  model_fields = {'email': FieldInfo(annotation=EmailStr, required=True)...
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from pydantic.main.BaseModel:
     |
     |  __copy__(self) -> 'Self'
     |      Returns a shallow copy of the model.
     |
     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'
     |      Returns a deep copy of the model.
     |
     |  __delattr__(self, item: 'str') -> 'Any'
     |      Implement delattr(self, name).
     |
     |  __eq__(self, other: 'Any') -> 'bool'
     |      Return self==value.
     |
     |  __getattr__(self, item: 'str') -> 'Any'
     |
     |  __getstate__(self) -> 'dict[Any, Any]'
     |      Helper for pickle.
     |
     |  __init__(self, /, **data: 'Any') -> 'None'
     |      Create a new model by parsing and validating input data from keyword arguments.
     |
     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be
     |      validated to form a valid model.
     |
     |      `self` is explicitly positional-only to allow `self` as a field name.
     |
     |  __iter__(self) -> 'TupleGenerator'
     |      So `dict(model)` works.
     |
     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation
     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.
     |
     |  __repr__(self) -> 'str'
     |      Return repr(self).
     |
     |  __repr_args__(self) -> '_repr.ReprArgs'
     |
     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation
     |      Name of the instance's class, used in __repr__.
     |
     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation
     |
     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation
     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.
     |
     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'
     |
     |  __str__(self) -> 'str'
     |      Return str(self).
     |
     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Returns a copy of the model.
     |
     |      !!! warning "Deprecated"
     |          This method is now deprecated; use `model_copy` instead.
     |
     |      If you need `include` or `exclude`, use:
     |
     |      ```py
     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)
     |      data = {**data, **(update or {})}
     |      copied = self.model_validate(data)
     |      ```
     |
     |      Args:
     |          include: Optional set or mapping specifying which fields to include in the copied model.
     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.
     |          update: Optional dictionary of field-value pairs to override field values in the copied model.
     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.
     |
     |      Returns:
     |          A copy of the model with included, excluded and updated fields as specified.
     |
     |  dict(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'
     |
     |  json(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'
     |
     |  model_copy(self, *, update: 'dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#model_copy
     |
     |      Returns a copy of the model.
     |
     |      Args:
     |          update: Values to change/add in the new model. Note: the data is not validated
     |              before creating the new model. You should trust this data.
     |          deep: Set to `True` to make a deep copy of the model.
     |
     |      Returns:
     |          New model instance.
     |
     |  model_dump(self, *, mode: "Literal['json', 'python'] | str" = 'python', include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump
     |
     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.
     |
     |      Args:
     |          mode: The mode in which `to_python` should run.
     |              If mode is 'json', the output will only contain JSON serializable types.
     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.
     |          include: A set of fields to include in the output.
     |          exclude: A set of fields to exclude from the output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to use the field's alias in the dictionary key if defined.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A dictionary representation of the model.
     |
     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'str'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump_json
     |
     |      Generates a JSON representation of the model using Pydantic's `to_json` method.
     |
     |      Args:
     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.
     |          include: Field(s) to include in the JSON output.
     |          exclude: Field(s) to exclude from the JSON output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to serialize using field aliases.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A JSON string representation of the model.
     |
     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'
     |      Override this method to perform additional initialization after `__init__` and `model_construct`.
     |      This is useful if you want to do some validation that requires the entire model to be initialized.
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from pydantic.main.BaseModel:
     |
     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'
     |
     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'
     |      Hook into generating the model's CoreSchema.
     |
     |      Args:
     |          source: The class we are generating a schema for.
     |              This will generally be the same as the `cls` argument if this is a classmethod.
     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.
     |
     |      Returns:
     |          A `pydantic-core` `CoreSchema`.
     |
     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'
     |      Hook into generating the model's JSON schema.
     |
     |      Args:
     |          core_schema: A `pydantic-core` CoreSchema.
     |              You can ignore this argument and call the handler with a new CoreSchema,
     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),
     |              or just call the handler with the original schema.
     |          handler: Call into Pydantic's internal JSON schema generation.
     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema
     |              generation fails.
     |              Since this gets called by `BaseModel.model_json_schema` you can override the
     |              `schema_generator` argument to that function to change JSON schema generation globally
     |              for a type.
     |
     |      Returns:
     |          A JSON schema, as a Python object.
     |
     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'
     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`
     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will
     |      be present when this is called.
     |
     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,
     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that
     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.
     |
     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,
     |      any kwargs passed to the class definition that aren't used internally by pydantic.
     |
     |      Args:
     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally
     |              by pydantic.
     |
     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |
     |  from_orm(obj: 'Any') -> 'Self'
     |
     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |      Creates a new instance of the `Model` class with validated data.
     |
     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.
     |      Default values are respected, but no other validation is performed.
     |
     |      !!! note
     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.
     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`
     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.
     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in
     |          an error if extra values are passed, but they will be ignored.
     |
     |      Args:
     |          _fields_set: The set of field names accepted for the Model instance.
     |          values: Trusted or pre-validated data dictionary.
     |
     |      Returns:
     |          A new instance of the `Model` class with validated data.
     |
     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'
     |      Generates a JSON schema for a model class.
     |
     |      Args:
     |          by_alias: Whether to use attribute aliases or not.
     |          ref_template: The reference template.
     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of
     |              `GenerateJsonSchema` with your desired modifications
     |          mode: The mode in which to generate the schema.
     |
     |      Returns:
     |          The JSON schema for the given model class.
     |
     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'
     |      Compute the class name for parametrizations of generic classes.
     |
     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.
     |
     |      Args:
     |          params: Tuple of types of the class. Given a generic class
     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,
     |              the value `(str, int)` would be passed to `params`.
     |
     |      Returns:
     |          String representing the new class where `params` are passed to `cls` as type variables.
     |
     |      Raises:
     |          TypeError: Raised when trying to generate concrete names for non-generic models.
     |
     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'dict[str, Any] | None' = None) -> 'bool | None'
     |      Try to rebuild the pydantic-core schema for the model.
     |
     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during
     |      the initial attempt to build the schema, and automatic rebuilding fails.
     |
     |      Args:
     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.
     |          raise_errors: Whether to raise errors, defaults to `True`.
     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.
     |          _types_namespace: The types namespace, defaults to `None`.
     |
     |      Returns:
     |          Returns `None` if the schema is already "complete" and rebuilding was not required.
     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.
     |
     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate a pydantic model instance.
     |
     |      Args:
     |          obj: The object to validate.
     |          strict: Whether to enforce types strictly.
     |          from_attributes: Whether to extract data from object attributes.
     |          context: Additional context to pass to the validator.
     |
     |      Raises:
     |          ValidationError: If the object could not be validated.
     |
     |      Returns:
     |          The validated model instance.
     |
     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/json/#json-parsing
     |
     |      Validate the given JSON data against the Pydantic model.
     |
     |      Args:
     |          json_data: The JSON data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |      Raises:
     |          ValueError: If `json_data` is not a JSON string.
     |
     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate the given object with string data against the Pydantic model.
     |
     |      Args:
     |          obj: The object containing string data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  parse_obj(obj: 'Any') -> 'Self'
     |
     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'
     |
     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'
     |
     |  update_forward_refs(**localns: 'Any') -> 'None'
     |
     |  validate(value: 'Any') -> 'Self'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from pydantic.main.BaseModel:
     |
     |  __fields_set__
     |
     |  model_extra
     |      Get extra fields set during validation.
     |
     |      Returns:
     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `"allow"`.
     |
     |  model_fields_set
     |      Returns the set of fields that have been explicitly set on this model instance.
     |
     |      Returns:
     |          A set of strings representing the fields that have been set,
     |              i.e. that were not filled from defaults.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from pydantic.main.BaseModel:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __pydantic_extra__
     |
     |  __pydantic_fields_set__
     |
     |  __pydantic_private__
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from pydantic.main.BaseModel:
     |
     |  __hash__ = None
     |
     |  __pydantic_root_model__ = False

    class DeleteCollaboratorRequest(pydantic.main.BaseModel)
     |  DeleteCollaboratorRequest(*, collaborator_user_id: int) -> None
     |
     |  Modelo Pydantic para la solicitud de eliminación de un colaborador.
     |
     |  Attributes:
     |      collaborator_user_id (int): ID del usuario colaborador que se desea eliminar.
     |
     |  Method resolution order:
     |      DeleteCollaboratorRequest
     |      pydantic.main.BaseModel
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  validate_input(self)
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  Config = <class 'endpoints.collaborators.DeleteCollaboratorRequest.Con...
     |
     |  __abstractmethods__ = frozenset()
     |
     |  __annotations__ = {'collaborator_user_id': <class 'int'>}
     |
     |  __class_vars__ = set()
     |
     |  __private_attributes__ = {}
     |
     |  __pydantic_complete__ = True
     |
     |  __pydantic_core_schema__ = {'cls': <class 'endpoints.collaborators.Del...
     |
     |  __pydantic_custom_init__ = False
     |
     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...
     |
     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...
     |
     |  __pydantic_parent_namespace__ = {'APIRouter': <pydantic._internal._mod...
     |
     |  __pydantic_post_init__ = None
     |
     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(
     |      Model...
     |
     |  __pydantic_validator__ = SchemaValidator(title="DeleteCollaboratorRequ...
     |
     |  __signature__ = <Signature (*, collaborator_user_id: int) -> None>
     |
     |  model_computed_fields = {}
     |
     |  model_config = {'from_attributes': True, 'populate_by_name': True}
     |
     |  model_fields = {'collaborator_user_id': FieldInfo(annotation=int, requ...
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from pydantic.main.BaseModel:
     |
     |  __copy__(self) -> 'Self'
     |      Returns a shallow copy of the model.
     |
     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'
     |      Returns a deep copy of the model.
     |
     |  __delattr__(self, item: 'str') -> 'Any'
     |      Implement delattr(self, name).
     |
     |  __eq__(self, other: 'Any') -> 'bool'
     |      Return self==value.
     |
     |  __getattr__(self, item: 'str') -> 'Any'
     |
     |  __getstate__(self) -> 'dict[Any, Any]'
     |      Helper for pickle.
     |
     |  __init__(self, /, **data: 'Any') -> 'None'
     |      Create a new model by parsing and validating input data from keyword arguments.
     |
     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be
     |      validated to form a valid model.
     |
     |      `self` is explicitly positional-only to allow `self` as a field name.
     |
     |  __iter__(self) -> 'TupleGenerator'
     |      So `dict(model)` works.
     |
     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation
     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.
     |
     |  __repr__(self) -> 'str'
     |      Return repr(self).
     |
     |  __repr_args__(self) -> '_repr.ReprArgs'
     |
     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation
     |      Name of the instance's class, used in __repr__.
     |
     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation
     |
     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation
     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.
     |
     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'
     |
     |  __str__(self) -> 'str'
     |      Return str(self).
     |
     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Returns a copy of the model.
     |
     |      !!! warning "Deprecated"
     |          This method is now deprecated; use `model_copy` instead.
     |
     |      If you need `include` or `exclude`, use:
     |
     |      ```py
     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)
     |      data = {**data, **(update or {})}
     |      copied = self.model_validate(data)
     |      ```
     |
     |      Args:
     |          include: Optional set or mapping specifying which fields to include in the copied model.
     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.
     |          update: Optional dictionary of field-value pairs to override field values in the copied model.
     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.
     |
     |      Returns:
     |          A copy of the model with included, excluded and updated fields as specified.
     |
     |  dict(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'
     |
     |  json(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'
     |
     |  model_copy(self, *, update: 'dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#model_copy
     |
     |      Returns a copy of the model.
     |
     |      Args:
     |          update: Values to change/add in the new model. Note: the data is not validated
     |              before creating the new model. You should trust this data.
     |          deep: Set to `True` to make a deep copy of the model.
     |
     |      Returns:
     |          New model instance.
     |
     |  model_dump(self, *, mode: "Literal['json', 'python'] | str" = 'python', include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump
     |
     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.
     |
     |      Args:
     |          mode: The mode in which `to_python` should run.
     |              If mode is 'json', the output will only contain JSON serializable types.
     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.
     |          include: A set of fields to include in the output.
     |          exclude: A set of fields to exclude from the output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to use the field's alias in the dictionary key if defined.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A dictionary representation of the model.
     |
     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'str'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump_json
     |
     |      Generates a JSON representation of the model using Pydantic's `to_json` method.
     |
     |      Args:
     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.
     |          include: Field(s) to include in the JSON output.
     |          exclude: Field(s) to exclude from the JSON output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to serialize using field aliases.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A JSON string representation of the model.
     |
     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'
     |      Override this method to perform additional initialization after `__init__` and `model_construct`.
     |      This is useful if you want to do some validation that requires the entire model to be initialized.
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from pydantic.main.BaseModel:
     |
     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'
     |
     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'
     |      Hook into generating the model's CoreSchema.
     |
     |      Args:
     |          source: The class we are generating a schema for.
     |              This will generally be the same as the `cls` argument if this is a classmethod.
     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.
     |
     |      Returns:
     |          A `pydantic-core` `CoreSchema`.
     |
     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'
     |      Hook into generating the model's JSON schema.
     |
     |      Args:
     |          core_schema: A `pydantic-core` CoreSchema.
     |              You can ignore this argument and call the handler with a new CoreSchema,
     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),
     |              or just call the handler with the original schema.
     |          handler: Call into Pydantic's internal JSON schema generation.
     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema
     |              generation fails.
     |              Since this gets called by `BaseModel.model_json_schema` you can override the
     |              `schema_generator` argument to that function to change JSON schema generation globally
     |              for a type.
     |
     |      Returns:
     |          A JSON schema, as a Python object.
     |
     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'
     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`
     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will
     |      be present when this is called.
     |
     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,
     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that
     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.
     |
     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,
     |      any kwargs passed to the class definition that aren't used internally by pydantic.
     |
     |      Args:
     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally
     |              by pydantic.
     |
     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |
     |  from_orm(obj: 'Any') -> 'Self'
     |
     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |      Creates a new instance of the `Model` class with validated data.
     |
     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.
     |      Default values are respected, but no other validation is performed.
     |
     |      !!! note
     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.
     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`
     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.
     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in
     |          an error if extra values are passed, but they will be ignored.
     |
     |      Args:
     |          _fields_set: The set of field names accepted for the Model instance.
     |          values: Trusted or pre-validated data dictionary.
     |
     |      Returns:
     |          A new instance of the `Model` class with validated data.
     |
     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'
     |      Generates a JSON schema for a model class.
     |
     |      Args:
     |          by_alias: Whether to use attribute aliases or not.
     |          ref_template: The reference template.
     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of
     |              `GenerateJsonSchema` with your desired modifications
     |          mode: The mode in which to generate the schema.
     |
     |      Returns:
     |          The JSON schema for the given model class.
     |
     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'
     |      Compute the class name for parametrizations of generic classes.
     |
     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.
     |
     |      Args:
     |          params: Tuple of types of the class. Given a generic class
     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,
     |              the value `(str, int)` would be passed to `params`.
     |
     |      Returns:
     |          String representing the new class where `params` are passed to `cls` as type variables.
     |
     |      Raises:
     |          TypeError: Raised when trying to generate concrete names for non-generic models.
     |
     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'dict[str, Any] | None' = None) -> 'bool | None'
     |      Try to rebuild the pydantic-core schema for the model.
     |
     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during
     |      the initial attempt to build the schema, and automatic rebuilding fails.
     |
     |      Args:
     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.
     |          raise_errors: Whether to raise errors, defaults to `True`.
     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.
     |          _types_namespace: The types namespace, defaults to `None`.
     |
     |      Returns:
     |          Returns `None` if the schema is already "complete" and rebuilding was not required.
     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.
     |
     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate a pydantic model instance.
     |
     |      Args:
     |          obj: The object to validate.
     |          strict: Whether to enforce types strictly.
     |          from_attributes: Whether to extract data from object attributes.
     |          context: Additional context to pass to the validator.
     |
     |      Raises:
     |          ValidationError: If the object could not be validated.
     |
     |      Returns:
     |          The validated model instance.
     |
     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/json/#json-parsing
     |
     |      Validate the given JSON data against the Pydantic model.
     |
     |      Args:
     |          json_data: The JSON data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |      Raises:
     |          ValueError: If `json_data` is not a JSON string.
     |
     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate the given object with string data against the Pydantic model.
     |
     |      Args:
     |          obj: The object containing string data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  parse_obj(obj: 'Any') -> 'Self'
     |
     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'
     |
     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'
     |
     |  update_forward_refs(**localns: 'Any') -> 'None'
     |
     |  validate(value: 'Any') -> 'Self'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from pydantic.main.BaseModel:
     |
     |  __fields_set__
     |
     |  model_extra
     |      Get extra fields set during validation.
     |
     |      Returns:
     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `"allow"`.
     |
     |  model_fields_set
     |      Returns the set of fields that have been explicitly set on this model instance.
     |
     |      Returns:
     |          A set of strings representing the fields that have been set,
     |              i.e. that were not filled from defaults.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from pydantic.main.BaseModel:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __pydantic_extra__
     |
     |  __pydantic_fields_set__
     |
     |  __pydantic_private__
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from pydantic.main.BaseModel:
     |
     |  __hash__ = None
     |
     |  __pydantic_root_model__ = False

    class EditCollaboratorRoleRequest(pydantic.main.BaseModel)
     |  EditCollaboratorRoleRequest(*, collaborator_user_id: int, new_role: str) -> None
     |
     |  Modelo Pydantic para la solicitud de edición de rol de un colaborador.
     |
     |  Attributes:
     |      collaborator_user_id (int): ID del usuario colaborador cuyo rol se desea editar.
     |      new_role (str): Nuevo rol que se asignará al colaborador.
     |
     |  Method resolution order:
     |      EditCollaboratorRoleRequest
     |      pydantic.main.BaseModel
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  validate_input(self)
     |      Valida que el nuevo rol sea válido.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  Config = <class 'endpoints.collaborators.EditCollaboratorRoleRequest.C...
     |
     |  __abstractmethods__ = frozenset()
     |
     |  __annotations__ = {'collaborator_user_id': <class 'int'>, 'new_role': ...
     |
     |  __class_vars__ = set()
     |
     |  __private_attributes__ = {}
     |
     |  __pydantic_complete__ = True
     |
     |  __pydantic_core_schema__ = {'cls': <class 'endpoints.collaborators.Edi...
     |
     |  __pydantic_custom_init__ = False
     |
     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...
     |
     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...
     |
     |  __pydantic_parent_namespace__ = {'APIRouter': <pydantic._internal._mod...
     |
     |  __pydantic_post_init__ = None
     |
     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(
     |      Model...
     |
     |  __pydantic_validator__ = SchemaValidator(title="EditCollaboratorRoleRe...
     |
     |  __signature__ = <Signature (*, collaborator_user_id: int, new_role: st...
     |
     |  model_computed_fields = {}
     |
     |  model_config = {'from_attributes': True, 'populate_by_name': True}
     |
     |  model_fields = {'collaborator_user_id': FieldInfo(annotation=int, requ...
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from pydantic.main.BaseModel:
     |
     |  __copy__(self) -> 'Self'
     |      Returns a shallow copy of the model.
     |
     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'
     |      Returns a deep copy of the model.
     |
     |  __delattr__(self, item: 'str') -> 'Any'
     |      Implement delattr(self, name).
     |
     |  __eq__(self, other: 'Any') -> 'bool'
     |      Return self==value.
     |
     |  __getattr__(self, item: 'str') -> 'Any'
     |
     |  __getstate__(self) -> 'dict[Any, Any]'
     |      Helper for pickle.
     |
     |  __init__(self, /, **data: 'Any') -> 'None'
     |      Create a new model by parsing and validating input data from keyword arguments.
     |
     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be
     |      validated to form a valid model.
     |
     |      `self` is explicitly positional-only to allow `self` as a field name.
     |
     |  __iter__(self) -> 'TupleGenerator'
     |      So `dict(model)` works.
     |
     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation
     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.
     |
     |  __repr__(self) -> 'str'
     |      Return repr(self).
     |
     |  __repr_args__(self) -> '_repr.ReprArgs'
     |
     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation
     |      Name of the instance's class, used in __repr__.
     |
     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation
     |
     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation
     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.
     |
     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'
     |
     |  __str__(self) -> 'str'
     |      Return str(self).
     |
     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Returns a copy of the model.
     |
     |      !!! warning "Deprecated"
     |          This method is now deprecated; use `model_copy` instead.
     |
     |      If you need `include` or `exclude`, use:
     |
     |      ```py
     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)
     |      data = {**data, **(update or {})}
     |      copied = self.model_validate(data)
     |      ```
     |
     |      Args:
     |          include: Optional set or mapping specifying which fields to include in the copied model.
     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.
     |          update: Optional dictionary of field-value pairs to override field values in the copied model.
     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.
     |
     |      Returns:
     |          A copy of the model with included, excluded and updated fields as specified.
     |
     |  dict(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'
     |
     |  json(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'
     |
     |  model_copy(self, *, update: 'dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#model_copy
     |
     |      Returns a copy of the model.
     |
     |      Args:
     |          update: Values to change/add in the new model. Note: the data is not validated
     |              before creating the new model. You should trust this data.
     |          deep: Set to `True` to make a deep copy of the model.
     |
     |      Returns:
     |          New model instance.
     |
     |  model_dump(self, *, mode: "Literal['json', 'python'] | str" = 'python', include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump
     |
     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.
     |
     |      Args:
     |          mode: The mode in which `to_python` should run.
     |              If mode is 'json', the output will only contain JSON serializable types.
     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.
     |          include: A set of fields to include in the output.
     |          exclude: A set of fields to exclude from the output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to use the field's alias in the dictionary key if defined.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A dictionary representation of the model.
     |
     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'str'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump_json
     |
     |      Generates a JSON representation of the model using Pydantic's `to_json` method.
     |
     |      Args:
     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.
     |          include: Field(s) to include in the JSON output.
     |          exclude: Field(s) to exclude from the JSON output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to serialize using field aliases.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A JSON string representation of the model.
     |
     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'
     |      Override this method to perform additional initialization after `__init__` and `model_construct`.
     |      This is useful if you want to do some validation that requires the entire model to be initialized.
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from pydantic.main.BaseModel:
     |
     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'
     |
     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'
     |      Hook into generating the model's CoreSchema.
     |
     |      Args:
     |          source: The class we are generating a schema for.
     |              This will generally be the same as the `cls` argument if this is a classmethod.
     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.
     |
     |      Returns:
     |          A `pydantic-core` `CoreSchema`.
     |
     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'
     |      Hook into generating the model's JSON schema.
     |
     |      Args:
     |          core_schema: A `pydantic-core` CoreSchema.
     |              You can ignore this argument and call the handler with a new CoreSchema,
     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),
     |              or just call the handler with the original schema.
     |          handler: Call into Pydantic's internal JSON schema generation.
     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema
     |              generation fails.
     |              Since this gets called by `BaseModel.model_json_schema` you can override the
     |              `schema_generator` argument to that function to change JSON schema generation globally
     |              for a type.
     |
     |      Returns:
     |          A JSON schema, as a Python object.
     |
     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'
     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`
     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will
     |      be present when this is called.
     |
     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,
     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that
     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.
     |
     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,
     |      any kwargs passed to the class definition that aren't used internally by pydantic.
     |
     |      Args:
     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally
     |              by pydantic.
     |
     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |
     |  from_orm(obj: 'Any') -> 'Self'
     |
     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |      Creates a new instance of the `Model` class with validated data.
     |
     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.
     |      Default values are respected, but no other validation is performed.
     |
     |      !!! note
     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.
     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`
     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.
     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in
     |          an error if extra values are passed, but they will be ignored.
     |
     |      Args:
     |          _fields_set: The set of field names accepted for the Model instance.
     |          values: Trusted or pre-validated data dictionary.
     |
     |      Returns:
     |          A new instance of the `Model` class with validated data.
     |
     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'
     |      Generates a JSON schema for a model class.
     |
     |      Args:
     |          by_alias: Whether to use attribute aliases or not.
     |          ref_template: The reference template.
     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of
     |              `GenerateJsonSchema` with your desired modifications
     |          mode: The mode in which to generate the schema.
     |
     |      Returns:
     |          The JSON schema for the given model class.
     |
     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'
     |      Compute the class name for parametrizations of generic classes.
     |
     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.
     |
     |      Args:
     |          params: Tuple of types of the class. Given a generic class
     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,
     |              the value `(str, int)` would be passed to `params`.
     |
     |      Returns:
     |          String representing the new class where `params` are passed to `cls` as type variables.
     |
     |      Raises:
     |          TypeError: Raised when trying to generate concrete names for non-generic models.
     |
     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'dict[str, Any] | None' = None) -> 'bool | None'
     |      Try to rebuild the pydantic-core schema for the model.
     |
     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during
     |      the initial attempt to build the schema, and automatic rebuilding fails.
     |
     |      Args:
     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.
     |          raise_errors: Whether to raise errors, defaults to `True`.
     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.
     |          _types_namespace: The types namespace, defaults to `None`.
     |
     |      Returns:
     |          Returns `None` if the schema is already "complete" and rebuilding was not required.
     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.
     |
     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate a pydantic model instance.
     |
     |      Args:
     |          obj: The object to validate.
     |          strict: Whether to enforce types strictly.
     |          from_attributes: Whether to extract data from object attributes.
     |          context: Additional context to pass to the validator.
     |
     |      Raises:
     |          ValidationError: If the object could not be validated.
     |
     |      Returns:
     |          The validated model instance.
     |
     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/json/#json-parsing
     |
     |      Validate the given JSON data against the Pydantic model.
     |
     |      Args:
     |          json_data: The JSON data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |      Raises:
     |          ValueError: If `json_data` is not a JSON string.
     |
     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate the given object with string data against the Pydantic model.
     |
     |      Args:
     |          obj: The object containing string data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  parse_obj(obj: 'Any') -> 'Self'
     |
     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'
     |
     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'
     |
     |  update_forward_refs(**localns: 'Any') -> 'None'
     |
     |  validate(value: 'Any') -> 'Self'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from pydantic.main.BaseModel:
     |
     |  __fields_set__
     |
     |  model_extra
     |      Get extra fields set during validation.
     |
     |      Returns:
     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `"allow"`.
     |
     |  model_fields_set
     |      Returns the set of fields that have been explicitly set on this model instance.
     |
     |      Returns:
     |          A set of strings representing the fields that have been set,
     |              i.e. that were not filled from defaults.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from pydantic.main.BaseModel:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __pydantic_extra__
     |
     |  __pydantic_fields_set__
     |
     |  __pydantic_private__
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from pydantic.main.BaseModel:
     |
     |  __hash__ = None
     |
     |  __pydantic_root_model__ = False

FUNCTIONS
    delete_collaborator(delete_request: endpoints.collaborators.DeleteCollaboratorRequest, farm_id: int, session_token: str, db: sqlalchemy.orm.session.Session = Depends(get_db_session))
        Elimina un colaborador de una finca específica.

        Parámetros:
        - delete_request (DeleteCollaboratorRequest): Cuerpo de la solicitud que contiene el ID del colaborador a eliminar.
        - farm_id (int): ID de la finca desde la que se eliminará al colaborador.
        - session_token (str): Token de sesión del usuario que realiza la solicitud.
        - db (Session): Sesión de la base de datos proporcionada por FastAPI con `Depends`.

        Retornos:
        - Dict[str, Any]: Respuesta indicando éxito o error con el mensaje adecuado.

        Posibles Respuestas:
        - 200: Colaborador eliminado exitosamente.
        - 400: Error en la validación de la solicitud o algún otro fallo.
        - 403: El usuario no tiene permisos o está intentando eliminarse a sí mismo.
        - 404: Finca o colaborador no encontrado.
        - 500: Error en el servidor o al actualizar la base de datos.

    edit_collaborator_role(edit_request: endpoints.collaborators.EditCollaboratorRoleRequest, farm_id: int, session_token: str, db: sqlalchemy.orm.session.Session = Depends(get_db_session))
        ### Descripción:
        Endpoint para editar el rol de un colaborador en una finca específica.

        ### Parámetros:
        - **edit_request (EditCollaboratorRoleRequest)**: Objeto con los campos `collaborator_user_id` y `new_role`, que contiene la información del colaborador y el nuevo rol que se le asignará.
        - **farm_id (int)**: ID de la finca donde se cambiará el rol del colaborador.
        - **session_token (str)**: Token de sesión del usuario autenticado que está realizando la acción.
        - **db (Session)**: Sesión de la base de datos obtenida mediante la dependencia `get_db_session`.

        ### Proceso:
        1. **Validación de entrada**: Se valida la solicitud recibida.
        2. **Autenticación**: Se verifica el `session_token` para autenticar al usuario.
        3. **Verificación de la finca**: Se comprueba si la finca existe.
        4. **Estado 'Activo'**: Se busca el estado 'Activo' para roles en fincas (`user_role_farm`).
        5. **Rol actual del usuario**: Se verifica el rol del usuario que realiza la acción en la finca.
        6. **Verificación del colaborador**: Se obtiene al colaborador cuyo rol se desea editar.
        7. **Evitar auto-cambio de rol**: El usuario no puede cambiar su propio rol.
        8. **Rol del colaborador actual**: Se comprueba el rol actual del colaborador en la finca.
        9. **Permisos necesarios**: Se verifican los permisos del usuario para asignar el nuevo rol.
        10. **Jerarquía de roles**: Se valida la jerarquía de roles para determinar si el usuario puede asignar el nuevo rol.
        11. **Rol objetivo**: Se obtiene el rol que se desea asignar al colaborador.
        12. **Actualización del rol**: Se actualiza el rol del colaborador en la base de datos.

        ### Respuestas:
        - **200 (success)**: El rol del colaborador ha sido actualizado exitosamente.
        - **400 (error)**: Error de validación de entrada o intento de asignar el mismo rol.
        - **403 (error)**: El usuario no tiene permisos suficientes o intentó cambiar su propio rol.
        - **404 (error)**: La finca o el colaborador no existen.
        - **500 (error)**: Error interno del servidor al procesar la solicitud.

        ### Ejemplo de respuesta:
        ```json
        {
            "status": "success",
            "message": "Rol del colaborador 'Juan Pérez' actualizado a 'Administrador de finca' exitosamente",
            "status_code": 200
        }
        ```

    list_collaborators(farm_id: int, session_token: str, db: sqlalchemy.orm.session.Session = Depends(get_db_session))
        Endpoint para listar los colaboradores de una finca específica.

        Args:
            farm_id (int): ID de la finca de la cual se listarán los colaboradores.
            session_token (str): Token de sesión del usuario autenticado.
            db (Session): Sesión de la base de datos.

        Returns:
            Dict[str, Any]: Respuesta con el estado de la operación y la lista de colaboradores.

DATA
    Dict = typing.Dict
        A generic version of dict.

    List = typing.List
        A generic version of list.

    func = <sqlalchemy.sql.functions._FunctionGenerator object>
    logger = <Logger endpoints.collaborators (INFO)>
    router = <fastapi.routing.APIRouter object>

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\endpoints\collaborators.py



================================================================================
postgresql://coffeetech:Coffeetech.12@localhost:5432/CoffeeTech
Conexión exitosa a la base de datos
Help on module endpoints.farm in endpoints:

NAME
    endpoints.farm

CLASSES
    pydantic.main.BaseModel(builtins.object)
        CreateFarmRequest
        ListFarmResponse
        UpdateFarmRequest

    class CreateFarmRequest(pydantic.main.BaseModel)
     |  CreateFarmRequest(*, name: str, area: float, unitMeasure: str) -> None
     |
     |  Modelo de datos para la creación de una finca.
     |
     |  **Atributos**:
     |  - **name**: Nombre de la finca (cadena de texto). Debe ser un valor no vacío ni contener solo espacios.
     |  - **area**: Área de la finca (float). Debe ser un número positivo mayor que cero.
     |  - **unitMeasure**: Unidad de medida del área (cadena de texto). Debe ser una unidad de medida válida como 'hectáreas' o 'metros cuadrados'.
     |
     |  Method resolution order:
     |      CreateFarmRequest
     |      pydantic.main.BaseModel
     |      builtins.object
     |
     |  Data descriptors defined here:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  __abstractmethods__ = frozenset()
     |
     |  __annotations__ = {'area': <class 'float'>, 'name': <class 'str'>, 'un...
     |
     |  __class_vars__ = set()
     |
     |  __private_attributes__ = {}
     |
     |  __pydantic_complete__ = True
     |
     |  __pydantic_core_schema__ = {'cls': <class 'endpoints.farm.CreateFarmRe...
     |
     |  __pydantic_custom_init__ = False
     |
     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...
     |
     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...
     |
     |  __pydantic_parent_namespace__ = {'APIRouter': <pydantic._internal._mod...
     |
     |  __pydantic_post_init__ = None
     |
     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(
     |      Model...
     |
     |  __pydantic_validator__ = SchemaValidator(title="CreateFarmRequest", va...
     |
     |  __signature__ = <Signature (*, name: str, area: float, unitMeasure: st...
     |
     |  model_computed_fields = {}
     |
     |  model_config = {}
     |
     |  model_fields = {'area': FieldInfo(annotation=float, required=True), 'n...
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from pydantic.main.BaseModel:
     |
     |  __copy__(self) -> 'Self'
     |      Returns a shallow copy of the model.
     |
     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'
     |      Returns a deep copy of the model.
     |
     |  __delattr__(self, item: 'str') -> 'Any'
     |      Implement delattr(self, name).
     |
     |  __eq__(self, other: 'Any') -> 'bool'
     |      Return self==value.
     |
     |  __getattr__(self, item: 'str') -> 'Any'
     |
     |  __getstate__(self) -> 'dict[Any, Any]'
     |      Helper for pickle.
     |
     |  __init__(self, /, **data: 'Any') -> 'None'
     |      Create a new model by parsing and validating input data from keyword arguments.
     |
     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be
     |      validated to form a valid model.
     |
     |      `self` is explicitly positional-only to allow `self` as a field name.
     |
     |  __iter__(self) -> 'TupleGenerator'
     |      So `dict(model)` works.
     |
     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation
     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.
     |
     |  __repr__(self) -> 'str'
     |      Return repr(self).
     |
     |  __repr_args__(self) -> '_repr.ReprArgs'
     |
     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation
     |      Name of the instance's class, used in __repr__.
     |
     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation
     |
     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation
     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.
     |
     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'
     |
     |  __str__(self) -> 'str'
     |      Return str(self).
     |
     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Returns a copy of the model.
     |
     |      !!! warning "Deprecated"
     |          This method is now deprecated; use `model_copy` instead.
     |
     |      If you need `include` or `exclude`, use:
     |
     |      ```py
     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)
     |      data = {**data, **(update or {})}
     |      copied = self.model_validate(data)
     |      ```
     |
     |      Args:
     |          include: Optional set or mapping specifying which fields to include in the copied model.
     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.
     |          update: Optional dictionary of field-value pairs to override field values in the copied model.
     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.
     |
     |      Returns:
     |          A copy of the model with included, excluded and updated fields as specified.
     |
     |  dict(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'
     |
     |  json(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'
     |
     |  model_copy(self, *, update: 'dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#model_copy
     |
     |      Returns a copy of the model.
     |
     |      Args:
     |          update: Values to change/add in the new model. Note: the data is not validated
     |              before creating the new model. You should trust this data.
     |          deep: Set to `True` to make a deep copy of the model.
     |
     |      Returns:
     |          New model instance.
     |
     |  model_dump(self, *, mode: "Literal['json', 'python'] | str" = 'python', include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump
     |
     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.
     |
     |      Args:
     |          mode: The mode in which `to_python` should run.
     |              If mode is 'json', the output will only contain JSON serializable types.
     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.
     |          include: A set of fields to include in the output.
     |          exclude: A set of fields to exclude from the output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to use the field's alias in the dictionary key if defined.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A dictionary representation of the model.
     |
     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'str'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump_json
     |
     |      Generates a JSON representation of the model using Pydantic's `to_json` method.
     |
     |      Args:
     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.
     |          include: Field(s) to include in the JSON output.
     |          exclude: Field(s) to exclude from the JSON output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to serialize using field aliases.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A JSON string representation of the model.
     |
     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'
     |      Override this method to perform additional initialization after `__init__` and `model_construct`.
     |      This is useful if you want to do some validation that requires the entire model to be initialized.
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from pydantic.main.BaseModel:
     |
     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'
     |
     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'
     |      Hook into generating the model's CoreSchema.
     |
     |      Args:
     |          source: The class we are generating a schema for.
     |              This will generally be the same as the `cls` argument if this is a classmethod.
     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.
     |
     |      Returns:
     |          A `pydantic-core` `CoreSchema`.
     |
     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'
     |      Hook into generating the model's JSON schema.
     |
     |      Args:
     |          core_schema: A `pydantic-core` CoreSchema.
     |              You can ignore this argument and call the handler with a new CoreSchema,
     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),
     |              or just call the handler with the original schema.
     |          handler: Call into Pydantic's internal JSON schema generation.
     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema
     |              generation fails.
     |              Since this gets called by `BaseModel.model_json_schema` you can override the
     |              `schema_generator` argument to that function to change JSON schema generation globally
     |              for a type.
     |
     |      Returns:
     |          A JSON schema, as a Python object.
     |
     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'
     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`
     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will
     |      be present when this is called.
     |
     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,
     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that
     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.
     |
     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,
     |      any kwargs passed to the class definition that aren't used internally by pydantic.
     |
     |      Args:
     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally
     |              by pydantic.
     |
     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |
     |  from_orm(obj: 'Any') -> 'Self'
     |
     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |      Creates a new instance of the `Model` class with validated data.
     |
     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.
     |      Default values are respected, but no other validation is performed.
     |
     |      !!! note
     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.
     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`
     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.
     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in
     |          an error if extra values are passed, but they will be ignored.
     |
     |      Args:
     |          _fields_set: The set of field names accepted for the Model instance.
     |          values: Trusted or pre-validated data dictionary.
     |
     |      Returns:
     |          A new instance of the `Model` class with validated data.
     |
     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'
     |      Generates a JSON schema for a model class.
     |
     |      Args:
     |          by_alias: Whether to use attribute aliases or not.
     |          ref_template: The reference template.
     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of
     |              `GenerateJsonSchema` with your desired modifications
     |          mode: The mode in which to generate the schema.
     |
     |      Returns:
     |          The JSON schema for the given model class.
     |
     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'
     |      Compute the class name for parametrizations of generic classes.
     |
     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.
     |
     |      Args:
     |          params: Tuple of types of the class. Given a generic class
     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,
     |              the value `(str, int)` would be passed to `params`.
     |
     |      Returns:
     |          String representing the new class where `params` are passed to `cls` as type variables.
     |
     |      Raises:
     |          TypeError: Raised when trying to generate concrete names for non-generic models.
     |
     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'dict[str, Any] | None' = None) -> 'bool | None'
     |      Try to rebuild the pydantic-core schema for the model.
     |
     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during
     |      the initial attempt to build the schema, and automatic rebuilding fails.
     |
     |      Args:
     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.
     |          raise_errors: Whether to raise errors, defaults to `True`.
     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.
     |          _types_namespace: The types namespace, defaults to `None`.
     |
     |      Returns:
     |          Returns `None` if the schema is already "complete" and rebuilding was not required.
     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.
     |
     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate a pydantic model instance.
     |
     |      Args:
     |          obj: The object to validate.
     |          strict: Whether to enforce types strictly.
     |          from_attributes: Whether to extract data from object attributes.
     |          context: Additional context to pass to the validator.
     |
     |      Raises:
     |          ValidationError: If the object could not be validated.
     |
     |      Returns:
     |          The validated model instance.
     |
     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/json/#json-parsing
     |
     |      Validate the given JSON data against the Pydantic model.
     |
     |      Args:
     |          json_data: The JSON data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |      Raises:
     |          ValueError: If `json_data` is not a JSON string.
     |
     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate the given object with string data against the Pydantic model.
     |
     |      Args:
     |          obj: The object containing string data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  parse_obj(obj: 'Any') -> 'Self'
     |
     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'
     |
     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'
     |
     |  update_forward_refs(**localns: 'Any') -> 'None'
     |
     |  validate(value: 'Any') -> 'Self'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from pydantic.main.BaseModel:
     |
     |  __fields_set__
     |
     |  model_extra
     |      Get extra fields set during validation.
     |
     |      Returns:
     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `"allow"`.
     |
     |  model_fields_set
     |      Returns the set of fields that have been explicitly set on this model instance.
     |
     |      Returns:
     |          A set of strings representing the fields that have been set,
     |              i.e. that were not filled from defaults.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from pydantic.main.BaseModel:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __pydantic_extra__
     |
     |  __pydantic_fields_set__
     |
     |  __pydantic_private__
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from pydantic.main.BaseModel:
     |
     |  __hash__ = None
     |
     |  __pydantic_root_model__ = False

    class ListFarmResponse(pydantic.main.BaseModel)
     |  ListFarmResponse(*, farm_id: int, name: str, area: float, unit_of_measure: str, status: str, role: str) -> None
     |
     |  Modelo de datos para la respuesta al listar fincas.
     |
     |  **Atributos**:
     |  - **farm_id**: ID único de la finca (entero).
     |  - **name**: Nombre de la finca (cadena de texto).
     |  - **area**: Área de la finca (float), representada en la unidad de medida especificada.
     |  - **unit_of_measure**: Unidad de medida del área (cadena de texto).
     |  - **status**: Estado actual de la finca (cadena de texto), por ejemplo, 'Activo' o 'Inactivo'.
     |  - **role**: Rol del usuario en relación a la finca (cadena de texto), como 'Propietario' o 'Administrador'.
     |
     |  Method resolution order:
     |      ListFarmResponse
     |      pydantic.main.BaseModel
     |      builtins.object
     |
     |  Data descriptors defined here:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  __abstractmethods__ = frozenset()
     |
     |  __annotations__ = {'area': <class 'float'>, 'farm_id': <class 'int'>, ...
     |
     |  __class_vars__ = set()
     |
     |  __private_attributes__ = {}
     |
     |  __pydantic_complete__ = True
     |
     |  __pydantic_core_schema__ = {'cls': <class 'endpoints.farm.ListFarmResp...
     |
     |  __pydantic_custom_init__ = False
     |
     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...
     |
     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...
     |
     |  __pydantic_parent_namespace__ = {'APIRouter': <pydantic._internal._mod...
     |
     |  __pydantic_post_init__ = None
     |
     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(
     |      Model...
     |
     |  __pydantic_validator__ = SchemaValidator(title="ListFarmResponse", val...
     |
     |  __signature__ = <Signature (*, farm_id: int, name: str, area: fl...of_...
     |
     |  model_computed_fields = {}
     |
     |  model_config = {}
     |
     |  model_fields = {'area': FieldInfo(annotation=float, required=True), 'f...
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from pydantic.main.BaseModel:
     |
     |  __copy__(self) -> 'Self'
     |      Returns a shallow copy of the model.
     |
     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'
     |      Returns a deep copy of the model.
     |
     |  __delattr__(self, item: 'str') -> 'Any'
     |      Implement delattr(self, name).
     |
     |  __eq__(self, other: 'Any') -> 'bool'
     |      Return self==value.
     |
     |  __getattr__(self, item: 'str') -> 'Any'
     |
     |  __getstate__(self) -> 'dict[Any, Any]'
     |      Helper for pickle.
     |
     |  __init__(self, /, **data: 'Any') -> 'None'
     |      Create a new model by parsing and validating input data from keyword arguments.
     |
     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be
     |      validated to form a valid model.
     |
     |      `self` is explicitly positional-only to allow `self` as a field name.
     |
     |  __iter__(self) -> 'TupleGenerator'
     |      So `dict(model)` works.
     |
     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation
     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.
     |
     |  __repr__(self) -> 'str'
     |      Return repr(self).
     |
     |  __repr_args__(self) -> '_repr.ReprArgs'
     |
     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation
     |      Name of the instance's class, used in __repr__.
     |
     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation
     |
     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation
     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.
     |
     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'
     |
     |  __str__(self) -> 'str'
     |      Return str(self).
     |
     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Returns a copy of the model.
     |
     |      !!! warning "Deprecated"
     |          This method is now deprecated; use `model_copy` instead.
     |
     |      If you need `include` or `exclude`, use:
     |
     |      ```py
     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)
     |      data = {**data, **(update or {})}
     |      copied = self.model_validate(data)
     |      ```
     |
     |      Args:
     |          include: Optional set or mapping specifying which fields to include in the copied model.
     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.
     |          update: Optional dictionary of field-value pairs to override field values in the copied model.
     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.
     |
     |      Returns:
     |          A copy of the model with included, excluded and updated fields as specified.
     |
     |  dict(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'
     |
     |  json(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'
     |
     |  model_copy(self, *, update: 'dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#model_copy
     |
     |      Returns a copy of the model.
     |
     |      Args:
     |          update: Values to change/add in the new model. Note: the data is not validated
     |              before creating the new model. You should trust this data.
     |          deep: Set to `True` to make a deep copy of the model.
     |
     |      Returns:
     |          New model instance.
     |
     |  model_dump(self, *, mode: "Literal['json', 'python'] | str" = 'python', include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump
     |
     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.
     |
     |      Args:
     |          mode: The mode in which `to_python` should run.
     |              If mode is 'json', the output will only contain JSON serializable types.
     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.
     |          include: A set of fields to include in the output.
     |          exclude: A set of fields to exclude from the output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to use the field's alias in the dictionary key if defined.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A dictionary representation of the model.
     |
     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'str'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump_json
     |
     |      Generates a JSON representation of the model using Pydantic's `to_json` method.
     |
     |      Args:
     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.
     |          include: Field(s) to include in the JSON output.
     |          exclude: Field(s) to exclude from the JSON output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to serialize using field aliases.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A JSON string representation of the model.
     |
     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'
     |      Override this method to perform additional initialization after `__init__` and `model_construct`.
     |      This is useful if you want to do some validation that requires the entire model to be initialized.
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from pydantic.main.BaseModel:
     |
     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'
     |
     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'
     |      Hook into generating the model's CoreSchema.
     |
     |      Args:
     |          source: The class we are generating a schema for.
     |              This will generally be the same as the `cls` argument if this is a classmethod.
     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.
     |
     |      Returns:
     |          A `pydantic-core` `CoreSchema`.
     |
     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'
     |      Hook into generating the model's JSON schema.
     |
     |      Args:
     |          core_schema: A `pydantic-core` CoreSchema.
     |              You can ignore this argument and call the handler with a new CoreSchema,
     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),
     |              or just call the handler with the original schema.
     |          handler: Call into Pydantic's internal JSON schema generation.
     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema
     |              generation fails.
     |              Since this gets called by `BaseModel.model_json_schema` you can override the
     |              `schema_generator` argument to that function to change JSON schema generation globally
     |              for a type.
     |
     |      Returns:
     |          A JSON schema, as a Python object.
     |
     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'
     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`
     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will
     |      be present when this is called.
     |
     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,
     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that
     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.
     |
     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,
     |      any kwargs passed to the class definition that aren't used internally by pydantic.
     |
     |      Args:
     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally
     |              by pydantic.
     |
     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |
     |  from_orm(obj: 'Any') -> 'Self'
     |
     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |      Creates a new instance of the `Model` class with validated data.
     |
     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.
     |      Default values are respected, but no other validation is performed.
     |
     |      !!! note
     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.
     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`
     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.
     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in
     |          an error if extra values are passed, but they will be ignored.
     |
     |      Args:
     |          _fields_set: The set of field names accepted for the Model instance.
     |          values: Trusted or pre-validated data dictionary.
     |
     |      Returns:
     |          A new instance of the `Model` class with validated data.
     |
     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'
     |      Generates a JSON schema for a model class.
     |
     |      Args:
     |          by_alias: Whether to use attribute aliases or not.
     |          ref_template: The reference template.
     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of
     |              `GenerateJsonSchema` with your desired modifications
     |          mode: The mode in which to generate the schema.
     |
     |      Returns:
     |          The JSON schema for the given model class.
     |
     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'
     |      Compute the class name for parametrizations of generic classes.
     |
     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.
     |
     |      Args:
     |          params: Tuple of types of the class. Given a generic class
     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,
     |              the value `(str, int)` would be passed to `params`.
     |
     |      Returns:
     |          String representing the new class where `params` are passed to `cls` as type variables.
     |
     |      Raises:
     |          TypeError: Raised when trying to generate concrete names for non-generic models.
     |
     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'dict[str, Any] | None' = None) -> 'bool | None'
     |      Try to rebuild the pydantic-core schema for the model.
     |
     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during
     |      the initial attempt to build the schema, and automatic rebuilding fails.
     |
     |      Args:
     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.
     |          raise_errors: Whether to raise errors, defaults to `True`.
     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.
     |          _types_namespace: The types namespace, defaults to `None`.
     |
     |      Returns:
     |          Returns `None` if the schema is already "complete" and rebuilding was not required.
     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.
     |
     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate a pydantic model instance.
     |
     |      Args:
     |          obj: The object to validate.
     |          strict: Whether to enforce types strictly.
     |          from_attributes: Whether to extract data from object attributes.
     |          context: Additional context to pass to the validator.
     |
     |      Raises:
     |          ValidationError: If the object could not be validated.
     |
     |      Returns:
     |          The validated model instance.
     |
     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/json/#json-parsing
     |
     |      Validate the given JSON data against the Pydantic model.
     |
     |      Args:
     |          json_data: The JSON data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |      Raises:
     |          ValueError: If `json_data` is not a JSON string.
     |
     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate the given object with string data against the Pydantic model.
     |
     |      Args:
     |          obj: The object containing string data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  parse_obj(obj: 'Any') -> 'Self'
     |
     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'
     |
     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'
     |
     |  update_forward_refs(**localns: 'Any') -> 'None'
     |
     |  validate(value: 'Any') -> 'Self'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from pydantic.main.BaseModel:
     |
     |  __fields_set__
     |
     |  model_extra
     |      Get extra fields set during validation.
     |
     |      Returns:
     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `"allow"`.
     |
     |  model_fields_set
     |      Returns the set of fields that have been explicitly set on this model instance.
     |
     |      Returns:
     |          A set of strings representing the fields that have been set,
     |              i.e. that were not filled from defaults.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from pydantic.main.BaseModel:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __pydantic_extra__
     |
     |  __pydantic_fields_set__
     |
     |  __pydantic_private__
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from pydantic.main.BaseModel:
     |
     |  __hash__ = None
     |
     |  __pydantic_root_model__ = False

    class UpdateFarmRequest(pydantic.main.BaseModel)
     |  UpdateFarmRequest(*, farm_id: int, name: str, area: float, unitMeasure: str) -> None
     |
     |  Modelo de datos para la actualización de una finca existente.
     |
     |  **Atributos**:
     |  - **farm_id**: ID de la finca a actualizar (entero). Debe existir una finca con este ID.
     |  - **name**: Nuevo nombre de la finca (cadena de texto). No puede estar vacío ni contener solo espacios.
     |  - **area**: Nueva área de la finca (float). Debe ser un número positivo mayor que cero.
     |  - **unitMeasure**: Nueva unidad de medida del área (cadena de texto). Debe ser una unidad de medida válida como 'hectáreas' o 'metros cuadrados'.
     |
     |  Method resolution order:
     |      UpdateFarmRequest
     |      pydantic.main.BaseModel
     |      builtins.object
     |
     |  Data descriptors defined here:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  __abstractmethods__ = frozenset()
     |
     |  __annotations__ = {'area': <class 'float'>, 'farm_id': <class 'int'>, ...
     |
     |  __class_vars__ = set()
     |
     |  __private_attributes__ = {}
     |
     |  __pydantic_complete__ = True
     |
     |  __pydantic_core_schema__ = {'cls': <class 'endpoints.farm.UpdateFarmRe...
     |
     |  __pydantic_custom_init__ = False
     |
     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...
     |
     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...
     |
     |  __pydantic_parent_namespace__ = {'APIRouter': <pydantic._internal._mod...
     |
     |  __pydantic_post_init__ = None
     |
     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(
     |      Model...
     |
     |  __pydantic_validator__ = SchemaValidator(title="UpdateFarmRequest", va...
     |
     |  __signature__ = <Signature (*, farm_id: int, name: str, area: float, u...
     |
     |  model_computed_fields = {}
     |
     |  model_config = {}
     |
     |  model_fields = {'area': FieldInfo(annotation=float, required=True), 'f...
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from pydantic.main.BaseModel:
     |
     |  __copy__(self) -> 'Self'
     |      Returns a shallow copy of the model.
     |
     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'
     |      Returns a deep copy of the model.
     |
     |  __delattr__(self, item: 'str') -> 'Any'
     |      Implement delattr(self, name).
     |
     |  __eq__(self, other: 'Any') -> 'bool'
     |      Return self==value.
     |
     |  __getattr__(self, item: 'str') -> 'Any'
     |
     |  __getstate__(self) -> 'dict[Any, Any]'
     |      Helper for pickle.
     |
     |  __init__(self, /, **data: 'Any') -> 'None'
     |      Create a new model by parsing and validating input data from keyword arguments.
     |
     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be
     |      validated to form a valid model.
     |
     |      `self` is explicitly positional-only to allow `self` as a field name.
     |
     |  __iter__(self) -> 'TupleGenerator'
     |      So `dict(model)` works.
     |
     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation
     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.
     |
     |  __repr__(self) -> 'str'
     |      Return repr(self).
     |
     |  __repr_args__(self) -> '_repr.ReprArgs'
     |
     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation
     |      Name of the instance's class, used in __repr__.
     |
     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation
     |
     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation
     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.
     |
     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'
     |
     |  __str__(self) -> 'str'
     |      Return str(self).
     |
     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Returns a copy of the model.
     |
     |      !!! warning "Deprecated"
     |          This method is now deprecated; use `model_copy` instead.
     |
     |      If you need `include` or `exclude`, use:
     |
     |      ```py
     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)
     |      data = {**data, **(update or {})}
     |      copied = self.model_validate(data)
     |      ```
     |
     |      Args:
     |          include: Optional set or mapping specifying which fields to include in the copied model.
     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.
     |          update: Optional dictionary of field-value pairs to override field values in the copied model.
     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.
     |
     |      Returns:
     |          A copy of the model with included, excluded and updated fields as specified.
     |
     |  dict(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'
     |
     |  json(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'
     |
     |  model_copy(self, *, update: 'dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#model_copy
     |
     |      Returns a copy of the model.
     |
     |      Args:
     |          update: Values to change/add in the new model. Note: the data is not validated
     |              before creating the new model. You should trust this data.
     |          deep: Set to `True` to make a deep copy of the model.
     |
     |      Returns:
     |          New model instance.
     |
     |  model_dump(self, *, mode: "Literal['json', 'python'] | str" = 'python', include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump
     |
     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.
     |
     |      Args:
     |          mode: The mode in which `to_python` should run.
     |              If mode is 'json', the output will only contain JSON serializable types.
     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.
     |          include: A set of fields to include in the output.
     |          exclude: A set of fields to exclude from the output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to use the field's alias in the dictionary key if defined.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A dictionary representation of the model.
     |
     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'str'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump_json
     |
     |      Generates a JSON representation of the model using Pydantic's `to_json` method.
     |
     |      Args:
     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.
     |          include: Field(s) to include in the JSON output.
     |          exclude: Field(s) to exclude from the JSON output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to serialize using field aliases.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A JSON string representation of the model.
     |
     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'
     |      Override this method to perform additional initialization after `__init__` and `model_construct`.
     |      This is useful if you want to do some validation that requires the entire model to be initialized.
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from pydantic.main.BaseModel:
     |
     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'
     |
     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'
     |      Hook into generating the model's CoreSchema.
     |
     |      Args:
     |          source: The class we are generating a schema for.
     |              This will generally be the same as the `cls` argument if this is a classmethod.
     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.
     |
     |      Returns:
     |          A `pydantic-core` `CoreSchema`.
     |
     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'
     |      Hook into generating the model's JSON schema.
     |
     |      Args:
     |          core_schema: A `pydantic-core` CoreSchema.
     |              You can ignore this argument and call the handler with a new CoreSchema,
     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),
     |              or just call the handler with the original schema.
     |          handler: Call into Pydantic's internal JSON schema generation.
     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema
     |              generation fails.
     |              Since this gets called by `BaseModel.model_json_schema` you can override the
     |              `schema_generator` argument to that function to change JSON schema generation globally
     |              for a type.
     |
     |      Returns:
     |          A JSON schema, as a Python object.
     |
     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'
     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`
     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will
     |      be present when this is called.
     |
     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,
     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that
     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.
     |
     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,
     |      any kwargs passed to the class definition that aren't used internally by pydantic.
     |
     |      Args:
     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally
     |              by pydantic.
     |
     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |
     |  from_orm(obj: 'Any') -> 'Self'
     |
     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |      Creates a new instance of the `Model` class with validated data.
     |
     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.
     |      Default values are respected, but no other validation is performed.
     |
     |      !!! note
     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.
     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`
     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.
     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in
     |          an error if extra values are passed, but they will be ignored.
     |
     |      Args:
     |          _fields_set: The set of field names accepted for the Model instance.
     |          values: Trusted or pre-validated data dictionary.
     |
     |      Returns:
     |          A new instance of the `Model` class with validated data.
     |
     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'
     |      Generates a JSON schema for a model class.
     |
     |      Args:
     |          by_alias: Whether to use attribute aliases or not.
     |          ref_template: The reference template.
     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of
     |              `GenerateJsonSchema` with your desired modifications
     |          mode: The mode in which to generate the schema.
     |
     |      Returns:
     |          The JSON schema for the given model class.
     |
     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'
     |      Compute the class name for parametrizations of generic classes.
     |
     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.
     |
     |      Args:
     |          params: Tuple of types of the class. Given a generic class
     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,
     |              the value `(str, int)` would be passed to `params`.
     |
     |      Returns:
     |          String representing the new class where `params` are passed to `cls` as type variables.
     |
     |      Raises:
     |          TypeError: Raised when trying to generate concrete names for non-generic models.
     |
     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'dict[str, Any] | None' = None) -> 'bool | None'
     |      Try to rebuild the pydantic-core schema for the model.
     |
     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during
     |      the initial attempt to build the schema, and automatic rebuilding fails.
     |
     |      Args:
     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.
     |          raise_errors: Whether to raise errors, defaults to `True`.
     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.
     |          _types_namespace: The types namespace, defaults to `None`.
     |
     |      Returns:
     |          Returns `None` if the schema is already "complete" and rebuilding was not required.
     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.
     |
     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate a pydantic model instance.
     |
     |      Args:
     |          obj: The object to validate.
     |          strict: Whether to enforce types strictly.
     |          from_attributes: Whether to extract data from object attributes.
     |          context: Additional context to pass to the validator.
     |
     |      Raises:
     |          ValidationError: If the object could not be validated.
     |
     |      Returns:
     |          The validated model instance.
     |
     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/json/#json-parsing
     |
     |      Validate the given JSON data against the Pydantic model.
     |
     |      Args:
     |          json_data: The JSON data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |      Raises:
     |          ValueError: If `json_data` is not a JSON string.
     |
     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate the given object with string data against the Pydantic model.
     |
     |      Args:
     |          obj: The object containing string data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  parse_obj(obj: 'Any') -> 'Self'
     |
     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'
     |
     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'
     |
     |  update_forward_refs(**localns: 'Any') -> 'None'
     |
     |  validate(value: 'Any') -> 'Self'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from pydantic.main.BaseModel:
     |
     |  __fields_set__
     |
     |  model_extra
     |      Get extra fields set during validation.
     |
     |      Returns:
     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `"allow"`.
     |
     |  model_fields_set
     |      Returns the set of fields that have been explicitly set on this model instance.
     |
     |      Returns:
     |          A set of strings representing the fields that have been set,
     |              i.e. that were not filled from defaults.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from pydantic.main.BaseModel:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __pydantic_extra__
     |
     |  __pydantic_fields_set__
     |
     |  __pydantic_private__
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from pydantic.main.BaseModel:
     |
     |  __hash__ = None
     |
     |  __pydantic_root_model__ = False

FUNCTIONS
    create_farm(request: endpoints.farm.CreateFarmRequest, session_token: str, db: sqlalchemy.orm.session.Session = Depends(get_db_session))
        Crea una nueva finca y asigna al usuario como propietario.

        **Parámetros**:
        - **request**: Objeto que contiene los datos de la finca (nombre, área, y unidad de medida).
        - **session_token**: Token de sesión del usuario.
        - **db**: Sesión de base de datos, se obtiene automáticamente.

        **Respuestas**:
        - **200 OK**: Finca creada y usuario asignado correctamente.
        - **400 Bad Request**: Si los datos de la finca no son válidos o no se encuentra el estado requerido.
        - **401 Unauthorized**: Si el token de sesión es inválido o el usuario no tiene permisos.
        - **500 Internal Server Error**: Si ocurre un error al intentar crear la finca o asignar el usuario.

        **Ejemplo de respuesta exitosa**:
        {
            "status": "success",
            "message": "Finca creada y usuario asignado correctamente",
            "data": {
                "farm_id": 1,
                "name": "Mi Finca",
                "area": 100.0,
                "unit_of_measure": "hectárea"
            }
        }

        **Ejemplo de respuesta de error**:
        {
            "status": "error",
            "message": "Ya existe una finca activa con el nombre 'Mi Finca'"
        }

    delete_farm(farm_id: int, session_token: str, db: sqlalchemy.orm.session.Session = Depends(get_db_session))
        Elimina (inactiva) una finca específica.

        **Parámetros:**
        - `farm_id` (int): ID de la finca a eliminar.
        - `session_token` (str): Token de sesión del usuario que está haciendo la solicitud.

        **Respuesta exitosa (200):**
        - **Descripción**: Indica que la finca ha sido desactivada correctamente.
        - **Ejemplo de respuesta:**
          ```json
          {
              "status": "success",
              "message": "Finca puesta en estado 'Inactiva' correctamente"
          }
          ```

        **Errores:**
        - **401 Unauthorized**: Si el token de sesión es inválido o el usuario no se encuentra.
        - **400 Bad Request**: Si no se encuentra el estado "Activo" para la finca o para la relación `user_role_farm`.
        - **403 Forbidden**: Si el usuario no tiene permiso para eliminar la finca.
        - **404 Not Found**: Si la finca no se encuentra.
        - **500 Internal Server Error**: Si ocurre un error al desactivar la finca.

        **Ejemplo de respuesta de error:**
        ```json
        {
            "status": "error",
            "message": "No tienes permiso para eliminar esta finca"
        }
        ```

    get_farm(farm_id: int, session_token: str, db: sqlalchemy.orm.session.Session = Depends(get_db_session))
        Obtiene los detalles de una finca específica en la que el usuario tiene permisos.

        **Parámetros:**
        - `farm_id` (int): ID de la finca a consultar.
        - `session_token` (str): Token de sesión del usuario que está haciendo la solicitud.

        **Respuesta exitosa (200):**
        - **Descripción**: Devuelve la información de la finca, incluyendo nombre, área, unidad de medida, estado y rol del usuario en relación a la finca.
        - **Ejemplo de respuesta:**
          ```json
          {
              "status": "success",
              "message": "Finca obtenida exitosamente",
              "data": {
                  "farm": {
                      "farm_id": 1,
                      "name": "Finca Ejemplo",
                      "area": 10.5,
                      "unit_of_measure": "Hectárea",
                      "status": "Activo",
                      "role": "Dueño"
                  }
              }
          }
          ```

        **Errores:**
        - **401 Unauthorized**: Si el token de sesión es inválido o el usuario no se encuentra.
        - **400 Bad Request**: Si no se encuentra el estado "Activo" para la finca o para la relación `user_role_farm`.
        - **404 Not Found**: Si la finca no se encuentra o no pertenece al usuario.

        **Ejemplo de respuesta de error:**
        ```json
        {
            "status": "error",
            "message": "Finca no encontrada o no pertenece al usuario"
        }
        ```

    list_farm(session_token: str, db: sqlalchemy.orm.session.Session = Depends(get_db_session))
        Endpoint para listar las fincas activas asociadas a un usuario autenticado mediante un token de sesión.

        **Parámetros**:
        - **session_token**: Token de sesión proporcionado por el usuario para autenticarse.
        - **db**: Sesión de base de datos proporcionada por FastAPI a través de la dependencia.

        **Descripción**:
        1. **Verificar sesión**:
           Se verifica el token de sesión del usuario. Si no es válido, se devuelve una respuesta de token inválido.

        2. **Obtener estados activos**:
           Se buscan los estados "Activo" tanto para las fincas como para la relación `user_role_farm` que define el rol del usuario en la finca.

        3. **Realizar la consulta**:
           Se realiza una consulta a la base de datos para obtener las fincas activas asociadas al usuario autenticado, filtrando por estado "Activo" tanto en la finca como en la relación `user_role_farm`.

        4. **Construir la respuesta**:
           Se construye una lista de las fincas obtenidas, incluyendo detalles como el nombre de la finca, área, unidad de medida, estado y el rol del usuario.

        **Respuestas**:
        - **200**: Lista de fincas obtenida exitosamente.
        - **400**: Error al obtener los estados activos para las fincas o la relación `user_role_farm`.
        - **500**: Error interno del servidor durante la consulta.

    update_farm(request: endpoints.farm.UpdateFarmRequest, session_token: str, db: sqlalchemy.orm.session.Session = Depends(get_db_session))
        Endpoint para actualizar la información de una finca asociada a un usuario autenticado.

        **Parámetros**:
        - **request**: Objeto de tipo `UpdateFarmRequest` que contiene los datos a actualizar de la finca (nombre, área, unidad de medida).
        - **session_token**: Token de sesión proporcionado por el usuario para autenticarse.
        - **db**: Sesión de base de datos proporcionada por FastAPI a través de la dependencia.

        **Descripción**:
        1. **Verificar sesión**:
           Se verifica el token de sesión del usuario. Si no es válido, se devuelve una respuesta de token inválido.

        2. **Verificar asociación de usuario**:
           Se verifica si el usuario está asociado con la finca activa que desea actualizar y si tiene el rol adecuado para editar.

        3. **Verificar permisos de edición**:
           Se comprueba si el rol del usuario tiene permisos para editar fincas.

        4. **Validaciones de nombre y área**:
           Se valida que el nombre no esté vacío, que no exceda los 50 caracteres y que el área sea mayor que cero. También se valida la unidad de medida.

        5. **Verificar existencia de finca y nombre duplicado**:
           Se busca la finca en la base de datos y se verifica si el nuevo nombre ya está en uso por otra finca del mismo usuario.

        6. **Actualizar finca**:
           Si todas las validaciones son correctas, se actualizan los datos de la finca en la base de datos.

        **Respuestas**:
        - **200**: Finca actualizada correctamente.
        - **400**: Error en las validaciones de nombre, área o permisos de usuario.
        - **500**: Error interno del servidor durante la actualización.

DATA
    Dict = typing.Dict
        A generic version of dict.

    List = typing.List
        A generic version of list.

    logger = <Logger endpoints.farm (INFO)>
    router = <fastapi.routing.APIRouter object>

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\endpoints\farm.py



================================================================================
postgresql://coffeetech:Coffeetech.12@localhost:5432/CoffeeTech
Conexión exitosa a la base de datos
Help on module endpoints.flowering in endpoints:

NAME
    endpoints.flowering

CLASSES
    pydantic.main.BaseModel(builtins.object)
        CreateFloweringRequest
        UpdateFloweringRequest

    class CreateFloweringRequest(pydantic.main.BaseModel)
     |  CreateFloweringRequest(*, plot_id: int, flowering_type_name: str, flowering_date: datetime.date, harvest_date: Optional[datetime.date] = None) -> None
     |
     |  Modelo para la solicitud de creación de floración.
     |
     |  Attributes:
     |      plot_id (int): ID del lote donde se realiza la floración.
     |      flowering_type_name (str): Nombre del tipo de floración.
     |      flowering_date (date): Fecha en que ocurre la floración.
     |      harvest_date (Optional[date]): Fecha en que se realizará la cosecha (opcional).
     |
     |  Method resolution order:
     |      CreateFloweringRequest
     |      pydantic.main.BaseModel
     |      builtins.object
     |
     |  Data descriptors defined here:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  __abstractmethods__ = frozenset()
     |
     |  __annotations__ = {'flowering_date': <class 'datetime.date'>, 'floweri...
     |
     |  __class_vars__ = set()
     |
     |  __private_attributes__ = {}
     |
     |  __pydantic_complete__ = True
     |
     |  __pydantic_core_schema__ = {'cls': <class 'endpoints.flowering.CreateF...
     |
     |  __pydantic_custom_init__ = False
     |
     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...
     |
     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...
     |
     |  __pydantic_parent_namespace__ = {'APIRouter': <pydantic._internal._mod...
     |
     |  __pydantic_post_init__ = None
     |
     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(
     |      Model...
     |
     |  __pydantic_validator__ = SchemaValidator(title="CreateFloweringRequest...
     |
     |  __signature__ = <Signature (*, plot_id: int, flowering_type_name...st_...
     |
     |  model_computed_fields = {}
     |
     |  model_config = {}
     |
     |  model_fields = {'flowering_date': FieldInfo(annotation=date, required=...
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from pydantic.main.BaseModel:
     |
     |  __copy__(self) -> 'Self'
     |      Returns a shallow copy of the model.
     |
     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'
     |      Returns a deep copy of the model.
     |
     |  __delattr__(self, item: 'str') -> 'Any'
     |      Implement delattr(self, name).
     |
     |  __eq__(self, other: 'Any') -> 'bool'
     |      Return self==value.
     |
     |  __getattr__(self, item: 'str') -> 'Any'
     |
     |  __getstate__(self) -> 'dict[Any, Any]'
     |      Helper for pickle.
     |
     |  __init__(self, /, **data: 'Any') -> 'None'
     |      Create a new model by parsing and validating input data from keyword arguments.
     |
     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be
     |      validated to form a valid model.
     |
     |      `self` is explicitly positional-only to allow `self` as a field name.
     |
     |  __iter__(self) -> 'TupleGenerator'
     |      So `dict(model)` works.
     |
     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation
     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.
     |
     |  __repr__(self) -> 'str'
     |      Return repr(self).
     |
     |  __repr_args__(self) -> '_repr.ReprArgs'
     |
     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation
     |      Name of the instance's class, used in __repr__.
     |
     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation
     |
     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation
     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.
     |
     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'
     |
     |  __str__(self) -> 'str'
     |      Return str(self).
     |
     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Returns a copy of the model.
     |
     |      !!! warning "Deprecated"
     |          This method is now deprecated; use `model_copy` instead.
     |
     |      If you need `include` or `exclude`, use:
     |
     |      ```py
     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)
     |      data = {**data, **(update or {})}
     |      copied = self.model_validate(data)
     |      ```
     |
     |      Args:
     |          include: Optional set or mapping specifying which fields to include in the copied model.
     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.
     |          update: Optional dictionary of field-value pairs to override field values in the copied model.
     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.
     |
     |      Returns:
     |          A copy of the model with included, excluded and updated fields as specified.
     |
     |  dict(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'
     |
     |  json(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'
     |
     |  model_copy(self, *, update: 'dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#model_copy
     |
     |      Returns a copy of the model.
     |
     |      Args:
     |          update: Values to change/add in the new model. Note: the data is not validated
     |              before creating the new model. You should trust this data.
     |          deep: Set to `True` to make a deep copy of the model.
     |
     |      Returns:
     |          New model instance.
     |
     |  model_dump(self, *, mode: "Literal['json', 'python'] | str" = 'python', include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump
     |
     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.
     |
     |      Args:
     |          mode: The mode in which `to_python` should run.
     |              If mode is 'json', the output will only contain JSON serializable types.
     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.
     |          include: A set of fields to include in the output.
     |          exclude: A set of fields to exclude from the output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to use the field's alias in the dictionary key if defined.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A dictionary representation of the model.
     |
     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'str'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump_json
     |
     |      Generates a JSON representation of the model using Pydantic's `to_json` method.
     |
     |      Args:
     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.
     |          include: Field(s) to include in the JSON output.
     |          exclude: Field(s) to exclude from the JSON output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to serialize using field aliases.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A JSON string representation of the model.
     |
     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'
     |      Override this method to perform additional initialization after `__init__` and `model_construct`.
     |      This is useful if you want to do some validation that requires the entire model to be initialized.
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from pydantic.main.BaseModel:
     |
     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'
     |
     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'
     |      Hook into generating the model's CoreSchema.
     |
     |      Args:
     |          source: The class we are generating a schema for.
     |              This will generally be the same as the `cls` argument if this is a classmethod.
     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.
     |
     |      Returns:
     |          A `pydantic-core` `CoreSchema`.
     |
     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'
     |      Hook into generating the model's JSON schema.
     |
     |      Args:
     |          core_schema: A `pydantic-core` CoreSchema.
     |              You can ignore this argument and call the handler with a new CoreSchema,
     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),
     |              or just call the handler with the original schema.
     |          handler: Call into Pydantic's internal JSON schema generation.
     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema
     |              generation fails.
     |              Since this gets called by `BaseModel.model_json_schema` you can override the
     |              `schema_generator` argument to that function to change JSON schema generation globally
     |              for a type.
     |
     |      Returns:
     |          A JSON schema, as a Python object.
     |
     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'
     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`
     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will
     |      be present when this is called.
     |
     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,
     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that
     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.
     |
     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,
     |      any kwargs passed to the class definition that aren't used internally by pydantic.
     |
     |      Args:
     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally
     |              by pydantic.
     |
     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |
     |  from_orm(obj: 'Any') -> 'Self'
     |
     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |      Creates a new instance of the `Model` class with validated data.
     |
     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.
     |      Default values are respected, but no other validation is performed.
     |
     |      !!! note
     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.
     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`
     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.
     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in
     |          an error if extra values are passed, but they will be ignored.
     |
     |      Args:
     |          _fields_set: The set of field names accepted for the Model instance.
     |          values: Trusted or pre-validated data dictionary.
     |
     |      Returns:
     |          A new instance of the `Model` class with validated data.
     |
     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'
     |      Generates a JSON schema for a model class.
     |
     |      Args:
     |          by_alias: Whether to use attribute aliases or not.
     |          ref_template: The reference template.
     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of
     |              `GenerateJsonSchema` with your desired modifications
     |          mode: The mode in which to generate the schema.
     |
     |      Returns:
     |          The JSON schema for the given model class.
     |
     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'
     |      Compute the class name for parametrizations of generic classes.
     |
     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.
     |
     |      Args:
     |          params: Tuple of types of the class. Given a generic class
     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,
     |              the value `(str, int)` would be passed to `params`.
     |
     |      Returns:
     |          String representing the new class where `params` are passed to `cls` as type variables.
     |
     |      Raises:
     |          TypeError: Raised when trying to generate concrete names for non-generic models.
     |
     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'dict[str, Any] | None' = None) -> 'bool | None'
     |      Try to rebuild the pydantic-core schema for the model.
     |
     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during
     |      the initial attempt to build the schema, and automatic rebuilding fails.
     |
     |      Args:
     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.
     |          raise_errors: Whether to raise errors, defaults to `True`.
     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.
     |          _types_namespace: The types namespace, defaults to `None`.
     |
     |      Returns:
     |          Returns `None` if the schema is already "complete" and rebuilding was not required.
     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.
     |
     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate a pydantic model instance.
     |
     |      Args:
     |          obj: The object to validate.
     |          strict: Whether to enforce types strictly.
     |          from_attributes: Whether to extract data from object attributes.
     |          context: Additional context to pass to the validator.
     |
     |      Raises:
     |          ValidationError: If the object could not be validated.
     |
     |      Returns:
     |          The validated model instance.
     |
     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/json/#json-parsing
     |
     |      Validate the given JSON data against the Pydantic model.
     |
     |      Args:
     |          json_data: The JSON data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |      Raises:
     |          ValueError: If `json_data` is not a JSON string.
     |
     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate the given object with string data against the Pydantic model.
     |
     |      Args:
     |          obj: The object containing string data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  parse_obj(obj: 'Any') -> 'Self'
     |
     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'
     |
     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'
     |
     |  update_forward_refs(**localns: 'Any') -> 'None'
     |
     |  validate(value: 'Any') -> 'Self'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from pydantic.main.BaseModel:
     |
     |  __fields_set__
     |
     |  model_extra
     |      Get extra fields set during validation.
     |
     |      Returns:
     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `"allow"`.
     |
     |  model_fields_set
     |      Returns the set of fields that have been explicitly set on this model instance.
     |
     |      Returns:
     |          A set of strings representing the fields that have been set,
     |              i.e. that were not filled from defaults.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from pydantic.main.BaseModel:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __pydantic_extra__
     |
     |  __pydantic_fields_set__
     |
     |  __pydantic_private__
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from pydantic.main.BaseModel:
     |
     |  __hash__ = None
     |
     |  __pydantic_root_model__ = False

    class UpdateFloweringRequest(pydantic.main.BaseModel)
     |  UpdateFloweringRequest(*, flowering_id: int, harvest_date: datetime.date) -> None
     |
     |  Modelo para la solicitud de actualización de floración.
     |
     |  Attributes:
     |      flowering_id (int): ID de la floración a actualizar.
     |      harvest_date (date): Nueva fecha de cosecha.
     |
     |  Method resolution order:
     |      UpdateFloweringRequest
     |      pydantic.main.BaseModel
     |      builtins.object
     |
     |  Data descriptors defined here:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  __abstractmethods__ = frozenset()
     |
     |  __annotations__ = {'flowering_id': <class 'int'>, 'harvest_date': <cla...
     |
     |  __class_vars__ = set()
     |
     |  __private_attributes__ = {}
     |
     |  __pydantic_complete__ = True
     |
     |  __pydantic_core_schema__ = {'cls': <class 'endpoints.flowering.UpdateF...
     |
     |  __pydantic_custom_init__ = False
     |
     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...
     |
     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...
     |
     |  __pydantic_parent_namespace__ = {'APIRouter': <pydantic._internal._mod...
     |
     |  __pydantic_post_init__ = None
     |
     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(
     |      Model...
     |
     |  __pydantic_validator__ = SchemaValidator(title="UpdateFloweringRequest...
     |
     |  __signature__ = <Signature (*, flowering_id: int, harvest_date: dateti...
     |
     |  model_computed_fields = {}
     |
     |  model_config = {}
     |
     |  model_fields = {'flowering_id': FieldInfo(annotation=int, required=Tru...
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from pydantic.main.BaseModel:
     |
     |  __copy__(self) -> 'Self'
     |      Returns a shallow copy of the model.
     |
     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'
     |      Returns a deep copy of the model.
     |
     |  __delattr__(self, item: 'str') -> 'Any'
     |      Implement delattr(self, name).
     |
     |  __eq__(self, other: 'Any') -> 'bool'
     |      Return self==value.
     |
     |  __getattr__(self, item: 'str') -> 'Any'
     |
     |  __getstate__(self) -> 'dict[Any, Any]'
     |      Helper for pickle.
     |
     |  __init__(self, /, **data: 'Any') -> 'None'
     |      Create a new model by parsing and validating input data from keyword arguments.
     |
     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be
     |      validated to form a valid model.
     |
     |      `self` is explicitly positional-only to allow `self` as a field name.
     |
     |  __iter__(self) -> 'TupleGenerator'
     |      So `dict(model)` works.
     |
     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation
     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.
     |
     |  __repr__(self) -> 'str'
     |      Return repr(self).
     |
     |  __repr_args__(self) -> '_repr.ReprArgs'
     |
     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation
     |      Name of the instance's class, used in __repr__.
     |
     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation
     |
     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation
     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.
     |
     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'
     |
     |  __str__(self) -> 'str'
     |      Return str(self).
     |
     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Returns a copy of the model.
     |
     |      !!! warning "Deprecated"
     |          This method is now deprecated; use `model_copy` instead.
     |
     |      If you need `include` or `exclude`, use:
     |
     |      ```py
     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)
     |      data = {**data, **(update or {})}
     |      copied = self.model_validate(data)
     |      ```
     |
     |      Args:
     |          include: Optional set or mapping specifying which fields to include in the copied model.
     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.
     |          update: Optional dictionary of field-value pairs to override field values in the copied model.
     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.
     |
     |      Returns:
     |          A copy of the model with included, excluded and updated fields as specified.
     |
     |  dict(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'
     |
     |  json(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'
     |
     |  model_copy(self, *, update: 'dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#model_copy
     |
     |      Returns a copy of the model.
     |
     |      Args:
     |          update: Values to change/add in the new model. Note: the data is not validated
     |              before creating the new model. You should trust this data.
     |          deep: Set to `True` to make a deep copy of the model.
     |
     |      Returns:
     |          New model instance.
     |
     |  model_dump(self, *, mode: "Literal['json', 'python'] | str" = 'python', include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump
     |
     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.
     |
     |      Args:
     |          mode: The mode in which `to_python` should run.
     |              If mode is 'json', the output will only contain JSON serializable types.
     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.
     |          include: A set of fields to include in the output.
     |          exclude: A set of fields to exclude from the output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to use the field's alias in the dictionary key if defined.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A dictionary representation of the model.
     |
     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'str'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump_json
     |
     |      Generates a JSON representation of the model using Pydantic's `to_json` method.
     |
     |      Args:
     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.
     |          include: Field(s) to include in the JSON output.
     |          exclude: Field(s) to exclude from the JSON output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to serialize using field aliases.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A JSON string representation of the model.
     |
     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'
     |      Override this method to perform additional initialization after `__init__` and `model_construct`.
     |      This is useful if you want to do some validation that requires the entire model to be initialized.
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from pydantic.main.BaseModel:
     |
     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'
     |
     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'
     |      Hook into generating the model's CoreSchema.
     |
     |      Args:
     |          source: The class we are generating a schema for.
     |              This will generally be the same as the `cls` argument if this is a classmethod.
     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.
     |
     |      Returns:
     |          A `pydantic-core` `CoreSchema`.
     |
     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'
     |      Hook into generating the model's JSON schema.
     |
     |      Args:
     |          core_schema: A `pydantic-core` CoreSchema.
     |              You can ignore this argument and call the handler with a new CoreSchema,
     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),
     |              or just call the handler with the original schema.
     |          handler: Call into Pydantic's internal JSON schema generation.
     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema
     |              generation fails.
     |              Since this gets called by `BaseModel.model_json_schema` you can override the
     |              `schema_generator` argument to that function to change JSON schema generation globally
     |              for a type.
     |
     |      Returns:
     |          A JSON schema, as a Python object.
     |
     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'
     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`
     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will
     |      be present when this is called.
     |
     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,
     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that
     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.
     |
     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,
     |      any kwargs passed to the class definition that aren't used internally by pydantic.
     |
     |      Args:
     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally
     |              by pydantic.
     |
     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |
     |  from_orm(obj: 'Any') -> 'Self'
     |
     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |      Creates a new instance of the `Model` class with validated data.
     |
     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.
     |      Default values are respected, but no other validation is performed.
     |
     |      !!! note
     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.
     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`
     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.
     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in
     |          an error if extra values are passed, but they will be ignored.
     |
     |      Args:
     |          _fields_set: The set of field names accepted for the Model instance.
     |          values: Trusted or pre-validated data dictionary.
     |
     |      Returns:
     |          A new instance of the `Model` class with validated data.
     |
     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'
     |      Generates a JSON schema for a model class.
     |
     |      Args:
     |          by_alias: Whether to use attribute aliases or not.
     |          ref_template: The reference template.
     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of
     |              `GenerateJsonSchema` with your desired modifications
     |          mode: The mode in which to generate the schema.
     |
     |      Returns:
     |          The JSON schema for the given model class.
     |
     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'
     |      Compute the class name for parametrizations of generic classes.
     |
     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.
     |
     |      Args:
     |          params: Tuple of types of the class. Given a generic class
     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,
     |              the value `(str, int)` would be passed to `params`.
     |
     |      Returns:
     |          String representing the new class where `params` are passed to `cls` as type variables.
     |
     |      Raises:
     |          TypeError: Raised when trying to generate concrete names for non-generic models.
     |
     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'dict[str, Any] | None' = None) -> 'bool | None'
     |      Try to rebuild the pydantic-core schema for the model.
     |
     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during
     |      the initial attempt to build the schema, and automatic rebuilding fails.
     |
     |      Args:
     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.
     |          raise_errors: Whether to raise errors, defaults to `True`.
     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.
     |          _types_namespace: The types namespace, defaults to `None`.
     |
     |      Returns:
     |          Returns `None` if the schema is already "complete" and rebuilding was not required.
     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.
     |
     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate a pydantic model instance.
     |
     |      Args:
     |          obj: The object to validate.
     |          strict: Whether to enforce types strictly.
     |          from_attributes: Whether to extract data from object attributes.
     |          context: Additional context to pass to the validator.
     |
     |      Raises:
     |          ValidationError: If the object could not be validated.
     |
     |      Returns:
     |          The validated model instance.
     |
     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/json/#json-parsing
     |
     |      Validate the given JSON data against the Pydantic model.
     |
     |      Args:
     |          json_data: The JSON data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |      Raises:
     |          ValueError: If `json_data` is not a JSON string.
     |
     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate the given object with string data against the Pydantic model.
     |
     |      Args:
     |          obj: The object containing string data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  parse_obj(obj: 'Any') -> 'Self'
     |
     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'
     |
     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'
     |
     |  update_forward_refs(**localns: 'Any') -> 'None'
     |
     |  validate(value: 'Any') -> 'Self'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from pydantic.main.BaseModel:
     |
     |  __fields_set__
     |
     |  model_extra
     |      Get extra fields set during validation.
     |
     |      Returns:
     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `"allow"`.
     |
     |  model_fields_set
     |      Returns the set of fields that have been explicitly set on this model instance.
     |
     |      Returns:
     |          A set of strings representing the fields that have been set,
     |              i.e. that were not filled from defaults.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from pydantic.main.BaseModel:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __pydantic_extra__
     |
     |  __pydantic_fields_set__
     |
     |  __pydantic_private__
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from pydantic.main.BaseModel:
     |
     |  __hash__ = None
     |
     |  __pydantic_root_model__ = False

FUNCTIONS
    create_flowering(request: endpoints.flowering.CreateFloweringRequest, session_token: str, db: sqlalchemy.orm.session.Session = Depends(get_db_session))
        Endpoint para crear una nueva floración.

        Este endpoint permite agregar una nueva floración a un lote específico.
        Requiere un token de sesión para verificar la identidad del usuario y
        asegura que el usuario tenga permisos adecuados para realizar esta acción.

        Parameters:
            request (CreateFloweringRequest): Modelo de solicitud que contiene
                los detalles de la floración a crear.
            session_token (str): Token de sesión del usuario.
            db (Session, optional): Sesión de la base de datos, inyectada por
                FastAPI.

        Returns:
            dict: Un diccionario que indica el resultado de la operación. Puede
                incluir el ID de la floración creada, el estado y otros
                detalles.

        Raises:
            HTTPException: Si ocurre un error en el proceso de creación.

        **Ejemplo de solicitud:**

        ```json
        {
            "plot_id": 1,
            "flowering_type_name": "Floración A",
            "flowering_date": "2024-10-01",
            "harvest_date": "2024-12-15"
        }
        ```

        **Ejemplo de respuesta exitosa:**

        ```json
        {
            "status": "success",
            "message": "Floración creada correctamente",
            "data": {
                "flowering_id": 123,
                "plot_id": 1,
                "flowering_date": "2024-10-01",
                "harvest_date": "2024-12-15",
                "status": "Activa",
                "flowering_type_name": "Floración A"
            }
        }
        ```

        **Ejemplo de respuesta de error:**

        ```json
        {
            "status": "error",
            "message": "La fecha de floración no puede ser en el futuro"
        }
        ```

    delete_flowering(flowering_id: int, session_token: str, db: sqlalchemy.orm.session.Session = Depends(get_db_session))
        Elimina (desactiva) una floración activa.

        **Parámetros**:
        - **flowering_id**: ID de la floración a eliminar.
        - **session_token**: Token de sesión del usuario.
        - **db**: Sesión de base de datos, se obtiene automáticamente.

        **Respuestas**:
        - **200 OK**: Floración eliminada correctamente.
        - **400 Bad Request**: Si los estados necesarios no se encuentran o son inválidos.
        - **401 Unauthorized**: Si el token de sesión es inválido o el usuario no tiene permisos.
        - **404 Not Found**: Si la floración no existe o no está activa.
        - **500 Internal Server Error**: Si ocurre un error al intentar eliminar la floración.

        **Ejemplo de respuesta exitosa**:
        {
            "status": "success",
            "message": "Floración eliminada correctamente"
        }

        **Ejemplo de respuesta de error**:
        {
            "status": "error",
            "message": "No tienes permiso para eliminar esta floración"
        }

    get_active_flowerings(plot_id: int, session_token: str, db: sqlalchemy.orm.session.Session = Depends(get_db_session))
        Obtiene las floraciones activas para un lote específico.

        **Parámetros**:
        - **plot_id**: ID del lote para el cual se obtendrán las floraciones activas.
        - **session_token**: Token de sesión del usuario.
        - **db**: Sesión de base de datos, se obtiene automáticamente.

        **Respuestas**:
        - **200 OK**: Floraciones activas obtenidas correctamente.
        - **400 Bad Request**: Si los estados necesarios no se encuentran o son inválidos.
        - **401 Unauthorized**: Si el token de sesión es inválido o el usuario no tiene permisos.
        - **404 Not Found**: Si el lote no existe o no está activo.
        - **500 Internal Server Error**: Si ocurre un error al intentar obtener las floraciones.

        **Ejemplo de respuesta exitosa**:
        {
            "status": "success",
            "message": "Floraciones activas obtenidas exitosamente",
            "data": {
                "flowerings": [
                    {
                        "flowering_id": 1,
                        "flowering_type_name": "Floración Temprana",
                        "flowering_date": "2024-01-01",
                        "status": "Activa"
                    },
                    ...
                ]
            }
        }

    get_flowering_history(plot_id: int, session_token: str, db: sqlalchemy.orm.session.Session = Depends(get_db_session))
        Obtiene el historial de floraciones cosechadas para un lote específico.

        **Parámetros**:
        - **plot_id**: ID del lote para el cual se obtendrá el historial de floraciones.
        - **session_token**: Token de sesión del usuario.
        - **db**: Sesión de base de datos, se obtiene automáticamente.

        **Respuestas**:
        - **200 OK**: Historial de floraciones obtenido correctamente.
        - **400 Bad Request**: Si los estados necesarios no se encuentran o son inválidos.
        - **401 Unauthorized**: Si el token de sesión es inválido o el usuario no tiene permisos.
        - **404 Not Found**: Si el lote no existe o no está activo.
        - **500 Internal Server Error**: Si ocurre un error al intentar obtener el historial.

        **Ejemplo de respuesta exitosa**:
        {
            "status": "success",
            "message": "Historial de floraciones obtenido exitosamente",
            "data": {
                "flowerings": [
                    {
                        "flowering_id": 1,
                        "flowering_type_name": "Floración Temprana",
                        "flowering_date": "2023-05-01",
                        "harvest_date": "2023-08-01",
                        "status": "Cosechada"
                    },
                    ...
                ]
            }
        }

    get_recommendations(flowering_id: int, session_token: str, db: sqlalchemy.orm.session.Session = Depends(get_db_session))
        Obtiene recomendaciones basadas en la floración dada.

        **Parámetros**:
        - **flowering_id**: ID de la floración para la cual se obtendrán recomendaciones.
        - **session_token**: Token de sesión del usuario.

        - **db**: Sesión de base de datos, se obtiene automáticamente.

        **Respuestas**:
        - **200 OK**: Recomendaciones obtenidas exitosamente.
        - **400 Bad Request**: Si no se encuentran los estados necesarios.
        - **401 Unauthorized**: Si el token de sesión es inválido o el usuario no tiene permisos.
        - **404 Not Found**: Si la floración no existe o no está activa.

        **Ejemplo de respuesta exitosa**:
        {
            "status": "success",
            "message": "Recomendaciones obtenidas exitosamente",
            "data": {
                "recommendations": {
                    "flowering_id": 1,
                    "flowering_type_name": "Tipo de floración",
                    "flowering_date": "2024-01-01",
                    "tasks": [
                        {
                            "task": "Detección de enfermedades",
                            "start_date": "2024-03-01",
                            "end_date": "2024-03-08",
                            "programar": "Sí"
                        },
                        ...
                    ]
                }
            }
        }

    update_flowering(request: endpoints.flowering.UpdateFloweringRequest, session_token: str, db: sqlalchemy.orm.session.Session = Depends(get_db_session))
        Actualiza una floración existente.

        **Parámetros**:
        - **request**: Un objeto `UpdateFloweringRequest` que contiene la información de la floración a actualizar.
            - **flowering_id**: ID de la floración a actualizar.
            - **harvest_date**: Nueva fecha de cosecha.

        - **session_token**: Token de sesión del usuario.

        - **db**: Sesión de base de datos, se obtiene automáticamente.

        **Respuestas**:
        - **200 OK**: Floración actualizada correctamente.
        - **400 Bad Request**: Si no se encuentran los estados necesarios o si las fechas son inválidas.
        - **401 Unauthorized**: Si el token de sesión es inválido o el usuario no tiene permisos.
        - **404 Not Found**: Si la floración no existe o no está activa.
        - **500 Internal Server Error**: Si ocurre un error al intentar actualizar la floración.

        **Ejemplo de respuesta exitosa**:
        {
            "status": "success",
            "message": "Floración actualizada correctamente",
            "data": {
                "flowering_id": 1,
                "plot_id": 10,
                "flowering_date": "2024-01-01",
                "harvest_date": "2024-04-01",
                "status": "Cosechada",
                "flowering_type_name": "Tipo de floración"
            }
        }

DATA
    Dict = typing.Dict
        A generic version of dict.

    List = typing.List
        A generic version of list.

    Optional = typing.Optional
        Optional[X] is equivalent to Union[X, None].

    logger = <Logger endpoints.flowering (INFO)>
    router = <fastapi.routing.APIRouter object>

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\endpoints\flowering.py



================================================================================
postgresql://coffeetech:Coffeetech.12@localhost:5432/CoffeeTech
Conexión exitosa a la base de datos
Help on module endpoints.invitation in endpoints:

NAME
    endpoints.invitation

CLASSES
    pydantic.main.BaseModel(builtins.object)
        InvitationCreate

    class InvitationCreate(pydantic.main.BaseModel)
     |  InvitationCreate(*, email: pydantic.networks.EmailStr, suggested_role: str, farm_id: int) -> None
     |
     |  Modelo para la creación de una invitación.
     |
     |  Attributes:
     |      email (EmailStr): Dirección de correo electrónico del usuario a invitar.
     |      suggested_role (str): Rol sugerido para el usuario invitado.
     |      farm_id (int): Identificador de la finca a la que se invita.
     |
     |  Method resolution order:
     |      InvitationCreate
     |      pydantic.main.BaseModel
     |      builtins.object
     |
     |  Data descriptors defined here:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  __abstractmethods__ = frozenset()
     |
     |  __annotations__ = {'email': <class 'pydantic.networks.EmailStr'>, 'far...
     |
     |  __class_vars__ = set()
     |
     |  __private_attributes__ = {}
     |
     |  __pydantic_complete__ = True
     |
     |  __pydantic_core_schema__ = {'cls': <class 'endpoints.invitation.Invita...
     |
     |  __pydantic_custom_init__ = False
     |
     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...
     |
     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...
     |
     |  __pydantic_parent_namespace__ = {'APIRouter': <pydantic._internal._mod...
     |
     |  __pydantic_post_init__ = None
     |
     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(
     |      Model...
     |
     |  __pydantic_validator__ = SchemaValidator(title="InvitationCreate", val...
     |
     |  __signature__ = <Signature (*, email: pydantic.networks.EmailStr, sugg...
     |
     |  model_computed_fields = {}
     |
     |  model_config = {}
     |
     |  model_fields = {'email': FieldInfo(annotation=EmailStr, required=True)...
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from pydantic.main.BaseModel:
     |
     |  __copy__(self) -> 'Self'
     |      Returns a shallow copy of the model.
     |
     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'
     |      Returns a deep copy of the model.
     |
     |  __delattr__(self, item: 'str') -> 'Any'
     |      Implement delattr(self, name).
     |
     |  __eq__(self, other: 'Any') -> 'bool'
     |      Return self==value.
     |
     |  __getattr__(self, item: 'str') -> 'Any'
     |
     |  __getstate__(self) -> 'dict[Any, Any]'
     |      Helper for pickle.
     |
     |  __init__(self, /, **data: 'Any') -> 'None'
     |      Create a new model by parsing and validating input data from keyword arguments.
     |
     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be
     |      validated to form a valid model.
     |
     |      `self` is explicitly positional-only to allow `self` as a field name.
     |
     |  __iter__(self) -> 'TupleGenerator'
     |      So `dict(model)` works.
     |
     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation
     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.
     |
     |  __repr__(self) -> 'str'
     |      Return repr(self).
     |
     |  __repr_args__(self) -> '_repr.ReprArgs'
     |
     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation
     |      Name of the instance's class, used in __repr__.
     |
     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation
     |
     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation
     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.
     |
     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'
     |
     |  __str__(self) -> 'str'
     |      Return str(self).
     |
     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Returns a copy of the model.
     |
     |      !!! warning "Deprecated"
     |          This method is now deprecated; use `model_copy` instead.
     |
     |      If you need `include` or `exclude`, use:
     |
     |      ```py
     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)
     |      data = {**data, **(update or {})}
     |      copied = self.model_validate(data)
     |      ```
     |
     |      Args:
     |          include: Optional set or mapping specifying which fields to include in the copied model.
     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.
     |          update: Optional dictionary of field-value pairs to override field values in the copied model.
     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.
     |
     |      Returns:
     |          A copy of the model with included, excluded and updated fields as specified.
     |
     |  dict(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'
     |
     |  json(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'
     |
     |  model_copy(self, *, update: 'dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#model_copy
     |
     |      Returns a copy of the model.
     |
     |      Args:
     |          update: Values to change/add in the new model. Note: the data is not validated
     |              before creating the new model. You should trust this data.
     |          deep: Set to `True` to make a deep copy of the model.
     |
     |      Returns:
     |          New model instance.
     |
     |  model_dump(self, *, mode: "Literal['json', 'python'] | str" = 'python', include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump
     |
     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.
     |
     |      Args:
     |          mode: The mode in which `to_python` should run.
     |              If mode is 'json', the output will only contain JSON serializable types.
     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.
     |          include: A set of fields to include in the output.
     |          exclude: A set of fields to exclude from the output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to use the field's alias in the dictionary key if defined.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A dictionary representation of the model.
     |
     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'str'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump_json
     |
     |      Generates a JSON representation of the model using Pydantic's `to_json` method.
     |
     |      Args:
     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.
     |          include: Field(s) to include in the JSON output.
     |          exclude: Field(s) to exclude from the JSON output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to serialize using field aliases.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A JSON string representation of the model.
     |
     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'
     |      Override this method to perform additional initialization after `__init__` and `model_construct`.
     |      This is useful if you want to do some validation that requires the entire model to be initialized.
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from pydantic.main.BaseModel:
     |
     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'
     |
     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'
     |      Hook into generating the model's CoreSchema.
     |
     |      Args:
     |          source: The class we are generating a schema for.
     |              This will generally be the same as the `cls` argument if this is a classmethod.
     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.
     |
     |      Returns:
     |          A `pydantic-core` `CoreSchema`.
     |
     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'
     |      Hook into generating the model's JSON schema.
     |
     |      Args:
     |          core_schema: A `pydantic-core` CoreSchema.
     |              You can ignore this argument and call the handler with a new CoreSchema,
     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),
     |              or just call the handler with the original schema.
     |          handler: Call into Pydantic's internal JSON schema generation.
     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema
     |              generation fails.
     |              Since this gets called by `BaseModel.model_json_schema` you can override the
     |              `schema_generator` argument to that function to change JSON schema generation globally
     |              for a type.
     |
     |      Returns:
     |          A JSON schema, as a Python object.
     |
     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'
     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`
     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will
     |      be present when this is called.
     |
     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,
     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that
     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.
     |
     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,
     |      any kwargs passed to the class definition that aren't used internally by pydantic.
     |
     |      Args:
     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally
     |              by pydantic.
     |
     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |
     |  from_orm(obj: 'Any') -> 'Self'
     |
     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |      Creates a new instance of the `Model` class with validated data.
     |
     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.
     |      Default values are respected, but no other validation is performed.
     |
     |      !!! note
     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.
     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`
     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.
     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in
     |          an error if extra values are passed, but they will be ignored.
     |
     |      Args:
     |          _fields_set: The set of field names accepted for the Model instance.
     |          values: Trusted or pre-validated data dictionary.
     |
     |      Returns:
     |          A new instance of the `Model` class with validated data.
     |
     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'
     |      Generates a JSON schema for a model class.
     |
     |      Args:
     |          by_alias: Whether to use attribute aliases or not.
     |          ref_template: The reference template.
     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of
     |              `GenerateJsonSchema` with your desired modifications
     |          mode: The mode in which to generate the schema.
     |
     |      Returns:
     |          The JSON schema for the given model class.
     |
     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'
     |      Compute the class name for parametrizations of generic classes.
     |
     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.
     |
     |      Args:
     |          params: Tuple of types of the class. Given a generic class
     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,
     |              the value `(str, int)` would be passed to `params`.
     |
     |      Returns:
     |          String representing the new class where `params` are passed to `cls` as type variables.
     |
     |      Raises:
     |          TypeError: Raised when trying to generate concrete names for non-generic models.
     |
     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'dict[str, Any] | None' = None) -> 'bool | None'
     |      Try to rebuild the pydantic-core schema for the model.
     |
     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during
     |      the initial attempt to build the schema, and automatic rebuilding fails.
     |
     |      Args:
     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.
     |          raise_errors: Whether to raise errors, defaults to `True`.
     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.
     |          _types_namespace: The types namespace, defaults to `None`.
     |
     |      Returns:
     |          Returns `None` if the schema is already "complete" and rebuilding was not required.
     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.
     |
     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate a pydantic model instance.
     |
     |      Args:
     |          obj: The object to validate.
     |          strict: Whether to enforce types strictly.
     |          from_attributes: Whether to extract data from object attributes.
     |          context: Additional context to pass to the validator.
     |
     |      Raises:
     |          ValidationError: If the object could not be validated.
     |
     |      Returns:
     |          The validated model instance.
     |
     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/json/#json-parsing
     |
     |      Validate the given JSON data against the Pydantic model.
     |
     |      Args:
     |          json_data: The JSON data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |      Raises:
     |          ValueError: If `json_data` is not a JSON string.
     |
     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate the given object with string data against the Pydantic model.
     |
     |      Args:
     |          obj: The object containing string data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  parse_obj(obj: 'Any') -> 'Self'
     |
     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'
     |
     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'
     |
     |  update_forward_refs(**localns: 'Any') -> 'None'
     |
     |  validate(value: 'Any') -> 'Self'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from pydantic.main.BaseModel:
     |
     |  __fields_set__
     |
     |  model_extra
     |      Get extra fields set during validation.
     |
     |      Returns:
     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `"allow"`.
     |
     |  model_fields_set
     |      Returns the set of fields that have been explicitly set on this model instance.
     |
     |      Returns:
     |          A set of strings representing the fields that have been set,
     |              i.e. that were not filled from defaults.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from pydantic.main.BaseModel:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __pydantic_extra__
     |
     |  __pydantic_fields_set__
     |
     |  __pydantic_private__
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from pydantic.main.BaseModel:
     |
     |  __hash__ = None
     |
     |  __pydantic_root_model__ = False

FUNCTIONS
    create_invitation(invitation_data: endpoints.invitation.InvitationCreate, session_token: str, db: sqlalchemy.orm.session.Session = Depends(get_db_session))
        Crea una invitación para un usuario a una finca.

        Args:
            invitation_data (InvitationCreate): Datos de la invitación a crear.
            session_token (str): Token de sesión del usuario autenticado.
            db (Session): Sesión de base de datos.

        Returns:
            JSONResponse: Respuesta con el resultado de la creación de la invitación.

    has_permission(user: models.models.User, permission_name: str, db: sqlalchemy.orm.session.Session) -> bool
        Verifica si el usuario tiene un permiso específico.

        Args:
            user (User): Usuario a verificar.
            permission_name (str): Nombre del permiso a verificar.
            db (Session): Sesión de base de datos.

        Returns:
            bool: True si el usuario tiene el permiso, False en caso contrario.

    respond_invitation(invitation_id: int, action: str, session_token: str, db: sqlalchemy.orm.session.Session = Depends(get_db_session))
        Responde a una invitación con las acciones 'accept' o 'reject'.

        Parámetros:
        - invitation_id: ID de la invitación a procesar.
        - action: La acción a realizar ('accept' o 'reject').
        - session_token: Token de sesión del usuario autenticado.
        - db: Sesión de la base de datos (inyectada mediante Depends).

        Retorna:
        - Un mensaje de éxito o error en función de la acción realizada.

DATA
    Dict = typing.Dict
        A generic version of dict.

    List = typing.List
        A generic version of list.

    logger = <Logger endpoints.invitation (INFO)>
    router = <fastapi.routing.APIRouter object>

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\endpoints\invitation.py



================================================================================
postgresql://coffeetech:Coffeetech.12@localhost:5432/CoffeeTech
Conexión exitosa a la base de datos
Help on module endpoints.notification in endpoints:

NAME
    endpoints.notification

CLASSES
    pydantic.main.BaseModel(builtins.object)
        NotificationResponse

    class NotificationResponse(pydantic.main.BaseModel)
     |  NotificationResponse(*, notifications_id: int, message: Optional[str], date: datetime.datetime, notification_type: Optional[str], invitation_id: Optional[int], farm_id: Optional[int], reminder_time: Optional[datetime.datetime], status: Optional[str]) -> None
     |
     |  # Pydantic model para la respuesta de notificación
     |
     |  Method resolution order:
     |      NotificationResponse
     |      pydantic.main.BaseModel
     |      builtins.object
     |
     |  Data descriptors defined here:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  Config = <class 'endpoints.notification.NotificationResponse.Config'>
     |
     |  __abstractmethods__ = frozenset()
     |
     |  __annotations__ = {'date': <class 'datetime.datetime'>, 'farm_id': typ...
     |
     |  __class_vars__ = set()
     |
     |  __private_attributes__ = {}
     |
     |  __pydantic_complete__ = True
     |
     |  __pydantic_core_schema__ = {'cls': <class 'endpoints.notification.Noti...
     |
     |  __pydantic_custom_init__ = False
     |
     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...
     |
     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...
     |
     |  __pydantic_parent_namespace__ = {'APIRouter': <pydantic._internal._mod...
     |
     |  __pydantic_post_init__ = None
     |
     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(
     |      Model...
     |
     |  __pydantic_validator__ = SchemaValidator(title="NotificationResponse",...
     |
     |  __signature__ = <Signature (*, notifications_id: int, message: O...tet...
     |
     |  model_computed_fields = {}
     |
     |  model_config = {'from_attributes': True, 'json_encoders': {<class 'dat...
     |
     |  model_fields = {'date': FieldInfo(annotation=datetime, required=True),...
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from pydantic.main.BaseModel:
     |
     |  __copy__(self) -> 'Self'
     |      Returns a shallow copy of the model.
     |
     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'
     |      Returns a deep copy of the model.
     |
     |  __delattr__(self, item: 'str') -> 'Any'
     |      Implement delattr(self, name).
     |
     |  __eq__(self, other: 'Any') -> 'bool'
     |      Return self==value.
     |
     |  __getattr__(self, item: 'str') -> 'Any'
     |
     |  __getstate__(self) -> 'dict[Any, Any]'
     |      Helper for pickle.
     |
     |  __init__(self, /, **data: 'Any') -> 'None'
     |      Create a new model by parsing and validating input data from keyword arguments.
     |
     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be
     |      validated to form a valid model.
     |
     |      `self` is explicitly positional-only to allow `self` as a field name.
     |
     |  __iter__(self) -> 'TupleGenerator'
     |      So `dict(model)` works.
     |
     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation
     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.
     |
     |  __repr__(self) -> 'str'
     |      Return repr(self).
     |
     |  __repr_args__(self) -> '_repr.ReprArgs'
     |
     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation
     |      Name of the instance's class, used in __repr__.
     |
     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation
     |
     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation
     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.
     |
     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'
     |
     |  __str__(self) -> 'str'
     |      Return str(self).
     |
     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Returns a copy of the model.
     |
     |      !!! warning "Deprecated"
     |          This method is now deprecated; use `model_copy` instead.
     |
     |      If you need `include` or `exclude`, use:
     |
     |      ```py
     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)
     |      data = {**data, **(update or {})}
     |      copied = self.model_validate(data)
     |      ```
     |
     |      Args:
     |          include: Optional set or mapping specifying which fields to include in the copied model.
     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.
     |          update: Optional dictionary of field-value pairs to override field values in the copied model.
     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.
     |
     |      Returns:
     |          A copy of the model with included, excluded and updated fields as specified.
     |
     |  dict(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'
     |
     |  json(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'
     |
     |  model_copy(self, *, update: 'dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#model_copy
     |
     |      Returns a copy of the model.
     |
     |      Args:
     |          update: Values to change/add in the new model. Note: the data is not validated
     |              before creating the new model. You should trust this data.
     |          deep: Set to `True` to make a deep copy of the model.
     |
     |      Returns:
     |          New model instance.
     |
     |  model_dump(self, *, mode: "Literal['json', 'python'] | str" = 'python', include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump
     |
     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.
     |
     |      Args:
     |          mode: The mode in which `to_python` should run.
     |              If mode is 'json', the output will only contain JSON serializable types.
     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.
     |          include: A set of fields to include in the output.
     |          exclude: A set of fields to exclude from the output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to use the field's alias in the dictionary key if defined.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A dictionary representation of the model.
     |
     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'str'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump_json
     |
     |      Generates a JSON representation of the model using Pydantic's `to_json` method.
     |
     |      Args:
     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.
     |          include: Field(s) to include in the JSON output.
     |          exclude: Field(s) to exclude from the JSON output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to serialize using field aliases.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A JSON string representation of the model.
     |
     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'
     |      Override this method to perform additional initialization after `__init__` and `model_construct`.
     |      This is useful if you want to do some validation that requires the entire model to be initialized.
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from pydantic.main.BaseModel:
     |
     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'
     |
     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'
     |      Hook into generating the model's CoreSchema.
     |
     |      Args:
     |          source: The class we are generating a schema for.
     |              This will generally be the same as the `cls` argument if this is a classmethod.
     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.
     |
     |      Returns:
     |          A `pydantic-core` `CoreSchema`.
     |
     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'
     |      Hook into generating the model's JSON schema.
     |
     |      Args:
     |          core_schema: A `pydantic-core` CoreSchema.
     |              You can ignore this argument and call the handler with a new CoreSchema,
     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),
     |              or just call the handler with the original schema.
     |          handler: Call into Pydantic's internal JSON schema generation.
     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema
     |              generation fails.
     |              Since this gets called by `BaseModel.model_json_schema` you can override the
     |              `schema_generator` argument to that function to change JSON schema generation globally
     |              for a type.
     |
     |      Returns:
     |          A JSON schema, as a Python object.
     |
     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'
     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`
     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will
     |      be present when this is called.
     |
     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,
     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that
     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.
     |
     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,
     |      any kwargs passed to the class definition that aren't used internally by pydantic.
     |
     |      Args:
     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally
     |              by pydantic.
     |
     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |
     |  from_orm(obj: 'Any') -> 'Self'
     |
     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |      Creates a new instance of the `Model` class with validated data.
     |
     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.
     |      Default values are respected, but no other validation is performed.
     |
     |      !!! note
     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.
     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`
     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.
     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in
     |          an error if extra values are passed, but they will be ignored.
     |
     |      Args:
     |          _fields_set: The set of field names accepted for the Model instance.
     |          values: Trusted or pre-validated data dictionary.
     |
     |      Returns:
     |          A new instance of the `Model` class with validated data.
     |
     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'
     |      Generates a JSON schema for a model class.
     |
     |      Args:
     |          by_alias: Whether to use attribute aliases or not.
     |          ref_template: The reference template.
     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of
     |              `GenerateJsonSchema` with your desired modifications
     |          mode: The mode in which to generate the schema.
     |
     |      Returns:
     |          The JSON schema for the given model class.
     |
     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'
     |      Compute the class name for parametrizations of generic classes.
     |
     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.
     |
     |      Args:
     |          params: Tuple of types of the class. Given a generic class
     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,
     |              the value `(str, int)` would be passed to `params`.
     |
     |      Returns:
     |          String representing the new class where `params` are passed to `cls` as type variables.
     |
     |      Raises:
     |          TypeError: Raised when trying to generate concrete names for non-generic models.
     |
     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'dict[str, Any] | None' = None) -> 'bool | None'
     |      Try to rebuild the pydantic-core schema for the model.
     |
     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during
     |      the initial attempt to build the schema, and automatic rebuilding fails.
     |
     |      Args:
     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.
     |          raise_errors: Whether to raise errors, defaults to `True`.
     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.
     |          _types_namespace: The types namespace, defaults to `None`.
     |
     |      Returns:
     |          Returns `None` if the schema is already "complete" and rebuilding was not required.
     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.
     |
     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate a pydantic model instance.
     |
     |      Args:
     |          obj: The object to validate.
     |          strict: Whether to enforce types strictly.
     |          from_attributes: Whether to extract data from object attributes.
     |          context: Additional context to pass to the validator.
     |
     |      Raises:
     |          ValidationError: If the object could not be validated.
     |
     |      Returns:
     |          The validated model instance.
     |
     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/json/#json-parsing
     |
     |      Validate the given JSON data against the Pydantic model.
     |
     |      Args:
     |          json_data: The JSON data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |      Raises:
     |          ValueError: If `json_data` is not a JSON string.
     |
     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate the given object with string data against the Pydantic model.
     |
     |      Args:
     |          obj: The object containing string data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  parse_obj(obj: 'Any') -> 'Self'
     |
     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'
     |
     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'
     |
     |  update_forward_refs(**localns: 'Any') -> 'None'
     |
     |  validate(value: 'Any') -> 'Self'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from pydantic.main.BaseModel:
     |
     |  __fields_set__
     |
     |  model_extra
     |      Get extra fields set during validation.
     |
     |      Returns:
     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `"allow"`.
     |
     |  model_fields_set
     |      Returns the set of fields that have been explicitly set on this model instance.
     |
     |      Returns:
     |          A set of strings representing the fields that have been set,
     |              i.e. that were not filled from defaults.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from pydantic.main.BaseModel:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __pydantic_extra__
     |
     |  __pydantic_fields_set__
     |
     |  __pydantic_private__
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from pydantic.main.BaseModel:
     |
     |  __hash__ = None
     |
     |  __pydantic_root_model__ = False

FUNCTIONS
    create_response(status: str, message: str, data: Optional[Any] = None, status_code: int = 200) -> fastapi.responses.ORJSONResponse
        Crea una respuesta estructurada para el API.

        Parámetros:
        - status: Estado de la respuesta (ej. "success", "error").
        - message: Mensaje adicional sobre la respuesta.
        - data: Datos opcionales a incluir en la respuesta.
        - status_code: Código de estado HTTP (default es 200).

        Retorna:
        - Respuesta en formato ORJSONResponse.

    get_notifications(session_token: str, db: sqlalchemy.orm.session.Session = Depends(get_db_session))
        Endpoint para obtener las notificaciones de un usuario autenticado.

        Parámetros:
        - session_token: Token de sesión del usuario.
        - db: Sesión de la base de datos (inyectada automáticamente).

        Retorna:
        - Respuesta con las notificaciones del usuario.

    session_token_invalid_response() -> fastapi.responses.ORJSONResponse
        Crea una respuesta para el caso en que el token de sesión es inválido.

        Retorna:
        - Respuesta indicando que las credenciales han expirado.

DATA
    Optional = typing.Optional
        Optional[X] is equivalent to Union[X, None].

    logger = <Logger endpoints.notification (INFO)>
    router = <fastapi.routing.APIRouter object>

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\endpoints\notification.py



================================================================================
postgresql://coffeetech:Coffeetech.12@localhost:5432/CoffeeTech
Conexión exitosa a la base de datos
Help on module endpoints.plots in endpoints:

NAME
    endpoints.plots

CLASSES
    pydantic.main.BaseModel(builtins.object)
        CreatePlotRequest
        UpdatePlotGeneralInfoRequest
        UpdatePlotLocationRequest

    class CreatePlotRequest(pydantic.main.BaseModel)
     |  CreatePlotRequest(*, name: Annotated[str, MaxLen(max_length=100)], coffee_variety_name: str, latitude: str, longitude: str, altitude: str, farm_id: int) -> None
     |
     |  Modelo para la solicitud de creación de un lote (plot).
     |
     |  Method resolution order:
     |      CreatePlotRequest
     |      pydantic.main.BaseModel
     |      builtins.object
     |
     |  Data descriptors defined here:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  __abstractmethods__ = frozenset()
     |
     |  __annotations__ = {'altitude': <class 'str'>, 'coffee_variety_name': <...
     |
     |  __class_vars__ = set()
     |
     |  __private_attributes__ = {}
     |
     |  __pydantic_complete__ = True
     |
     |  __pydantic_core_schema__ = {'cls': <class 'endpoints.plots.CreatePlotR...
     |
     |  __pydantic_custom_init__ = False
     |
     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...
     |
     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...
     |
     |  __pydantic_parent_namespace__ = {'APIRouter': <pydantic._internal._mod...
     |
     |  __pydantic_post_init__ = None
     |
     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(
     |      Model...
     |
     |  __pydantic_validator__ = SchemaValidator(title="CreatePlotRequest", va...
     |
     |  __signature__ = <Signature (*, name: Annotated[str, MaxLen(max_l...itu...
     |
     |  model_computed_fields = {}
     |
     |  model_config = {}
     |
     |  model_fields = {'altitude': FieldInfo(annotation=str, required=True, d...
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from pydantic.main.BaseModel:
     |
     |  __copy__(self) -> 'Self'
     |      Returns a shallow copy of the model.
     |
     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'
     |      Returns a deep copy of the model.
     |
     |  __delattr__(self, item: 'str') -> 'Any'
     |      Implement delattr(self, name).
     |
     |  __eq__(self, other: 'Any') -> 'bool'
     |      Return self==value.
     |
     |  __getattr__(self, item: 'str') -> 'Any'
     |
     |  __getstate__(self) -> 'dict[Any, Any]'
     |      Helper for pickle.
     |
     |  __init__(self, /, **data: 'Any') -> 'None'
     |      Create a new model by parsing and validating input data from keyword arguments.
     |
     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be
     |      validated to form a valid model.
     |
     |      `self` is explicitly positional-only to allow `self` as a field name.
     |
     |  __iter__(self) -> 'TupleGenerator'
     |      So `dict(model)` works.
     |
     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation
     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.
     |
     |  __repr__(self) -> 'str'
     |      Return repr(self).
     |
     |  __repr_args__(self) -> '_repr.ReprArgs'
     |
     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation
     |      Name of the instance's class, used in __repr__.
     |
     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation
     |
     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation
     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.
     |
     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'
     |
     |  __str__(self) -> 'str'
     |      Return str(self).
     |
     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Returns a copy of the model.
     |
     |      !!! warning "Deprecated"
     |          This method is now deprecated; use `model_copy` instead.
     |
     |      If you need `include` or `exclude`, use:
     |
     |      ```py
     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)
     |      data = {**data, **(update or {})}
     |      copied = self.model_validate(data)
     |      ```
     |
     |      Args:
     |          include: Optional set or mapping specifying which fields to include in the copied model.
     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.
     |          update: Optional dictionary of field-value pairs to override field values in the copied model.
     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.
     |
     |      Returns:
     |          A copy of the model with included, excluded and updated fields as specified.
     |
     |  dict(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'
     |
     |  json(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'
     |
     |  model_copy(self, *, update: 'dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#model_copy
     |
     |      Returns a copy of the model.
     |
     |      Args:
     |          update: Values to change/add in the new model. Note: the data is not validated
     |              before creating the new model. You should trust this data.
     |          deep: Set to `True` to make a deep copy of the model.
     |
     |      Returns:
     |          New model instance.
     |
     |  model_dump(self, *, mode: "Literal['json', 'python'] | str" = 'python', include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump
     |
     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.
     |
     |      Args:
     |          mode: The mode in which `to_python` should run.
     |              If mode is 'json', the output will only contain JSON serializable types.
     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.
     |          include: A set of fields to include in the output.
     |          exclude: A set of fields to exclude from the output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to use the field's alias in the dictionary key if defined.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A dictionary representation of the model.
     |
     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'str'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump_json
     |
     |      Generates a JSON representation of the model using Pydantic's `to_json` method.
     |
     |      Args:
     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.
     |          include: Field(s) to include in the JSON output.
     |          exclude: Field(s) to exclude from the JSON output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to serialize using field aliases.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A JSON string representation of the model.
     |
     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'
     |      Override this method to perform additional initialization after `__init__` and `model_construct`.
     |      This is useful if you want to do some validation that requires the entire model to be initialized.
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from pydantic.main.BaseModel:
     |
     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'
     |
     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'
     |      Hook into generating the model's CoreSchema.
     |
     |      Args:
     |          source: The class we are generating a schema for.
     |              This will generally be the same as the `cls` argument if this is a classmethod.
     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.
     |
     |      Returns:
     |          A `pydantic-core` `CoreSchema`.
     |
     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'
     |      Hook into generating the model's JSON schema.
     |
     |      Args:
     |          core_schema: A `pydantic-core` CoreSchema.
     |              You can ignore this argument and call the handler with a new CoreSchema,
     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),
     |              or just call the handler with the original schema.
     |          handler: Call into Pydantic's internal JSON schema generation.
     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema
     |              generation fails.
     |              Since this gets called by `BaseModel.model_json_schema` you can override the
     |              `schema_generator` argument to that function to change JSON schema generation globally
     |              for a type.
     |
     |      Returns:
     |          A JSON schema, as a Python object.
     |
     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'
     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`
     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will
     |      be present when this is called.
     |
     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,
     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that
     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.
     |
     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,
     |      any kwargs passed to the class definition that aren't used internally by pydantic.
     |
     |      Args:
     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally
     |              by pydantic.
     |
     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |
     |  from_orm(obj: 'Any') -> 'Self'
     |
     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |      Creates a new instance of the `Model` class with validated data.
     |
     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.
     |      Default values are respected, but no other validation is performed.
     |
     |      !!! note
     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.
     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`
     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.
     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in
     |          an error if extra values are passed, but they will be ignored.
     |
     |      Args:
     |          _fields_set: The set of field names accepted for the Model instance.
     |          values: Trusted or pre-validated data dictionary.
     |
     |      Returns:
     |          A new instance of the `Model` class with validated data.
     |
     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'
     |      Generates a JSON schema for a model class.
     |
     |      Args:
     |          by_alias: Whether to use attribute aliases or not.
     |          ref_template: The reference template.
     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of
     |              `GenerateJsonSchema` with your desired modifications
     |          mode: The mode in which to generate the schema.
     |
     |      Returns:
     |          The JSON schema for the given model class.
     |
     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'
     |      Compute the class name for parametrizations of generic classes.
     |
     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.
     |
     |      Args:
     |          params: Tuple of types of the class. Given a generic class
     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,
     |              the value `(str, int)` would be passed to `params`.
     |
     |      Returns:
     |          String representing the new class where `params` are passed to `cls` as type variables.
     |
     |      Raises:
     |          TypeError: Raised when trying to generate concrete names for non-generic models.
     |
     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'dict[str, Any] | None' = None) -> 'bool | None'
     |      Try to rebuild the pydantic-core schema for the model.
     |
     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during
     |      the initial attempt to build the schema, and automatic rebuilding fails.
     |
     |      Args:
     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.
     |          raise_errors: Whether to raise errors, defaults to `True`.
     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.
     |          _types_namespace: The types namespace, defaults to `None`.
     |
     |      Returns:
     |          Returns `None` if the schema is already "complete" and rebuilding was not required.
     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.
     |
     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate a pydantic model instance.
     |
     |      Args:
     |          obj: The object to validate.
     |          strict: Whether to enforce types strictly.
     |          from_attributes: Whether to extract data from object attributes.
     |          context: Additional context to pass to the validator.
     |
     |      Raises:
     |          ValidationError: If the object could not be validated.
     |
     |      Returns:
     |          The validated model instance.
     |
     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/json/#json-parsing
     |
     |      Validate the given JSON data against the Pydantic model.
     |
     |      Args:
     |          json_data: The JSON data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |      Raises:
     |          ValueError: If `json_data` is not a JSON string.
     |
     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate the given object with string data against the Pydantic model.
     |
     |      Args:
     |          obj: The object containing string data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  parse_obj(obj: 'Any') -> 'Self'
     |
     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'
     |
     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'
     |
     |  update_forward_refs(**localns: 'Any') -> 'None'
     |
     |  validate(value: 'Any') -> 'Self'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from pydantic.main.BaseModel:
     |
     |  __fields_set__
     |
     |  model_extra
     |      Get extra fields set during validation.
     |
     |      Returns:
     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `"allow"`.
     |
     |  model_fields_set
     |      Returns the set of fields that have been explicitly set on this model instance.
     |
     |      Returns:
     |          A set of strings representing the fields that have been set,
     |              i.e. that were not filled from defaults.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from pydantic.main.BaseModel:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __pydantic_extra__
     |
     |  __pydantic_fields_set__
     |
     |  __pydantic_private__
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from pydantic.main.BaseModel:
     |
     |  __hash__ = None
     |
     |  __pydantic_root_model__ = False

    class UpdatePlotGeneralInfoRequest(pydantic.main.BaseModel)
     |  UpdatePlotGeneralInfoRequest(*, plot_id: int, name: Annotated[str, MaxLen(max_length=100)], coffee_variety_name: str) -> None
     |
     |  Modelo para la solicitud de actualización de información general de un lote.
     |
     |  Method resolution order:
     |      UpdatePlotGeneralInfoRequest
     |      pydantic.main.BaseModel
     |      builtins.object
     |
     |  Data descriptors defined here:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  __abstractmethods__ = frozenset()
     |
     |  __annotations__ = {'coffee_variety_name': <class 'str'>, 'name': <clas...
     |
     |  __class_vars__ = set()
     |
     |  __private_attributes__ = {}
     |
     |  __pydantic_complete__ = True
     |
     |  __pydantic_core_schema__ = {'cls': <class 'endpoints.plots.UpdatePlotG...
     |
     |  __pydantic_custom_init__ = False
     |
     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...
     |
     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...
     |
     |  __pydantic_parent_namespace__ = {'APIRouter': <pydantic._internal._mod...
     |
     |  __pydantic_post_init__ = None
     |
     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(
     |      Model...
     |
     |  __pydantic_validator__ = SchemaValidator(title="UpdatePlotGeneralInfoR...
     |
     |  __signature__ = <Signature (*, plot_id: int, name: Annotated[str..._le...
     |
     |  model_computed_fields = {}
     |
     |  model_config = {}
     |
     |  model_fields = {'coffee_variety_name': FieldInfo(annotation=str, requi...
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from pydantic.main.BaseModel:
     |
     |  __copy__(self) -> 'Self'
     |      Returns a shallow copy of the model.
     |
     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'
     |      Returns a deep copy of the model.
     |
     |  __delattr__(self, item: 'str') -> 'Any'
     |      Implement delattr(self, name).
     |
     |  __eq__(self, other: 'Any') -> 'bool'
     |      Return self==value.
     |
     |  __getattr__(self, item: 'str') -> 'Any'
     |
     |  __getstate__(self) -> 'dict[Any, Any]'
     |      Helper for pickle.
     |
     |  __init__(self, /, **data: 'Any') -> 'None'
     |      Create a new model by parsing and validating input data from keyword arguments.
     |
     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be
     |      validated to form a valid model.
     |
     |      `self` is explicitly positional-only to allow `self` as a field name.
     |
     |  __iter__(self) -> 'TupleGenerator'
     |      So `dict(model)` works.
     |
     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation
     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.
     |
     |  __repr__(self) -> 'str'
     |      Return repr(self).
     |
     |  __repr_args__(self) -> '_repr.ReprArgs'
     |
     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation
     |      Name of the instance's class, used in __repr__.
     |
     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation
     |
     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation
     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.
     |
     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'
     |
     |  __str__(self) -> 'str'
     |      Return str(self).
     |
     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Returns a copy of the model.
     |
     |      !!! warning "Deprecated"
     |          This method is now deprecated; use `model_copy` instead.
     |
     |      If you need `include` or `exclude`, use:
     |
     |      ```py
     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)
     |      data = {**data, **(update or {})}
     |      copied = self.model_validate(data)
     |      ```
     |
     |      Args:
     |          include: Optional set or mapping specifying which fields to include in the copied model.
     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.
     |          update: Optional dictionary of field-value pairs to override field values in the copied model.
     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.
     |
     |      Returns:
     |          A copy of the model with included, excluded and updated fields as specified.
     |
     |  dict(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'
     |
     |  json(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'
     |
     |  model_copy(self, *, update: 'dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#model_copy
     |
     |      Returns a copy of the model.
     |
     |      Args:
     |          update: Values to change/add in the new model. Note: the data is not validated
     |              before creating the new model. You should trust this data.
     |          deep: Set to `True` to make a deep copy of the model.
     |
     |      Returns:
     |          New model instance.
     |
     |  model_dump(self, *, mode: "Literal['json', 'python'] | str" = 'python', include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump
     |
     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.
     |
     |      Args:
     |          mode: The mode in which `to_python` should run.
     |              If mode is 'json', the output will only contain JSON serializable types.
     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.
     |          include: A set of fields to include in the output.
     |          exclude: A set of fields to exclude from the output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to use the field's alias in the dictionary key if defined.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A dictionary representation of the model.
     |
     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'str'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump_json
     |
     |      Generates a JSON representation of the model using Pydantic's `to_json` method.
     |
     |      Args:
     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.
     |          include: Field(s) to include in the JSON output.
     |          exclude: Field(s) to exclude from the JSON output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to serialize using field aliases.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A JSON string representation of the model.
     |
     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'
     |      Override this method to perform additional initialization after `__init__` and `model_construct`.
     |      This is useful if you want to do some validation that requires the entire model to be initialized.
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from pydantic.main.BaseModel:
     |
     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'
     |
     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'
     |      Hook into generating the model's CoreSchema.
     |
     |      Args:
     |          source: The class we are generating a schema for.
     |              This will generally be the same as the `cls` argument if this is a classmethod.
     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.
     |
     |      Returns:
     |          A `pydantic-core` `CoreSchema`.
     |
     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'
     |      Hook into generating the model's JSON schema.
     |
     |      Args:
     |          core_schema: A `pydantic-core` CoreSchema.
     |              You can ignore this argument and call the handler with a new CoreSchema,
     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),
     |              or just call the handler with the original schema.
     |          handler: Call into Pydantic's internal JSON schema generation.
     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema
     |              generation fails.
     |              Since this gets called by `BaseModel.model_json_schema` you can override the
     |              `schema_generator` argument to that function to change JSON schema generation globally
     |              for a type.
     |
     |      Returns:
     |          A JSON schema, as a Python object.
     |
     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'
     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`
     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will
     |      be present when this is called.
     |
     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,
     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that
     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.
     |
     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,
     |      any kwargs passed to the class definition that aren't used internally by pydantic.
     |
     |      Args:
     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally
     |              by pydantic.
     |
     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |
     |  from_orm(obj: 'Any') -> 'Self'
     |
     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |      Creates a new instance of the `Model` class with validated data.
     |
     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.
     |      Default values are respected, but no other validation is performed.
     |
     |      !!! note
     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.
     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`
     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.
     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in
     |          an error if extra values are passed, but they will be ignored.
     |
     |      Args:
     |          _fields_set: The set of field names accepted for the Model instance.
     |          values: Trusted or pre-validated data dictionary.
     |
     |      Returns:
     |          A new instance of the `Model` class with validated data.
     |
     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'
     |      Generates a JSON schema for a model class.
     |
     |      Args:
     |          by_alias: Whether to use attribute aliases or not.
     |          ref_template: The reference template.
     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of
     |              `GenerateJsonSchema` with your desired modifications
     |          mode: The mode in which to generate the schema.
     |
     |      Returns:
     |          The JSON schema for the given model class.
     |
     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'
     |      Compute the class name for parametrizations of generic classes.
     |
     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.
     |
     |      Args:
     |          params: Tuple of types of the class. Given a generic class
     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,
     |              the value `(str, int)` would be passed to `params`.
     |
     |      Returns:
     |          String representing the new class where `params` are passed to `cls` as type variables.
     |
     |      Raises:
     |          TypeError: Raised when trying to generate concrete names for non-generic models.
     |
     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'dict[str, Any] | None' = None) -> 'bool | None'
     |      Try to rebuild the pydantic-core schema for the model.
     |
     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during
     |      the initial attempt to build the schema, and automatic rebuilding fails.
     |
     |      Args:
     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.
     |          raise_errors: Whether to raise errors, defaults to `True`.
     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.
     |          _types_namespace: The types namespace, defaults to `None`.
     |
     |      Returns:
     |          Returns `None` if the schema is already "complete" and rebuilding was not required.
     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.
     |
     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate a pydantic model instance.
     |
     |      Args:
     |          obj: The object to validate.
     |          strict: Whether to enforce types strictly.
     |          from_attributes: Whether to extract data from object attributes.
     |          context: Additional context to pass to the validator.
     |
     |      Raises:
     |          ValidationError: If the object could not be validated.
     |
     |      Returns:
     |          The validated model instance.
     |
     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/json/#json-parsing
     |
     |      Validate the given JSON data against the Pydantic model.
     |
     |      Args:
     |          json_data: The JSON data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |      Raises:
     |          ValueError: If `json_data` is not a JSON string.
     |
     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate the given object with string data against the Pydantic model.
     |
     |      Args:
     |          obj: The object containing string data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  parse_obj(obj: 'Any') -> 'Self'
     |
     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'
     |
     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'
     |
     |  update_forward_refs(**localns: 'Any') -> 'None'
     |
     |  validate(value: 'Any') -> 'Self'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from pydantic.main.BaseModel:
     |
     |  __fields_set__
     |
     |  model_extra
     |      Get extra fields set during validation.
     |
     |      Returns:
     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `"allow"`.
     |
     |  model_fields_set
     |      Returns the set of fields that have been explicitly set on this model instance.
     |
     |      Returns:
     |          A set of strings representing the fields that have been set,
     |              i.e. that were not filled from defaults.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from pydantic.main.BaseModel:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __pydantic_extra__
     |
     |  __pydantic_fields_set__
     |
     |  __pydantic_private__
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from pydantic.main.BaseModel:
     |
     |  __hash__ = None
     |
     |  __pydantic_root_model__ = False

    class UpdatePlotLocationRequest(pydantic.main.BaseModel)
     |  UpdatePlotLocationRequest(*, plot_id: int, latitude: str, longitude: str, altitude: str) -> None
     |
     |  Modelo para la solicitud de actualización de la ubicación de un lote.
     |
     |  Method resolution order:
     |      UpdatePlotLocationRequest
     |      pydantic.main.BaseModel
     |      builtins.object
     |
     |  Data descriptors defined here:
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  __abstractmethods__ = frozenset()
     |
     |  __annotations__ = {'altitude': <class 'str'>, 'latitude': <class 'str'...
     |
     |  __class_vars__ = set()
     |
     |  __private_attributes__ = {}
     |
     |  __pydantic_complete__ = True
     |
     |  __pydantic_core_schema__ = {'cls': <class 'endpoints.plots.UpdatePlotL...
     |
     |  __pydantic_custom_init__ = False
     |
     |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...
     |
     |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...
     |
     |  __pydantic_parent_namespace__ = {'APIRouter': <pydantic._internal._mod...
     |
     |  __pydantic_post_init__ = None
     |
     |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(
     |      Model...
     |
     |  __pydantic_validator__ = SchemaValidator(title="UpdatePlotLocationRequ...
     |
     |  __signature__ = <Signature (*, plot_id: int, latitude: str, longitude:...
     |
     |  model_computed_fields = {}
     |
     |  model_config = {}
     |
     |  model_fields = {'altitude': FieldInfo(annotation=str, required=True, d...
     |
     |  ----------------------------------------------------------------------
     |  Methods inherited from pydantic.main.BaseModel:
     |
     |  __copy__(self) -> 'Self'
     |      Returns a shallow copy of the model.
     |
     |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'
     |      Returns a deep copy of the model.
     |
     |  __delattr__(self, item: 'str') -> 'Any'
     |      Implement delattr(self, name).
     |
     |  __eq__(self, other: 'Any') -> 'bool'
     |      Return self==value.
     |
     |  __getattr__(self, item: 'str') -> 'Any'
     |
     |  __getstate__(self) -> 'dict[Any, Any]'
     |      Helper for pickle.
     |
     |  __init__(self, /, **data: 'Any') -> 'None'
     |      Create a new model by parsing and validating input data from keyword arguments.
     |
     |      Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be
     |      validated to form a valid model.
     |
     |      `self` is explicitly positional-only to allow `self` as a field name.
     |
     |  __iter__(self) -> 'TupleGenerator'
     |      So `dict(model)` works.
     |
     |  __pretty__(self, fmt: 'typing.Callable[[Any], Any]', **kwargs: 'Any') -> 'typing.Generator[Any, None, None]' from pydantic._internal._repr.Representation
     |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.
     |
     |  __repr__(self) -> 'str'
     |      Return repr(self).
     |
     |  __repr_args__(self) -> '_repr.ReprArgs'
     |
     |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation
     |      Name of the instance's class, used in __repr__.
     |
     |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation
     |
     |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation
     |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.
     |
     |  __setattr__(self, name: 'str', value: 'Any') -> 'None'
     |      Implement setattr(self, name, value).
     |
     |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'
     |
     |  __str__(self) -> 'str'
     |      Return str(self).
     |
     |  copy(self, *, include: 'AbstractSetIntStr | MappingIntStrAny | None' = None, exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None, update: 'Dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Returns a copy of the model.
     |
     |      !!! warning "Deprecated"
     |          This method is now deprecated; use `model_copy` instead.
     |
     |      If you need `include` or `exclude`, use:
     |
     |      ```py
     |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)
     |      data = {**data, **(update or {})}
     |      copied = self.model_validate(data)
     |      ```
     |
     |      Args:
     |          include: Optional set or mapping specifying which fields to include in the copied model.
     |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.
     |          update: Optional dictionary of field-value pairs to override field values in the copied model.
     |          deep: If True, the values of fields that are Pydantic models will be deep-copied.
     |
     |      Returns:
     |          A copy of the model with included, excluded and updated fields as specified.
     |
     |  dict(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False) -> 'Dict[str, Any]'
     |
     |  json(self, *, include: 'IncEx' = None, exclude: 'IncEx' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, encoder: 'Callable[[Any], Any] | None' = PydanticUndefined, models_as_dict: 'bool' = PydanticUndefined, **dumps_kwargs: 'Any') -> 'str'
     |
     |  model_copy(self, *, update: 'dict[str, Any] | None' = None, deep: 'bool' = False) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#model_copy
     |
     |      Returns a copy of the model.
     |
     |      Args:
     |          update: Values to change/add in the new model. Note: the data is not validated
     |              before creating the new model. You should trust this data.
     |          deep: Set to `True` to make a deep copy of the model.
     |
     |      Returns:
     |          New model instance.
     |
     |  model_dump(self, *, mode: "Literal['json', 'python'] | str" = 'python', include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'dict[str, Any]'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump
     |
     |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.
     |
     |      Args:
     |          mode: The mode in which `to_python` should run.
     |              If mode is 'json', the output will only contain JSON serializable types.
     |              If mode is 'python', the output may contain non-JSON-serializable Python objects.
     |          include: A set of fields to include in the output.
     |          exclude: A set of fields to exclude from the output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to use the field's alias in the dictionary key if defined.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A dictionary representation of the model.
     |
     |  model_dump_json(self, *, indent: 'int | None' = None, include: 'IncEx' = None, exclude: 'IncEx' = None, context: 'Any | None' = None, by_alias: 'bool' = False, exclude_unset: 'bool' = False, exclude_defaults: 'bool' = False, exclude_none: 'bool' = False, round_trip: 'bool' = False, warnings: "bool | Literal['none', 'warn', 'error']" = True, serialize_as_any: 'bool' = False) -> 'str'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/serialization/#modelmodel_dump_json
     |
     |      Generates a JSON representation of the model using Pydantic's `to_json` method.
     |
     |      Args:
     |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.
     |          include: Field(s) to include in the JSON output.
     |          exclude: Field(s) to exclude from the JSON output.
     |          context: Additional context to pass to the serializer.
     |          by_alias: Whether to serialize using field aliases.
     |          exclude_unset: Whether to exclude fields that have not been explicitly set.
     |          exclude_defaults: Whether to exclude fields that are set to their default value.
     |          exclude_none: Whether to exclude fields that have a value of `None`.
     |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
     |          warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
     |              "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
     |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.
     |
     |      Returns:
     |          A JSON string representation of the model.
     |
     |  model_post_init(self, _BaseModel__context: 'Any') -> 'None'
     |      Override this method to perform additional initialization after `__init__` and `model_construct`.
     |      This is useful if you want to do some validation that requires the entire model to be initialized.
     |
     |  ----------------------------------------------------------------------
     |  Class methods inherited from pydantic.main.BaseModel:
     |
     |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'
     |
     |  __get_pydantic_core_schema__(source: 'type[BaseModel]', handler: 'GetCoreSchemaHandler', /) -> 'CoreSchema'
     |      Hook into generating the model's CoreSchema.
     |
     |      Args:
     |          source: The class we are generating a schema for.
     |              This will generally be the same as the `cls` argument if this is a classmethod.
     |          handler: A callable that calls into Pydantic's internal CoreSchema generation logic.
     |
     |      Returns:
     |          A `pydantic-core` `CoreSchema`.
     |
     |  __get_pydantic_json_schema__(core_schema: 'CoreSchema', handler: 'GetJsonSchemaHandler', /) -> 'JsonSchemaValue'
     |      Hook into generating the model's JSON schema.
     |
     |      Args:
     |          core_schema: A `pydantic-core` CoreSchema.
     |              You can ignore this argument and call the handler with a new CoreSchema,
     |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),
     |              or just call the handler with the original schema.
     |          handler: Call into Pydantic's internal JSON schema generation.
     |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema
     |              generation fails.
     |              Since this gets called by `BaseModel.model_json_schema` you can override the
     |              `schema_generator` argument to that function to change JSON schema generation globally
     |              for a type.
     |
     |      Returns:
     |          A JSON schema, as a Python object.
     |
     |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'
     |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`
     |      only after the class is actually fully initialized. In particular, attributes like `model_fields` will
     |      be present when this is called.
     |
     |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,
     |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that
     |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.
     |
     |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,
     |      any kwargs passed to the class definition that aren't used internally by pydantic.
     |
     |      Args:
     |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally
     |              by pydantic.
     |
     |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |
     |  from_orm(obj: 'Any') -> 'Self'
     |
     |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'
     |      Creates a new instance of the `Model` class with validated data.
     |
     |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.
     |      Default values are respected, but no other validation is performed.
     |
     |      !!! note
     |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.
     |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`
     |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.
     |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in
     |          an error if extra values are passed, but they will be ignored.
     |
     |      Args:
     |          _fields_set: The set of field names accepted for the Model instance.
     |          values: Trusted or pre-validated data dictionary.
     |
     |      Returns:
     |          A new instance of the `Model` class with validated data.
     |
     |  model_json_schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>, mode: 'JsonSchemaMode' = 'validation') -> 'dict[str, Any]'
     |      Generates a JSON schema for a model class.
     |
     |      Args:
     |          by_alias: Whether to use attribute aliases or not.
     |          ref_template: The reference template.
     |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of
     |              `GenerateJsonSchema` with your desired modifications
     |          mode: The mode in which to generate the schema.
     |
     |      Returns:
     |          The JSON schema for the given model class.
     |
     |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'
     |      Compute the class name for parametrizations of generic classes.
     |
     |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.
     |
     |      Args:
     |          params: Tuple of types of the class. Given a generic class
     |              `Model` with 2 type variables and a concrete model `Model[str, int]`,
     |              the value `(str, int)` would be passed to `params`.
     |
     |      Returns:
     |          String representing the new class where `params` are passed to `cls` as type variables.
     |
     |      Raises:
     |          TypeError: Raised when trying to generate concrete names for non-generic models.
     |
     |  model_rebuild(*, force: 'bool' = False, raise_errors: 'bool' = True, _parent_namespace_depth: 'int' = 2, _types_namespace: 'dict[str, Any] | None' = None) -> 'bool | None'
     |      Try to rebuild the pydantic-core schema for the model.
     |
     |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during
     |      the initial attempt to build the schema, and automatic rebuilding fails.
     |
     |      Args:
     |          force: Whether to force the rebuilding of the model schema, defaults to `False`.
     |          raise_errors: Whether to raise errors, defaults to `True`.
     |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.
     |          _types_namespace: The types namespace, defaults to `None`.
     |
     |      Returns:
     |          Returns `None` if the schema is already "complete" and rebuilding was not required.
     |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.
     |
     |  model_validate(obj: 'Any', *, strict: 'bool | None' = None, from_attributes: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate a pydantic model instance.
     |
     |      Args:
     |          obj: The object to validate.
     |          strict: Whether to enforce types strictly.
     |          from_attributes: Whether to extract data from object attributes.
     |          context: Additional context to pass to the validator.
     |
     |      Raises:
     |          ValidationError: If the object could not be validated.
     |
     |      Returns:
     |          The validated model instance.
     |
     |  model_validate_json(json_data: 'str | bytes | bytearray', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Usage docs: https://docs.pydantic.dev/2.8/concepts/json/#json-parsing
     |
     |      Validate the given JSON data against the Pydantic model.
     |
     |      Args:
     |          json_data: The JSON data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |      Raises:
     |          ValueError: If `json_data` is not a JSON string.
     |
     |  model_validate_strings(obj: 'Any', *, strict: 'bool | None' = None, context: 'Any | None' = None) -> 'Self'
     |      Validate the given object with string data against the Pydantic model.
     |
     |      Args:
     |          obj: The object containing string data to validate.
     |          strict: Whether to enforce types strictly.
     |          context: Extra variables to pass to the validator.
     |
     |      Returns:
     |          The validated Pydantic model.
     |
     |  parse_file(path: 'str | Path', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  parse_obj(obj: 'Any') -> 'Self'
     |
     |  parse_raw(b: 'str | bytes', *, content_type: 'str | None' = None, encoding: 'str' = 'utf8', proto: 'DeprecatedParseProtocol | None' = None, allow_pickle: 'bool' = False) -> 'Self'
     |
     |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'
     |
     |  schema_json(*, by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}', **dumps_kwargs: 'Any') -> 'str'
     |
     |  update_forward_refs(**localns: 'Any') -> 'None'
     |
     |  validate(value: 'Any') -> 'Self'
     |
     |  ----------------------------------------------------------------------
     |  Readonly properties inherited from pydantic.main.BaseModel:
     |
     |  __fields_set__
     |
     |  model_extra
     |      Get extra fields set during validation.
     |
     |      Returns:
     |          A dictionary of extra fields, or `None` if `config.extra` is not set to `"allow"`.
     |
     |  model_fields_set
     |      Returns the set of fields that have been explicitly set on this model instance.
     |
     |      Returns:
     |          A set of strings representing the fields that have been set,
     |              i.e. that were not filled from defaults.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from pydantic.main.BaseModel:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __pydantic_extra__
     |
     |  __pydantic_fields_set__
     |
     |  __pydantic_private__
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from pydantic.main.BaseModel:
     |
     |  __hash__ = None
     |
     |  __pydantic_root_model__ = False

FUNCTIONS
    create_plot(request: endpoints.plots.CreatePlotRequest, session_token: str, db: sqlalchemy.orm.session.Session = Depends(get_db_session))
        Crea un nuevo lote (plot) en una finca.

        Parámetros:
        - request (CreatePlotRequest): Los datos necesarios para crear el lote.
        - session_token (str): Token de sesión del usuario.
        - db (Session): Sesión de base de datos.

        Retorna:
        - Respuesta exitosa con los datos del lote creado, o un error si algo falla.

    delete_plot(plot_id: int, session_token: str, db: sqlalchemy.orm.session.Session = Depends(get_db_session))
        Elimina un lote (cambia su estado a 'Inactivo').

        - **plot_id**: ID del lote.
        - **session_token**: Token de sesión del usuario autenticado.

        **Respuestas**:
        - **200**: Lote eliminado exitosamente (estado 'Inactivo').
        - **400**: Token inválido o falta de permisos para eliminar el lote.
        - **404**: Lote no encontrado o ya inactivo.
        - **500**: Error al eliminar el lote.

    get_plot(plot_id: int, session_token: str, db: sqlalchemy.orm.session.Session = Depends(get_db_session))
        Obtiene la información detallada de un lote específico.

        - **plot_id**: ID del lote.
        - **session_token**: Token de sesión del usuario autenticado.

        **Respuestas**:
        - **200**: Información del lote obtenida exitosamente.
        - **400**: Token inválido o falta de permisos para ver el lote.
        - **404**: Lote no encontrado o inactivo.
        - **500**: Error al obtener la información del lote.

    list_plots(farm_id: int, session_token: str, db: sqlalchemy.orm.session.Session = Depends(get_db_session))
        Obtiene una lista de todos los lotes activos de una finca específica.

        - **farm_id**: ID de la finca.
        - **session_token**: Token de sesión del usuario autenticado.

        **Respuestas**:
        - **200**: Lista de lotes obtenida exitosamente.
        - **400**: Token inválido o falta de permisos para ver los lotes.
        - **404**: Finca no encontrada o inactiva.
        - **500**: Error al obtener la lista de lotes.

    update_plot_general_info(request: endpoints.plots.UpdatePlotGeneralInfoRequest, session_token: str, db: sqlalchemy.orm.session.Session = Depends(get_db_session))
        Actualiza el nombre y la variedad de café de un lote específico.

        Args:
            request (UpdatePlotGeneralInfoRequest): Contiene la nueva información del lote.
            session_token (str): Token de sesión del usuario para autenticar la solicitud.
            db (Session): Sesión de base de datos proporcionada por la dependencia.

        Returns:
            dict: Respuesta indicando el estado del proceso de actualización del lote.

    update_plot_location(request: endpoints.plots.UpdatePlotLocationRequest, session_token: str, db: sqlalchemy.orm.session.Session = Depends(get_db_session))
        Actualiza las coordenadas geográficas (latitud, longitud, altitud) de un lote específico.

        Args:
            request (UpdatePlotLocationRequest): Contiene la nueva ubicación del lote.
            session_token (str): Token de sesión del usuario para autenticar la solicitud.
            db (Session): Sesión de base de datos proporcionada por la dependencia.

        Returns:
            dict: Respuesta indicando el estado del proceso de actualización de la ubicación del lote.

DATA
    Dict = typing.Dict
        A generic version of dict.

    List = typing.List
        A generic version of list.

    logger = <Logger endpoints.plots (INFO)>
    router = <fastapi.routing.APIRouter object>

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\endpoints\plots.py



================================================================================
postgresql://coffeetech:Coffeetech.12@localhost:5432/CoffeeTech
Conexión exitosa a la base de datos
Help on module endpoints.utils in endpoints:

NAME
    endpoints.utils

FUNCTIONS
    list_coffee_varieties(db: sqlalchemy.orm.session.Session = Depends(get_db_session))
        Obtiene una lista de todas las variedades de café disponibles junto con sus parcelas asociadas.

        Args:
            db (Session): Sesión de base de datos proporcionada por la dependencia.

        Returns:
            dict: Diccionario con el estado, mensaje y datos de las variedades de café.

    list_roles(db: sqlalchemy.orm.session.Session = Depends(get_db_session))
        Obtiene una lista de todos los roles disponibles junto con sus permisos asociados.

        Args:
            db (Session): Sesión de base de datos proporcionada por la dependencia.

        Returns:
            dict: Diccionario con el estado, mensaje y datos de los roles y sus permisos.

    list_unit_measures(db: sqlalchemy.orm.session.Session = Depends(get_db_session))
        Obtiene una lista de todas las unidades de medida disponibles junto con su tipo correspondiente.

        Args:
            db (Session): Sesión de base de datos proporcionada por la dependencia.

        Returns:
            dict: Diccionario con el estado, mensaje y datos de las unidades de medida y sus tipos.

DATA
    router = <fastapi.routing.APIRouter object>

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\endpoints\utils.py



================================================================================
Help on module models.models in models:

NAME
    models.models

CLASSES
    sqlalchemy.orm.decl_api.Base(builtins.object)
        CoffeeVariety
        Farm
        Flowering
        FloweringType
        Invitation
        Notification
        NotificationType
        Permission
        Plot
        Role
        RolePermission
        Status
        StatusType
        UnitOfMeasure
        UnitOfMeasureType
        User
        UserRoleFarm

    class CoffeeVariety(sqlalchemy.orm.decl_api.Base)
     |  CoffeeVariety(**kwargs)
     |
     |  Representa una variedad de café.
     |
     |  Atributos:
     |  ----------
     |  coffee_variety_id : int
     |      Identificador único de la variedad de café.
     |  name : str
     |      Nombre de la variedad de café.
     |  description : str
     |      Descripción de la variedad de café.
     |  rust_resistant : bool
     |      Indica si la variedad es resistente a la roya.
     |  growth_habit : str
     |      Hábitos de crecimiento de la variedad.
     |  plant_density_sun : float
     |      Densidad de plantación en sol (hectáreas por hectárea).
     |  plant_density_shade : float
     |      Densidad de plantación en sombra (hectáreas por hectárea).
     |  production : float
     |      Producción esperada (toneladas por hectárea).
     |  altitude_min : int
     |      Altitud mínima para el cultivo (metros).
     |  altitude_max : int
     |      Altitud máxima para el cultivo (metros).
     |  plant_density_unit_id : int
     |      Relación con la unidad de medida para la densidad de plantación.
     |  status_id : int
     |      Relación con el estado de la variedad de café.
     |
     |  Method resolution order:
     |      CoffeeVariety
     |      sqlalchemy.orm.decl_api.Base
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, **kwargs) from sqlalchemy.orm.instrumentation
     |      A simple constructor that allows initialization from kwargs.
     |
     |      Sets attributes on the constructed instance using the names and
     |      values in ``kwargs``.
     |
     |      Only keys that are present as
     |      attributes of the instance's class are allowed. These could be,
     |      for example, any mapped columns or relationships.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  altitude_max
     |
     |  altitude_min
     |
     |  altitude_unit_id
     |
     |  coffee_variety_id
     |
     |  description
     |
     |  growth_habit
     |
     |  name
     |
     |  plant_density_shade
     |
     |  plant_density_sun
     |
     |  plant_density_unit_id
     |
     |  plots
     |
     |  production
     |
     |  production_unit_id
     |
     |  rust_resistant
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  __mapper__ = <Mapper at 0x21fb3086f30; CoffeeVariety>
     |
     |  __table__ = Table('coffee_variety', MetaData(), Column('coff...asure_i...
     |
     |  __tablename__ = 'coffee_variety'
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from sqlalchemy.orm.decl_api.Base:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from sqlalchemy.orm.decl_api.Base:
     |
     |  __abstract__ = True
     |
     |  metadata = MetaData()
     |
     |  registry = <sqlalchemy.orm.decl_api.registry object>

    class Farm(sqlalchemy.orm.decl_api.Base)
     |  Farm(**kwargs)
     |
     |  Modelo de base de datos para representar una finca.
     |
     |  Atributos:
     |  ----------
     |  farm_id : int
     |      Identificador único de la finca (clave primaria).
     |  name : str
     |      Nombre de la finca.
     |  area : Numeric
     |      Área de la finca.
     |  area_unit_id : int
     |      Unidad de medida del área (relación con UnitOfMeasure).
     |  status_id : int
     |      Estado actual de la finca (relación con Status).
     |
     |  Method resolution order:
     |      Farm
     |      sqlalchemy.orm.decl_api.Base
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, **kwargs) from sqlalchemy.orm.instrumentation
     |      A simple constructor that allows initialization from kwargs.
     |
     |      Sets attributes on the constructed instance using the names and
     |      values in ``kwargs``.
     |
     |      Only keys that are present as
     |      attributes of the instance's class are allowed. These could be,
     |      for example, any mapped columns or relationships.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  area
     |
     |  area_unit
     |
     |  area_unit_id
     |
     |  farm_id
     |
     |  invitations
     |
     |  name
     |
     |  plots
     |
     |  status
     |
     |  status_id
     |
     |  user_roles_farms
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  __mapper__ = <Mapper at 0x21fb1f3d5b0; Farm>
     |
     |  __table__ = Table('farm', MetaData(), Column('farm_id', Inte...id'), t...
     |
     |  __tablename__ = 'farm'
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from sqlalchemy.orm.decl_api.Base:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from sqlalchemy.orm.decl_api.Base:
     |
     |  __abstract__ = True
     |
     |  metadata = MetaData()
     |
     |  registry = <sqlalchemy.orm.decl_api.registry object>

    class Flowering(sqlalchemy.orm.decl_api.Base)
     |  Flowering(**kwargs)
     |
     |  Representa un evento de floración en un lote de cultivo.
     |
     |  Atributos:
     |  ----------
     |  flowering_id : int
     |      Identificador único de la floración.
     |  plot_id : int
     |      Relación con el lote en el que ocurre la floración.
     |  flowering_date : date
     |      Fecha de la floración.
     |  harvest_date : date
     |      Fecha de la cosecha, si aplica.
     |  status_id : int
     |      Relación con el estado de la floración.
     |  flowering_type_id : int
     |      Relación con el tipo de floración.
     |
     |  Method resolution order:
     |      Flowering
     |      sqlalchemy.orm.decl_api.Base
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, **kwargs) from sqlalchemy.orm.instrumentation
     |      A simple constructor that allows initialization from kwargs.
     |
     |      Sets attributes on the constructed instance using the names and
     |      values in ``kwargs``.
     |
     |      Only keys that are present as
     |      attributes of the instance's class are allowed. These could be,
     |      for example, any mapped columns or relationships.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  flowering_date
     |
     |  flowering_id
     |
     |  flowering_type
     |
     |  flowering_type_id
     |
     |  harvest_date
     |
     |  plot
     |
     |  plot_id
     |
     |  status
     |
     |  status_id
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  __mapper__ = <Mapper at 0x21fb3087fb0; Flowering>
     |
     |  __table__ = Table('flowering', MetaData(), Column('flowering... table=...
     |
     |  __tablename__ = 'flowering'
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from sqlalchemy.orm.decl_api.Base:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from sqlalchemy.orm.decl_api.Base:
     |
     |  __abstract__ = True
     |
     |  metadata = MetaData()
     |
     |  registry = <sqlalchemy.orm.decl_api.registry object>

    class FloweringType(sqlalchemy.orm.decl_api.Base)
     |  FloweringType(**kwargs)
     |
     |  Representa un tipo de floración en el sistema.
     |
     |  Atributos:
     |  ----------
     |  flowering_type_id : int
     |      Identificador único del tipo de floración.
     |  name : str
     |      Nombre del tipo de floración.
     |
     |  Method resolution order:
     |      FloweringType
     |      sqlalchemy.orm.decl_api.Base
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, **kwargs) from sqlalchemy.orm.instrumentation
     |      A simple constructor that allows initialization from kwargs.
     |
     |      Sets attributes on the constructed instance using the names and
     |      values in ``kwargs``.
     |
     |      Only keys that are present as
     |      attributes of the instance's class are allowed. These could be,
     |      for example, any mapped columns or relationships.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  flowering_type_id
     |
     |  flowerings
     |
     |  name
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  __mapper__ = <Mapper at 0x21fb3087920; FloweringType>
     |
     |  __table__ = Table('flowering_type', MetaData(), Column('flow...e=<flow...
     |
     |  __tablename__ = 'flowering_type'
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from sqlalchemy.orm.decl_api.Base:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from sqlalchemy.orm.decl_api.Base:
     |
     |  __abstract__ = True
     |
     |  metadata = MetaData()
     |
     |  registry = <sqlalchemy.orm.decl_api.registry object>

    class Invitation(sqlalchemy.orm.decl_api.Base)
     |  Invitation(**kwargs)
     |
     |  Representa una invitación para un usuario.
     |
     |  Atributos:
     |  ----------
     |  invitation_id : int
     |      Identificador único de la invitación.
     |  email : str
     |      Correo electrónico del invitado.
     |  suggested_role : str
     |      Rol sugerido para el invitado.
     |  status_id : int
     |      Relación con el estado de la invitación.
     |  farm_id : int
     |      Relación con la finca a la que se invita.
     |  inviter_user_id : int
     |      Identificador del usuario que envía la invitación.
     |  date : datetime
     |      Fecha de creación de la invitación.
     |
     |  Method resolution order:
     |      Invitation
     |      sqlalchemy.orm.decl_api.Base
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, **kwargs) from sqlalchemy.orm.instrumentation
     |      A simple constructor that allows initialization from kwargs.
     |
     |      Sets attributes on the constructed instance using the names and
     |      values in ``kwargs``.
     |
     |      Only keys that are present as
     |      attributes of the instance's class are allowed. These could be,
     |      for example, any mapped columns or relationships.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  date
     |
     |  email
     |
     |  farm
     |
     |  farm_id
     |
     |  invitation_id
     |
     |  inviter
     |
     |  inviter_user_id
     |
     |  notifications
     |
     |  status
     |
     |  status_id
     |
     |  suggested_role
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  __mapper__ = <Mapper at 0x21fb3084470; Invitation>
     |
     |  __table__ = Table('invitation', MetaData(), Column('invitati...ime.utc...
     |
     |  __tablename__ = 'invitation'
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from sqlalchemy.orm.decl_api.Base:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from sqlalchemy.orm.decl_api.Base:
     |
     |  __abstract__ = True
     |
     |  metadata = MetaData()
     |
     |  registry = <sqlalchemy.orm.decl_api.registry object>

    class Notification(sqlalchemy.orm.decl_api.Base)
     |  Notification(**kwargs)
     |
     |  Representa una notificación en el sistema.
     |
     |  Atributos:
     |  ----------
     |  notifications_id : int
     |      Identificador único de la notificación.
     |  message : str
     |      Mensaje de la notificación.
     |  date : datetime
     |      Fecha de creación de la notificación.
     |  user_id : int
     |      Identificador del usuario que recibe la notificación.
     |  invitation_id : int
     |      Identificador de la invitación relacionada, si aplica.
     |  notification_type_id : int
     |      Tipo de notificación.
     |  reminder_time : datetime
     |      Tiempo para el recordatorio de la notificación.
     |  farm_id : int
     |      Identificador de la finca relacionada, si aplica.
     |  status_id : int
     |      Relación con el estado de la notificación.
     |
     |  Method resolution order:
     |      Notification
     |      sqlalchemy.orm.decl_api.Base
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, **kwargs) from sqlalchemy.orm.instrumentation
     |      A simple constructor that allows initialization from kwargs.
     |
     |      Sets attributes on the constructed instance using the names and
     |      values in ``kwargs``.
     |
     |      Only keys that are present as
     |      attributes of the instance's class are allowed. These could be,
     |      for example, any mapped columns or relationships.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  date
     |
     |  farm
     |
     |  farm_id
     |
     |  invitation
     |
     |  invitation_id
     |
     |  message
     |
     |  notification_type
     |
     |  notification_type_id
     |
     |  notifications_id
     |
     |  reminder_time
     |
     |  status
     |
     |  status_id
     |
     |  user
     |
     |  user_id
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  __mapper__ = <Mapper at 0x21fb30855b0; Notification>
     |
     |  __table__ = Table('notifications', MetaData(), Column('notif...status_...
     |
     |  __tablename__ = 'notifications'
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from sqlalchemy.orm.decl_api.Base:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from sqlalchemy.orm.decl_api.Base:
     |
     |  __abstract__ = True
     |
     |  metadata = MetaData()
     |
     |  registry = <sqlalchemy.orm.decl_api.registry object>

    class NotificationType(sqlalchemy.orm.decl_api.Base)
     |  NotificationType(**kwargs)
     |
     |  Representa el tipo de notificación.
     |
     |  Atributos:
     |  ----------
     |  notification_type_id : int
     |      Identificador único del tipo de notificación.
     |  name : str
     |      Nombre del tipo de notificación.
     |
     |  Method resolution order:
     |      NotificationType
     |      sqlalchemy.orm.decl_api.Base
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, **kwargs) from sqlalchemy.orm.instrumentation
     |      A simple constructor that allows initialization from kwargs.
     |
     |      Sets attributes on the constructed instance using the names and
     |      values in ``kwargs``.
     |
     |      Only keys that are present as
     |      attributes of the instance's class are allowed. These could be,
     |      for example, any mapped columns or relationships.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  name
     |
     |  notification_type_id
     |
     |  notifications
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  __mapper__ = <Mapper at 0x21fb3084cb0; NotificationType>
     |
     |  __table__ = Table('notification_type', MetaData(), Column('n...notific...
     |
     |  __tablename__ = 'notification_type'
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from sqlalchemy.orm.decl_api.Base:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from sqlalchemy.orm.decl_api.Base:
     |
     |  __abstract__ = True
     |
     |  metadata = MetaData()
     |
     |  registry = <sqlalchemy.orm.decl_api.registry object>

    class Permission(sqlalchemy.orm.decl_api.Base)
     |  Permission(**kwargs)
     |
     |  Representa un permiso en el sistema.
     |
     |  Atributos:
     |  ----------
     |  permission_id : int
     |      Identificador único del permiso.
     |  description : str
     |      Descripción del permiso.
     |  name : str
     |      Nombre del permiso.
     |
     |  Method resolution order:
     |      Permission
     |      sqlalchemy.orm.decl_api.Base
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, **kwargs) from sqlalchemy.orm.instrumentation
     |      A simple constructor that allows initialization from kwargs.
     |
     |      Sets attributes on the constructed instance using the names and
     |      values in ``kwargs``.
     |
     |      Only keys that are present as
     |      attributes of the instance's class are allowed. These could be,
     |      for example, any mapped columns or relationships.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  description
     |
     |  name
     |
     |  permission_id
     |
     |  roles
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  __mapper__ = <Mapper at 0x21fb3017560; Permission>
     |
     |  __table__ = Table('permission', MetaData(), Column('permissi...ing(len...
     |
     |  __tablename__ = 'permission'
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from sqlalchemy.orm.decl_api.Base:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from sqlalchemy.orm.decl_api.Base:
     |
     |  __abstract__ = True
     |
     |  metadata = MetaData()
     |
     |  registry = <sqlalchemy.orm.decl_api.registry object>

    class Plot(sqlalchemy.orm.decl_api.Base)
     |  Plot(**kwargs)
     |
     |  Representa un lote de cultivo en una finca.
     |
     |  Atributos:
     |  ----------
     |  plot_id : int
     |      Identificador único del lote.
     |  name : str
     |      Nombre del lote.
     |  longitude : str
     |      Longitud del lote.
     |  latitude : str
     |      Latitud del lote.
     |  altitude : str
     |      Altitud del lote.
     |  coffee_variety_id : int
     |      Relación con la variedad de café plantada en el lote.
     |  farm_id : int
     |      Relación con la finca a la que pertenece el lote.
     |  status_id : int
     |      Relación con el estado del lote.
     |
     |  Method resolution order:
     |      Plot
     |      sqlalchemy.orm.decl_api.Base
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, **kwargs) from sqlalchemy.orm.instrumentation
     |      A simple constructor that allows initialization from kwargs.
     |
     |      Sets attributes on the constructed instance using the names and
     |      values in ``kwargs``.
     |
     |      Only keys that are present as
     |      attributes of the instance's class are allowed. These could be,
     |      for example, any mapped columns or relationships.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  altitude
     |
     |  coffee_variety
     |
     |  coffee_variety_id
     |
     |  farm
     |
     |  farm_id
     |
     |  latitude
     |
     |  longitude
     |
     |  name
     |
     |  plot_id
     |
     |  status_id
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  __mapper__ = <Mapper at 0x21fb30861e0; Plot>
     |
     |  __table__ = Table('plot', MetaData(), Column('plot_id', Inte...('statu...
     |
     |  __tablename__ = 'plot'
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from sqlalchemy.orm.decl_api.Base:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from sqlalchemy.orm.decl_api.Base:
     |
     |  __abstract__ = True
     |
     |  metadata = MetaData()
     |
     |  registry = <sqlalchemy.orm.decl_api.registry object>

    class Role(sqlalchemy.orm.decl_api.Base)
     |  Role(**kwargs)
     |
     |  Representa un rol que un usuario puede tener.
     |
     |  Atributos:
     |  ----------
     |  role_id : int
     |      Identificador único del rol.
     |  name : str
     |      Nombre del rol (único).
     |
     |  Method resolution order:
     |      Role
     |      sqlalchemy.orm.decl_api.Base
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, **kwargs) from sqlalchemy.orm.instrumentation
     |      A simple constructor that allows initialization from kwargs.
     |
     |      Sets attributes on the constructed instance using the names and
     |      values in ``kwargs``.
     |
     |      Only keys that are present as
     |      attributes of the instance's class are allowed. These could be,
     |      for example, any mapped columns or relationships.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  name
     |
     |  permissions
     |
     |  role_id
     |
     |  user_roles_farms
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  __mapper__ = <Mapper at 0x21fb3015190; Role>
     |
     |  __table__ = Table('role', MetaData(), Column('role_id', Inte...=50), t...
     |
     |  __tablename__ = 'role'
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from sqlalchemy.orm.decl_api.Base:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from sqlalchemy.orm.decl_api.Base:
     |
     |  __abstract__ = True
     |
     |  metadata = MetaData()
     |
     |  registry = <sqlalchemy.orm.decl_api.registry object>

    class RolePermission(sqlalchemy.orm.decl_api.Base)
     |  RolePermission(**kwargs)
     |
     |  Representa la relación entre roles y permisos.
     |
     |  Atributos:
     |  ----------
     |  role_id : int
     |      Identificador del rol.
     |  permission_id : int
     |      Identificador del permiso.
     |
     |  Method resolution order:
     |      RolePermission
     |      sqlalchemy.orm.decl_api.Base
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, **kwargs) from sqlalchemy.orm.instrumentation
     |      A simple constructor that allows initialization from kwargs.
     |
     |      Sets attributes on the constructed instance using the names and
     |      values in ``kwargs``.
     |
     |      Only keys that are present as
     |      attributes of the instance's class are allowed. These could be,
     |      for example, any mapped columns or relationships.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  permission
     |
     |  permission_id
     |
     |  role
     |
     |  role_id
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  __mapper__ = <Mapper at 0x21fb3017ad0; RolePermission>
     |
     |  __table__ = Table('role_permission', MetaData(), Column('rol..., prima...
     |
     |  __tablename__ = 'role_permission'
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from sqlalchemy.orm.decl_api.Base:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from sqlalchemy.orm.decl_api.Base:
     |
     |  __abstract__ = True
     |
     |  metadata = MetaData()
     |
     |  registry = <sqlalchemy.orm.decl_api.registry object>

    class Status(sqlalchemy.orm.decl_api.Base)
     |  Status(**kwargs)
     |
     |  Representa un estado de un registro (ejemplo: activo, inactivo).
     |
     |  Atributos:
     |  ----------
     |  status_id : int
     |      Identificador único del estado.
     |  name : str
     |      Nombre del estado.
     |  description : str
     |      Descripción del estado.
     |  status_type_id : int
     |      Relación con el tipo de estado.
     |
     |  Method resolution order:
     |      Status
     |      sqlalchemy.orm.decl_api.Base
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, **kwargs) from sqlalchemy.orm.instrumentation
     |      A simple constructor that allows initialization from kwargs.
     |
     |      Sets attributes on the constructed instance using the names and
     |      values in ``kwargs``.
     |
     |      Only keys that are present as
     |      attributes of the instance's class are allowed. These could be,
     |      for example, any mapped columns or relationships.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  description
     |
     |  name
     |
     |  notifications
     |
     |  status_id
     |
     |  status_type
     |
     |  status_type_id
     |
     |  users
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  __mapper__ = <Mapper at 0x21fb3016510; Status>
     |
     |  __table__ = Table('status', MetaData(), Column('status_id', ...'), tab...
     |
     |  __tablename__ = 'status'
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from sqlalchemy.orm.decl_api.Base:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from sqlalchemy.orm.decl_api.Base:
     |
     |  __abstract__ = True
     |
     |  metadata = MetaData()
     |
     |  registry = <sqlalchemy.orm.decl_api.registry object>

    class StatusType(sqlalchemy.orm.decl_api.Base)
     |  StatusType(**kwargs)
     |
     |  Representa los tipos de estado de los registros.
     |
     |  Atributos:
     |  ----------
     |  status_type_id : int
     |      Identificador único del tipo de estado.
     |  name : str
     |      Nombre del tipo de estado.
     |
     |  Method resolution order:
     |      StatusType
     |      sqlalchemy.orm.decl_api.Base
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, **kwargs) from sqlalchemy.orm.instrumentation
     |      A simple constructor that allows initialization from kwargs.
     |
     |      Sets attributes on the constructed instance using the names and
     |      values in ``kwargs``.
     |
     |      Only keys that are present as
     |      attributes of the instance's class are allowed. These could be,
     |      for example, any mapped columns or relationships.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  name
     |
     |  status_type_id
     |
     |  statuses
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  __mapper__ = <Mapper at 0x21fb3015fd0; StatusType>
     |
     |  __table__ = Table('status_type', MetaData(), Column('status_...able=<s...
     |
     |  __tablename__ = 'status_type'
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from sqlalchemy.orm.decl_api.Base:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from sqlalchemy.orm.decl_api.Base:
     |
     |  __abstract__ = True
     |
     |  metadata = MetaData()
     |
     |  registry = <sqlalchemy.orm.decl_api.registry object>

    class UnitOfMeasure(sqlalchemy.orm.decl_api.Base)
     |  UnitOfMeasure(**kwargs)
     |
     |  Representa una unidad de medida (ejemplo: hectáreas, metros).
     |
     |  Atributos:
     |  ----------
     |  unit_of_measure_id : int
     |      Identificador único de la unidad de medida.
     |  name : str
     |      Nombre de la unidad de medida.
     |  abbreviation : str
     |      Abreviación de la unidad de medida.
     |  unit_of_measure_type_id : int
     |      Relación con el tipo de unidad de medida.
     |
     |  Method resolution order:
     |      UnitOfMeasure
     |      sqlalchemy.orm.decl_api.Base
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, **kwargs) from sqlalchemy.orm.instrumentation
     |      A simple constructor that allows initialization from kwargs.
     |
     |      Sets attributes on the constructed instance using the names and
     |      values in ``kwargs``.
     |
     |      Only keys that are present as
     |      attributes of the instance's class are allowed. These could be,
     |      for example, any mapped columns or relationships.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  abbreviation
     |
     |  name
     |
     |  unit_of_measure_id
     |
     |  unit_of_measure_type
     |
     |  unit_of_measure_type_id
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  __mapper__ = <Mapper at 0x21fb30158b0; UnitOfMeasure>
     |
     |  __table__ = Table('unit_of_measure', MetaData(), Column('uni...=<unit_...
     |
     |  __tablename__ = 'unit_of_measure'
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from sqlalchemy.orm.decl_api.Base:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from sqlalchemy.orm.decl_api.Base:
     |
     |  __abstract__ = True
     |
     |  metadata = MetaData()
     |
     |  registry = <sqlalchemy.orm.decl_api.registry object>

    class UnitOfMeasureType(sqlalchemy.orm.decl_api.Base)
     |  UnitOfMeasureType(**kwargs)
     |
     |  Tipo de unidad de medida (ejemplo: área, volumen).
     |
     |  Atributos:
     |  ----------
     |  unit_of_measure_type_id : int
     |      Identificador único del tipo de unidad.
     |  name : str
     |      Nombre del tipo de unidad.
     |
     |  Method resolution order:
     |      UnitOfMeasureType
     |      sqlalchemy.orm.decl_api.Base
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, **kwargs) from sqlalchemy.orm.instrumentation
     |      A simple constructor that allows initialization from kwargs.
     |
     |      Sets attributes on the constructed instance using the names and
     |      values in ``kwargs``.
     |
     |      Only keys that are present as
     |      attributes of the instance's class are allowed. These could be,
     |      for example, any mapped columns or relationships.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  name
     |
     |  unit_of_measure_type_id
     |
     |  units_of_measure
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  __mapper__ = <Mapper at 0x21fb3015580; UnitOfMeasureType>
     |
     |  __table__ = Table('unit_of_measure_type', MetaData(), Column...t_of_me...
     |
     |  __tablename__ = 'unit_of_measure_type'
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from sqlalchemy.orm.decl_api.Base:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from sqlalchemy.orm.decl_api.Base:
     |
     |  __abstract__ = True
     |
     |  metadata = MetaData()
     |
     |  registry = <sqlalchemy.orm.decl_api.registry object>

    class User(sqlalchemy.orm.decl_api.Base)
     |  User(**kwargs)
     |
     |  Representa un usuario en el sistema.
     |
     |  Atributos:
     |  ----------
     |  user_id : int
     |      Identificador único del usuario.
     |  name : str
     |      Nombre del usuario.
     |  email : str
     |      Correo electrónico del usuario.
     |  password_hash : str
     |      Hash de la contraseña del usuario.
     |  verification_token : str
     |      Token de verificación del usuario.
     |  session_token : str
     |      Token de sesión del usuario.
     |  fcm_token : str
     |      Token de Firebase Cloud Messaging del usuario.
     |  status_id : int
     |      Relación con el estado del usuario.
     |
     |  Method resolution order:
     |      User
     |      sqlalchemy.orm.decl_api.Base
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, **kwargs) from sqlalchemy.orm.instrumentation
     |      A simple constructor that allows initialization from kwargs.
     |
     |      Sets attributes on the constructed instance using the names and
     |      values in ``kwargs``.
     |
     |      Only keys that are present as
     |      attributes of the instance's class are allowed. These could be,
     |      for example, any mapped columns or relationships.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  email
     |
     |  fcm_token
     |
     |  name
     |
     |  notifications
     |
     |  password_hash
     |
     |  session_token
     |
     |  status
     |
     |  status_id
     |
     |  user_id
     |
     |  user_roles_farms
     |
     |  verification_token
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  __mapper__ = <Mapper at 0x21fb3016d50; User>
     |
     |  __table__ = Table('users', MetaData(), Column('user_id', Int...d'), ta...
     |
     |  __tablename__ = 'users'
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from sqlalchemy.orm.decl_api.Base:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from sqlalchemy.orm.decl_api.Base:
     |
     |  __abstract__ = True
     |
     |  metadata = MetaData()
     |
     |  registry = <sqlalchemy.orm.decl_api.registry object>

    class UserRoleFarm(sqlalchemy.orm.decl_api.Base)
     |  UserRoleFarm(**kwargs)
     |
     |  Relación entre usuarios, roles y fincas.
     |
     |  Atributos:
     |  ----------
     |  user_role_farm_id : int
     |      Identificador único de la relación.
     |  role_id : int
     |      Identificador del rol (relación con Role).
     |  user_id : int
     |      Identificador del usuario (relación con User).
     |  farm_id : int
     |      Identificador de la finca (relación con Farm).
     |  status_id : int
     |      Estado actual de la relación.
     |
     |  Method resolution order:
     |      UserRoleFarm
     |      sqlalchemy.orm.decl_api.Base
     |      builtins.object
     |
     |  Methods defined here:
     |
     |  __init__(self, **kwargs) from sqlalchemy.orm.instrumentation
     |      A simple constructor that allows initialization from kwargs.
     |
     |      Sets attributes on the constructed instance using the names and
     |      values in ``kwargs``.
     |
     |      Only keys that are present as
     |      attributes of the instance's class are allowed. These could be,
     |      for example, any mapped columns or relationships.
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors defined here:
     |
     |  farm
     |
     |  farm_id
     |
     |  role
     |
     |  role_id
     |
     |  status
     |
     |  status_id
     |
     |  user
     |
     |  user_id
     |
     |  user_role_farm_id
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes defined here:
     |
     |  __mapper__ = <Mapper at 0x21fb3014920; UserRoleFarm>
     |
     |  __table__ = Table('user_role_farm', MetaData(), Column('user...ult=Sca...
     |
     |  __tablename__ = 'user_role_farm'
     |
     |  ----------------------------------------------------------------------
     |  Data descriptors inherited from sqlalchemy.orm.decl_api.Base:
     |
     |  __dict__
     |      dictionary for instance variables
     |
     |  __weakref__
     |      list of weak references to the object
     |
     |  ----------------------------------------------------------------------
     |  Data and other attributes inherited from sqlalchemy.orm.decl_api.Base:
     |
     |  __abstract__ = True
     |
     |  metadata = MetaData()
     |
     |  registry = <sqlalchemy.orm.decl_api.registry object>

DATA
    __warningregistry__ = {'version': 0}

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\models\models.py



================================================================================
Help on module utils.email in utils:

NAME
    utils.email

FUNCTIONS
    send_email(email, token, email_type, farm_name=None, owner_name=None, suggested_role=None)
        Envía un correo electrónico basado en el tipo especificado.

        :param email: Dirección de correo electrónico del destinatario.
        :param token: Token a incluir en el cuerpo del correo electrónico.
        :param email_type: Tipo de correo a enviar ('verification', 'reset' o 'invitation').
        :param farm_name: Nombre de la finca (opcional, solo para invitación).
        :param owner_name: Nombre del dueño (opcional, solo para invitación).
        :param suggested_role: Rol sugerido para el invitado (opcional, solo para invitación).

DATA
    logger = <Logger utils.email (INFO)>

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\utils\email.py



================================================================================
Help on module utils.FCM in utils:

NAME
    utils.FCM

FUNCTIONS
    send_fcm_notification(fcm_token: str, title: str, body: str)
        Envía una notificación utilizando Firebase Cloud Messaging (FCM).

        Args:
            fcm_token (str): El token de registro FCM del dispositivo al que se enviará la notificación.
            title (str): El título de la notificación.
            body (str): El cuerpo del mensaje de la notificación.

        Raises:
            Exception: Si hay un error al enviar la notificación.

DATA
    cred = <firebase_admin.credentials.Certificate object>
    firebase_credentials = {'auth_provider_x509_cert_url': 'https://www.go...
    temp_json_file = <tempfile._TemporaryFileWrapper object>
    temp_json_file_name = r'C:\Users\sebas\AppData\Local\Temp\tmptp7rrsfk'

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\utils\fcm.py



================================================================================
Help on module utils.response in utils:

NAME
    utils.response

FUNCTIONS
    create_response(status: str, message: str, data: Optional[Any] = None, status_code: int = 200) -> starlette.responses.JSONResponse
        Crea una respuesta JSON estructurada para ser devuelta por la API.

        Args:
            status (str): Estado de la respuesta (ej. "success" o "error").
            message (str): Mensaje que describe el estado de la respuesta.
            data (Optional[Any], optional): Datos adicionales a incluir en la respuesta. Puede ser cualquier tipo. Por defecto es None.
            status_code (int, optional): Código de estado HTTP a devolver. Por defecto es 200.

        Returns:
            JSONResponse: Respuesta en formato JSON que incluye el estado, mensaje y datos.

    session_token_invalid_response() -> starlette.responses.JSONResponse
        Crea una respuesta JSON específica para cuando el token de sesión es inválido.

        Returns:
            JSONResponse: Respuesta en formato JSON que indica que las credenciales han expirado.

DATA
    Dict = typing.Dict
        A generic version of dict.

    Optional = typing.Optional
        Optional[X] is equivalent to Union[X, None].

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\utils\response.py



================================================================================
postgresql://coffeetech:Coffeetech.12@localhost:5432/CoffeeTech
Conexión exitosa a la base de datos
Help on module utils.security in utils:

NAME
    utils.security

FUNCTIONS
    generate_verification_token(length: int = 3) -> str
        Genera un token de verificación aleatorio.

        Args:
            length (int): La longitud del token. Por defecto es 3.

        Returns:
            str: Un token de verificación aleatorio compuesto por letras y dígitos.

    get_current_user(db: sqlalchemy.orm.session.Session = Depends(get_db_session), token: str = Depends(OAuth2PasswordBearer))
        Obtiene el usuario actual basado en el token de verificación.

        Args:
            db (Session, optional): Sesión de base de datos. Se obtiene automáticamente.
            token (str): El token de verificación recibido.

        Returns:
            User: El objeto usuario correspondiente al token.

        Raises:
            HTTPException: Si el token es inválido o el usuario no está verificado.

    hash_password(password: str) -> str
        Hashea una contraseña utilizando el esquema configurado en CryptContext.

        Args:
            password (str): La contraseña en texto plano a hashear.

        Returns:
            str: La contraseña hasheada.

    verify_password(plain_password: str, hashed_password: str) -> bool
        Verifica una contraseña en texto plano contra una contraseña hasheada.

        Args:
            plain_password (str): La contraseña en texto plano.
            hashed_password (str): La contraseña hasheada a comparar.

        Returns:
            bool: Verdadero si las contraseñas coinciden, falso en caso contrario.

    verify_session_token(session_token: str, db: sqlalchemy.orm.session.Session) -> models.models.User
        Verifica si un token de sesión es válido y devuelve el usuario correspondiente.

        Args:
            session_token (str): El token de sesión a verificar.
            db (Session): La sesión de base de datos.

        Returns:
            User: El objeto usuario correspondiente al token de sesión, o None si no se encuentra.

DATA
    oauth2_scheme = <fastapi.security.oauth2.OAuth2PasswordBearer object>
    pwd_context = <CryptContext>

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\utils\security.py



================================================================================
Help on module utils.status in utils:

NAME
    utils.status

FUNCTIONS
    get_status(db: sqlalchemy.orm.session.Session, status_name: str, status_type_name: str) -> models.models.Status
        Obtiene un objeto Status basado en el nombre y tipo de estado proporcionados.

        Args:
            db (Session): La sesión de base de datos activa.
            status_name (str): El nombre del estado que se desea buscar.
            status_type_name (str): El nombre del tipo de estado asociado.

        Returns:
            Status: El objeto Status correspondiente, o None si no se encuentra.

FILE
    c:\users\sebas\onedrive\escritorio\caffee\coffeetech_backend\utils\status.py



================================================================================
